/**
 * Copyright 2017-2021 LinkedIn Corporation. All rights reserved.
 * Licensed under the BSD-2 Clause license.
 * See LICENSE in the project root for license information.
 */
package com.linkedin.coral.hive.hive2rel.parsetree.parser;

import java.util.ArrayList;
import java.util.Collection;
import java.util.HashMap;
import java.util.List;
import java.util.Stack;

import org.antlr.runtime.BaseRecognizer;
import org.antlr.runtime.BitSet;
import org.antlr.runtime.DFA;
import org.antlr.runtime.EarlyExitException;
import org.antlr.runtime.FailedPredicateException;
import org.antlr.runtime.IntStream;
import org.antlr.runtime.MismatchedSetException;
import org.antlr.runtime.MismatchedTokenException;
import org.antlr.runtime.NoViableAltException;
import org.antlr.runtime.Parser;
import org.antlr.runtime.ParserRuleReturnScope;
import org.antlr.runtime.RecognitionException;
import org.antlr.runtime.RecognizerSharedState;
import org.antlr.runtime.RuleReturnScope;
import org.antlr.runtime.Token;
import org.antlr.runtime.TokenStream;
import org.antlr.runtime.tree.CommonTree;
import org.antlr.runtime.tree.CommonTreeAdaptor;
import org.antlr.runtime.tree.RewriteEarlyExitException;
import org.antlr.runtime.tree.RewriteRuleSubtreeStream;
import org.antlr.runtime.tree.RewriteRuleTokenStream;
import org.antlr.runtime.tree.TreeAdaptor;


//spotless:off
@SuppressWarnings({ "all", "warnings", "unchecked" })
public class HiveParser extends Parser {
  public static final String[] tokenNames =
      new String[] { "<invalid>", "<EOR>", "<DOWN>", "<UP>", "AMPERSAND", "BITWISEOR", "BITWISEXOR", "BigintLiteral", "ByteLengthLiteral", "COLON", "COMMA", "COMMENT", "CharSetLiteral", "CharSetName", "DIV", "DIVIDE", "DOLLAR", "DOT", "DecimalLiteral", "Digit", "EQUAL", "EQUAL_NS", "Exponent", "GREATERTHAN", "GREATERTHANOREQUALTO", "HexDigit", "Identifier", "KW_ADD", "KW_ADMIN", "KW_AFTER", "KW_ALL", "KW_ALTER", "KW_ANALYZE", "KW_AND", "KW_ARCHIVE", "KW_ARRAY", "KW_AS", "KW_ASC", "KW_AUTHORIZATION", "KW_BEFORE", "KW_BETWEEN", "KW_BIGINT", "KW_BINARY", "KW_BOOLEAN", "KW_BOTH", "KW_BUCKET", "KW_BUCKETS", "KW_BY", "KW_CASCADE", "KW_CASE", "KW_CAST", "KW_CHANGE", "KW_CHAR", "KW_CLUSTER", "KW_CLUSTERED", "KW_CLUSTERSTATUS", "KW_COLLECTION", "KW_COLUMN", "KW_COLUMNS", "KW_COMMENT", "KW_COMPACT", "KW_COMPACTIONS", "KW_COMPUTE", "KW_CONCATENATE", "KW_CONF", "KW_CONTINUE", "KW_CREATE", "KW_CROSS", "KW_CUBE", "KW_CURRENT", "KW_CURRENT_DATE", "KW_CURRENT_TIMESTAMP", "KW_CURSOR", "KW_DATA", "KW_DATABASE", "KW_DATABASES", "KW_DATE", "KW_DATETIME", "KW_DBPROPERTIES", "KW_DECIMAL", "KW_DEFAULT", "KW_DEFERRED", "KW_DEFINED", "KW_DELETE", "KW_DELIMITED", "KW_DEPENDENCY", "KW_DESC", "KW_DESCRIBE", "KW_DIRECTORIES", "KW_DIRECTORY", "KW_DISABLE", "KW_DISTINCT", "KW_DISTRIBUTE", "KW_DOUBLE", "KW_DROP", "KW_ELEM_TYPE", "KW_ELSE", "KW_ENABLE", "KW_END", "KW_ESCAPED", "KW_EXCHANGE", "KW_EXCLUSIVE", "KW_EXISTS", "KW_EXPLAIN", "KW_EXPORT", "KW_EXTENDED", "KW_EXTERNAL", "KW_FALSE", "KW_FETCH", "KW_FIELDS", "KW_FILE", "KW_FILEFORMAT", "KW_FIRST", "KW_FLOAT", "KW_FOLLOWING", "KW_FOR", "KW_FORMAT", "KW_FORMATTED", "KW_FROM", "KW_FULL", "KW_FUNCTION", "KW_FUNCTIONS", "KW_GRANT", "KW_GROUP", "KW_GROUPING", "KW_HAVING", "KW_HOLD_DDLTIME", "KW_IDXPROPERTIES", "KW_IF", "KW_IGNORE", "KW_IMPORT", "KW_IN", "KW_INDEX", "KW_INDEXES", "KW_INNER", "KW_INPATH", "KW_INPUTDRIVER", "KW_INPUTFORMAT", "KW_INSERT", "KW_INT", "KW_INTERSECT", "KW_INTO", "KW_IS", "KW_ITEMS", "KW_JAR", "KW_JOIN", "KW_KEYS", "KW_KEY_TYPE", "KW_LATERAL", "KW_LEFT", "KW_LESS", "KW_LIKE", "KW_LIMIT", "KW_LINES", "KW_LOAD", "KW_LOCAL", "KW_LOCATION", "KW_LOCK", "KW_LOCKS", "KW_LOGICAL", "KW_LONG", "KW_MACRO", "KW_MAP", "KW_MAPJOIN", "KW_MATERIALIZED", "KW_METADATA", "KW_MINUS", "KW_MORE", "KW_MSCK", "KW_NONE", "KW_NOSCAN", "KW_NOT", "KW_NO_DROP", "KW_NULL", "KW_OF", "KW_OFFLINE", "KW_ON", "KW_OPTION", "KW_OR", "KW_ORDER", "KW_OUT", "KW_OUTER", "KW_OUTPUTDRIVER", "KW_OUTPUTFORMAT", "KW_OVER", "KW_OVERWRITE", "KW_OWNER", "KW_PARTIALSCAN", "KW_PARTITION", "KW_PARTITIONED", "KW_PARTITIONS", "KW_PERCENT", "KW_PLUS", "KW_PRECEDING", "KW_PRESERVE", "KW_PRETTY", "KW_PRINCIPALS", "KW_PROCEDURE", "KW_PROTECTION", "KW_PURGE", "KW_RANGE", "KW_READ", "KW_READONLY", "KW_READS", "KW_REBUILD", "KW_RECORDREADER", "KW_RECORDWRITER", "KW_REDUCE", "KW_REGEXP", "KW_RELOAD", "KW_RENAME", "KW_REPAIR", "KW_REPLACE", "KW_REPLICATION", "KW_RESTRICT", "KW_REVOKE", "KW_REWRITE", "KW_RIGHT", "KW_RLIKE", "KW_ROLE", "KW_ROLES", "KW_ROLLUP", "KW_ROW", "KW_ROWS", "KW_SCHEMA", "KW_SCHEMAS", "KW_SELECT", "KW_SEMI", "KW_SERDE", "KW_SERDEPROPERTIES", "KW_SERVER", "KW_SET", "KW_SETS", "KW_SHARED", "KW_SHOW", "KW_SHOW_DATABASE", "KW_SKEWED", "KW_SMALLINT", "KW_SORT", "KW_SORTED", "KW_SSL", "KW_STATISTICS", "KW_STORED", "KW_STREAMTABLE", "KW_STRING", "KW_STRUCT", "KW_TABLE", "KW_TABLES", "KW_TABLESAMPLE", "KW_TBLPROPERTIES", "KW_TEMPORARY", "KW_TERMINATED", "KW_THEN", "KW_TIMESTAMP", "KW_TINYINT", "KW_TO", "KW_TOUCH", "KW_TRANSACTIONS", "KW_TRANSFORM", "KW_TRIGGER", "KW_TRUE", "KW_TRUNCATE", "KW_UNARCHIVE", "KW_UNBOUNDED", "KW_UNDO", "KW_UNION", "KW_UNIONTYPE", "KW_UNIQUEJOIN", "KW_UNLOCK", "KW_UNSET", "KW_UNSIGNED", "KW_UPDATE", "KW_URI", "KW_USE", "KW_USER", "KW_USING", "KW_UTC", "KW_UTCTIMESTAMP", "KW_VALUES", "KW_VALUE_TYPE", "KW_VARCHAR", "KW_VIEW", "KW_WHEN", "KW_WHERE", "KW_WHILE", "KW_WINDOW", "KW_WITH", "LCURLY", "LESSTHAN", "LESSTHANOREQUALTO", "LPAREN", "LSQUARE", "Letter", "MINUS", "MOD", "NOTEQUAL", "Number", "PLUS", "QUESTION", "QuotedIdentifier", "RCURLY", "RPAREN", "RSQUARE", "RegexComponent", "SEMICOLON", "STAR", "SmallintLiteral", "StringLiteral", "TILDE", "TinyintLiteral", "WS", "TOK_ADMIN_OPTION_FOR", "TOK_ALIASLIST", "TOK_ALLCOLREF", "TOK_ALTERDATABASE_OWNER", "TOK_ALTERDATABASE_PROPERTIES", "TOK_ALTERINDEX_PROPERTIES", "TOK_ALTERINDEX_REBUILD", "TOK_ALTERTABLE", "TOK_ALTERTABLE_ADDCOLS", "TOK_ALTERTABLE_ADDPARTS", "TOK_ALTERTABLE_ARCHIVE", "TOK_ALTERTABLE_BUCKETS", "TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION", "TOK_ALTERTABLE_CLUSTER_SORT", "TOK_ALTERTABLE_COMPACT", "TOK_ALTERTABLE_DROPPARTS", "TOK_ALTERTABLE_DROPPROPERTIES", "TOK_ALTERTABLE_EXCHANGEPARTITION", "TOK_ALTERTABLE_FILEFORMAT", "TOK_ALTERTABLE_MERGEFILES", "TOK_ALTERTABLE_PARTCOLTYPE", "TOK_ALTERTABLE_PROPERTIES", "TOK_ALTERTABLE_PROTECTMODE", "TOK_ALTERTABLE_RENAME", "TOK_ALTERTABLE_RENAMECOL", "TOK_ALTERTABLE_RENAMEPART", "TOK_ALTERTABLE_REPLACECOLS", "TOK_ALTERTABLE_SERDEPROPERTIES", "TOK_ALTERTABLE_SERIALIZER", "TOK_ALTERTABLE_SKEWED", "TOK_ALTERTABLE_SKEWED_LOCATION", "TOK_ALTERTABLE_TOUCH", "TOK_ALTERTABLE_UNARCHIVE", "TOK_ALTERTABLE_UPDATECOLSTATS", "TOK_ALTERVIEW", "TOK_ALTERVIEW_ADDPARTS", "TOK_ALTERVIEW_DROPPARTS", "TOK_ALTERVIEW_DROPPROPERTIES", "TOK_ALTERVIEW_PROPERTIES", "TOK_ALTERVIEW_RENAME", "TOK_ANALYZE", "TOK_ANONYMOUS", "TOK_ARCHIVE", "TOK_BIGINT", "TOK_BINARY", "TOK_BOOLEAN", "TOK_CASCADE", "TOK_CHAR", "TOK_CHARSETLITERAL", "TOK_CLUSTERBY", "TOK_COLTYPELIST", "TOK_COL_NAME", "TOK_CREATEDATABASE", "TOK_CREATEFUNCTION", "TOK_CREATEINDEX", "TOK_CREATEINDEX_INDEXTBLNAME", "TOK_CREATEMACRO", "TOK_CREATEROLE", "TOK_CREATETABLE", "TOK_CREATEVIEW", "TOK_CROSSJOIN", "TOK_CTE", "TOK_CUBE_GROUPBY", "TOK_DATABASECOMMENT", "TOK_DATABASEPROPERTIES", "TOK_DATE", "TOK_DATELITERAL", "TOK_DATETIME", "TOK_DBPROPLIST", "TOK_DB_TYPE", "TOK_DECIMAL", "TOK_DEFERRED_REBUILDINDEX", "TOK_DELETE_FROM", "TOK_DESCDATABASE", "TOK_DESCFUNCTION", "TOK_DESCTABLE", "TOK_DESTINATION", "TOK_DIR", "TOK_DISABLE", "TOK_DISTRIBUTEBY", "TOK_DOUBLE", "TOK_DROPDATABASE", "TOK_DROPFUNCTION", "TOK_DROPINDEX", "TOK_DROPMACRO", "TOK_DROPROLE", "TOK_DROPTABLE", "TOK_DROPVIEW", "TOK_ENABLE", "TOK_EXPLAIN", "TOK_EXPLAIN_SQ_REWRITE", "TOK_EXPLIST", "TOK_EXPORT", "TOK_FALSE", "TOK_FILE", "TOK_FILEFORMAT_GENERIC", "TOK_FLOAT", "TOK_FROM", "TOK_FULLOUTERJOIN", "TOK_FUNCTION", "TOK_FUNCTIONDI", "TOK_FUNCTIONSTAR", "TOK_GRANT", "TOK_GRANT_OPTION_FOR", "TOK_GRANT_ROLE", "TOK_GRANT_WITH_ADMIN_OPTION", "TOK_GRANT_WITH_OPTION", "TOK_GROUP", "TOK_GROUPBY", "TOK_GROUPING_SETS", "TOK_GROUPING_SETS_EXPRESSION", "TOK_HAVING", "TOK_HINT", "TOK_HINTARGLIST", "TOK_HINTLIST", "TOK_HOLD_DDLTIME", "TOK_IFEXISTS", "TOK_IFNOTEXISTS", "TOK_IGNOREPROTECTION", "TOK_IMPORT", "TOK_INDEXCOMMENT", "TOK_INDEXPROPERTIES", "TOK_INDEXPROPLIST", "TOK_INSERT", "TOK_INSERT_INTO", "TOK_INT", "TOK_ISNOTNULL", "TOK_ISNULL", "TOK_JAR", "TOK_JOIN", "TOK_LATERAL_VIEW", "TOK_LATERAL_VIEW_OUTER", "TOK_LEFTOUTERJOIN", "TOK_LEFTSEMIJOIN", "TOK_LENGTH", "TOK_LIKETABLE", "TOK_LIMIT", "TOK_LIST", "TOK_LOAD", "TOK_LOCATION", "TOK_LOCKDB", "TOK_LOCKTABLE", "TOK_MAP", "TOK_MAPJOIN", "TOK_METADATA", "TOK_MSCK", "TOK_NOT_CLUSTERED", "TOK_NOT_SORTED", "TOK_NO_DROP", "TOK_NULL", "TOK_OFFLINE", "TOK_OP_ADD", "TOK_OP_AND", "TOK_OP_BITAND", "TOK_OP_BITNOT", "TOK_OP_BITOR", "TOK_OP_BITXOR", "TOK_OP_DIV", "TOK_OP_EQ", "TOK_OP_GE", "TOK_OP_GT", "TOK_OP_LE", "TOK_OP_LIKE", "TOK_OP_LT", "TOK_OP_MOD", "TOK_OP_MUL", "TOK_OP_NE", "TOK_OP_NOT", "TOK_OP_OR", "TOK_OP_SUB", "TOK_ORDERBY", "TOK_ORREPLACE", "TOK_PARTITIONFILEFORMAT", "TOK_PARTITIONINGSPEC", "TOK_PARTITIONSERDEPROPERTIES", "TOK_PARTSPEC", "TOK_PARTVAL", "TOK_PERCENT", "TOK_PRINCIPAL_NAME", "TOK_PRIVILEGE", "TOK_PRIVILEGE_LIST", "TOK_PRIV_ALL", "TOK_PRIV_ALTER_DATA", "TOK_PRIV_ALTER_METADATA", "TOK_PRIV_CREATE", "TOK_PRIV_DELETE", "TOK_PRIV_DROP", "TOK_PRIV_INDEX", "TOK_PRIV_INSERT", "TOK_PRIV_LOCK", "TOK_PRIV_OBJECT", "TOK_PRIV_OBJECT_COL", "TOK_PRIV_SELECT", "TOK_PRIV_SHOW_DATABASE", "TOK_PTBLFUNCTION", "TOK_QUERY", "TOK_READONLY", "TOK_RECORDREADER", "TOK_RECORDWRITER", "TOK_RELOADFUNCTION", "TOK_REPLICATION", "TOK_RESOURCE_ALL", "TOK_RESOURCE_LIST", "TOK_RESOURCE_URI", "TOK_RESTRICT", "TOK_REVOKE", "TOK_REVOKE_ROLE", "TOK_RIGHTOUTERJOIN", "TOK_ROLE", "TOK_ROLLUP_GROUPBY", "TOK_ROWCOUNT", "TOK_SELECT", "TOK_SELECTDI", "TOK_SELEXPR", "TOK_SERDE", "TOK_SERDENAME", "TOK_SERDEPROPS", "TOK_SERVER_TYPE", "TOK_SET_COLUMNS_CLAUSE", "TOK_SHOWCOLUMNS", "TOK_SHOWCONF", "TOK_SHOWDATABASES", "TOK_SHOWDBLOCKS", "TOK_SHOWFUNCTIONS", "TOK_SHOWINDEXES", "TOK_SHOWLOCKS", "TOK_SHOWPARTITIONS", "TOK_SHOWTABLES", "TOK_SHOW_COMPACTIONS", "TOK_SHOW_CREATETABLE", "TOK_SHOW_GRANT", "TOK_SHOW_ROLES", "TOK_SHOW_ROLE_GRANT", "TOK_SHOW_ROLE_PRINCIPALS", "TOK_SHOW_SET_ROLE", "TOK_SHOW_TABLESTATUS", "TOK_SHOW_TBLPROPERTIES", "TOK_SHOW_TRANSACTIONS", "TOK_SKEWED_LOCATIONS", "TOK_SKEWED_LOCATION_LIST", "TOK_SKEWED_LOCATION_MAP", "TOK_SMALLINT", "TOK_SORTBY", "TOK_STORAGEHANDLER", "TOK_STOREDASDIRS", "TOK_STREAMTABLE", "TOK_STRING", "TOK_STRINGLITERALSEQUENCE", "TOK_STRUCT", "TOK_SUBQUERY", "TOK_SUBQUERY_EXPR", "TOK_SUBQUERY_OP", "TOK_SUBQUERY_OP_NOTEXISTS", "TOK_SUBQUERY_OP_NOTIN", "TOK_SWITCHDATABASE", "TOK_TAB", "TOK_TABALIAS", "TOK_TABCOL", "TOK_TABCOLLIST", "TOK_TABCOLNAME", "TOK_TABCOLVALUE", "TOK_TABCOLVALUES", "TOK_TABCOLVALUE_PAIR", "TOK_TABLEBUCKETSAMPLE", "TOK_TABLECOMMENT", "TOK_TABLEFILEFORMAT", "TOK_TABLEPARTCOLS", "TOK_TABLEPROPERTIES", "TOK_TABLEPROPERTY", "TOK_TABLEPROPLIST", "TOK_TABLEROWFORMAT", "TOK_TABLEROWFORMATCOLLITEMS", "TOK_TABLEROWFORMATFIELD", "TOK_TABLEROWFORMATLINES", "TOK_TABLEROWFORMATMAPKEYS", "TOK_TABLEROWFORMATNULL", "TOK_TABLESERIALIZER", "TOK_TABLESKEWED", "TOK_TABLESPLITSAMPLE", "TOK_TABLE_OR_COL", "TOK_TABLE_PARTITION", "TOK_TABLE_TYPE", "TOK_TABNAME", "TOK_TABREF", "TOK_TABSORTCOLNAMEASC", "TOK_TABSORTCOLNAMEDESC", "TOK_TABSRC", "TOK_TABTYPE", "TOK_TEMPORARY", "TOK_TIMESTAMP", "TOK_TIMESTAMPLITERAL", "TOK_TINYINT", "TOK_TMP_FILE", "TOK_TRANSFORM", "TOK_TRUE", "TOK_TRUNCATETABLE", "TOK_UNION", "TOK_UNIONTYPE", "TOK_UNIQUEJOIN", "TOK_UNLOCKDB", "TOK_UNLOCKTABLE", "TOK_UPDATE_TABLE", "TOK_URI_TYPE", "TOK_USER", "TOK_USERSCRIPTCOLNAMES", "TOK_USERSCRIPTCOLSCHEMA", "TOK_VALUES_TABLE", "TOK_VALUE_ROW", "TOK_VARCHAR", "TOK_VIEWPARTCOLS", "TOK_VIRTUAL_TABLE", "TOK_VIRTUAL_TABREF", "TOK_WHERE", "TOK_WINDOWDEF", "TOK_WINDOWRANGE", "TOK_WINDOWSPEC", "TOK_WINDOWVALUES", "909" };

  public static final int EOF = -1;
  public static final int AMPERSAND = 4;
  public static final int BITWISEOR = 5;
  public static final int BITWISEXOR = 6;
  public static final int BigintLiteral = 7;
  public static final int ByteLengthLiteral = 8;
  public static final int COLON = 9;
  public static final int COMMA = 10;
  public static final int COMMENT = 11;
  public static final int CharSetLiteral = 12;
  public static final int CharSetName = 13;
  public static final int DIV = 14;
  public static final int DIVIDE = 15;
  public static final int DOLLAR = 16;
  public static final int DOT = 17;
  public static final int DecimalLiteral = 18;
  public static final int Digit = 19;
  public static final int EQUAL = 20;
  public static final int EQUAL_NS = 21;
  public static final int Exponent = 22;
  public static final int GREATERTHAN = 23;
  public static final int GREATERTHANOREQUALTO = 24;
  public static final int HexDigit = 25;
  public static final int Identifier = 26;
  public static final int KW_ADD = 27;
  public static final int KW_ADMIN = 28;
  public static final int KW_AFTER = 29;
  public static final int KW_ALL = 30;
  public static final int KW_ALTER = 31;
  public static final int KW_ANALYZE = 32;
  public static final int KW_AND = 33;
  public static final int KW_ARCHIVE = 34;
  public static final int KW_ARRAY = 35;
  public static final int KW_AS = 36;
  public static final int KW_ASC = 37;
  public static final int KW_AUTHORIZATION = 38;
  public static final int KW_BEFORE = 39;
  public static final int KW_BETWEEN = 40;
  public static final int KW_BIGINT = 41;
  public static final int KW_BINARY = 42;
  public static final int KW_BOOLEAN = 43;
  public static final int KW_BOTH = 44;
  public static final int KW_BUCKET = 45;
  public static final int KW_BUCKETS = 46;
  public static final int KW_BY = 47;
  public static final int KW_CASCADE = 48;
  public static final int KW_CASE = 49;
  public static final int KW_CAST = 50;
  public static final int KW_CHANGE = 51;
  public static final int KW_CHAR = 52;
  public static final int KW_CLUSTER = 53;
  public static final int KW_CLUSTERED = 54;
  public static final int KW_CLUSTERSTATUS = 55;
  public static final int KW_COLLECTION = 56;
  public static final int KW_COLUMN = 57;
  public static final int KW_COLUMNS = 58;
  public static final int KW_COMMENT = 59;
  public static final int KW_COMPACT = 60;
  public static final int KW_COMPACTIONS = 61;
  public static final int KW_COMPUTE = 62;
  public static final int KW_CONCATENATE = 63;
  public static final int KW_CONF = 64;
  public static final int KW_CONTINUE = 65;
  public static final int KW_CREATE = 66;
  public static final int KW_CROSS = 67;
  public static final int KW_CUBE = 68;
  public static final int KW_CURRENT = 69;
  public static final int KW_CURRENT_DATE = 70;
  public static final int KW_CURRENT_TIMESTAMP = 71;
  public static final int KW_CURSOR = 72;
  public static final int KW_DATA = 73;
  public static final int KW_DATABASE = 74;
  public static final int KW_DATABASES = 75;
  public static final int KW_DATE = 76;
  public static final int KW_DATETIME = 77;
  public static final int KW_DBPROPERTIES = 78;
  public static final int KW_DECIMAL = 79;
  public static final int KW_DEFAULT = 80;
  public static final int KW_DEFERRED = 81;
  public static final int KW_DEFINED = 82;
  public static final int KW_DELETE = 83;
  public static final int KW_DELIMITED = 84;
  public static final int KW_DEPENDENCY = 85;
  public static final int KW_DESC = 86;
  public static final int KW_DESCRIBE = 87;
  public static final int KW_DIRECTORIES = 88;
  public static final int KW_DIRECTORY = 89;
  public static final int KW_DISABLE = 90;
  public static final int KW_DISTINCT = 91;
  public static final int KW_DISTRIBUTE = 92;
  public static final int KW_DOUBLE = 93;
  public static final int KW_DROP = 94;
  public static final int KW_ELEM_TYPE = 95;
  public static final int KW_ELSE = 96;
  public static final int KW_ENABLE = 97;
  public static final int KW_END = 98;
  public static final int KW_ESCAPED = 99;
  public static final int KW_EXCHANGE = 100;
  public static final int KW_EXCLUSIVE = 101;
  public static final int KW_EXISTS = 102;
  public static final int KW_EXPLAIN = 103;
  public static final int KW_EXPORT = 104;
  public static final int KW_EXTENDED = 105;
  public static final int KW_EXTERNAL = 106;
  public static final int KW_FALSE = 107;
  public static final int KW_FETCH = 108;
  public static final int KW_FIELDS = 109;
  public static final int KW_FILE = 110;
  public static final int KW_FILEFORMAT = 111;
  public static final int KW_FIRST = 112;
  public static final int KW_FLOAT = 113;
  public static final int KW_FOLLOWING = 114;
  public static final int KW_FOR = 115;
  public static final int KW_FORMAT = 116;
  public static final int KW_FORMATTED = 117;
  public static final int KW_FROM = 118;
  public static final int KW_FULL = 119;
  public static final int KW_FUNCTION = 120;
  public static final int KW_FUNCTIONS = 121;
  public static final int KW_GRANT = 122;
  public static final int KW_GROUP = 123;
  public static final int KW_GROUPING = 124;
  public static final int KW_HAVING = 125;
  public static final int KW_HOLD_DDLTIME = 126;
  public static final int KW_IDXPROPERTIES = 127;
  public static final int KW_IF = 128;
  public static final int KW_IGNORE = 129;
  public static final int KW_IMPORT = 130;
  public static final int KW_IN = 131;
  public static final int KW_INDEX = 132;
  public static final int KW_INDEXES = 133;
  public static final int KW_INNER = 134;
  public static final int KW_INPATH = 135;
  public static final int KW_INPUTDRIVER = 136;
  public static final int KW_INPUTFORMAT = 137;
  public static final int KW_INSERT = 138;
  public static final int KW_INT = 139;
  public static final int KW_INTERSECT = 140;
  public static final int KW_INTO = 141;
  public static final int KW_IS = 142;
  public static final int KW_ITEMS = 143;
  public static final int KW_JAR = 144;
  public static final int KW_JOIN = 145;
  public static final int KW_KEYS = 146;
  public static final int KW_KEY_TYPE = 147;
  public static final int KW_LATERAL = 148;
  public static final int KW_LEFT = 149;
  public static final int KW_LESS = 150;
  public static final int KW_LIKE = 151;
  public static final int KW_LIMIT = 152;
  public static final int KW_LINES = 153;
  public static final int KW_LOAD = 154;
  public static final int KW_LOCAL = 155;
  public static final int KW_LOCATION = 156;
  public static final int KW_LOCK = 157;
  public static final int KW_LOCKS = 158;
  public static final int KW_LOGICAL = 159;
  public static final int KW_LONG = 160;
  public static final int KW_MACRO = 161;
  public static final int KW_MAP = 162;
  public static final int KW_MAPJOIN = 163;
  public static final int KW_MATERIALIZED = 164;
  public static final int KW_METADATA = 165;
  public static final int KW_MINUS = 166;
  public static final int KW_MORE = 167;
  public static final int KW_MSCK = 168;
  public static final int KW_NONE = 169;
  public static final int KW_NOSCAN = 170;
  public static final int KW_NOT = 171;
  public static final int KW_NO_DROP = 172;
  public static final int KW_NULL = 173;
  public static final int KW_OF = 174;
  public static final int KW_OFFLINE = 175;
  public static final int KW_ON = 176;
  public static final int KW_OPTION = 177;
  public static final int KW_OR = 178;
  public static final int KW_ORDER = 179;
  public static final int KW_OUT = 180;
  public static final int KW_OUTER = 181;
  public static final int KW_OUTPUTDRIVER = 182;
  public static final int KW_OUTPUTFORMAT = 183;
  public static final int KW_OVER = 184;
  public static final int KW_OVERWRITE = 185;
  public static final int KW_OWNER = 186;
  public static final int KW_PARTIALSCAN = 187;
  public static final int KW_PARTITION = 188;
  public static final int KW_PARTITIONED = 189;
  public static final int KW_PARTITIONS = 190;
  public static final int KW_PERCENT = 191;
  public static final int KW_PLUS = 192;
  public static final int KW_PRECEDING = 193;
  public static final int KW_PRESERVE = 194;
  public static final int KW_PRETTY = 195;
  public static final int KW_PRINCIPALS = 196;
  public static final int KW_PROCEDURE = 197;
  public static final int KW_PROTECTION = 198;
  public static final int KW_PURGE = 199;
  public static final int KW_RANGE = 200;
  public static final int KW_READ = 201;
  public static final int KW_READONLY = 202;
  public static final int KW_READS = 203;
  public static final int KW_REBUILD = 204;
  public static final int KW_RECORDREADER = 205;
  public static final int KW_RECORDWRITER = 206;
  public static final int KW_REDUCE = 207;
  public static final int KW_REGEXP = 208;
  public static final int KW_RELOAD = 209;
  public static final int KW_RENAME = 210;
  public static final int KW_REPAIR = 211;
  public static final int KW_REPLACE = 212;
  public static final int KW_REPLICATION = 213;
  public static final int KW_RESTRICT = 214;
  public static final int KW_REVOKE = 215;
  public static final int KW_REWRITE = 216;
  public static final int KW_RIGHT = 217;
  public static final int KW_RLIKE = 218;
  public static final int KW_ROLE = 219;
  public static final int KW_ROLES = 220;
  public static final int KW_ROLLUP = 221;
  public static final int KW_ROW = 222;
  public static final int KW_ROWS = 223;
  public static final int KW_SCHEMA = 224;
  public static final int KW_SCHEMAS = 225;
  public static final int KW_SELECT = 226;
  public static final int KW_SEMI = 227;
  public static final int KW_SERDE = 228;
  public static final int KW_SERDEPROPERTIES = 229;
  public static final int KW_SERVER = 230;
  public static final int KW_SET = 231;
  public static final int KW_SETS = 232;
  public static final int KW_SHARED = 233;
  public static final int KW_SHOW = 234;
  public static final int KW_SHOW_DATABASE = 235;
  public static final int KW_SKEWED = 236;
  public static final int KW_SMALLINT = 237;
  public static final int KW_SORT = 238;
  public static final int KW_SORTED = 239;
  public static final int KW_SSL = 240;
  public static final int KW_STATISTICS = 241;
  public static final int KW_STORED = 242;
  public static final int KW_STREAMTABLE = 243;
  public static final int KW_STRING = 244;
  public static final int KW_STRUCT = 245;
  public static final int KW_TABLE = 246;
  public static final int KW_TABLES = 247;
  public static final int KW_TABLESAMPLE = 248;
  public static final int KW_TBLPROPERTIES = 249;
  public static final int KW_TEMPORARY = 250;
  public static final int KW_TERMINATED = 251;
  public static final int KW_THEN = 252;
  public static final int KW_TIMESTAMP = 253;
  public static final int KW_TINYINT = 254;
  public static final int KW_TO = 255;
  public static final int KW_TOUCH = 256;
  public static final int KW_TRANSACTIONS = 257;
  public static final int KW_TRANSFORM = 258;
  public static final int KW_TRIGGER = 259;
  public static final int KW_TRUE = 260;
  public static final int KW_TRUNCATE = 261;
  public static final int KW_UNARCHIVE = 262;
  public static final int KW_UNBOUNDED = 263;
  public static final int KW_UNDO = 264;
  public static final int KW_UNION = 265;
  public static final int KW_UNIONTYPE = 266;
  public static final int KW_UNIQUEJOIN = 267;
  public static final int KW_UNLOCK = 268;
  public static final int KW_UNSET = 269;
  public static final int KW_UNSIGNED = 270;
  public static final int KW_UPDATE = 271;
  public static final int KW_URI = 272;
  public static final int KW_USE = 273;
  public static final int KW_USER = 274;
  public static final int KW_USING = 275;
  public static final int KW_UTC = 276;
  public static final int KW_UTCTIMESTAMP = 277;
  public static final int KW_VALUES = 278;
  public static final int KW_VALUE_TYPE = 279;
  public static final int KW_VARCHAR = 280;
  public static final int KW_VIEW = 281;
  public static final int KW_WHEN = 282;
  public static final int KW_WHERE = 283;
  public static final int KW_WHILE = 284;
  public static final int KW_WINDOW = 285;
  public static final int KW_WITH = 286;
  public static final int LCURLY = 287;
  public static final int LESSTHAN = 288;
  public static final int LESSTHANOREQUALTO = 289;
  public static final int LPAREN = 290;
  public static final int LSQUARE = 291;
  public static final int Letter = 292;
  public static final int MINUS = 293;
  public static final int MOD = 294;
  public static final int NOTEQUAL = 295;
  public static final int Number = 296;
  public static final int PLUS = 297;
  public static final int QUESTION = 298;
  public static final int QuotedIdentifier = 299;
  public static final int RCURLY = 300;
  public static final int RPAREN = 301;
  public static final int RSQUARE = 302;
  public static final int RegexComponent = 303;
  public static final int SEMICOLON = 304;
  public static final int STAR = 305;
  public static final int SmallintLiteral = 306;
  public static final int StringLiteral = 307;
  public static final int TILDE = 308;
  public static final int TinyintLiteral = 309;
  public static final int WS = 310;
  public static final int TOK_ADMIN_OPTION_FOR = 592;
  public static final int TOK_ALIASLIST = 593;
  public static final int TOK_ALLCOLREF = 594;
  public static final int TOK_ALTERDATABASE_OWNER = 595;
  public static final int TOK_ALTERDATABASE_PROPERTIES = 596;
  public static final int TOK_ALTERINDEX_PROPERTIES = 597;
  public static final int TOK_ALTERINDEX_REBUILD = 598;
  public static final int TOK_ALTERTABLE = 599;
  public static final int TOK_ALTERTABLE_ADDCOLS = 600;
  public static final int TOK_ALTERTABLE_ADDPARTS = 601;
  public static final int TOK_ALTERTABLE_ARCHIVE = 602;
  public static final int TOK_ALTERTABLE_BUCKETS = 603;
  public static final int TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION = 604;
  public static final int TOK_ALTERTABLE_CLUSTER_SORT = 605;
  public static final int TOK_ALTERTABLE_COMPACT = 606;
  public static final int TOK_ALTERTABLE_DROPPARTS = 607;
  public static final int TOK_ALTERTABLE_DROPPROPERTIES = 608;
  public static final int TOK_ALTERTABLE_EXCHANGEPARTITION = 609;
  public static final int TOK_ALTERTABLE_FILEFORMAT = 610;
  public static final int TOK_ALTERTABLE_MERGEFILES = 611;
  public static final int TOK_ALTERTABLE_PARTCOLTYPE = 612;
  public static final int TOK_ALTERTABLE_PROPERTIES = 613;
  public static final int TOK_ALTERTABLE_PROTECTMODE = 614;
  public static final int TOK_ALTERTABLE_RENAME = 615;
  public static final int TOK_ALTERTABLE_RENAMECOL = 616;
  public static final int TOK_ALTERTABLE_RENAMEPART = 617;
  public static final int TOK_ALTERTABLE_REPLACECOLS = 618;
  public static final int TOK_ALTERTABLE_SERDEPROPERTIES = 619;
  public static final int TOK_ALTERTABLE_SERIALIZER = 620;
  public static final int TOK_ALTERTABLE_SKEWED = 621;
  public static final int TOK_ALTERTABLE_SKEWED_LOCATION = 622;
  public static final int TOK_ALTERTABLE_TOUCH = 623;
  public static final int TOK_ALTERTABLE_UNARCHIVE = 624;
  public static final int TOK_ALTERTABLE_UPDATECOLSTATS = 625;
  public static final int TOK_ALTERVIEW = 626;
  public static final int TOK_ALTERVIEW_ADDPARTS = 627;
  public static final int TOK_ALTERVIEW_DROPPARTS = 628;
  public static final int TOK_ALTERVIEW_DROPPROPERTIES = 629;
  public static final int TOK_ALTERVIEW_PROPERTIES = 630;
  public static final int TOK_ALTERVIEW_RENAME = 631;
  public static final int TOK_ANALYZE = 632;
  public static final int TOK_ANONYMOUS = 633;
  public static final int TOK_ARCHIVE = 634;
  public static final int TOK_BIGINT = 635;
  public static final int TOK_BINARY = 636;
  public static final int TOK_BOOLEAN = 637;
  public static final int TOK_CASCADE = 638;
  public static final int TOK_CHAR = 639;
  public static final int TOK_CHARSETLITERAL = 640;
  public static final int TOK_CLUSTERBY = 641;
  public static final int TOK_COLTYPELIST = 642;
  public static final int TOK_COL_NAME = 643;
  public static final int TOK_CREATEDATABASE = 644;
  public static final int TOK_CREATEFUNCTION = 645;
  public static final int TOK_CREATEINDEX = 646;
  public static final int TOK_CREATEINDEX_INDEXTBLNAME = 647;
  public static final int TOK_CREATEMACRO = 648;
  public static final int TOK_CREATEROLE = 649;
  public static final int TOK_CREATETABLE = 650;
  public static final int TOK_CREATEVIEW = 651;
  public static final int TOK_CROSSJOIN = 652;
  public static final int TOK_CTE = 653;
  public static final int TOK_CUBE_GROUPBY = 654;
  public static final int TOK_DATABASECOMMENT = 655;
  public static final int TOK_DATABASEPROPERTIES = 656;
  public static final int TOK_DATE = 657;
  public static final int TOK_DATELITERAL = 658;
  public static final int TOK_DATETIME = 659;
  public static final int TOK_DBPROPLIST = 660;
  public static final int TOK_DB_TYPE = 661;
  public static final int TOK_DECIMAL = 662;
  public static final int TOK_DEFERRED_REBUILDINDEX = 663;
  public static final int TOK_DELETE_FROM = 664;
  public static final int TOK_DESCDATABASE = 665;
  public static final int TOK_DESCFUNCTION = 666;
  public static final int TOK_DESCTABLE = 667;
  public static final int TOK_DESTINATION = 668;
  public static final int TOK_DIR = 669;
  public static final int TOK_DISABLE = 670;
  public static final int TOK_DISTRIBUTEBY = 671;
  public static final int TOK_DOUBLE = 672;
  public static final int TOK_DROPDATABASE = 673;
  public static final int TOK_DROPFUNCTION = 674;
  public static final int TOK_DROPINDEX = 675;
  public static final int TOK_DROPMACRO = 676;
  public static final int TOK_DROPROLE = 677;
  public static final int TOK_DROPTABLE = 678;
  public static final int TOK_DROPVIEW = 679;
  public static final int TOK_ENABLE = 680;
  public static final int TOK_EXPLAIN = 681;
  public static final int TOK_EXPLAIN_SQ_REWRITE = 682;
  public static final int TOK_EXPLIST = 683;
  public static final int TOK_EXPORT = 684;
  public static final int TOK_FALSE = 685;
  public static final int TOK_FILE = 686;
  public static final int TOK_FILEFORMAT_GENERIC = 687;
  public static final int TOK_FLOAT = 688;
  public static final int TOK_FROM = 689;
  public static final int TOK_FULLOUTERJOIN = 690;
  public static final int TOK_FUNCTION = 691;
  public static final int TOK_FUNCTIONDI = 692;
  public static final int TOK_FUNCTIONSTAR = 693;
  public static final int TOK_GRANT = 694;
  public static final int TOK_GRANT_OPTION_FOR = 695;
  public static final int TOK_GRANT_ROLE = 696;
  public static final int TOK_GRANT_WITH_ADMIN_OPTION = 697;
  public static final int TOK_GRANT_WITH_OPTION = 698;
  public static final int TOK_GROUP = 699;
  public static final int TOK_GROUPBY = 700;
  public static final int TOK_GROUPING_SETS = 701;
  public static final int TOK_GROUPING_SETS_EXPRESSION = 702;
  public static final int TOK_HAVING = 703;
  public static final int TOK_HINT = 704;
  public static final int TOK_HINTARGLIST = 705;
  public static final int TOK_HINTLIST = 706;
  public static final int TOK_HOLD_DDLTIME = 707;
  public static final int TOK_IFEXISTS = 708;
  public static final int TOK_IFNOTEXISTS = 709;
  public static final int TOK_IGNOREPROTECTION = 710;
  public static final int TOK_IMPORT = 711;
  public static final int TOK_INDEXCOMMENT = 712;
  public static final int TOK_INDEXPROPERTIES = 713;
  public static final int TOK_INDEXPROPLIST = 714;
  public static final int TOK_INSERT = 715;
  public static final int TOK_INSERT_INTO = 716;
  public static final int TOK_INT = 717;
  public static final int TOK_ISNOTNULL = 718;
  public static final int TOK_ISNULL = 719;
  public static final int TOK_JAR = 720;
  public static final int TOK_JOIN = 721;
  public static final int TOK_LATERAL_VIEW = 722;
  public static final int TOK_LATERAL_VIEW_OUTER = 723;
  public static final int TOK_LEFTOUTERJOIN = 724;
  public static final int TOK_LEFTSEMIJOIN = 725;
  public static final int TOK_LENGTH = 726;
  public static final int TOK_LIKETABLE = 727;
  public static final int TOK_LIMIT = 728;
  public static final int TOK_LIST = 729;
  public static final int TOK_LOAD = 730;
  public static final int TOK_LOCATION = 731;
  public static final int TOK_LOCKDB = 732;
  public static final int TOK_LOCKTABLE = 733;
  public static final int TOK_MAP = 734;
  public static final int TOK_MAPJOIN = 735;
  public static final int TOK_METADATA = 736;
  public static final int TOK_MSCK = 737;
  public static final int TOK_NOT_CLUSTERED = 738;
  public static final int TOK_NOT_SORTED = 739;
  public static final int TOK_NO_DROP = 740;
  public static final int TOK_NULL = 741;
  public static final int TOK_OFFLINE = 742;
  public static final int TOK_OP_ADD = 743;
  public static final int TOK_OP_AND = 744;
  public static final int TOK_OP_BITAND = 745;
  public static final int TOK_OP_BITNOT = 746;
  public static final int TOK_OP_BITOR = 747;
  public static final int TOK_OP_BITXOR = 748;
  public static final int TOK_OP_DIV = 749;
  public static final int TOK_OP_EQ = 750;
  public static final int TOK_OP_GE = 751;
  public static final int TOK_OP_GT = 752;
  public static final int TOK_OP_LE = 753;
  public static final int TOK_OP_LIKE = 754;
  public static final int TOK_OP_LT = 755;
  public static final int TOK_OP_MOD = 756;
  public static final int TOK_OP_MUL = 757;
  public static final int TOK_OP_NE = 758;
  public static final int TOK_OP_NOT = 759;
  public static final int TOK_OP_OR = 760;
  public static final int TOK_OP_SUB = 761;
  public static final int TOK_ORDERBY = 762;
  public static final int TOK_ORREPLACE = 763;
  public static final int TOK_PARTITIONFILEFORMAT = 764;
  public static final int TOK_PARTITIONINGSPEC = 765;
  public static final int TOK_PARTITIONSERDEPROPERTIES = 766;
  public static final int TOK_PARTSPEC = 767;
  public static final int TOK_PARTVAL = 768;
  public static final int TOK_PERCENT = 769;
  public static final int TOK_PRINCIPAL_NAME = 770;
  public static final int TOK_PRIVILEGE = 771;
  public static final int TOK_PRIVILEGE_LIST = 772;
  public static final int TOK_PRIV_ALL = 773;
  public static final int TOK_PRIV_ALTER_DATA = 774;
  public static final int TOK_PRIV_ALTER_METADATA = 775;
  public static final int TOK_PRIV_CREATE = 776;
  public static final int TOK_PRIV_DELETE = 777;
  public static final int TOK_PRIV_DROP = 778;
  public static final int TOK_PRIV_INDEX = 779;
  public static final int TOK_PRIV_INSERT = 780;
  public static final int TOK_PRIV_LOCK = 781;
  public static final int TOK_PRIV_OBJECT = 782;
  public static final int TOK_PRIV_OBJECT_COL = 783;
  public static final int TOK_PRIV_SELECT = 784;
  public static final int TOK_PRIV_SHOW_DATABASE = 785;
  public static final int TOK_PTBLFUNCTION = 786;
  public static final int TOK_QUERY = 787;
  public static final int TOK_READONLY = 788;
  public static final int TOK_RECORDREADER = 789;
  public static final int TOK_RECORDWRITER = 790;
  public static final int TOK_RELOADFUNCTION = 791;
  public static final int TOK_REPLICATION = 792;
  public static final int TOK_RESOURCE_ALL = 793;
  public static final int TOK_RESOURCE_LIST = 794;
  public static final int TOK_RESOURCE_URI = 795;
  public static final int TOK_RESTRICT = 796;
  public static final int TOK_REVOKE = 797;
  public static final int TOK_REVOKE_ROLE = 798;
  public static final int TOK_RIGHTOUTERJOIN = 799;
  public static final int TOK_ROLE = 800;
  public static final int TOK_ROLLUP_GROUPBY = 801;
  public static final int TOK_ROWCOUNT = 802;
  public static final int TOK_SELECT = 803;
  public static final int TOK_SELECTDI = 804;
  public static final int TOK_SELEXPR = 805;
  public static final int TOK_SERDE = 806;
  public static final int TOK_SERDENAME = 807;
  public static final int TOK_SERDEPROPS = 808;
  public static final int TOK_SERVER_TYPE = 809;
  public static final int TOK_SET_COLUMNS_CLAUSE = 810;
  public static final int TOK_SHOWCOLUMNS = 811;
  public static final int TOK_SHOWCONF = 812;
  public static final int TOK_SHOWDATABASES = 813;
  public static final int TOK_SHOWDBLOCKS = 814;
  public static final int TOK_SHOWFUNCTIONS = 815;
  public static final int TOK_SHOWINDEXES = 816;
  public static final int TOK_SHOWLOCKS = 817;
  public static final int TOK_SHOWPARTITIONS = 818;
  public static final int TOK_SHOWTABLES = 819;
  public static final int TOK_SHOW_COMPACTIONS = 820;
  public static final int TOK_SHOW_CREATETABLE = 821;
  public static final int TOK_SHOW_GRANT = 822;
  public static final int TOK_SHOW_ROLES = 823;
  public static final int TOK_SHOW_ROLE_GRANT = 824;
  public static final int TOK_SHOW_ROLE_PRINCIPALS = 825;
  public static final int TOK_SHOW_SET_ROLE = 826;
  public static final int TOK_SHOW_TABLESTATUS = 827;
  public static final int TOK_SHOW_TBLPROPERTIES = 828;
  public static final int TOK_SHOW_TRANSACTIONS = 829;
  public static final int TOK_SKEWED_LOCATIONS = 830;
  public static final int TOK_SKEWED_LOCATION_LIST = 831;
  public static final int TOK_SKEWED_LOCATION_MAP = 832;
  public static final int TOK_SMALLINT = 833;
  public static final int TOK_SORTBY = 834;
  public static final int TOK_STORAGEHANDLER = 835;
  public static final int TOK_STOREDASDIRS = 836;
  public static final int TOK_STREAMTABLE = 837;
  public static final int TOK_STRING = 838;
  public static final int TOK_STRINGLITERALSEQUENCE = 839;
  public static final int TOK_STRUCT = 840;
  public static final int TOK_SUBQUERY = 841;
  public static final int TOK_SUBQUERY_EXPR = 842;
  public static final int TOK_SUBQUERY_OP = 843;
  public static final int TOK_SUBQUERY_OP_NOTEXISTS = 844;
  public static final int TOK_SUBQUERY_OP_NOTIN = 845;
  public static final int TOK_SWITCHDATABASE = 846;
  public static final int TOK_TAB = 847;
  public static final int TOK_TABALIAS = 848;
  public static final int TOK_TABCOL = 849;
  public static final int TOK_TABCOLLIST = 850;
  public static final int TOK_TABCOLNAME = 851;
  public static final int TOK_TABCOLVALUE = 852;
  public static final int TOK_TABCOLVALUES = 853;
  public static final int TOK_TABCOLVALUE_PAIR = 854;
  public static final int TOK_TABLEBUCKETSAMPLE = 855;
  public static final int TOK_TABLECOMMENT = 856;
  public static final int TOK_TABLEFILEFORMAT = 857;
  public static final int TOK_TABLEPARTCOLS = 858;
  public static final int TOK_TABLEPROPERTIES = 859;
  public static final int TOK_TABLEPROPERTY = 860;
  public static final int TOK_TABLEPROPLIST = 861;
  public static final int TOK_TABLEROWFORMAT = 862;
  public static final int TOK_TABLEROWFORMATCOLLITEMS = 863;
  public static final int TOK_TABLEROWFORMATFIELD = 864;
  public static final int TOK_TABLEROWFORMATLINES = 865;
  public static final int TOK_TABLEROWFORMATMAPKEYS = 866;
  public static final int TOK_TABLEROWFORMATNULL = 867;
  public static final int TOK_TABLESERIALIZER = 868;
  public static final int TOK_TABLESKEWED = 869;
  public static final int TOK_TABLESPLITSAMPLE = 870;
  public static final int TOK_TABLE_OR_COL = 871;
  public static final int TOK_TABLE_PARTITION = 872;
  public static final int TOK_TABLE_TYPE = 873;
  public static final int TOK_TABNAME = 874;
  public static final int TOK_TABREF = 875;
  public static final int TOK_TABSORTCOLNAMEASC = 876;
  public static final int TOK_TABSORTCOLNAMEDESC = 877;
  public static final int TOK_TABSRC = 878;
  public static final int TOK_TABTYPE = 879;
  public static final int TOK_TEMPORARY = 880;
  public static final int TOK_TIMESTAMP = 881;
  public static final int TOK_TIMESTAMPLITERAL = 882;
  public static final int TOK_TINYINT = 883;
  public static final int TOK_TMP_FILE = 884;
  public static final int TOK_TRANSFORM = 885;
  public static final int TOK_TRUE = 886;
  public static final int TOK_TRUNCATETABLE = 887;
  public static final int TOK_UNION = 888;
  public static final int TOK_UNIONTYPE = 889;
  public static final int TOK_UNIQUEJOIN = 890;
  public static final int TOK_UNLOCKDB = 891;
  public static final int TOK_UNLOCKTABLE = 892;
  public static final int TOK_UPDATE_TABLE = 893;
  public static final int TOK_URI_TYPE = 894;
  public static final int TOK_USER = 895;
  public static final int TOK_USERSCRIPTCOLNAMES = 896;
  public static final int TOK_USERSCRIPTCOLSCHEMA = 897;
  public static final int TOK_VALUES_TABLE = 898;
  public static final int TOK_VALUE_ROW = 899;
  public static final int TOK_VARCHAR = 900;
  public static final int TOK_VIEWPARTCOLS = 901;
  public static final int TOK_VIRTUAL_TABLE = 902;
  public static final int TOK_VIRTUAL_TABREF = 903;
  public static final int TOK_WHERE = 904;
  public static final int TOK_WINDOWDEF = 905;
  public static final int TOK_WINDOWRANGE = 906;
  public static final int TOK_WINDOWSPEC = 907;
  public static final int TOK_WINDOWVALUES = 908;

  // delegates
  public HiveParser_SelectClauseParser gSelectClauseParser;
  public HiveParser_FromClauseParser gFromClauseParser;
  public HiveParser_IdentifiersParser gIdentifiersParser;

  public Parser[] getDelegates() {
    return new Parser[] { gSelectClauseParser, gFromClauseParser, gIdentifiersParser };
  }

  // delegators

  public HiveParser(TokenStream input) {
    this(input, new RecognizerSharedState());
  }

  public HiveParser(TokenStream input, RecognizerSharedState state) {
    super(input, state);
    gSelectClauseParser = new HiveParser_SelectClauseParser(input, state, this);
    gFromClauseParser = new HiveParser_FromClauseParser(input, state, this);
    gIdentifiersParser = new HiveParser_IdentifiersParser(input, state, this);
  }

  protected TreeAdaptor adaptor = new CommonTreeAdaptor();

  public void setTreeAdaptor(TreeAdaptor adaptor) {
    this.adaptor = adaptor;
    gSelectClauseParser.setTreeAdaptor(this.adaptor);
    gFromClauseParser.setTreeAdaptor(this.adaptor);
    gIdentifiersParser.setTreeAdaptor(this.adaptor);
  }

  public TreeAdaptor getTreeAdaptor() {
    return adaptor;
  }

  public String[] getTokenNames() {
    return HiveParser.tokenNames;
  }

  public String getGrammarFileName() {
    return "org/apache/hadoop/hive/ql/parse/HiveParser.g";
  }

  ArrayList<ParseError> errors = new ArrayList<ParseError>();
  Stack msgs = new Stack<String>();

  private static HashMap<String, String> xlateMap;

  static {
    xlateMap = new HashMap<String, String>();

    // Keywords
    xlateMap.put("KW_TRUE", "TRUE");
    xlateMap.put("KW_FALSE", "FALSE");
    xlateMap.put("KW_ALL", "ALL");
    xlateMap.put("KW_NONE", "NONE");
    xlateMap.put("KW_DEFAULT", "DEFAULT");
    xlateMap.put("KW_AND", "AND");
    xlateMap.put("KW_OR", "OR");
    xlateMap.put("KW_NOT", "NOT");
    xlateMap.put("KW_LIKE", "LIKE");

    xlateMap.put("KW_ASC", "ASC");
    xlateMap.put("KW_DESC", "DESC");
    xlateMap.put("KW_ORDER", "ORDER");
    xlateMap.put("KW_BY", "BY");
    xlateMap.put("KW_GROUP", "GROUP");
    xlateMap.put("KW_WHERE", "WHERE");
    xlateMap.put("KW_FROM", "FROM");
    xlateMap.put("KW_AS", "AS");
    xlateMap.put("KW_SELECT", "SELECT");
    xlateMap.put("KW_DISTINCT", "DISTINCT");
    xlateMap.put("KW_INSERT", "INSERT");
    xlateMap.put("KW_OVERWRITE", "OVERWRITE");
    xlateMap.put("KW_OUTER", "OUTER");
    xlateMap.put("KW_JOIN", "JOIN");
    xlateMap.put("KW_LEFT", "LEFT");
    xlateMap.put("KW_RIGHT", "RIGHT");
    xlateMap.put("KW_FULL", "FULL");
    xlateMap.put("KW_ON", "ON");
    xlateMap.put("KW_PARTITION", "PARTITION");
    xlateMap.put("KW_PARTITIONS", "PARTITIONS");
    xlateMap.put("KW_TABLE", "TABLE");
    xlateMap.put("KW_TABLES", "TABLES");
    xlateMap.put("KW_TBLPROPERTIES", "TBLPROPERTIES");
    xlateMap.put("KW_SHOW", "SHOW");
    xlateMap.put("KW_MSCK", "MSCK");
    xlateMap.put("KW_DIRECTORY", "DIRECTORY");
    xlateMap.put("KW_LOCAL", "LOCAL");
    xlateMap.put("KW_TRANSFORM", "TRANSFORM");
    xlateMap.put("KW_USING", "USING");
    xlateMap.put("KW_CLUSTER", "CLUSTER");
    xlateMap.put("KW_DISTRIBUTE", "DISTRIBUTE");
    xlateMap.put("KW_SORT", "SORT");
    xlateMap.put("KW_UNION", "UNION");
    xlateMap.put("KW_LOAD", "LOAD");
    xlateMap.put("KW_DATA", "DATA");
    xlateMap.put("KW_INPATH", "INPATH");
    xlateMap.put("KW_IS", "IS");
    xlateMap.put("KW_NULL", "NULL");
    xlateMap.put("KW_CREATE", "CREATE");
    xlateMap.put("KW_EXTERNAL", "EXTERNAL");
    xlateMap.put("KW_ALTER", "ALTER");
    xlateMap.put("KW_DESCRIBE", "DESCRIBE");
    xlateMap.put("KW_DROP", "DROP");
    xlateMap.put("KW_RENAME", "RENAME");
    xlateMap.put("KW_TO", "TO");
    xlateMap.put("KW_COMMENT", "COMMENT");
    xlateMap.put("KW_BOOLEAN", "BOOLEAN");
    xlateMap.put("KW_TINYINT", "TINYINT");
    xlateMap.put("KW_SMALLINT", "SMALLINT");
    xlateMap.put("KW_INT", "INT");
    xlateMap.put("KW_BIGINT", "BIGINT");
    xlateMap.put("KW_FLOAT", "FLOAT");
    xlateMap.put("KW_DOUBLE", "DOUBLE");
    xlateMap.put("KW_DATE", "DATE");
    xlateMap.put("KW_DATETIME", "DATETIME");
    xlateMap.put("KW_TIMESTAMP", "TIMESTAMP");
    xlateMap.put("KW_STRING", "STRING");
    xlateMap.put("KW_BINARY", "BINARY");
    xlateMap.put("KW_ARRAY", "ARRAY");
    xlateMap.put("KW_MAP", "MAP");
    xlateMap.put("KW_REDUCE", "REDUCE");
    xlateMap.put("KW_PARTITIONED", "PARTITIONED");
    xlateMap.put("KW_CLUSTERED", "CLUSTERED");
    xlateMap.put("KW_SORTED", "SORTED");
    xlateMap.put("KW_INTO", "INTO");
    xlateMap.put("KW_BUCKETS", "BUCKETS");
    xlateMap.put("KW_ROW", "ROW");
    xlateMap.put("KW_FORMAT", "FORMAT");
    xlateMap.put("KW_DELIMITED", "DELIMITED");
    xlateMap.put("KW_FIELDS", "FIELDS");
    xlateMap.put("KW_TERMINATED", "TERMINATED");
    xlateMap.put("KW_COLLECTION", "COLLECTION");
    xlateMap.put("KW_ITEMS", "ITEMS");
    xlateMap.put("KW_KEYS", "KEYS");
    xlateMap.put("KW_KEY_TYPE", "$KEY$");
    xlateMap.put("KW_LINES", "LINES");
    xlateMap.put("KW_STORED", "STORED");
    xlateMap.put("KW_SEQUENCEFILE", "SEQUENCEFILE");
    xlateMap.put("KW_TEXTFILE", "TEXTFILE");
    xlateMap.put("KW_INPUTFORMAT", "INPUTFORMAT");
    xlateMap.put("KW_OUTPUTFORMAT", "OUTPUTFORMAT");
    xlateMap.put("KW_LOCATION", "LOCATION");
    xlateMap.put("KW_TABLESAMPLE", "TABLESAMPLE");
    xlateMap.put("KW_BUCKET", "BUCKET");
    xlateMap.put("KW_OUT", "OUT");
    xlateMap.put("KW_OF", "OF");
    xlateMap.put("KW_CAST", "CAST");
    xlateMap.put("KW_ADD", "ADD");
    xlateMap.put("KW_REPLACE", "REPLACE");
    xlateMap.put("KW_COLUMNS", "COLUMNS");
    xlateMap.put("KW_RLIKE", "RLIKE");
    xlateMap.put("KW_REGEXP", "REGEXP");
    xlateMap.put("KW_TEMPORARY", "TEMPORARY");
    xlateMap.put("KW_FUNCTION", "FUNCTION");
    xlateMap.put("KW_EXPLAIN", "EXPLAIN");
    xlateMap.put("KW_EXTENDED", "EXTENDED");
    xlateMap.put("KW_SERDE", "SERDE");
    xlateMap.put("KW_WITH", "WITH");
    xlateMap.put("KW_SERDEPROPERTIES", "SERDEPROPERTIES");
    xlateMap.put("KW_LIMIT", "LIMIT");
    xlateMap.put("KW_SET", "SET");
    xlateMap.put("KW_PROPERTIES", "TBLPROPERTIES");
    xlateMap.put("KW_VALUE_TYPE", "$VALUE$");
    xlateMap.put("KW_ELEM_TYPE", "$ELEM$");
    xlateMap.put("KW_DEFINED", "DEFINED");
    xlateMap.put("KW_SUBQUERY", "SUBQUERY");
    xlateMap.put("KW_REWRITE", "REWRITE");
    xlateMap.put("KW_UPDATE", "UPDATE");
    xlateMap.put("KW_VALUES", "VALUES");
    xlateMap.put("KW_PURGE", "PURGE");

    // Operators
    xlateMap.put("DOT", ".");
    xlateMap.put("COLON", ":");
    xlateMap.put("COMMA", ",");
    xlateMap.put("SEMICOLON", ");");

    xlateMap.put("LPAREN", "(");
    xlateMap.put("RPAREN", ")");
    xlateMap.put("LSQUARE", "[");
    xlateMap.put("RSQUARE", "]");

    xlateMap.put("EQUAL", "=");
    xlateMap.put("NOTEQUAL", "<>");
    xlateMap.put("EQUAL_NS", "<=>");
    xlateMap.put("LESSTHANOREQUALTO", "<=");
    xlateMap.put("LESSTHAN", "<");
    xlateMap.put("GREATERTHANOREQUALTO", ">=");
    xlateMap.put("GREATERTHAN", ">");

    xlateMap.put("DIVIDE", "/");
    xlateMap.put("PLUS", "+");
    xlateMap.put("MINUS", "-");
    xlateMap.put("STAR", "*");
    xlateMap.put("MOD", "%");

    xlateMap.put("AMPERSAND", "&");
    xlateMap.put("TILDE", "~");
    xlateMap.put("BITWISEOR", "|");
    xlateMap.put("BITWISEXOR", "^");
    xlateMap.put("CharSetLiteral", "\\'");
  }

  public static Collection<String> getKeywords() {
    return xlateMap.values();
  }

  private static String xlate(String name) {

    String ret = xlateMap.get(name);
    if (ret == null) {
      ret = name;
    }

    return ret;
  }

  @Override
  public Object recoverFromMismatchedSet(IntStream input, RecognitionException re, BitSet follow)
      throws RecognitionException {
    throw re;
  }

  @Override
  public void displayRecognitionError(String[] tokenNames, RecognitionException e) {
    errors.add(new ParseError(this, e, tokenNames));
  }

  @Override
  public String getErrorHeader(RecognitionException e) {
    String header = null;
    if (e.charPositionInLine < 0 && input.LT(-1) != null) {
      Token t = input.LT(-1);
      header = "line " + t.getLine() + ":" + t.getCharPositionInLine();
    } else {
      header = super.getErrorHeader(e);
    }

    return header;
  }

  @Override
  public String getErrorMessage(RecognitionException e, String[] tokenNames) {
    String msg = null;

    // Translate the token names to something that the user can understand
    String[] xlateNames = new String[tokenNames.length];
    for (int i = 0; i < tokenNames.length; ++i) {
      xlateNames[i] = HiveParser.xlate(tokenNames[i]);
    }

    if (e instanceof NoViableAltException) {
      @SuppressWarnings("unused")
      NoViableAltException nvae = (NoViableAltException) e;
      // for development, can add
      // "decision=<<"+nvae.grammarDecisionDescription+">>"
      // and "(decision="+nvae.decisionNumber+") and
      // "state "+nvae.stateNumber
      msg = "cannot recognize input near" + (input.LT(1) != null ? " " + getTokenErrorDisplay(input.LT(1)) : "")
          + (input.LT(2) != null ? " " + getTokenErrorDisplay(input.LT(2)) : "")
          + (input.LT(3) != null ? " " + getTokenErrorDisplay(input.LT(3)) : "");
    } else if (e instanceof MismatchedTokenException) {
      MismatchedTokenException mte = (MismatchedTokenException) e;
      msg =
          super.getErrorMessage(e, xlateNames) + (input.LT(-1) == null ? "" : " near '" + input.LT(-1).getText()) + "'";
    } else if (e instanceof FailedPredicateException) {
      FailedPredicateException fpe = (FailedPredicateException) e;
      msg = "Failed to recognize predicate '" + fpe.token.getText() + "'. Failed rule: '" + fpe.ruleName + "'";
    } else {
      msg = super.getErrorMessage(e, xlateNames);
    }

    if (msgs.size() > 0) {
      msg = msg + " in " + msgs.peek();
    }
    return msg;
  }

  public void pushMsg(String msg, RecognizerSharedState state) {
    // ANTLR generated code does not wrap the @init code wit this backtracking check,
    //  even if the matching @after has it. If we have parser rules with that are doing
    // some lookahead with syntactic predicates this can cause the push() and pop() calls
    // to become unbalanced, so make sure both push/pop check the backtracking state.
    if (state.backtracking == 0) {
      msgs.push(msg);
    }
  }

  public void popMsg(RecognizerSharedState state) {
    if (state.backtracking == 0) {
      msgs.pop();
    }
  }

  // counter to generate unique union aliases
  private int aliasCounter;

  private String generateUnionAlias() {
    return "_u" + (++aliasCounter);
  }

  public static class statement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "statement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:630:1: statement : ( explainStatement EOF | execStatement EOF );
  public final HiveParser.statement_return statement() throws RecognitionException {
    HiveParser.statement_return retval = new HiveParser.statement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token EOF2 = null;
    Token EOF4 = null;
    HiveParser.explainStatement_return explainStatement1 = null;

    HiveParser.execStatement_return execStatement3 = null;

    CommonTree EOF2_tree = null;
    CommonTree EOF4_tree = null;

    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:631:2: ( explainStatement EOF | execStatement EOF )
      int alt1 = 2;
      switch (input.LA(1)) {
        case KW_EXPLAIN: {
          alt1 = 1;
        }
          break;
        case KW_ALTER:
        case KW_ANALYZE:
        case KW_CREATE:
        case KW_DELETE:
        case KW_DESC:
        case KW_DESCRIBE:
        case KW_DROP:
        case KW_EXPORT:
        case KW_FROM:
        case KW_GRANT:
        case KW_IMPORT:
        case KW_INSERT:
        case KW_LOAD:
        case KW_LOCK:
        case KW_MAP:
        case KW_MSCK:
        case KW_REDUCE:
        case KW_RELOAD:
        case KW_REVOKE:
        case KW_SELECT:
        case KW_SET:
        case KW_SHOW:
        case KW_TRUNCATE:
        case KW_UNLOCK:
        case KW_UPDATE:
        case KW_USE:
        case KW_WITH: {
          alt1 = 2;
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 1, 0, input);

          throw nvae;
      }

      switch (alt1) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:631:4: explainStatement EOF
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_explainStatement_in_statement1034);
          explainStatement1 = explainStatement();

          state._fsp--;

          adaptor.addChild(root_0, explainStatement1.getTree());

          EOF2 = (Token) match(input, EOF, FOLLOW_EOF_in_statement1036);
          EOF2_tree = (CommonTree) adaptor.create(EOF2);
          adaptor.addChild(root_0, EOF2_tree);
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:632:4: execStatement EOF
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_execStatement_in_statement1041);
          execStatement3 = execStatement();

          state._fsp--;

          adaptor.addChild(root_0, execStatement3.getTree());

          EOF4 = (Token) match(input, EOF, FOLLOW_EOF_in_statement1043);
          EOF4_tree = (CommonTree) adaptor.create(EOF4);
          adaptor.addChild(root_0, EOF4_tree);
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "statement"

  public static class explainStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "explainStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:635:1: explainStatement : KW_EXPLAIN ( ( explainOption )* execStatement -> ^( TOK_EXPLAIN execStatement ( explainOption )* ) | KW_REWRITE queryStatementExpression[true] -> ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression ) ) ;
  public final HiveParser.explainStatement_return explainStatement() throws RecognitionException {
    HiveParser.explainStatement_return retval = new HiveParser.explainStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_EXPLAIN5 = null;
    Token KW_REWRITE8 = null;
    HiveParser.explainOption_return explainOption6 = null;

    HiveParser.execStatement_return execStatement7 = null;

    HiveParser.queryStatementExpression_return queryStatementExpression9 = null;

    CommonTree KW_EXPLAIN5_tree = null;
    CommonTree KW_REWRITE8_tree = null;
    RewriteRuleTokenStream stream_KW_REWRITE = new RewriteRuleTokenStream(adaptor, "token KW_REWRITE");
    RewriteRuleTokenStream stream_KW_EXPLAIN = new RewriteRuleTokenStream(adaptor, "token KW_EXPLAIN");
    RewriteRuleSubtreeStream stream_queryStatementExpression =
        new RewriteRuleSubtreeStream(adaptor, "rule queryStatementExpression");
    RewriteRuleSubtreeStream stream_explainOption = new RewriteRuleSubtreeStream(adaptor, "rule explainOption");
    RewriteRuleSubtreeStream stream_execStatement = new RewriteRuleSubtreeStream(adaptor, "rule execStatement");
    pushMsg("explain statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:638:2: ( KW_EXPLAIN ( ( explainOption )* execStatement -> ^( TOK_EXPLAIN execStatement ( explainOption )* ) | KW_REWRITE queryStatementExpression[true] -> ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression ) ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:638:4: KW_EXPLAIN ( ( explainOption )* execStatement -> ^( TOK_EXPLAIN execStatement ( explainOption )* ) | KW_REWRITE queryStatementExpression[true] -> ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression ) )
      {
        KW_EXPLAIN5 = (Token) match(input, KW_EXPLAIN, FOLLOW_KW_EXPLAIN_in_explainStatement1064);
        stream_KW_EXPLAIN.add(KW_EXPLAIN5);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:638:15: ( ( explainOption )* execStatement -> ^( TOK_EXPLAIN execStatement ( explainOption )* ) | KW_REWRITE queryStatementExpression[true] -> ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression ) )
        int alt3 = 2;
        switch (input.LA(1)) {
          case KW_ALTER:
          case KW_ANALYZE:
          case KW_AUTHORIZATION:
          case KW_CREATE:
          case KW_DELETE:
          case KW_DEPENDENCY:
          case KW_DESC:
          case KW_DESCRIBE:
          case KW_DROP:
          case KW_EXPORT:
          case KW_EXTENDED:
          case KW_FORMATTED:
          case KW_FROM:
          case KW_GRANT:
          case KW_IMPORT:
          case KW_INSERT:
          case KW_LOAD:
          case KW_LOCK:
          case KW_LOGICAL:
          case KW_MAP:
          case KW_MSCK:
          case KW_REDUCE:
          case KW_RELOAD:
          case KW_REVOKE:
          case KW_SELECT:
          case KW_SET:
          case KW_SHOW:
          case KW_TRUNCATE:
          case KW_UNLOCK:
          case KW_UPDATE:
          case KW_USE:
          case KW_WITH: {
            alt3 = 1;
          }
            break;
          case KW_REWRITE: {
            alt3 = 2;
          }
            break;
          default:
            NoViableAltException nvae = new NoViableAltException("", 3, 0, input);

            throw nvae;
        }

        switch (alt3) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:639:6: ( explainOption )* execStatement
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:639:6: ( explainOption )*
            loop2: do {
              int alt2 = 2;
              switch (input.LA(1)) {
                case KW_AUTHORIZATION:
                case KW_DEPENDENCY:
                case KW_EXTENDED:
                case KW_FORMATTED:
                case KW_LOGICAL: {
                  alt2 = 1;
                }
                  break;
              }

              switch (alt2) {
                case 1:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:639:6: explainOption
                {
                  pushFollow(FOLLOW_explainOption_in_explainStatement1073);
                  explainOption6 = explainOption();

                  state._fsp--;

                  stream_explainOption.add(explainOption6.getTree());
                }
                  break;

                default:
                  break loop2;
              }
            } while (true);

            pushFollow(FOLLOW_execStatement_in_explainStatement1076);
            execStatement7 = execStatement();

            state._fsp--;

            stream_execStatement.add(execStatement7.getTree());

            // AST REWRITE
            // elements: explainOption, execStatement
            // token labels:
            // rule labels: retval
            // token list labels:
            // rule list labels:
            // wildcard labels:
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval =
                new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

            root_0 = (CommonTree) adaptor.nil();
            // 639:35: -> ^( TOK_EXPLAIN execStatement ( explainOption )* )
            {
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:639:38: ^( TOK_EXPLAIN execStatement ( explainOption )* )
              {
                CommonTree root_1 = (CommonTree) adaptor.nil();
                root_1 =
                    (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_EXPLAIN, "TOK_EXPLAIN"), root_1);

                adaptor.addChild(root_1, stream_execStatement.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:639:66: ( explainOption )*
                while (stream_explainOption.hasNext()) {
                  adaptor.addChild(root_1, stream_explainOption.nextTree());
                }
                stream_explainOption.reset();

                adaptor.addChild(root_0, root_1);
              }
            }

            retval.tree = root_0;
          }
            break;
          case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:641:9: KW_REWRITE queryStatementExpression[true]
          {
            KW_REWRITE8 = (Token) match(input, KW_REWRITE, FOLLOW_KW_REWRITE_in_explainStatement1107);
            stream_KW_REWRITE.add(KW_REWRITE8);

            pushFollow(FOLLOW_queryStatementExpression_in_explainStatement1109);
            queryStatementExpression9 = queryStatementExpression(true);

            state._fsp--;

            stream_queryStatementExpression.add(queryStatementExpression9.getTree());

            // AST REWRITE
            // elements: queryStatementExpression
            // token labels:
            // rule labels: retval
            // token list labels:
            // rule list labels:
            // wildcard labels:
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval =
                new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

            root_0 = (CommonTree) adaptor.nil();
            // 641:51: -> ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression )
            {
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:641:54: ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression )
              {
                CommonTree root_1 = (CommonTree) adaptor.nil();
                root_1 = (CommonTree) adaptor
                    .becomeRoot((CommonTree) adaptor.create(TOK_EXPLAIN_SQ_REWRITE, "TOK_EXPLAIN_SQ_REWRITE"), root_1);

                adaptor.addChild(root_1, stream_queryStatementExpression.nextTree());

                adaptor.addChild(root_0, root_1);
              }
            }

            retval.tree = root_0;
          }
            break;
        }
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "explainStatement"

  public static class explainOption_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "explainOption"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:644:1: explainOption : ( KW_EXTENDED | KW_FORMATTED | KW_DEPENDENCY | KW_LOGICAL | KW_AUTHORIZATION );
  public final HiveParser.explainOption_return explainOption() throws RecognitionException {
    HiveParser.explainOption_return retval = new HiveParser.explainOption_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token set10 = null;

    CommonTree set10_tree = null;

    msgs.push("explain option");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:647:5: ( KW_EXTENDED | KW_FORMATTED | KW_DEPENDENCY | KW_LOGICAL | KW_AUTHORIZATION )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:
      {
        root_0 = (CommonTree) adaptor.nil();

        set10 = (Token) input.LT(1);

        if (input.LA(1) == KW_AUTHORIZATION || input.LA(1) == KW_DEPENDENCY || input.LA(1) == KW_EXTENDED
            || input.LA(1) == KW_FORMATTED || input.LA(1) == KW_LOGICAL) {
          input.consume();
          adaptor.addChild(root_0, (CommonTree) adaptor.create(set10));
          state.errorRecovery = false;
        } else {
          MismatchedSetException mse = new MismatchedSetException(null, input);
          throw mse;
        }
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      msgs.pop();
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "explainOption"

  public static class execStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "execStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:650:1: execStatement : ( queryStatementExpression[true] | loadStatement | exportStatement | importStatement | ddlStatement | deleteStatement | updateStatement );
  public final HiveParser.execStatement_return execStatement() throws RecognitionException {
    HiveParser.execStatement_return retval = new HiveParser.execStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.queryStatementExpression_return queryStatementExpression11 = null;

    HiveParser.loadStatement_return loadStatement12 = null;

    HiveParser.exportStatement_return exportStatement13 = null;

    HiveParser.importStatement_return importStatement14 = null;

    HiveParser.ddlStatement_return ddlStatement15 = null;

    HiveParser.deleteStatement_return deleteStatement16 = null;

    HiveParser.updateStatement_return updateStatement17 = null;

    pushMsg("statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:653:5: ( queryStatementExpression[true] | loadStatement | exportStatement | importStatement | ddlStatement | deleteStatement | updateStatement )
      int alt4 = 7;
      switch (input.LA(1)) {
        case KW_FROM:
        case KW_INSERT:
        case KW_MAP:
        case KW_REDUCE:
        case KW_SELECT:
        case KW_WITH: {
          alt4 = 1;
        }
          break;
        case KW_LOAD: {
          alt4 = 2;
        }
          break;
        case KW_EXPORT: {
          alt4 = 3;
        }
          break;
        case KW_IMPORT: {
          alt4 = 4;
        }
          break;
        case KW_ALTER:
        case KW_ANALYZE:
        case KW_CREATE:
        case KW_DESC:
        case KW_DESCRIBE:
        case KW_DROP:
        case KW_GRANT:
        case KW_LOCK:
        case KW_MSCK:
        case KW_RELOAD:
        case KW_REVOKE:
        case KW_SET:
        case KW_SHOW:
        case KW_TRUNCATE:
        case KW_UNLOCK:
        case KW_USE: {
          alt4 = 5;
        }
          break;
        case KW_DELETE: {
          alt4 = 6;
        }
          break;
        case KW_UPDATE: {
          alt4 = 7;
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 4, 0, input);

          throw nvae;
      }

      switch (alt4) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:653:7: queryStatementExpression[true]
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_queryStatementExpression_in_execStatement1178);
          queryStatementExpression11 = queryStatementExpression(true);

          state._fsp--;

          adaptor.addChild(root_0, queryStatementExpression11.getTree());
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:654:7: loadStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_loadStatement_in_execStatement1187);
          loadStatement12 = loadStatement();

          state._fsp--;

          adaptor.addChild(root_0, loadStatement12.getTree());
        }
          break;
        case 3:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:655:7: exportStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_exportStatement_in_execStatement1195);
          exportStatement13 = exportStatement();

          state._fsp--;

          adaptor.addChild(root_0, exportStatement13.getTree());
        }
          break;
        case 4:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:656:7: importStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_importStatement_in_execStatement1203);
          importStatement14 = importStatement();

          state._fsp--;

          adaptor.addChild(root_0, importStatement14.getTree());
        }
          break;
        case 5:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:657:7: ddlStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_ddlStatement_in_execStatement1211);
          ddlStatement15 = ddlStatement();

          state._fsp--;

          adaptor.addChild(root_0, ddlStatement15.getTree());
        }
          break;
        case 6:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:658:7: deleteStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_deleteStatement_in_execStatement1219);
          deleteStatement16 = deleteStatement();

          state._fsp--;

          adaptor.addChild(root_0, deleteStatement16.getTree());
        }
          break;
        case 7:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:659:7: updateStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_updateStatement_in_execStatement1227);
          updateStatement17 = updateStatement();

          state._fsp--;

          adaptor.addChild(root_0, updateStatement17.getTree());
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "execStatement"

  public static class loadStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "loadStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:662:1: loadStatement : KW_LOAD KW_DATA (islocal= KW_LOCAL )? KW_INPATH (path= StringLiteral ) (isoverwrite= KW_OVERWRITE )? KW_INTO KW_TABLE (tab= tableOrPartition ) -> ^( TOK_LOAD $path $tab ( $islocal)? ( $isoverwrite)? ) ;
  public final HiveParser.loadStatement_return loadStatement() throws RecognitionException {
    HiveParser.loadStatement_return retval = new HiveParser.loadStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token islocal = null;
    Token path = null;
    Token isoverwrite = null;
    Token KW_LOAD18 = null;
    Token KW_DATA19 = null;
    Token KW_INPATH20 = null;
    Token KW_INTO21 = null;
    Token KW_TABLE22 = null;
    HiveParser_IdentifiersParser.tableOrPartition_return tab = null;

    CommonTree islocal_tree = null;
    CommonTree path_tree = null;
    CommonTree isoverwrite_tree = null;
    CommonTree KW_LOAD18_tree = null;
    CommonTree KW_DATA19_tree = null;
    CommonTree KW_INPATH20_tree = null;
    CommonTree KW_INTO21_tree = null;
    CommonTree KW_TABLE22_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_INTO = new RewriteRuleTokenStream(adaptor, "token KW_INTO");
    RewriteRuleTokenStream stream_KW_INPATH = new RewriteRuleTokenStream(adaptor, "token KW_INPATH");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleTokenStream stream_KW_OVERWRITE = new RewriteRuleTokenStream(adaptor, "token KW_OVERWRITE");
    RewriteRuleTokenStream stream_KW_LOAD = new RewriteRuleTokenStream(adaptor, "token KW_LOAD");
    RewriteRuleTokenStream stream_KW_DATA = new RewriteRuleTokenStream(adaptor, "token KW_DATA");
    RewriteRuleTokenStream stream_KW_LOCAL = new RewriteRuleTokenStream(adaptor, "token KW_LOCAL");
    RewriteRuleSubtreeStream stream_tableOrPartition = new RewriteRuleSubtreeStream(adaptor, "rule tableOrPartition");
    pushMsg("load statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:665:5: ( KW_LOAD KW_DATA (islocal= KW_LOCAL )? KW_INPATH (path= StringLiteral ) (isoverwrite= KW_OVERWRITE )? KW_INTO KW_TABLE (tab= tableOrPartition ) -> ^( TOK_LOAD $path $tab ( $islocal)? ( $isoverwrite)? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:665:7: KW_LOAD KW_DATA (islocal= KW_LOCAL )? KW_INPATH (path= StringLiteral ) (isoverwrite= KW_OVERWRITE )? KW_INTO KW_TABLE (tab= tableOrPartition )
      {
        KW_LOAD18 = (Token) match(input, KW_LOAD, FOLLOW_KW_LOAD_in_loadStatement1254);
        stream_KW_LOAD.add(KW_LOAD18);

        KW_DATA19 = (Token) match(input, KW_DATA, FOLLOW_KW_DATA_in_loadStatement1256);
        stream_KW_DATA.add(KW_DATA19);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:665:23: (islocal= KW_LOCAL )?
        int alt5 = 2;
        switch (input.LA(1)) {
          case KW_LOCAL: {
            alt5 = 1;
          }
            break;
        }

        switch (alt5) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:665:24: islocal= KW_LOCAL
          {
            islocal = (Token) match(input, KW_LOCAL, FOLLOW_KW_LOCAL_in_loadStatement1261);
            stream_KW_LOCAL.add(islocal);
          }
            break;
        }

        KW_INPATH20 = (Token) match(input, KW_INPATH, FOLLOW_KW_INPATH_in_loadStatement1265);
        stream_KW_INPATH.add(KW_INPATH20);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:665:53: (path= StringLiteral )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:665:54: path= StringLiteral
        {
          path = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_loadStatement1270);
          stream_StringLiteral.add(path);
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:665:74: (isoverwrite= KW_OVERWRITE )?
        int alt6 = 2;
        switch (input.LA(1)) {
          case KW_OVERWRITE: {
            alt6 = 1;
          }
            break;
        }

        switch (alt6) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:665:75: isoverwrite= KW_OVERWRITE
          {
            isoverwrite = (Token) match(input, KW_OVERWRITE, FOLLOW_KW_OVERWRITE_in_loadStatement1276);
            stream_KW_OVERWRITE.add(isoverwrite);
          }
            break;
        }

        KW_INTO21 = (Token) match(input, KW_INTO, FOLLOW_KW_INTO_in_loadStatement1280);
        stream_KW_INTO.add(KW_INTO21);

        KW_TABLE22 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_loadStatement1282);
        stream_KW_TABLE.add(KW_TABLE22);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:665:119: (tab= tableOrPartition )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:665:120: tab= tableOrPartition
        {
          pushFollow(FOLLOW_tableOrPartition_in_loadStatement1287);
          tab = tableOrPartition();

          state._fsp--;

          stream_tableOrPartition.add(tab.getTree());
        }

        // AST REWRITE
        // elements: isoverwrite, tab, islocal, path
        // token labels: islocal, path, isoverwrite
        // rule labels: tab, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_islocal = new RewriteRuleTokenStream(adaptor, "token islocal", islocal);
        RewriteRuleTokenStream stream_path = new RewriteRuleTokenStream(adaptor, "token path", path);
        RewriteRuleTokenStream stream_isoverwrite =
            new RewriteRuleTokenStream(adaptor, "token isoverwrite", isoverwrite);
        RewriteRuleSubtreeStream stream_tab =
            new RewriteRuleSubtreeStream(adaptor, "rule tab", tab != null ? tab.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 666:5: -> ^( TOK_LOAD $path $tab ( $islocal)? ( $isoverwrite)? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:666:8: ^( TOK_LOAD $path $tab ( $islocal)? ( $isoverwrite)? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_LOAD, "TOK_LOAD"), root_1);

            adaptor.addChild(root_1, stream_path.nextNode());

            adaptor.addChild(root_1, stream_tab.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:666:31: ( $islocal)?
            if (stream_islocal.hasNext()) {
              adaptor.addChild(root_1, stream_islocal.nextNode());
            }
            stream_islocal.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:666:41: ( $isoverwrite)?
            if (stream_isoverwrite.hasNext()) {
              adaptor.addChild(root_1, stream_isoverwrite.nextNode());
            }
            stream_isoverwrite.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "loadStatement"

  public static class replicationClause_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "replicationClause"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:669:1: replicationClause : KW_FOR (isMetadataOnly= KW_METADATA )? KW_REPLICATION LPAREN (replId= StringLiteral ) RPAREN -> ^( TOK_REPLICATION $replId ( $isMetadataOnly)? ) ;
  public final HiveParser.replicationClause_return replicationClause() throws RecognitionException {
    HiveParser.replicationClause_return retval = new HiveParser.replicationClause_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token isMetadataOnly = null;
    Token replId = null;
    Token KW_FOR23 = null;
    Token KW_REPLICATION24 = null;
    Token LPAREN25 = null;
    Token RPAREN26 = null;

    CommonTree isMetadataOnly_tree = null;
    CommonTree replId_tree = null;
    CommonTree KW_FOR23_tree = null;
    CommonTree KW_REPLICATION24_tree = null;
    CommonTree LPAREN25_tree = null;
    CommonTree RPAREN26_tree = null;
    RewriteRuleTokenStream stream_KW_REPLICATION = new RewriteRuleTokenStream(adaptor, "token KW_REPLICATION");
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_FOR = new RewriteRuleTokenStream(adaptor, "token KW_FOR");
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleTokenStream stream_KW_METADATA = new RewriteRuleTokenStream(adaptor, "token KW_METADATA");

    pushMsg("replication clause", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:672:5: ( KW_FOR (isMetadataOnly= KW_METADATA )? KW_REPLICATION LPAREN (replId= StringLiteral ) RPAREN -> ^( TOK_REPLICATION $replId ( $isMetadataOnly)? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:672:7: KW_FOR (isMetadataOnly= KW_METADATA )? KW_REPLICATION LPAREN (replId= StringLiteral ) RPAREN
      {
        KW_FOR23 = (Token) match(input, KW_FOR, FOLLOW_KW_FOR_in_replicationClause1339);
        stream_KW_FOR.add(KW_FOR23);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:672:14: (isMetadataOnly= KW_METADATA )?
        int alt7 = 2;
        switch (input.LA(1)) {
          case KW_METADATA: {
            alt7 = 1;
          }
            break;
        }

        switch (alt7) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:672:15: isMetadataOnly= KW_METADATA
          {
            isMetadataOnly = (Token) match(input, KW_METADATA, FOLLOW_KW_METADATA_in_replicationClause1344);
            stream_KW_METADATA.add(isMetadataOnly);
          }
            break;
        }

        KW_REPLICATION24 = (Token) match(input, KW_REPLICATION, FOLLOW_KW_REPLICATION_in_replicationClause1348);
        stream_KW_REPLICATION.add(KW_REPLICATION24);

        LPAREN25 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_replicationClause1350);
        stream_LPAREN.add(LPAREN25);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:672:66: (replId= StringLiteral )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:672:67: replId= StringLiteral
        {
          replId = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_replicationClause1355);
          stream_StringLiteral.add(replId);
        }

        RPAREN26 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_replicationClause1358);
        stream_RPAREN.add(RPAREN26);

        // AST REWRITE
        // elements: isMetadataOnly, replId
        // token labels: replId, isMetadataOnly
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_replId = new RewriteRuleTokenStream(adaptor, "token replId", replId);
        RewriteRuleTokenStream stream_isMetadataOnly =
            new RewriteRuleTokenStream(adaptor, "token isMetadataOnly", isMetadataOnly);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 673:5: -> ^( TOK_REPLICATION $replId ( $isMetadataOnly)? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:673:8: ^( TOK_REPLICATION $replId ( $isMetadataOnly)? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_REPLICATION, "TOK_REPLICATION"),
                root_1);

            adaptor.addChild(root_1, stream_replId.nextNode());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:673:35: ( $isMetadataOnly)?
            if (stream_isMetadataOnly.hasNext()) {
              adaptor.addChild(root_1, stream_isMetadataOnly.nextNode());
            }
            stream_isMetadataOnly.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "replicationClause"

  public static class exportStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "exportStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:676:1: exportStatement : KW_EXPORT KW_TABLE (tab= tableOrPartition ) KW_TO (path= StringLiteral ) ( replicationClause )? -> ^( TOK_EXPORT $tab $path ( replicationClause )? ) ;
  public final HiveParser.exportStatement_return exportStatement() throws RecognitionException {
    HiveParser.exportStatement_return retval = new HiveParser.exportStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token path = null;
    Token KW_EXPORT27 = null;
    Token KW_TABLE28 = null;
    Token KW_TO29 = null;
    HiveParser_IdentifiersParser.tableOrPartition_return tab = null;

    HiveParser.replicationClause_return replicationClause30 = null;

    CommonTree path_tree = null;
    CommonTree KW_EXPORT27_tree = null;
    CommonTree KW_TABLE28_tree = null;
    CommonTree KW_TO29_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_TO = new RewriteRuleTokenStream(adaptor, "token KW_TO");
    RewriteRuleTokenStream stream_KW_EXPORT = new RewriteRuleTokenStream(adaptor, "token KW_EXPORT");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleSubtreeStream stream_tableOrPartition = new RewriteRuleSubtreeStream(adaptor, "rule tableOrPartition");
    RewriteRuleSubtreeStream stream_replicationClause = new RewriteRuleSubtreeStream(adaptor, "rule replicationClause");
    pushMsg("export statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:679:5: ( KW_EXPORT KW_TABLE (tab= tableOrPartition ) KW_TO (path= StringLiteral ) ( replicationClause )? -> ^( TOK_EXPORT $tab $path ( replicationClause )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:679:7: KW_EXPORT KW_TABLE (tab= tableOrPartition ) KW_TO (path= StringLiteral ) ( replicationClause )?
      {
        KW_EXPORT27 = (Token) match(input, KW_EXPORT, FOLLOW_KW_EXPORT_in_exportStatement1402);
        stream_KW_EXPORT.add(KW_EXPORT27);

        KW_TABLE28 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_exportStatement1410);
        stream_KW_TABLE.add(KW_TABLE28);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:680:16: (tab= tableOrPartition )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:680:17: tab= tableOrPartition
        {
          pushFollow(FOLLOW_tableOrPartition_in_exportStatement1415);
          tab = tableOrPartition();

          state._fsp--;

          stream_tableOrPartition.add(tab.getTree());
        }

        KW_TO29 = (Token) match(input, KW_TO, FOLLOW_KW_TO_in_exportStatement1424);
        stream_KW_TO.add(KW_TO29);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:681:13: (path= StringLiteral )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:681:14: path= StringLiteral
        {
          path = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_exportStatement1429);
          stream_StringLiteral.add(path);
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:682:7: ( replicationClause )?
        int alt8 = 2;
        switch (input.LA(1)) {
          case KW_FOR: {
            alt8 = 1;
          }
            break;
        }

        switch (alt8) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:682:7: replicationClause
          {
            pushFollow(FOLLOW_replicationClause_in_exportStatement1438);
            replicationClause30 = replicationClause();

            state._fsp--;

            stream_replicationClause.add(replicationClause30.getTree());
          }
            break;
        }

        // AST REWRITE
        // elements: path, tab, replicationClause
        // token labels: path
        // rule labels: tab, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_path = new RewriteRuleTokenStream(adaptor, "token path", path);
        RewriteRuleSubtreeStream stream_tab =
            new RewriteRuleSubtreeStream(adaptor, "rule tab", tab != null ? tab.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 683:5: -> ^( TOK_EXPORT $tab $path ( replicationClause )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:683:8: ^( TOK_EXPORT $tab $path ( replicationClause )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_EXPORT, "TOK_EXPORT"), root_1);

            adaptor.addChild(root_1, stream_tab.nextTree());

            adaptor.addChild(root_1, stream_path.nextNode());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:683:32: ( replicationClause )?
            if (stream_replicationClause.hasNext()) {
              adaptor.addChild(root_1, stream_replicationClause.nextTree());
            }
            stream_replicationClause.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "exportStatement"

  public static class importStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "importStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:686:1: importStatement : KW_IMPORT ( (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition ) )? KW_FROM (path= StringLiteral ) ( location )? -> ^( TOK_IMPORT $path ( $tab)? ( $ext)? ( location )? ) ;
  public final HiveParser.importStatement_return importStatement() throws RecognitionException {
    HiveParser.importStatement_return retval = new HiveParser.importStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token ext = null;
    Token path = null;
    Token KW_IMPORT31 = null;
    Token KW_TABLE32 = null;
    Token KW_FROM33 = null;
    HiveParser_IdentifiersParser.tableOrPartition_return tab = null;

    HiveParser.location_return location34 = null;

    CommonTree ext_tree = null;
    CommonTree path_tree = null;
    CommonTree KW_IMPORT31_tree = null;
    CommonTree KW_TABLE32_tree = null;
    CommonTree KW_FROM33_tree = null;
    RewriteRuleTokenStream stream_KW_EXTERNAL = new RewriteRuleTokenStream(adaptor, "token KW_EXTERNAL");
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_FROM = new RewriteRuleTokenStream(adaptor, "token KW_FROM");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleTokenStream stream_KW_IMPORT = new RewriteRuleTokenStream(adaptor, "token KW_IMPORT");
    RewriteRuleSubtreeStream stream_location = new RewriteRuleSubtreeStream(adaptor, "rule location");
    RewriteRuleSubtreeStream stream_tableOrPartition = new RewriteRuleSubtreeStream(adaptor, "rule tableOrPartition");
    pushMsg("import statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:689:8: ( KW_IMPORT ( (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition ) )? KW_FROM (path= StringLiteral ) ( location )? -> ^( TOK_IMPORT $path ( $tab)? ( $ext)? ( location )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:689:10: KW_IMPORT ( (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition ) )? KW_FROM (path= StringLiteral ) ( location )?
      {
        KW_IMPORT31 = (Token) match(input, KW_IMPORT, FOLLOW_KW_IMPORT_in_importStatement1488);
        stream_KW_IMPORT.add(KW_IMPORT31);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:690:10: ( (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition ) )?
        int alt10 = 2;
        switch (input.LA(1)) {
          case KW_EXTERNAL:
          case KW_TABLE: {
            alt10 = 1;
          }
            break;
        }

        switch (alt10) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:690:11: (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:690:11: (ext= KW_EXTERNAL )?
            int alt9 = 2;
            switch (input.LA(1)) {
              case KW_EXTERNAL: {
                alt9 = 1;
              }
                break;
            }

            switch (alt9) {
              case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:690:12: ext= KW_EXTERNAL
              {
                ext = (Token) match(input, KW_EXTERNAL, FOLLOW_KW_EXTERNAL_in_importStatement1503);
                stream_KW_EXTERNAL.add(ext);
              }
                break;
            }

            KW_TABLE32 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_importStatement1507);
            stream_KW_TABLE.add(KW_TABLE32);

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:690:39: (tab= tableOrPartition )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:690:40: tab= tableOrPartition
            {
              pushFollow(FOLLOW_tableOrPartition_in_importStatement1512);
              tab = tableOrPartition();

              state._fsp--;

              stream_tableOrPartition.add(tab.getTree());
            }
          }
            break;
        }

        KW_FROM33 = (Token) match(input, KW_FROM, FOLLOW_KW_FROM_in_importStatement1526);
        stream_KW_FROM.add(KW_FROM33);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:691:18: (path= StringLiteral )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:691:19: path= StringLiteral
        {
          path = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_importStatement1531);
          stream_StringLiteral.add(path);
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:692:10: ( location )?
        int alt11 = 2;
        switch (input.LA(1)) {
          case KW_LOCATION: {
            alt11 = 1;
          }
            break;
        }

        switch (alt11) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:692:10: location
          {
            pushFollow(FOLLOW_location_in_importStatement1543);
            location34 = location();

            state._fsp--;

            stream_location.add(location34.getTree());
          }
            break;
        }

        // AST REWRITE
        // elements: tab, location, ext, path
        // token labels: ext, path
        // rule labels: tab, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_ext = new RewriteRuleTokenStream(adaptor, "token ext", ext);
        RewriteRuleTokenStream stream_path = new RewriteRuleTokenStream(adaptor, "token path", path);
        RewriteRuleSubtreeStream stream_tab =
            new RewriteRuleSubtreeStream(adaptor, "rule tab", tab != null ? tab.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 693:5: -> ^( TOK_IMPORT $path ( $tab)? ( $ext)? ( location )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:693:8: ^( TOK_IMPORT $path ( $tab)? ( $ext)? ( location )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_IMPORT, "TOK_IMPORT"), root_1);

            adaptor.addChild(root_1, stream_path.nextNode());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:693:28: ( $tab)?
            if (stream_tab.hasNext()) {
              adaptor.addChild(root_1, stream_tab.nextTree());
            }
            stream_tab.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:693:34: ( $ext)?
            if (stream_ext.hasNext()) {
              adaptor.addChild(root_1, stream_ext.nextNode());
            }
            stream_ext.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:693:39: ( location )?
            if (stream_location.hasNext()) {
              adaptor.addChild(root_1, stream_location.nextTree());
            }
            stream_location.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "importStatement"

  public static class ddlStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "ddlStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:696:1: ddlStatement : ( createDatabaseStatement | switchDatabaseStatement | dropDatabaseStatement | createTableStatement | dropTableStatement | truncateTableStatement | alterStatement | descStatement | showStatement | metastoreCheck | createViewStatement | dropViewStatement | createFunctionStatement | createMacroStatement | createIndexStatement | dropIndexStatement | dropFunctionStatement | reloadFunctionStatement | dropMacroStatement | analyzeStatement | lockStatement | unlockStatement | lockDatabase | unlockDatabase | createRoleStatement | dropRoleStatement | grantPrivileges | revokePrivileges | showGrants | showRoleGrants | showRolePrincipals | showRoles | grantRole | revokeRole | setRole | showCurrentRole );
  public final HiveParser.ddlStatement_return ddlStatement() throws RecognitionException {
    HiveParser.ddlStatement_return retval = new HiveParser.ddlStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.createDatabaseStatement_return createDatabaseStatement35 = null;

    HiveParser.switchDatabaseStatement_return switchDatabaseStatement36 = null;

    HiveParser.dropDatabaseStatement_return dropDatabaseStatement37 = null;

    HiveParser.createTableStatement_return createTableStatement38 = null;

    HiveParser.dropTableStatement_return dropTableStatement39 = null;

    HiveParser.truncateTableStatement_return truncateTableStatement40 = null;

    HiveParser.alterStatement_return alterStatement41 = null;

    HiveParser.descStatement_return descStatement42 = null;

    HiveParser.showStatement_return showStatement43 = null;

    HiveParser.metastoreCheck_return metastoreCheck44 = null;

    HiveParser.createViewStatement_return createViewStatement45 = null;

    HiveParser.dropViewStatement_return dropViewStatement46 = null;

    HiveParser.createFunctionStatement_return createFunctionStatement47 = null;

    HiveParser.createMacroStatement_return createMacroStatement48 = null;

    HiveParser.createIndexStatement_return createIndexStatement49 = null;

    HiveParser.dropIndexStatement_return dropIndexStatement50 = null;

    HiveParser.dropFunctionStatement_return dropFunctionStatement51 = null;

    HiveParser.reloadFunctionStatement_return reloadFunctionStatement52 = null;

    HiveParser.dropMacroStatement_return dropMacroStatement53 = null;

    HiveParser.analyzeStatement_return analyzeStatement54 = null;

    HiveParser.lockStatement_return lockStatement55 = null;

    HiveParser.unlockStatement_return unlockStatement56 = null;

    HiveParser.lockDatabase_return lockDatabase57 = null;

    HiveParser.unlockDatabase_return unlockDatabase58 = null;

    HiveParser.createRoleStatement_return createRoleStatement59 = null;

    HiveParser.dropRoleStatement_return dropRoleStatement60 = null;

    HiveParser.grantPrivileges_return grantPrivileges61 = null;

    HiveParser.revokePrivileges_return revokePrivileges62 = null;

    HiveParser.showGrants_return showGrants63 = null;

    HiveParser.showRoleGrants_return showRoleGrants64 = null;

    HiveParser.showRolePrincipals_return showRolePrincipals65 = null;

    HiveParser.showRoles_return showRoles66 = null;

    HiveParser.grantRole_return grantRole67 = null;

    HiveParser.revokeRole_return revokeRole68 = null;

    HiveParser.setRole_return setRole69 = null;

    HiveParser.showCurrentRole_return showCurrentRole70 = null;

    pushMsg("ddl statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:699:5: ( createDatabaseStatement | switchDatabaseStatement | dropDatabaseStatement | createTableStatement | dropTableStatement | truncateTableStatement | alterStatement | descStatement | showStatement | metastoreCheck | createViewStatement | dropViewStatement | createFunctionStatement | createMacroStatement | createIndexStatement | dropIndexStatement | dropFunctionStatement | reloadFunctionStatement | dropMacroStatement | analyzeStatement | lockStatement | unlockStatement | lockDatabase | unlockDatabase | createRoleStatement | dropRoleStatement | grantPrivileges | revokePrivileges | showGrants | showRoleGrants | showRolePrincipals | showRoles | grantRole | revokeRole | setRole | showCurrentRole )
      int alt12 = 36;
      alt12 = dfa12.predict(input);
      switch (alt12) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:699:7: createDatabaseStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_createDatabaseStatement_in_ddlStatement1595);
          createDatabaseStatement35 = createDatabaseStatement();

          state._fsp--;

          adaptor.addChild(root_0, createDatabaseStatement35.getTree());
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:700:7: switchDatabaseStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_switchDatabaseStatement_in_ddlStatement1603);
          switchDatabaseStatement36 = switchDatabaseStatement();

          state._fsp--;

          adaptor.addChild(root_0, switchDatabaseStatement36.getTree());
        }
          break;
        case 3:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:701:7: dropDatabaseStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_dropDatabaseStatement_in_ddlStatement1611);
          dropDatabaseStatement37 = dropDatabaseStatement();

          state._fsp--;

          adaptor.addChild(root_0, dropDatabaseStatement37.getTree());
        }
          break;
        case 4:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:702:7: createTableStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_createTableStatement_in_ddlStatement1619);
          createTableStatement38 = createTableStatement();

          state._fsp--;

          adaptor.addChild(root_0, createTableStatement38.getTree());
        }
          break;
        case 5:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:703:7: dropTableStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_dropTableStatement_in_ddlStatement1627);
          dropTableStatement39 = dropTableStatement();

          state._fsp--;

          adaptor.addChild(root_0, dropTableStatement39.getTree());
        }
          break;
        case 6:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:704:7: truncateTableStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_truncateTableStatement_in_ddlStatement1635);
          truncateTableStatement40 = truncateTableStatement();

          state._fsp--;

          adaptor.addChild(root_0, truncateTableStatement40.getTree());
        }
          break;
        case 7:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:705:7: alterStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatement_in_ddlStatement1643);
          alterStatement41 = alterStatement();

          state._fsp--;

          adaptor.addChild(root_0, alterStatement41.getTree());
        }
          break;
        case 8:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:706:7: descStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_descStatement_in_ddlStatement1651);
          descStatement42 = descStatement();

          state._fsp--;

          adaptor.addChild(root_0, descStatement42.getTree());
        }
          break;
        case 9:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:707:7: showStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_showStatement_in_ddlStatement1659);
          showStatement43 = showStatement();

          state._fsp--;

          adaptor.addChild(root_0, showStatement43.getTree());
        }
          break;
        case 10:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:708:7: metastoreCheck
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_metastoreCheck_in_ddlStatement1667);
          metastoreCheck44 = metastoreCheck();

          state._fsp--;

          adaptor.addChild(root_0, metastoreCheck44.getTree());
        }
          break;
        case 11:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:709:7: createViewStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_createViewStatement_in_ddlStatement1675);
          createViewStatement45 = createViewStatement();

          state._fsp--;

          adaptor.addChild(root_0, createViewStatement45.getTree());
        }
          break;
        case 12:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:710:7: dropViewStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_dropViewStatement_in_ddlStatement1683);
          dropViewStatement46 = dropViewStatement();

          state._fsp--;

          adaptor.addChild(root_0, dropViewStatement46.getTree());
        }
          break;
        case 13:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:711:7: createFunctionStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_createFunctionStatement_in_ddlStatement1691);
          createFunctionStatement47 = createFunctionStatement();

          state._fsp--;

          adaptor.addChild(root_0, createFunctionStatement47.getTree());
        }
          break;
        case 14:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:712:7: createMacroStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_createMacroStatement_in_ddlStatement1699);
          createMacroStatement48 = createMacroStatement();

          state._fsp--;

          adaptor.addChild(root_0, createMacroStatement48.getTree());
        }
          break;
        case 15:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:713:7: createIndexStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_createIndexStatement_in_ddlStatement1707);
          createIndexStatement49 = createIndexStatement();

          state._fsp--;

          adaptor.addChild(root_0, createIndexStatement49.getTree());
        }
          break;
        case 16:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:714:7: dropIndexStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_dropIndexStatement_in_ddlStatement1715);
          dropIndexStatement50 = dropIndexStatement();

          state._fsp--;

          adaptor.addChild(root_0, dropIndexStatement50.getTree());
        }
          break;
        case 17:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:715:7: dropFunctionStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_dropFunctionStatement_in_ddlStatement1723);
          dropFunctionStatement51 = dropFunctionStatement();

          state._fsp--;

          adaptor.addChild(root_0, dropFunctionStatement51.getTree());
        }
          break;
        case 18:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:716:7: reloadFunctionStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_reloadFunctionStatement_in_ddlStatement1731);
          reloadFunctionStatement52 = reloadFunctionStatement();

          state._fsp--;

          adaptor.addChild(root_0, reloadFunctionStatement52.getTree());
        }
          break;
        case 19:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:717:7: dropMacroStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_dropMacroStatement_in_ddlStatement1739);
          dropMacroStatement53 = dropMacroStatement();

          state._fsp--;

          adaptor.addChild(root_0, dropMacroStatement53.getTree());
        }
          break;
        case 20:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:718:7: analyzeStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_analyzeStatement_in_ddlStatement1747);
          analyzeStatement54 = analyzeStatement();

          state._fsp--;

          adaptor.addChild(root_0, analyzeStatement54.getTree());
        }
          break;
        case 21:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:719:7: lockStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_lockStatement_in_ddlStatement1755);
          lockStatement55 = lockStatement();

          state._fsp--;

          adaptor.addChild(root_0, lockStatement55.getTree());
        }
          break;
        case 22:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:720:7: unlockStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_unlockStatement_in_ddlStatement1763);
          unlockStatement56 = unlockStatement();

          state._fsp--;

          adaptor.addChild(root_0, unlockStatement56.getTree());
        }
          break;
        case 23:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:721:7: lockDatabase
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_lockDatabase_in_ddlStatement1771);
          lockDatabase57 = lockDatabase();

          state._fsp--;

          adaptor.addChild(root_0, lockDatabase57.getTree());
        }
          break;
        case 24:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:722:7: unlockDatabase
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_unlockDatabase_in_ddlStatement1779);
          unlockDatabase58 = unlockDatabase();

          state._fsp--;

          adaptor.addChild(root_0, unlockDatabase58.getTree());
        }
          break;
        case 25:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:723:7: createRoleStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_createRoleStatement_in_ddlStatement1787);
          createRoleStatement59 = createRoleStatement();

          state._fsp--;

          adaptor.addChild(root_0, createRoleStatement59.getTree());
        }
          break;
        case 26:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:724:7: dropRoleStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_dropRoleStatement_in_ddlStatement1795);
          dropRoleStatement60 = dropRoleStatement();

          state._fsp--;

          adaptor.addChild(root_0, dropRoleStatement60.getTree());
        }
          break;
        case 27:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:725:7: grantPrivileges
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_grantPrivileges_in_ddlStatement1803);
          grantPrivileges61 = grantPrivileges();

          state._fsp--;

          adaptor.addChild(root_0, grantPrivileges61.getTree());
        }
          break;
        case 28:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:726:7: revokePrivileges
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_revokePrivileges_in_ddlStatement1811);
          revokePrivileges62 = revokePrivileges();

          state._fsp--;

          adaptor.addChild(root_0, revokePrivileges62.getTree());
        }
          break;
        case 29:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:727:7: showGrants
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_showGrants_in_ddlStatement1819);
          showGrants63 = showGrants();

          state._fsp--;

          adaptor.addChild(root_0, showGrants63.getTree());
        }
          break;
        case 30:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:728:7: showRoleGrants
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_showRoleGrants_in_ddlStatement1827);
          showRoleGrants64 = showRoleGrants();

          state._fsp--;

          adaptor.addChild(root_0, showRoleGrants64.getTree());
        }
          break;
        case 31:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:729:7: showRolePrincipals
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_showRolePrincipals_in_ddlStatement1835);
          showRolePrincipals65 = showRolePrincipals();

          state._fsp--;

          adaptor.addChild(root_0, showRolePrincipals65.getTree());
        }
          break;
        case 32:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:730:7: showRoles
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_showRoles_in_ddlStatement1843);
          showRoles66 = showRoles();

          state._fsp--;

          adaptor.addChild(root_0, showRoles66.getTree());
        }
          break;
        case 33:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:731:7: grantRole
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_grantRole_in_ddlStatement1851);
          grantRole67 = grantRole();

          state._fsp--;

          adaptor.addChild(root_0, grantRole67.getTree());
        }
          break;
        case 34:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:732:7: revokeRole
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_revokeRole_in_ddlStatement1859);
          revokeRole68 = revokeRole();

          state._fsp--;

          adaptor.addChild(root_0, revokeRole68.getTree());
        }
          break;
        case 35:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:733:7: setRole
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_setRole_in_ddlStatement1867);
          setRole69 = setRole();

          state._fsp--;

          adaptor.addChild(root_0, setRole69.getTree());
        }
          break;
        case 36:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:734:7: showCurrentRole
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_showCurrentRole_in_ddlStatement1875);
          showCurrentRole70 = showCurrentRole();

          state._fsp--;

          adaptor.addChild(root_0, showCurrentRole70.getTree());
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "ddlStatement"

  public static class ifExists_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "ifExists"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:737:1: ifExists : KW_IF KW_EXISTS -> ^( TOK_IFEXISTS ) ;
  public final HiveParser.ifExists_return ifExists() throws RecognitionException {
    HiveParser.ifExists_return retval = new HiveParser.ifExists_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_IF71 = null;
    Token KW_EXISTS72 = null;

    CommonTree KW_IF71_tree = null;
    CommonTree KW_EXISTS72_tree = null;
    RewriteRuleTokenStream stream_KW_EXISTS = new RewriteRuleTokenStream(adaptor, "token KW_EXISTS");
    RewriteRuleTokenStream stream_KW_IF = new RewriteRuleTokenStream(adaptor, "token KW_IF");

    pushMsg("if exists clause", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:740:5: ( KW_IF KW_EXISTS -> ^( TOK_IFEXISTS ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:740:7: KW_IF KW_EXISTS
      {
        KW_IF71 = (Token) match(input, KW_IF, FOLLOW_KW_IF_in_ifExists1902);
        stream_KW_IF.add(KW_IF71);

        KW_EXISTS72 = (Token) match(input, KW_EXISTS, FOLLOW_KW_EXISTS_in_ifExists1904);
        stream_KW_EXISTS.add(KW_EXISTS72);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 741:5: -> ^( TOK_IFEXISTS )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:741:8: ^( TOK_IFEXISTS )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_IFEXISTS, "TOK_IFEXISTS"), root_1);

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "ifExists"

  public static class restrictOrCascade_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "restrictOrCascade"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:744:1: restrictOrCascade : ( KW_RESTRICT -> ^( TOK_RESTRICT ) | KW_CASCADE -> ^( TOK_CASCADE ) );
  public final HiveParser.restrictOrCascade_return restrictOrCascade() throws RecognitionException {
    HiveParser.restrictOrCascade_return retval = new HiveParser.restrictOrCascade_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_RESTRICT73 = null;
    Token KW_CASCADE74 = null;

    CommonTree KW_RESTRICT73_tree = null;
    CommonTree KW_CASCADE74_tree = null;
    RewriteRuleTokenStream stream_KW_CASCADE = new RewriteRuleTokenStream(adaptor, "token KW_CASCADE");
    RewriteRuleTokenStream stream_KW_RESTRICT = new RewriteRuleTokenStream(adaptor, "token KW_RESTRICT");

    pushMsg("restrict or cascade clause", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:747:5: ( KW_RESTRICT -> ^( TOK_RESTRICT ) | KW_CASCADE -> ^( TOK_CASCADE ) )
      int alt13 = 2;
      switch (input.LA(1)) {
        case KW_RESTRICT: {
          alt13 = 1;
        }
          break;
        case KW_CASCADE: {
          alt13 = 2;
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 13, 0, input);

          throw nvae;
      }

      switch (alt13) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:747:7: KW_RESTRICT
        {
          KW_RESTRICT73 = (Token) match(input, KW_RESTRICT, FOLLOW_KW_RESTRICT_in_restrictOrCascade1941);
          stream_KW_RESTRICT.add(KW_RESTRICT73);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 748:5: -> ^( TOK_RESTRICT )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:748:8: ^( TOK_RESTRICT )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_RESTRICT, "TOK_RESTRICT"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:749:7: KW_CASCADE
        {
          KW_CASCADE74 = (Token) match(input, KW_CASCADE, FOLLOW_KW_CASCADE_in_restrictOrCascade1959);
          stream_KW_CASCADE.add(KW_CASCADE74);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 750:5: -> ^( TOK_CASCADE )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:750:8: ^( TOK_CASCADE )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_CASCADE, "TOK_CASCADE"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "restrictOrCascade"

  public static class ifNotExists_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "ifNotExists"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:753:1: ifNotExists : KW_IF KW_NOT KW_EXISTS -> ^( TOK_IFNOTEXISTS ) ;
  public final HiveParser.ifNotExists_return ifNotExists() throws RecognitionException {
    HiveParser.ifNotExists_return retval = new HiveParser.ifNotExists_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_IF75 = null;
    Token KW_NOT76 = null;
    Token KW_EXISTS77 = null;

    CommonTree KW_IF75_tree = null;
    CommonTree KW_NOT76_tree = null;
    CommonTree KW_EXISTS77_tree = null;
    RewriteRuleTokenStream stream_KW_NOT = new RewriteRuleTokenStream(adaptor, "token KW_NOT");
    RewriteRuleTokenStream stream_KW_EXISTS = new RewriteRuleTokenStream(adaptor, "token KW_EXISTS");
    RewriteRuleTokenStream stream_KW_IF = new RewriteRuleTokenStream(adaptor, "token KW_IF");

    pushMsg("if not exists clause", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:756:5: ( KW_IF KW_NOT KW_EXISTS -> ^( TOK_IFNOTEXISTS ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:756:7: KW_IF KW_NOT KW_EXISTS
      {
        KW_IF75 = (Token) match(input, KW_IF, FOLLOW_KW_IF_in_ifNotExists1996);
        stream_KW_IF.add(KW_IF75);

        KW_NOT76 = (Token) match(input, KW_NOT, FOLLOW_KW_NOT_in_ifNotExists1998);
        stream_KW_NOT.add(KW_NOT76);

        KW_EXISTS77 = (Token) match(input, KW_EXISTS, FOLLOW_KW_EXISTS_in_ifNotExists2000);
        stream_KW_EXISTS.add(KW_EXISTS77);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 757:5: -> ^( TOK_IFNOTEXISTS )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:757:8: ^( TOK_IFNOTEXISTS )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_IFNOTEXISTS, "TOK_IFNOTEXISTS"),
                root_1);

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "ifNotExists"

  public static class storedAsDirs_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "storedAsDirs"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:760:1: storedAsDirs : KW_STORED KW_AS KW_DIRECTORIES -> ^( TOK_STOREDASDIRS ) ;
  public final HiveParser.storedAsDirs_return storedAsDirs() throws RecognitionException {
    HiveParser.storedAsDirs_return retval = new HiveParser.storedAsDirs_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_STORED78 = null;
    Token KW_AS79 = null;
    Token KW_DIRECTORIES80 = null;

    CommonTree KW_STORED78_tree = null;
    CommonTree KW_AS79_tree = null;
    CommonTree KW_DIRECTORIES80_tree = null;
    RewriteRuleTokenStream stream_KW_DIRECTORIES = new RewriteRuleTokenStream(adaptor, "token KW_DIRECTORIES");
    RewriteRuleTokenStream stream_KW_AS = new RewriteRuleTokenStream(adaptor, "token KW_AS");
    RewriteRuleTokenStream stream_KW_STORED = new RewriteRuleTokenStream(adaptor, "token KW_STORED");

    pushMsg("stored as directories", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:763:5: ( KW_STORED KW_AS KW_DIRECTORIES -> ^( TOK_STOREDASDIRS ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:763:7: KW_STORED KW_AS KW_DIRECTORIES
      {
        KW_STORED78 = (Token) match(input, KW_STORED, FOLLOW_KW_STORED_in_storedAsDirs2037);
        stream_KW_STORED.add(KW_STORED78);

        KW_AS79 = (Token) match(input, KW_AS, FOLLOW_KW_AS_in_storedAsDirs2039);
        stream_KW_AS.add(KW_AS79);

        KW_DIRECTORIES80 = (Token) match(input, KW_DIRECTORIES, FOLLOW_KW_DIRECTORIES_in_storedAsDirs2041);
        stream_KW_DIRECTORIES.add(KW_DIRECTORIES80);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 764:5: -> ^( TOK_STOREDASDIRS )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:764:8: ^( TOK_STOREDASDIRS )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_STOREDASDIRS, "TOK_STOREDASDIRS"),
                root_1);

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "storedAsDirs"

  public static class orReplace_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "orReplace"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:767:1: orReplace : KW_OR KW_REPLACE -> ^( TOK_ORREPLACE ) ;
  public final HiveParser.orReplace_return orReplace() throws RecognitionException {
    HiveParser.orReplace_return retval = new HiveParser.orReplace_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_OR81 = null;
    Token KW_REPLACE82 = null;

    CommonTree KW_OR81_tree = null;
    CommonTree KW_REPLACE82_tree = null;
    RewriteRuleTokenStream stream_KW_REPLACE = new RewriteRuleTokenStream(adaptor, "token KW_REPLACE");
    RewriteRuleTokenStream stream_KW_OR = new RewriteRuleTokenStream(adaptor, "token KW_OR");

    pushMsg("or replace clause", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:770:5: ( KW_OR KW_REPLACE -> ^( TOK_ORREPLACE ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:770:7: KW_OR KW_REPLACE
      {
        KW_OR81 = (Token) match(input, KW_OR, FOLLOW_KW_OR_in_orReplace2078);
        stream_KW_OR.add(KW_OR81);

        KW_REPLACE82 = (Token) match(input, KW_REPLACE, FOLLOW_KW_REPLACE_in_orReplace2080);
        stream_KW_REPLACE.add(KW_REPLACE82);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 771:5: -> ^( TOK_ORREPLACE )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:771:8: ^( TOK_ORREPLACE )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_ORREPLACE, "TOK_ORREPLACE"), root_1);

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "orReplace"

  public static class ignoreProtection_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "ignoreProtection"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:774:1: ignoreProtection : KW_IGNORE KW_PROTECTION -> ^( TOK_IGNOREPROTECTION ) ;
  public final HiveParser.ignoreProtection_return ignoreProtection() throws RecognitionException {
    HiveParser.ignoreProtection_return retval = new HiveParser.ignoreProtection_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_IGNORE83 = null;
    Token KW_PROTECTION84 = null;

    CommonTree KW_IGNORE83_tree = null;
    CommonTree KW_PROTECTION84_tree = null;
    RewriteRuleTokenStream stream_KW_PROTECTION = new RewriteRuleTokenStream(adaptor, "token KW_PROTECTION");
    RewriteRuleTokenStream stream_KW_IGNORE = new RewriteRuleTokenStream(adaptor, "token KW_IGNORE");

    pushMsg("ignore protection clause", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:777:9: ( KW_IGNORE KW_PROTECTION -> ^( TOK_IGNOREPROTECTION ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:777:11: KW_IGNORE KW_PROTECTION
      {
        KW_IGNORE83 = (Token) match(input, KW_IGNORE, FOLLOW_KW_IGNORE_in_ignoreProtection2121);
        stream_KW_IGNORE.add(KW_IGNORE83);

        KW_PROTECTION84 = (Token) match(input, KW_PROTECTION, FOLLOW_KW_PROTECTION_in_ignoreProtection2123);
        stream_KW_PROTECTION.add(KW_PROTECTION84);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 778:9: -> ^( TOK_IGNOREPROTECTION )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:778:12: ^( TOK_IGNOREPROTECTION )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_IGNOREPROTECTION, "TOK_IGNOREPROTECTION"), root_1);

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "ignoreProtection"

  public static class createDatabaseStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "createDatabaseStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:781:1: createDatabaseStatement : KW_CREATE ( KW_DATABASE | KW_SCHEMA ) ( ifNotExists )? name= identifier ( databaseComment )? ( location )? ( KW_WITH KW_DBPROPERTIES dbprops= dbProperties )? -> ^( TOK_CREATEDATABASE $name ( ifNotExists )? ( location )? ( databaseComment )? ( $dbprops)? ) ;
  public final HiveParser.createDatabaseStatement_return createDatabaseStatement() throws RecognitionException {
    HiveParser.createDatabaseStatement_return retval = new HiveParser.createDatabaseStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_CREATE85 = null;
    Token KW_DATABASE86 = null;
    Token KW_SCHEMA87 = null;
    Token KW_WITH91 = null;
    Token KW_DBPROPERTIES92 = null;
    HiveParser_IdentifiersParser.identifier_return name = null;

    HiveParser.dbProperties_return dbprops = null;

    HiveParser.ifNotExists_return ifNotExists88 = null;

    HiveParser.databaseComment_return databaseComment89 = null;

    HiveParser.location_return location90 = null;

    CommonTree KW_CREATE85_tree = null;
    CommonTree KW_DATABASE86_tree = null;
    CommonTree KW_SCHEMA87_tree = null;
    CommonTree KW_WITH91_tree = null;
    CommonTree KW_DBPROPERTIES92_tree = null;
    RewriteRuleTokenStream stream_KW_DBPROPERTIES = new RewriteRuleTokenStream(adaptor, "token KW_DBPROPERTIES");
    RewriteRuleTokenStream stream_KW_SCHEMA = new RewriteRuleTokenStream(adaptor, "token KW_SCHEMA");
    RewriteRuleTokenStream stream_KW_CREATE = new RewriteRuleTokenStream(adaptor, "token KW_CREATE");
    RewriteRuleTokenStream stream_KW_DATABASE = new RewriteRuleTokenStream(adaptor, "token KW_DATABASE");
    RewriteRuleTokenStream stream_KW_WITH = new RewriteRuleTokenStream(adaptor, "token KW_WITH");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_dbProperties = new RewriteRuleSubtreeStream(adaptor, "rule dbProperties");
    RewriteRuleSubtreeStream stream_databaseComment = new RewriteRuleSubtreeStream(adaptor, "rule databaseComment");
    RewriteRuleSubtreeStream stream_ifNotExists = new RewriteRuleSubtreeStream(adaptor, "rule ifNotExists");
    RewriteRuleSubtreeStream stream_location = new RewriteRuleSubtreeStream(adaptor, "rule location");
    pushMsg("create database statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:784:5: ( KW_CREATE ( KW_DATABASE | KW_SCHEMA ) ( ifNotExists )? name= identifier ( databaseComment )? ( location )? ( KW_WITH KW_DBPROPERTIES dbprops= dbProperties )? -> ^( TOK_CREATEDATABASE $name ( ifNotExists )? ( location )? ( databaseComment )? ( $dbprops)? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:784:7: KW_CREATE ( KW_DATABASE | KW_SCHEMA ) ( ifNotExists )? name= identifier ( databaseComment )? ( location )? ( KW_WITH KW_DBPROPERTIES dbprops= dbProperties )?
      {
        KW_CREATE85 = (Token) match(input, KW_CREATE, FOLLOW_KW_CREATE_in_createDatabaseStatement2168);
        stream_KW_CREATE.add(KW_CREATE85);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:784:17: ( KW_DATABASE | KW_SCHEMA )
        int alt14 = 2;
        switch (input.LA(1)) {
          case KW_DATABASE: {
            alt14 = 1;
          }
            break;
          case KW_SCHEMA: {
            alt14 = 2;
          }
            break;
          default:
            NoViableAltException nvae = new NoViableAltException("", 14, 0, input);

            throw nvae;
        }

        switch (alt14) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:784:18: KW_DATABASE
          {
            KW_DATABASE86 = (Token) match(input, KW_DATABASE, FOLLOW_KW_DATABASE_in_createDatabaseStatement2171);
            stream_KW_DATABASE.add(KW_DATABASE86);
          }
            break;
          case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:784:30: KW_SCHEMA
          {
            KW_SCHEMA87 = (Token) match(input, KW_SCHEMA, FOLLOW_KW_SCHEMA_in_createDatabaseStatement2173);
            stream_KW_SCHEMA.add(KW_SCHEMA87);
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:785:9: ( ifNotExists )?
        int alt15 = 2;
        switch (input.LA(1)) {
          case KW_IF: {
            alt15 = 1;
          }
            break;
        }

        switch (alt15) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:785:9: ifNotExists
          {
            pushFollow(FOLLOW_ifNotExists_in_createDatabaseStatement2184);
            ifNotExists88 = ifNotExists();

            state._fsp--;

            stream_ifNotExists.add(ifNotExists88.getTree());
          }
            break;
        }

        pushFollow(FOLLOW_identifier_in_createDatabaseStatement2197);
        name = identifier();

        state._fsp--;

        stream_identifier.add(name.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:787:9: ( databaseComment )?
        int alt16 = 2;
        switch (input.LA(1)) {
          case KW_COMMENT: {
            alt16 = 1;
          }
            break;
        }

        switch (alt16) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:787:9: databaseComment
          {
            pushFollow(FOLLOW_databaseComment_in_createDatabaseStatement2207);
            databaseComment89 = databaseComment();

            state._fsp--;

            stream_databaseComment.add(databaseComment89.getTree());
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:788:9: ( location )?
        int alt17 = 2;
        switch (input.LA(1)) {
          case KW_LOCATION: {
            alt17 = 1;
          }
            break;
        }

        switch (alt17) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:788:9: location
          {
            pushFollow(FOLLOW_location_in_createDatabaseStatement2218);
            location90 = location();

            state._fsp--;

            stream_location.add(location90.getTree());
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:789:9: ( KW_WITH KW_DBPROPERTIES dbprops= dbProperties )?
        int alt18 = 2;
        switch (input.LA(1)) {
          case KW_WITH: {
            alt18 = 1;
          }
            break;
        }

        switch (alt18) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:789:10: KW_WITH KW_DBPROPERTIES dbprops= dbProperties
          {
            KW_WITH91 = (Token) match(input, KW_WITH, FOLLOW_KW_WITH_in_createDatabaseStatement2230);
            stream_KW_WITH.add(KW_WITH91);

            KW_DBPROPERTIES92 =
                (Token) match(input, KW_DBPROPERTIES, FOLLOW_KW_DBPROPERTIES_in_createDatabaseStatement2232);
            stream_KW_DBPROPERTIES.add(KW_DBPROPERTIES92);

            pushFollow(FOLLOW_dbProperties_in_createDatabaseStatement2236);
            dbprops = dbProperties();

            state._fsp--;

            stream_dbProperties.add(dbprops.getTree());
          }
            break;
        }

        // AST REWRITE
        // elements: ifNotExists, dbprops, name, location, databaseComment
        // token labels:
        // rule labels: name, dbprops, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_name =
            new RewriteRuleSubtreeStream(adaptor, "rule name", name != null ? name.tree : null);
        RewriteRuleSubtreeStream stream_dbprops =
            new RewriteRuleSubtreeStream(adaptor, "rule dbprops", dbprops != null ? dbprops.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 790:5: -> ^( TOK_CREATEDATABASE $name ( ifNotExists )? ( location )? ( databaseComment )? ( $dbprops)? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:790:8: ^( TOK_CREATEDATABASE $name ( ifNotExists )? ( location )? ( databaseComment )? ( $dbprops)? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_CREATEDATABASE, "TOK_CREATEDATABASE"), root_1);

            adaptor.addChild(root_1, stream_name.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:790:35: ( ifNotExists )?
            if (stream_ifNotExists.hasNext()) {
              adaptor.addChild(root_1, stream_ifNotExists.nextTree());
            }
            stream_ifNotExists.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:790:48: ( location )?
            if (stream_location.hasNext()) {
              adaptor.addChild(root_1, stream_location.nextTree());
            }
            stream_location.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:790:58: ( databaseComment )?
            if (stream_databaseComment.hasNext()) {
              adaptor.addChild(root_1, stream_databaseComment.nextTree());
            }
            stream_databaseComment.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:790:76: ( $dbprops)?
            if (stream_dbprops.hasNext()) {
              adaptor.addChild(root_1, stream_dbprops.nextTree());
            }
            stream_dbprops.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "createDatabaseStatement"

  public static class location_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "location"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:793:1: location : KW_LOCATION locn= StringLiteral -> ^( TOK_LOCATION $locn) ;
  public final HiveParser.location_return location() throws RecognitionException {
    HiveParser.location_return retval = new HiveParser.location_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token locn = null;
    Token KW_LOCATION93 = null;

    CommonTree locn_tree = null;
    CommonTree KW_LOCATION93_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_LOCATION = new RewriteRuleTokenStream(adaptor, "token KW_LOCATION");

    pushMsg("location specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:796:5: ( KW_LOCATION locn= StringLiteral -> ^( TOK_LOCATION $locn) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:797:7: KW_LOCATION locn= StringLiteral
      {
        KW_LOCATION93 = (Token) match(input, KW_LOCATION, FOLLOW_KW_LOCATION_in_location2297);
        stream_KW_LOCATION.add(KW_LOCATION93);

        locn = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_location2301);
        stream_StringLiteral.add(locn);

        // AST REWRITE
        // elements: locn
        // token labels: locn
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_locn = new RewriteRuleTokenStream(adaptor, "token locn", locn);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 797:38: -> ^( TOK_LOCATION $locn)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:797:41: ^( TOK_LOCATION $locn)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_LOCATION, "TOK_LOCATION"), root_1);

            adaptor.addChild(root_1, stream_locn.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "location"

  public static class dbProperties_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "dbProperties"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:800:1: dbProperties : LPAREN dbPropertiesList RPAREN -> ^( TOK_DATABASEPROPERTIES dbPropertiesList ) ;
  public final HiveParser.dbProperties_return dbProperties() throws RecognitionException {
    HiveParser.dbProperties_return retval = new HiveParser.dbProperties_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token LPAREN94 = null;
    Token RPAREN96 = null;
    HiveParser.dbPropertiesList_return dbPropertiesList95 = null;

    CommonTree LPAREN94_tree = null;
    CommonTree RPAREN96_tree = null;
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleSubtreeStream stream_dbPropertiesList = new RewriteRuleSubtreeStream(adaptor, "rule dbPropertiesList");
    pushMsg("dbproperties", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:803:5: ( LPAREN dbPropertiesList RPAREN -> ^( TOK_DATABASEPROPERTIES dbPropertiesList ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:804:7: LPAREN dbPropertiesList RPAREN
      {
        LPAREN94 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_dbProperties2343);
        stream_LPAREN.add(LPAREN94);

        pushFollow(FOLLOW_dbPropertiesList_in_dbProperties2345);
        dbPropertiesList95 = dbPropertiesList();

        state._fsp--;

        stream_dbPropertiesList.add(dbPropertiesList95.getTree());

        RPAREN96 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_dbProperties2347);
        stream_RPAREN.add(RPAREN96);

        // AST REWRITE
        // elements: dbPropertiesList
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 804:38: -> ^( TOK_DATABASEPROPERTIES dbPropertiesList )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:804:41: ^( TOK_DATABASEPROPERTIES dbPropertiesList )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_DATABASEPROPERTIES, "TOK_DATABASEPROPERTIES"), root_1);

            adaptor.addChild(root_1, stream_dbPropertiesList.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "dbProperties"

  public static class dbPropertiesList_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "dbPropertiesList"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:807:1: dbPropertiesList : keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_DBPROPLIST ( keyValueProperty )+ ) ;
  public final HiveParser.dbPropertiesList_return dbPropertiesList() throws RecognitionException {
    HiveParser.dbPropertiesList_return retval = new HiveParser.dbPropertiesList_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token COMMA98 = null;
    HiveParser.keyValueProperty_return keyValueProperty97 = null;

    HiveParser.keyValueProperty_return keyValueProperty99 = null;

    CommonTree COMMA98_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleSubtreeStream stream_keyValueProperty = new RewriteRuleSubtreeStream(adaptor, "rule keyValueProperty");
    pushMsg("database properties list", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:810:5: ( keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_DBPROPLIST ( keyValueProperty )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:811:7: keyValueProperty ( COMMA keyValueProperty )*
      {
        pushFollow(FOLLOW_keyValueProperty_in_dbPropertiesList2388);
        keyValueProperty97 = keyValueProperty();

        state._fsp--;

        stream_keyValueProperty.add(keyValueProperty97.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:811:24: ( COMMA keyValueProperty )*
        loop19: do {
          int alt19 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt19 = 1;
            }
              break;
          }

          switch (alt19) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:811:25: COMMA keyValueProperty
            {
              COMMA98 = (Token) match(input, COMMA, FOLLOW_COMMA_in_dbPropertiesList2391);
              stream_COMMA.add(COMMA98);

              pushFollow(FOLLOW_keyValueProperty_in_dbPropertiesList2393);
              keyValueProperty99 = keyValueProperty();

              state._fsp--;

              stream_keyValueProperty.add(keyValueProperty99.getTree());
            }
              break;

            default:
              break loop19;
          }
        } while (true);

        // AST REWRITE
        // elements: keyValueProperty
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 811:50: -> ^( TOK_DBPROPLIST ( keyValueProperty )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:811:53: ^( TOK_DBPROPLIST ( keyValueProperty )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DBPROPLIST, "TOK_DBPROPLIST"), root_1);

            if (!(stream_keyValueProperty.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_keyValueProperty.hasNext()) {
              adaptor.addChild(root_1, stream_keyValueProperty.nextTree());
            }
            stream_keyValueProperty.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "dbPropertiesList"

  public static class switchDatabaseStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "switchDatabaseStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:815:1: switchDatabaseStatement : KW_USE identifier -> ^( TOK_SWITCHDATABASE identifier ) ;
  public final HiveParser.switchDatabaseStatement_return switchDatabaseStatement() throws RecognitionException {
    HiveParser.switchDatabaseStatement_return retval = new HiveParser.switchDatabaseStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_USE100 = null;
    HiveParser_IdentifiersParser.identifier_return identifier101 = null;

    CommonTree KW_USE100_tree = null;
    RewriteRuleTokenStream stream_KW_USE = new RewriteRuleTokenStream(adaptor, "token KW_USE");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    pushMsg("switch database statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:818:5: ( KW_USE identifier -> ^( TOK_SWITCHDATABASE identifier ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:818:7: KW_USE identifier
      {
        KW_USE100 = (Token) match(input, KW_USE, FOLLOW_KW_USE_in_switchDatabaseStatement2432);
        stream_KW_USE.add(KW_USE100);

        pushFollow(FOLLOW_identifier_in_switchDatabaseStatement2434);
        identifier101 = identifier();

        state._fsp--;

        stream_identifier.add(identifier101.getTree());

        // AST REWRITE
        // elements: identifier
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 819:5: -> ^( TOK_SWITCHDATABASE identifier )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:819:8: ^( TOK_SWITCHDATABASE identifier )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_SWITCHDATABASE, "TOK_SWITCHDATABASE"), root_1);

            adaptor.addChild(root_1, stream_identifier.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "switchDatabaseStatement"

  public static class dropDatabaseStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "dropDatabaseStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:822:1: dropDatabaseStatement : KW_DROP ( KW_DATABASE | KW_SCHEMA ) ( ifExists )? identifier ( restrictOrCascade )? -> ^( TOK_DROPDATABASE identifier ( ifExists )? ( restrictOrCascade )? ) ;
  public final HiveParser.dropDatabaseStatement_return dropDatabaseStatement() throws RecognitionException {
    HiveParser.dropDatabaseStatement_return retval = new HiveParser.dropDatabaseStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_DROP102 = null;
    Token KW_DATABASE103 = null;
    Token KW_SCHEMA104 = null;
    HiveParser.ifExists_return ifExists105 = null;

    HiveParser_IdentifiersParser.identifier_return identifier106 = null;

    HiveParser.restrictOrCascade_return restrictOrCascade107 = null;

    CommonTree KW_DROP102_tree = null;
    CommonTree KW_DATABASE103_tree = null;
    CommonTree KW_SCHEMA104_tree = null;
    RewriteRuleTokenStream stream_KW_DROP = new RewriteRuleTokenStream(adaptor, "token KW_DROP");
    RewriteRuleTokenStream stream_KW_SCHEMA = new RewriteRuleTokenStream(adaptor, "token KW_SCHEMA");
    RewriteRuleTokenStream stream_KW_DATABASE = new RewriteRuleTokenStream(adaptor, "token KW_DATABASE");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_ifExists = new RewriteRuleSubtreeStream(adaptor, "rule ifExists");
    RewriteRuleSubtreeStream stream_restrictOrCascade = new RewriteRuleSubtreeStream(adaptor, "rule restrictOrCascade");
    pushMsg("drop database statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:825:5: ( KW_DROP ( KW_DATABASE | KW_SCHEMA ) ( ifExists )? identifier ( restrictOrCascade )? -> ^( TOK_DROPDATABASE identifier ( ifExists )? ( restrictOrCascade )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:825:7: KW_DROP ( KW_DATABASE | KW_SCHEMA ) ( ifExists )? identifier ( restrictOrCascade )?
      {
        KW_DROP102 = (Token) match(input, KW_DROP, FOLLOW_KW_DROP_in_dropDatabaseStatement2473);
        stream_KW_DROP.add(KW_DROP102);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:825:15: ( KW_DATABASE | KW_SCHEMA )
        int alt20 = 2;
        switch (input.LA(1)) {
          case KW_DATABASE: {
            alt20 = 1;
          }
            break;
          case KW_SCHEMA: {
            alt20 = 2;
          }
            break;
          default:
            NoViableAltException nvae = new NoViableAltException("", 20, 0, input);

            throw nvae;
        }

        switch (alt20) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:825:16: KW_DATABASE
          {
            KW_DATABASE103 = (Token) match(input, KW_DATABASE, FOLLOW_KW_DATABASE_in_dropDatabaseStatement2476);
            stream_KW_DATABASE.add(KW_DATABASE103);
          }
            break;
          case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:825:28: KW_SCHEMA
          {
            KW_SCHEMA104 = (Token) match(input, KW_SCHEMA, FOLLOW_KW_SCHEMA_in_dropDatabaseStatement2478);
            stream_KW_SCHEMA.add(KW_SCHEMA104);
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:825:39: ( ifExists )?
        int alt21 = 2;
        switch (input.LA(1)) {
          case KW_IF: {
            alt21 = 1;
          }
            break;
        }

        switch (alt21) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:825:39: ifExists
          {
            pushFollow(FOLLOW_ifExists_in_dropDatabaseStatement2481);
            ifExists105 = ifExists();

            state._fsp--;

            stream_ifExists.add(ifExists105.getTree());
          }
            break;
        }

        pushFollow(FOLLOW_identifier_in_dropDatabaseStatement2484);
        identifier106 = identifier();

        state._fsp--;

        stream_identifier.add(identifier106.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:825:60: ( restrictOrCascade )?
        int alt22 = 2;
        switch (input.LA(1)) {
          case KW_CASCADE:
          case KW_RESTRICT: {
            alt22 = 1;
          }
            break;
        }

        switch (alt22) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:825:60: restrictOrCascade
          {
            pushFollow(FOLLOW_restrictOrCascade_in_dropDatabaseStatement2486);
            restrictOrCascade107 = restrictOrCascade();

            state._fsp--;

            stream_restrictOrCascade.add(restrictOrCascade107.getTree());
          }
            break;
        }

        // AST REWRITE
        // elements: ifExists, restrictOrCascade, identifier
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 826:5: -> ^( TOK_DROPDATABASE identifier ( ifExists )? ( restrictOrCascade )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:826:8: ^( TOK_DROPDATABASE identifier ( ifExists )? ( restrictOrCascade )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DROPDATABASE, "TOK_DROPDATABASE"),
                root_1);

            adaptor.addChild(root_1, stream_identifier.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:826:38: ( ifExists )?
            if (stream_ifExists.hasNext()) {
              adaptor.addChild(root_1, stream_ifExists.nextTree());
            }
            stream_ifExists.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:826:48: ( restrictOrCascade )?
            if (stream_restrictOrCascade.hasNext()) {
              adaptor.addChild(root_1, stream_restrictOrCascade.nextTree());
            }
            stream_restrictOrCascade.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "dropDatabaseStatement"

  public static class databaseComment_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "databaseComment"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:829:1: databaseComment : KW_COMMENT comment= StringLiteral -> ^( TOK_DATABASECOMMENT $comment) ;
  public final HiveParser.databaseComment_return databaseComment() throws RecognitionException {
    HiveParser.databaseComment_return retval = new HiveParser.databaseComment_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token comment = null;
    Token KW_COMMENT108 = null;

    CommonTree comment_tree = null;
    CommonTree KW_COMMENT108_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_COMMENT = new RewriteRuleTokenStream(adaptor, "token KW_COMMENT");

    pushMsg("database's comment", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:832:5: ( KW_COMMENT comment= StringLiteral -> ^( TOK_DATABASECOMMENT $comment) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:832:7: KW_COMMENT comment= StringLiteral
      {
        KW_COMMENT108 = (Token) match(input, KW_COMMENT, FOLLOW_KW_COMMENT_in_databaseComment2532);
        stream_KW_COMMENT.add(KW_COMMENT108);

        comment = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_databaseComment2536);
        stream_StringLiteral.add(comment);

        // AST REWRITE
        // elements: comment
        // token labels: comment
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_comment = new RewriteRuleTokenStream(adaptor, "token comment", comment);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 833:5: -> ^( TOK_DATABASECOMMENT $comment)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:833:8: ^( TOK_DATABASECOMMENT $comment)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_DATABASECOMMENT, "TOK_DATABASECOMMENT"), root_1);

            adaptor.addChild(root_1, stream_comment.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "databaseComment"

  public static class createTableStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "createTableStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:836:1: createTableStatement : KW_CREATE (temp= KW_TEMPORARY )? (ext= KW_EXTERNAL )? KW_TABLE ( ifNotExists )? name= tableName (like= KW_LIKE likeName= tableName ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? | ( LPAREN columnNameTypeList RPAREN )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? ( KW_AS selectStatementWithCTE )? ) -> ^( TOK_CREATETABLE $name ( $temp)? ( $ext)? ( ifNotExists )? ^( TOK_LIKETABLE ( $likeName)? ) ( columnNameTypeList )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? ( selectStatementWithCTE )? ) ;
  public final HiveParser.createTableStatement_return createTableStatement() throws RecognitionException {
    HiveParser.createTableStatement_return retval = new HiveParser.createTableStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token temp = null;
    Token ext = null;
    Token like = null;
    Token KW_CREATE109 = null;
    Token KW_TABLE110 = null;
    Token LPAREN116 = null;
    Token RPAREN118 = null;
    Token KW_AS127 = null;
    HiveParser_FromClauseParser.tableName_return name = null;

    HiveParser_FromClauseParser.tableName_return likeName = null;

    HiveParser.ifNotExists_return ifNotExists111 = null;

    HiveParser.tableRowFormat_return tableRowFormat112 = null;

    HiveParser.tableFileFormat_return tableFileFormat113 = null;

    HiveParser.location_return location114 = null;

    HiveParser.tablePropertiesPrefixed_return tablePropertiesPrefixed115 = null;

    HiveParser.columnNameTypeList_return columnNameTypeList117 = null;

    HiveParser.tableComment_return tableComment119 = null;

    HiveParser.tablePartition_return tablePartition120 = null;

    HiveParser.tableBuckets_return tableBuckets121 = null;

    HiveParser.tableSkewed_return tableSkewed122 = null;

    HiveParser.tableRowFormat_return tableRowFormat123 = null;

    HiveParser.tableFileFormat_return tableFileFormat124 = null;

    HiveParser.location_return location125 = null;

    HiveParser.tablePropertiesPrefixed_return tablePropertiesPrefixed126 = null;

    HiveParser.selectStatementWithCTE_return selectStatementWithCTE128 = null;

    CommonTree temp_tree = null;
    CommonTree ext_tree = null;
    CommonTree like_tree = null;
    CommonTree KW_CREATE109_tree = null;
    CommonTree KW_TABLE110_tree = null;
    CommonTree LPAREN116_tree = null;
    CommonTree RPAREN118_tree = null;
    CommonTree KW_AS127_tree = null;
    RewriteRuleTokenStream stream_KW_TEMPORARY = new RewriteRuleTokenStream(adaptor, "token KW_TEMPORARY");
    RewriteRuleTokenStream stream_KW_CREATE = new RewriteRuleTokenStream(adaptor, "token KW_CREATE");
    RewriteRuleTokenStream stream_KW_EXTERNAL = new RewriteRuleTokenStream(adaptor, "token KW_EXTERNAL");
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleTokenStream stream_KW_AS = new RewriteRuleTokenStream(adaptor, "token KW_AS");
    RewriteRuleTokenStream stream_KW_LIKE = new RewriteRuleTokenStream(adaptor, "token KW_LIKE");
    RewriteRuleSubtreeStream stream_tableRowFormat = new RewriteRuleSubtreeStream(adaptor, "rule tableRowFormat");
    RewriteRuleSubtreeStream stream_selectStatementWithCTE =
        new RewriteRuleSubtreeStream(adaptor, "rule selectStatementWithCTE");
    RewriteRuleSubtreeStream stream_tableSkewed = new RewriteRuleSubtreeStream(adaptor, "rule tableSkewed");
    RewriteRuleSubtreeStream stream_tablePropertiesPrefixed =
        new RewriteRuleSubtreeStream(adaptor, "rule tablePropertiesPrefixed");
    RewriteRuleSubtreeStream stream_ifNotExists = new RewriteRuleSubtreeStream(adaptor, "rule ifNotExists");
    RewriteRuleSubtreeStream stream_tableFileFormat = new RewriteRuleSubtreeStream(adaptor, "rule tableFileFormat");
    RewriteRuleSubtreeStream stream_tableComment = new RewriteRuleSubtreeStream(adaptor, "rule tableComment");
    RewriteRuleSubtreeStream stream_location = new RewriteRuleSubtreeStream(adaptor, "rule location");
    RewriteRuleSubtreeStream stream_tablePartition = new RewriteRuleSubtreeStream(adaptor, "rule tablePartition");
    RewriteRuleSubtreeStream stream_tableBuckets = new RewriteRuleSubtreeStream(adaptor, "rule tableBuckets");
    RewriteRuleSubtreeStream stream_columnNameTypeList =
        new RewriteRuleSubtreeStream(adaptor, "rule columnNameTypeList");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    pushMsg("create table statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:839:5: ( KW_CREATE (temp= KW_TEMPORARY )? (ext= KW_EXTERNAL )? KW_TABLE ( ifNotExists )? name= tableName (like= KW_LIKE likeName= tableName ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? | ( LPAREN columnNameTypeList RPAREN )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? ( KW_AS selectStatementWithCTE )? ) -> ^( TOK_CREATETABLE $name ( $temp)? ( $ext)? ( ifNotExists )? ^( TOK_LIKETABLE ( $likeName)? ) ( columnNameTypeList )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? ( selectStatementWithCTE )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:839:7: KW_CREATE (temp= KW_TEMPORARY )? (ext= KW_EXTERNAL )? KW_TABLE ( ifNotExists )? name= tableName (like= KW_LIKE likeName= tableName ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? | ( LPAREN columnNameTypeList RPAREN )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? ( KW_AS selectStatementWithCTE )? )
      {
        KW_CREATE109 = (Token) match(input, KW_CREATE, FOLLOW_KW_CREATE_in_createTableStatement2576);
        stream_KW_CREATE.add(KW_CREATE109);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:839:17: (temp= KW_TEMPORARY )?
        int alt23 = 2;
        switch (input.LA(1)) {
          case KW_TEMPORARY: {
            alt23 = 1;
          }
            break;
        }

        switch (alt23) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:839:18: temp= KW_TEMPORARY
          {
            temp = (Token) match(input, KW_TEMPORARY, FOLLOW_KW_TEMPORARY_in_createTableStatement2581);
            stream_KW_TEMPORARY.add(temp);
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:839:38: (ext= KW_EXTERNAL )?
        int alt24 = 2;
        switch (input.LA(1)) {
          case KW_EXTERNAL: {
            alt24 = 1;
          }
            break;
        }

        switch (alt24) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:839:39: ext= KW_EXTERNAL
          {
            ext = (Token) match(input, KW_EXTERNAL, FOLLOW_KW_EXTERNAL_in_createTableStatement2588);
            stream_KW_EXTERNAL.add(ext);
          }
            break;
        }

        KW_TABLE110 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_createTableStatement2592);
        stream_KW_TABLE.add(KW_TABLE110);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:839:66: ( ifNotExists )?
        int alt25 = 2;
        switch (input.LA(1)) {
          case KW_IF: {
            alt25 = 1;
          }
            break;
        }

        switch (alt25) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:839:66: ifNotExists
          {
            pushFollow(FOLLOW_ifNotExists_in_createTableStatement2594);
            ifNotExists111 = ifNotExists();

            state._fsp--;

            stream_ifNotExists.add(ifNotExists111.getTree());
          }
            break;
        }

        pushFollow(FOLLOW_tableName_in_createTableStatement2599);
        name = tableName();

        state._fsp--;

        stream_tableName.add(name.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:840:7: (like= KW_LIKE likeName= tableName ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? | ( LPAREN columnNameTypeList RPAREN )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? ( KW_AS selectStatementWithCTE )? )
        int alt40 = 2;
        switch (input.LA(1)) {
          case KW_LIKE: {
            alt40 = 1;
          }
            break;
          case EOF:
          case KW_AS:
          case KW_CLUSTERED:
          case KW_COMMENT:
          case KW_LOCATION:
          case KW_PARTITIONED:
          case KW_ROW:
          case KW_SKEWED:
          case KW_STORED:
          case KW_TBLPROPERTIES:
          case LPAREN: {
            alt40 = 2;
          }
            break;
          default:
            NoViableAltException nvae = new NoViableAltException("", 40, 0, input);

            throw nvae;
        }

        switch (alt40) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:840:10: like= KW_LIKE likeName= tableName ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )?
          {
            like = (Token) match(input, KW_LIKE, FOLLOW_KW_LIKE_in_createTableStatement2612);
            stream_KW_LIKE.add(like);

            pushFollow(FOLLOW_tableName_in_createTableStatement2616);
            likeName = tableName();

            state._fsp--;

            stream_tableName.add(likeName.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:841:10: ( tableRowFormat )?
            int alt26 = 2;
            switch (input.LA(1)) {
              case KW_ROW: {
                alt26 = 1;
              }
                break;
            }

            switch (alt26) {
              case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:841:10: tableRowFormat
              {
                pushFollow(FOLLOW_tableRowFormat_in_createTableStatement2627);
                tableRowFormat112 = tableRowFormat();

                state._fsp--;

                stream_tableRowFormat.add(tableRowFormat112.getTree());
              }
                break;
            }

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:842:10: ( tableFileFormat )?
            int alt27 = 2;
            switch (input.LA(1)) {
              case KW_STORED: {
                alt27 = 1;
              }
                break;
            }

            switch (alt27) {
              case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:842:10: tableFileFormat
              {
                pushFollow(FOLLOW_tableFileFormat_in_createTableStatement2639);
                tableFileFormat113 = tableFileFormat();

                state._fsp--;

                stream_tableFileFormat.add(tableFileFormat113.getTree());
              }
                break;
            }

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:843:10: ( location )?
            int alt28 = 2;
            switch (input.LA(1)) {
              case KW_LOCATION: {
                alt28 = 1;
              }
                break;
            }

            switch (alt28) {
              case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:843:10: location
              {
                pushFollow(FOLLOW_location_in_createTableStatement2651);
                location114 = location();

                state._fsp--;

                stream_location.add(location114.getTree());
              }
                break;
            }

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:844:10: ( tablePropertiesPrefixed )?
            int alt29 = 2;
            switch (input.LA(1)) {
              case KW_TBLPROPERTIES: {
                alt29 = 1;
              }
                break;
            }

            switch (alt29) {
              case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:844:10: tablePropertiesPrefixed
              {
                pushFollow(FOLLOW_tablePropertiesPrefixed_in_createTableStatement2663);
                tablePropertiesPrefixed115 = tablePropertiesPrefixed();

                state._fsp--;

                stream_tablePropertiesPrefixed.add(tablePropertiesPrefixed115.getTree());
              }
                break;
            }
          }
            break;
          case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:845:10: ( LPAREN columnNameTypeList RPAREN )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? ( KW_AS selectStatementWithCTE )?
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:845:10: ( LPAREN columnNameTypeList RPAREN )?
            int alt30 = 2;
            switch (input.LA(1)) {
              case LPAREN: {
                alt30 = 1;
              }
                break;
            }

            switch (alt30) {
              case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:845:11: LPAREN columnNameTypeList RPAREN
              {
                LPAREN116 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_createTableStatement2676);
                stream_LPAREN.add(LPAREN116);

                pushFollow(FOLLOW_columnNameTypeList_in_createTableStatement2678);
                columnNameTypeList117 = columnNameTypeList();

                state._fsp--;

                stream_columnNameTypeList.add(columnNameTypeList117.getTree());

                RPAREN118 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_createTableStatement2680);
                stream_RPAREN.add(RPAREN118);
              }
                break;
            }

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:846:10: ( tableComment )?
            int alt31 = 2;
            switch (input.LA(1)) {
              case KW_COMMENT: {
                alt31 = 1;
              }
                break;
            }

            switch (alt31) {
              case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:846:10: tableComment
              {
                pushFollow(FOLLOW_tableComment_in_createTableStatement2693);
                tableComment119 = tableComment();

                state._fsp--;

                stream_tableComment.add(tableComment119.getTree());
              }
                break;
            }

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:847:10: ( tablePartition )?
            int alt32 = 2;
            switch (input.LA(1)) {
              case KW_PARTITIONED: {
                alt32 = 1;
              }
                break;
            }

            switch (alt32) {
              case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:847:10: tablePartition
              {
                pushFollow(FOLLOW_tablePartition_in_createTableStatement2705);
                tablePartition120 = tablePartition();

                state._fsp--;

                stream_tablePartition.add(tablePartition120.getTree());
              }
                break;
            }

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:848:10: ( tableBuckets )?
            int alt33 = 2;
            switch (input.LA(1)) {
              case KW_CLUSTERED: {
                alt33 = 1;
              }
                break;
            }

            switch (alt33) {
              case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:848:10: tableBuckets
              {
                pushFollow(FOLLOW_tableBuckets_in_createTableStatement2717);
                tableBuckets121 = tableBuckets();

                state._fsp--;

                stream_tableBuckets.add(tableBuckets121.getTree());
              }
                break;
            }

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:849:10: ( tableSkewed )?
            int alt34 = 2;
            switch (input.LA(1)) {
              case KW_SKEWED: {
                alt34 = 1;
              }
                break;
            }

            switch (alt34) {
              case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:849:10: tableSkewed
              {
                pushFollow(FOLLOW_tableSkewed_in_createTableStatement2729);
                tableSkewed122 = tableSkewed();

                state._fsp--;

                stream_tableSkewed.add(tableSkewed122.getTree());
              }
                break;
            }

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:850:10: ( tableRowFormat )?
            int alt35 = 2;
            switch (input.LA(1)) {
              case KW_ROW: {
                alt35 = 1;
              }
                break;
            }

            switch (alt35) {
              case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:850:10: tableRowFormat
              {
                pushFollow(FOLLOW_tableRowFormat_in_createTableStatement2741);
                tableRowFormat123 = tableRowFormat();

                state._fsp--;

                stream_tableRowFormat.add(tableRowFormat123.getTree());
              }
                break;
            }

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:851:10: ( tableFileFormat )?
            int alt36 = 2;
            switch (input.LA(1)) {
              case KW_STORED: {
                alt36 = 1;
              }
                break;
            }

            switch (alt36) {
              case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:851:10: tableFileFormat
              {
                pushFollow(FOLLOW_tableFileFormat_in_createTableStatement2753);
                tableFileFormat124 = tableFileFormat();

                state._fsp--;

                stream_tableFileFormat.add(tableFileFormat124.getTree());
              }
                break;
            }

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:852:10: ( location )?
            int alt37 = 2;
            switch (input.LA(1)) {
              case KW_LOCATION: {
                alt37 = 1;
              }
                break;
            }

            switch (alt37) {
              case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:852:10: location
              {
                pushFollow(FOLLOW_location_in_createTableStatement2765);
                location125 = location();

                state._fsp--;

                stream_location.add(location125.getTree());
              }
                break;
            }

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:853:10: ( tablePropertiesPrefixed )?
            int alt38 = 2;
            switch (input.LA(1)) {
              case KW_TBLPROPERTIES: {
                alt38 = 1;
              }
                break;
            }

            switch (alt38) {
              case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:853:10: tablePropertiesPrefixed
              {
                pushFollow(FOLLOW_tablePropertiesPrefixed_in_createTableStatement2777);
                tablePropertiesPrefixed126 = tablePropertiesPrefixed();

                state._fsp--;

                stream_tablePropertiesPrefixed.add(tablePropertiesPrefixed126.getTree());
              }
                break;
            }

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:854:10: ( KW_AS selectStatementWithCTE )?
            int alt39 = 2;
            switch (input.LA(1)) {
              case KW_AS: {
                alt39 = 1;
              }
                break;
            }

            switch (alt39) {
              case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:854:11: KW_AS selectStatementWithCTE
              {
                KW_AS127 = (Token) match(input, KW_AS, FOLLOW_KW_AS_in_createTableStatement2790);
                stream_KW_AS.add(KW_AS127);

                pushFollow(FOLLOW_selectStatementWithCTE_in_createTableStatement2792);
                selectStatementWithCTE128 = selectStatementWithCTE();

                state._fsp--;

                stream_selectStatementWithCTE.add(selectStatementWithCTE128.getTree());
              }
                break;
            }
          }
            break;
        }

        // AST REWRITE
        // elements: temp, tableSkewed, tableRowFormat, tableBuckets, tableFileFormat, selectStatementWithCTE, tablePropertiesPrefixed, likeName, tablePartition, location, columnNameTypeList, ifNotExists, name, tableComment, ext
        // token labels: ext, temp
        // rule labels: likeName, name, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_ext = new RewriteRuleTokenStream(adaptor, "token ext", ext);
        RewriteRuleTokenStream stream_temp = new RewriteRuleTokenStream(adaptor, "token temp", temp);
        RewriteRuleSubtreeStream stream_likeName =
            new RewriteRuleSubtreeStream(adaptor, "rule likeName", likeName != null ? likeName.tree : null);
        RewriteRuleSubtreeStream stream_name =
            new RewriteRuleSubtreeStream(adaptor, "rule name", name != null ? name.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 856:5: -> ^( TOK_CREATETABLE $name ( $temp)? ( $ext)? ( ifNotExists )? ^( TOK_LIKETABLE ( $likeName)? ) ( columnNameTypeList )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? ( selectStatementWithCTE )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:856:8: ^( TOK_CREATETABLE $name ( $temp)? ( $ext)? ( ifNotExists )? ^( TOK_LIKETABLE ( $likeName)? ) ( columnNameTypeList )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? ( selectStatementWithCTE )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_CREATETABLE, "TOK_CREATETABLE"),
                root_1);

            adaptor.addChild(root_1, stream_name.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:856:33: ( $temp)?
            if (stream_temp.hasNext()) {
              adaptor.addChild(root_1, stream_temp.nextNode());
            }
            stream_temp.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:856:40: ( $ext)?
            if (stream_ext.hasNext()) {
              adaptor.addChild(root_1, stream_ext.nextNode());
            }
            stream_ext.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:856:45: ( ifNotExists )?
            if (stream_ifNotExists.hasNext()) {
              adaptor.addChild(root_1, stream_ifNotExists.nextTree());
            }
            stream_ifNotExists.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:857:10: ^( TOK_LIKETABLE ( $likeName)? )
            {
              CommonTree root_2 = (CommonTree) adaptor.nil();
              root_2 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_LIKETABLE, "TOK_LIKETABLE"), root_2);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:857:27: ( $likeName)?
              if (stream_likeName.hasNext()) {
                adaptor.addChild(root_2, stream_likeName.nextTree());
              }
              stream_likeName.reset();

              adaptor.addChild(root_1, root_2);
            }

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:858:10: ( columnNameTypeList )?
            if (stream_columnNameTypeList.hasNext()) {
              adaptor.addChild(root_1, stream_columnNameTypeList.nextTree());
            }
            stream_columnNameTypeList.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:859:10: ( tableComment )?
            if (stream_tableComment.hasNext()) {
              adaptor.addChild(root_1, stream_tableComment.nextTree());
            }
            stream_tableComment.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:860:10: ( tablePartition )?
            if (stream_tablePartition.hasNext()) {
              adaptor.addChild(root_1, stream_tablePartition.nextTree());
            }
            stream_tablePartition.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:861:10: ( tableBuckets )?
            if (stream_tableBuckets.hasNext()) {
              adaptor.addChild(root_1, stream_tableBuckets.nextTree());
            }
            stream_tableBuckets.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:862:10: ( tableSkewed )?
            if (stream_tableSkewed.hasNext()) {
              adaptor.addChild(root_1, stream_tableSkewed.nextTree());
            }
            stream_tableSkewed.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:863:10: ( tableRowFormat )?
            if (stream_tableRowFormat.hasNext()) {
              adaptor.addChild(root_1, stream_tableRowFormat.nextTree());
            }
            stream_tableRowFormat.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:864:10: ( tableFileFormat )?
            if (stream_tableFileFormat.hasNext()) {
              adaptor.addChild(root_1, stream_tableFileFormat.nextTree());
            }
            stream_tableFileFormat.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:865:10: ( location )?
            if (stream_location.hasNext()) {
              adaptor.addChild(root_1, stream_location.nextTree());
            }
            stream_location.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:866:10: ( tablePropertiesPrefixed )?
            if (stream_tablePropertiesPrefixed.hasNext()) {
              adaptor.addChild(root_1, stream_tablePropertiesPrefixed.nextTree());
            }
            stream_tablePropertiesPrefixed.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:867:10: ( selectStatementWithCTE )?
            if (stream_selectStatementWithCTE.hasNext()) {
              adaptor.addChild(root_1, stream_selectStatementWithCTE.nextTree());
            }
            stream_selectStatementWithCTE.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "createTableStatement"

  public static class truncateTableStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "truncateTableStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:871:1: truncateTableStatement : KW_TRUNCATE KW_TABLE tablePartitionPrefix ( KW_COLUMNS LPAREN columnNameList RPAREN )? -> ^( TOK_TRUNCATETABLE tablePartitionPrefix ( columnNameList )? ) ;
  public final HiveParser.truncateTableStatement_return truncateTableStatement() throws RecognitionException {
    HiveParser.truncateTableStatement_return retval = new HiveParser.truncateTableStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_TRUNCATE129 = null;
    Token KW_TABLE130 = null;
    Token KW_COLUMNS132 = null;
    Token LPAREN133 = null;
    Token RPAREN135 = null;
    HiveParser.tablePartitionPrefix_return tablePartitionPrefix131 = null;

    HiveParser.columnNameList_return columnNameList134 = null;

    CommonTree KW_TRUNCATE129_tree = null;
    CommonTree KW_TABLE130_tree = null;
    CommonTree KW_COLUMNS132_tree = null;
    CommonTree LPAREN133_tree = null;
    CommonTree RPAREN135_tree = null;
    RewriteRuleTokenStream stream_KW_COLUMNS = new RewriteRuleTokenStream(adaptor, "token KW_COLUMNS");
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_KW_TRUNCATE = new RewriteRuleTokenStream(adaptor, "token KW_TRUNCATE");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleSubtreeStream stream_tablePartitionPrefix =
        new RewriteRuleSubtreeStream(adaptor, "rule tablePartitionPrefix");
    RewriteRuleSubtreeStream stream_columnNameList = new RewriteRuleSubtreeStream(adaptor, "rule columnNameList");
    pushMsg("truncate table statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:874:5: ( KW_TRUNCATE KW_TABLE tablePartitionPrefix ( KW_COLUMNS LPAREN columnNameList RPAREN )? -> ^( TOK_TRUNCATETABLE tablePartitionPrefix ( columnNameList )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:874:7: KW_TRUNCATE KW_TABLE tablePartitionPrefix ( KW_COLUMNS LPAREN columnNameList RPAREN )?
      {
        KW_TRUNCATE129 = (Token) match(input, KW_TRUNCATE, FOLLOW_KW_TRUNCATE_in_truncateTableStatement2999);
        stream_KW_TRUNCATE.add(KW_TRUNCATE129);

        KW_TABLE130 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_truncateTableStatement3001);
        stream_KW_TABLE.add(KW_TABLE130);

        pushFollow(FOLLOW_tablePartitionPrefix_in_truncateTableStatement3003);
        tablePartitionPrefix131 = tablePartitionPrefix();

        state._fsp--;

        stream_tablePartitionPrefix.add(tablePartitionPrefix131.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:874:49: ( KW_COLUMNS LPAREN columnNameList RPAREN )?
        int alt41 = 2;
        switch (input.LA(1)) {
          case KW_COLUMNS: {
            alt41 = 1;
          }
            break;
        }

        switch (alt41) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:874:50: KW_COLUMNS LPAREN columnNameList RPAREN
          {
            KW_COLUMNS132 = (Token) match(input, KW_COLUMNS, FOLLOW_KW_COLUMNS_in_truncateTableStatement3006);
            stream_KW_COLUMNS.add(KW_COLUMNS132);

            LPAREN133 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_truncateTableStatement3008);
            stream_LPAREN.add(LPAREN133);

            pushFollow(FOLLOW_columnNameList_in_truncateTableStatement3010);
            columnNameList134 = columnNameList();

            state._fsp--;

            stream_columnNameList.add(columnNameList134.getTree());

            RPAREN135 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_truncateTableStatement3012);
            stream_RPAREN.add(RPAREN135);
          }
            break;
        }

        // AST REWRITE
        // elements: tablePartitionPrefix, columnNameList
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 874:92: -> ^( TOK_TRUNCATETABLE tablePartitionPrefix ( columnNameList )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:874:95: ^( TOK_TRUNCATETABLE tablePartitionPrefix ( columnNameList )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_TRUNCATETABLE, "TOK_TRUNCATETABLE"), root_1);

            adaptor.addChild(root_1, stream_tablePartitionPrefix.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:874:136: ( columnNameList )?
            if (stream_columnNameList.hasNext()) {
              adaptor.addChild(root_1, stream_columnNameList.nextTree());
            }
            stream_columnNameList.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "truncateTableStatement"

  public static class createIndexStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "createIndexStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:876:1: createIndexStatement : KW_CREATE KW_INDEX indexName= identifier KW_ON KW_TABLE tab= tableName LPAREN indexedCols= columnNameList RPAREN KW_AS typeName= StringLiteral ( autoRebuild )? ( indexPropertiesPrefixed )? ( indexTblName )? ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? ( indexComment )? -> ^( TOK_CREATEINDEX $indexName $typeName $tab $indexedCols ( autoRebuild )? ( indexPropertiesPrefixed )? ( indexTblName )? ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? ( indexComment )? ) ;
  public final HiveParser.createIndexStatement_return createIndexStatement() throws RecognitionException {
    HiveParser.createIndexStatement_return retval = new HiveParser.createIndexStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token typeName = null;
    Token KW_CREATE136 = null;
    Token KW_INDEX137 = null;
    Token KW_ON138 = null;
    Token KW_TABLE139 = null;
    Token LPAREN140 = null;
    Token RPAREN141 = null;
    Token KW_AS142 = null;
    HiveParser_IdentifiersParser.identifier_return indexName = null;

    HiveParser_FromClauseParser.tableName_return tab = null;

    HiveParser.columnNameList_return indexedCols = null;

    HiveParser.autoRebuild_return autoRebuild143 = null;

    HiveParser.indexPropertiesPrefixed_return indexPropertiesPrefixed144 = null;

    HiveParser.indexTblName_return indexTblName145 = null;

    HiveParser.tableRowFormat_return tableRowFormat146 = null;

    HiveParser.tableFileFormat_return tableFileFormat147 = null;

    HiveParser.location_return location148 = null;

    HiveParser.tablePropertiesPrefixed_return tablePropertiesPrefixed149 = null;

    HiveParser.indexComment_return indexComment150 = null;

    CommonTree typeName_tree = null;
    CommonTree KW_CREATE136_tree = null;
    CommonTree KW_INDEX137_tree = null;
    CommonTree KW_ON138_tree = null;
    CommonTree KW_TABLE139_tree = null;
    CommonTree LPAREN140_tree = null;
    CommonTree RPAREN141_tree = null;
    CommonTree KW_AS142_tree = null;
    RewriteRuleTokenStream stream_KW_CREATE = new RewriteRuleTokenStream(adaptor, "token KW_CREATE");
    RewriteRuleTokenStream stream_KW_INDEX = new RewriteRuleTokenStream(adaptor, "token KW_INDEX");
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_KW_ON = new RewriteRuleTokenStream(adaptor, "token KW_ON");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleTokenStream stream_KW_AS = new RewriteRuleTokenStream(adaptor, "token KW_AS");
    RewriteRuleSubtreeStream stream_tableRowFormat = new RewriteRuleSubtreeStream(adaptor, "rule tableRowFormat");
    RewriteRuleSubtreeStream stream_indexComment = new RewriteRuleSubtreeStream(adaptor, "rule indexComment");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_tablePropertiesPrefixed =
        new RewriteRuleSubtreeStream(adaptor, "rule tablePropertiesPrefixed");
    RewriteRuleSubtreeStream stream_tableFileFormat = new RewriteRuleSubtreeStream(adaptor, "rule tableFileFormat");
    RewriteRuleSubtreeStream stream_location = new RewriteRuleSubtreeStream(adaptor, "rule location");
    RewriteRuleSubtreeStream stream_columnNameList = new RewriteRuleSubtreeStream(adaptor, "rule columnNameList");
    RewriteRuleSubtreeStream stream_indexTblName = new RewriteRuleSubtreeStream(adaptor, "rule indexTblName");
    RewriteRuleSubtreeStream stream_autoRebuild = new RewriteRuleSubtreeStream(adaptor, "rule autoRebuild");
    RewriteRuleSubtreeStream stream_indexPropertiesPrefixed =
        new RewriteRuleSubtreeStream(adaptor, "rule indexPropertiesPrefixed");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    pushMsg("create index statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:879:5: ( KW_CREATE KW_INDEX indexName= identifier KW_ON KW_TABLE tab= tableName LPAREN indexedCols= columnNameList RPAREN KW_AS typeName= StringLiteral ( autoRebuild )? ( indexPropertiesPrefixed )? ( indexTblName )? ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? ( indexComment )? -> ^( TOK_CREATEINDEX $indexName $typeName $tab $indexedCols ( autoRebuild )? ( indexPropertiesPrefixed )? ( indexTblName )? ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? ( indexComment )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:879:7: KW_CREATE KW_INDEX indexName= identifier KW_ON KW_TABLE tab= tableName LPAREN indexedCols= columnNameList RPAREN KW_AS typeName= StringLiteral ( autoRebuild )? ( indexPropertiesPrefixed )? ( indexTblName )? ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? ( indexComment )?
      {
        KW_CREATE136 = (Token) match(input, KW_CREATE, FOLLOW_KW_CREATE_in_createIndexStatement3047);
        stream_KW_CREATE.add(KW_CREATE136);

        KW_INDEX137 = (Token) match(input, KW_INDEX, FOLLOW_KW_INDEX_in_createIndexStatement3049);
        stream_KW_INDEX.add(KW_INDEX137);

        pushFollow(FOLLOW_identifier_in_createIndexStatement3053);
        indexName = identifier();

        state._fsp--;

        stream_identifier.add(indexName.getTree());

        KW_ON138 = (Token) match(input, KW_ON, FOLLOW_KW_ON_in_createIndexStatement3061);
        stream_KW_ON.add(KW_ON138);

        KW_TABLE139 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_createIndexStatement3063);
        stream_KW_TABLE.add(KW_TABLE139);

        pushFollow(FOLLOW_tableName_in_createIndexStatement3067);
        tab = tableName();

        state._fsp--;

        stream_tableName.add(tab.getTree());

        LPAREN140 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_createIndexStatement3069);
        stream_LPAREN.add(LPAREN140);

        pushFollow(FOLLOW_columnNameList_in_createIndexStatement3073);
        indexedCols = columnNameList();

        state._fsp--;

        stream_columnNameList.add(indexedCols.getTree());

        RPAREN141 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_createIndexStatement3075);
        stream_RPAREN.add(RPAREN141);

        KW_AS142 = (Token) match(input, KW_AS, FOLLOW_KW_AS_in_createIndexStatement3083);
        stream_KW_AS.add(KW_AS142);

        typeName = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_createIndexStatement3087);
        stream_StringLiteral.add(typeName);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:882:7: ( autoRebuild )?
        int alt42 = 2;
        switch (input.LA(1)) {
          case KW_WITH: {
            alt42 = 1;
          }
            break;
        }

        switch (alt42) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:882:7: autoRebuild
          {
            pushFollow(FOLLOW_autoRebuild_in_createIndexStatement3095);
            autoRebuild143 = autoRebuild();

            state._fsp--;

            stream_autoRebuild.add(autoRebuild143.getTree());
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:883:7: ( indexPropertiesPrefixed )?
        int alt43 = 2;
        switch (input.LA(1)) {
          case KW_IDXPROPERTIES: {
            alt43 = 1;
          }
            break;
        }

        switch (alt43) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:883:7: indexPropertiesPrefixed
          {
            pushFollow(FOLLOW_indexPropertiesPrefixed_in_createIndexStatement3104);
            indexPropertiesPrefixed144 = indexPropertiesPrefixed();

            state._fsp--;

            stream_indexPropertiesPrefixed.add(indexPropertiesPrefixed144.getTree());
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:884:7: ( indexTblName )?
        int alt44 = 2;
        switch (input.LA(1)) {
          case KW_IN: {
            alt44 = 1;
          }
            break;
        }

        switch (alt44) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:884:7: indexTblName
          {
            pushFollow(FOLLOW_indexTblName_in_createIndexStatement3113);
            indexTblName145 = indexTblName();

            state._fsp--;

            stream_indexTblName.add(indexTblName145.getTree());
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:885:7: ( tableRowFormat )?
        int alt45 = 2;
        switch (input.LA(1)) {
          case KW_ROW: {
            alt45 = 1;
          }
            break;
        }

        switch (alt45) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:885:7: tableRowFormat
          {
            pushFollow(FOLLOW_tableRowFormat_in_createIndexStatement3122);
            tableRowFormat146 = tableRowFormat();

            state._fsp--;

            stream_tableRowFormat.add(tableRowFormat146.getTree());
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:886:7: ( tableFileFormat )?
        int alt46 = 2;
        switch (input.LA(1)) {
          case KW_STORED: {
            alt46 = 1;
          }
            break;
        }

        switch (alt46) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:886:7: tableFileFormat
          {
            pushFollow(FOLLOW_tableFileFormat_in_createIndexStatement3131);
            tableFileFormat147 = tableFileFormat();

            state._fsp--;

            stream_tableFileFormat.add(tableFileFormat147.getTree());
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:887:7: ( location )?
        int alt47 = 2;
        switch (input.LA(1)) {
          case KW_LOCATION: {
            alt47 = 1;
          }
            break;
        }

        switch (alt47) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:887:7: location
          {
            pushFollow(FOLLOW_location_in_createIndexStatement3140);
            location148 = location();

            state._fsp--;

            stream_location.add(location148.getTree());
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:888:7: ( tablePropertiesPrefixed )?
        int alt48 = 2;
        switch (input.LA(1)) {
          case KW_TBLPROPERTIES: {
            alt48 = 1;
          }
            break;
        }

        switch (alt48) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:888:7: tablePropertiesPrefixed
          {
            pushFollow(FOLLOW_tablePropertiesPrefixed_in_createIndexStatement3149);
            tablePropertiesPrefixed149 = tablePropertiesPrefixed();

            state._fsp--;

            stream_tablePropertiesPrefixed.add(tablePropertiesPrefixed149.getTree());
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:889:7: ( indexComment )?
        int alt49 = 2;
        switch (input.LA(1)) {
          case KW_COMMENT: {
            alt49 = 1;
          }
            break;
        }

        switch (alt49) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:889:7: indexComment
          {
            pushFollow(FOLLOW_indexComment_in_createIndexStatement3158);
            indexComment150 = indexComment();

            state._fsp--;

            stream_indexComment.add(indexComment150.getTree());
          }
            break;
        }

        // AST REWRITE
        // elements: autoRebuild, tableRowFormat, tab, indexName, indexTblName, tableFileFormat, location, indexPropertiesPrefixed, tablePropertiesPrefixed, indexedCols, indexComment, typeName
        // token labels: typeName
        // rule labels: indexedCols, tab, indexName, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_typeName = new RewriteRuleTokenStream(adaptor, "token typeName", typeName);
        RewriteRuleSubtreeStream stream_indexedCols =
            new RewriteRuleSubtreeStream(adaptor, "rule indexedCols", indexedCols != null ? indexedCols.tree : null);
        RewriteRuleSubtreeStream stream_tab =
            new RewriteRuleSubtreeStream(adaptor, "rule tab", tab != null ? tab.tree : null);
        RewriteRuleSubtreeStream stream_indexName =
            new RewriteRuleSubtreeStream(adaptor, "rule indexName", indexName != null ? indexName.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 890:5: -> ^( TOK_CREATEINDEX $indexName $typeName $tab $indexedCols ( autoRebuild )? ( indexPropertiesPrefixed )? ( indexTblName )? ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? ( indexComment )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:890:7: ^( TOK_CREATEINDEX $indexName $typeName $tab $indexedCols ( autoRebuild )? ( indexPropertiesPrefixed )? ( indexTblName )? ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? ( indexComment )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_CREATEINDEX, "TOK_CREATEINDEX"),
                root_1);

            adaptor.addChild(root_1, stream_indexName.nextTree());

            adaptor.addChild(root_1, stream_typeName.nextNode());

            adaptor.addChild(root_1, stream_tab.nextTree());

            adaptor.addChild(root_1, stream_indexedCols.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:891:9: ( autoRebuild )?
            if (stream_autoRebuild.hasNext()) {
              adaptor.addChild(root_1, stream_autoRebuild.nextTree());
            }
            stream_autoRebuild.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:892:9: ( indexPropertiesPrefixed )?
            if (stream_indexPropertiesPrefixed.hasNext()) {
              adaptor.addChild(root_1, stream_indexPropertiesPrefixed.nextTree());
            }
            stream_indexPropertiesPrefixed.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:893:9: ( indexTblName )?
            if (stream_indexTblName.hasNext()) {
              adaptor.addChild(root_1, stream_indexTblName.nextTree());
            }
            stream_indexTblName.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:894:9: ( tableRowFormat )?
            if (stream_tableRowFormat.hasNext()) {
              adaptor.addChild(root_1, stream_tableRowFormat.nextTree());
            }
            stream_tableRowFormat.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:895:9: ( tableFileFormat )?
            if (stream_tableFileFormat.hasNext()) {
              adaptor.addChild(root_1, stream_tableFileFormat.nextTree());
            }
            stream_tableFileFormat.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:896:9: ( location )?
            if (stream_location.hasNext()) {
              adaptor.addChild(root_1, stream_location.nextTree());
            }
            stream_location.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:897:9: ( tablePropertiesPrefixed )?
            if (stream_tablePropertiesPrefixed.hasNext()) {
              adaptor.addChild(root_1, stream_tablePropertiesPrefixed.nextTree());
            }
            stream_tablePropertiesPrefixed.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:898:9: ( indexComment )?
            if (stream_indexComment.hasNext()) {
              adaptor.addChild(root_1, stream_indexComment.nextTree());
            }
            stream_indexComment.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "createIndexStatement"

  public static class indexComment_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "indexComment"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:901:1: indexComment : KW_COMMENT comment= StringLiteral -> ^( TOK_INDEXCOMMENT $comment) ;
  public final HiveParser.indexComment_return indexComment() throws RecognitionException {
    HiveParser.indexComment_return retval = new HiveParser.indexComment_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token comment = null;
    Token KW_COMMENT151 = null;

    CommonTree comment_tree = null;
    CommonTree KW_COMMENT151_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_COMMENT = new RewriteRuleTokenStream(adaptor, "token KW_COMMENT");

    pushMsg("comment on an index", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:904:9: ( KW_COMMENT comment= StringLiteral -> ^( TOK_INDEXCOMMENT $comment) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:905:17: KW_COMMENT comment= StringLiteral
      {
        KW_COMMENT151 = (Token) match(input, KW_COMMENT, FOLLOW_KW_COMMENT_in_indexComment3315);
        stream_KW_COMMENT.add(KW_COMMENT151);

        comment = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_indexComment3319);
        stream_StringLiteral.add(comment);

        // AST REWRITE
        // elements: comment
        // token labels: comment
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_comment = new RewriteRuleTokenStream(adaptor, "token comment", comment);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 905:51: -> ^( TOK_INDEXCOMMENT $comment)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:905:54: ^( TOK_INDEXCOMMENT $comment)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_INDEXCOMMENT, "TOK_INDEXCOMMENT"),
                root_1);

            adaptor.addChild(root_1, stream_comment.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "indexComment"

  public static class autoRebuild_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "autoRebuild"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:908:1: autoRebuild : KW_WITH KW_DEFERRED KW_REBUILD -> ^( TOK_DEFERRED_REBUILDINDEX ) ;
  public final HiveParser.autoRebuild_return autoRebuild() throws RecognitionException {
    HiveParser.autoRebuild_return retval = new HiveParser.autoRebuild_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_WITH152 = null;
    Token KW_DEFERRED153 = null;
    Token KW_REBUILD154 = null;

    CommonTree KW_WITH152_tree = null;
    CommonTree KW_DEFERRED153_tree = null;
    CommonTree KW_REBUILD154_tree = null;
    RewriteRuleTokenStream stream_KW_REBUILD = new RewriteRuleTokenStream(adaptor, "token KW_REBUILD");
    RewriteRuleTokenStream stream_KW_WITH = new RewriteRuleTokenStream(adaptor, "token KW_WITH");
    RewriteRuleTokenStream stream_KW_DEFERRED = new RewriteRuleTokenStream(adaptor, "token KW_DEFERRED");

    pushMsg("auto rebuild index", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:911:5: ( KW_WITH KW_DEFERRED KW_REBUILD -> ^( TOK_DEFERRED_REBUILDINDEX ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:911:7: KW_WITH KW_DEFERRED KW_REBUILD
      {
        KW_WITH152 = (Token) match(input, KW_WITH, FOLLOW_KW_WITH_in_autoRebuild3360);
        stream_KW_WITH.add(KW_WITH152);

        KW_DEFERRED153 = (Token) match(input, KW_DEFERRED, FOLLOW_KW_DEFERRED_in_autoRebuild3362);
        stream_KW_DEFERRED.add(KW_DEFERRED153);

        KW_REBUILD154 = (Token) match(input, KW_REBUILD, FOLLOW_KW_REBUILD_in_autoRebuild3364);
        stream_KW_REBUILD.add(KW_REBUILD154);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 912:5: -> ^( TOK_DEFERRED_REBUILDINDEX )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:912:7: ^( TOK_DEFERRED_REBUILDINDEX )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_DEFERRED_REBUILDINDEX, "TOK_DEFERRED_REBUILDINDEX"), root_1);

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "autoRebuild"

  public static class indexTblName_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "indexTblName"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:915:1: indexTblName : KW_IN KW_TABLE indexTbl= tableName -> ^( TOK_CREATEINDEX_INDEXTBLNAME $indexTbl) ;
  public final HiveParser.indexTblName_return indexTblName() throws RecognitionException {
    HiveParser.indexTblName_return retval = new HiveParser.indexTblName_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_IN155 = null;
    Token KW_TABLE156 = null;
    HiveParser_FromClauseParser.tableName_return indexTbl = null;

    CommonTree KW_IN155_tree = null;
    CommonTree KW_TABLE156_tree = null;
    RewriteRuleTokenStream stream_KW_IN = new RewriteRuleTokenStream(adaptor, "token KW_IN");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    pushMsg("index table name", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:918:5: ( KW_IN KW_TABLE indexTbl= tableName -> ^( TOK_CREATEINDEX_INDEXTBLNAME $indexTbl) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:918:7: KW_IN KW_TABLE indexTbl= tableName
      {
        KW_IN155 = (Token) match(input, KW_IN, FOLLOW_KW_IN_in_indexTblName3400);
        stream_KW_IN.add(KW_IN155);

        KW_TABLE156 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_indexTblName3402);
        stream_KW_TABLE.add(KW_TABLE156);

        pushFollow(FOLLOW_tableName_in_indexTblName3406);
        indexTbl = tableName();

        state._fsp--;

        stream_tableName.add(indexTbl.getTree());

        // AST REWRITE
        // elements: indexTbl
        // token labels:
        // rule labels: indexTbl, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_indexTbl =
            new RewriteRuleSubtreeStream(adaptor, "rule indexTbl", indexTbl != null ? indexTbl.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 919:5: -> ^( TOK_CREATEINDEX_INDEXTBLNAME $indexTbl)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:919:7: ^( TOK_CREATEINDEX_INDEXTBLNAME $indexTbl)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_CREATEINDEX_INDEXTBLNAME, "TOK_CREATEINDEX_INDEXTBLNAME"), root_1);

            adaptor.addChild(root_1, stream_indexTbl.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "indexTblName"

  public static class indexPropertiesPrefixed_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "indexPropertiesPrefixed"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:922:1: indexPropertiesPrefixed : KW_IDXPROPERTIES ! indexProperties ;
  public final HiveParser.indexPropertiesPrefixed_return indexPropertiesPrefixed() throws RecognitionException {
    HiveParser.indexPropertiesPrefixed_return retval = new HiveParser.indexPropertiesPrefixed_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_IDXPROPERTIES157 = null;
    HiveParser.indexProperties_return indexProperties158 = null;

    CommonTree KW_IDXPROPERTIES157_tree = null;

    pushMsg("table properties with prefix", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:925:5: ( KW_IDXPROPERTIES ! indexProperties )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:926:9: KW_IDXPROPERTIES ! indexProperties
      {
        root_0 = (CommonTree) adaptor.nil();

        KW_IDXPROPERTIES157 =
            (Token) match(input, KW_IDXPROPERTIES, FOLLOW_KW_IDXPROPERTIES_in_indexPropertiesPrefixed3453);

        pushFollow(FOLLOW_indexProperties_in_indexPropertiesPrefixed3456);
        indexProperties158 = indexProperties();

        state._fsp--;

        adaptor.addChild(root_0, indexProperties158.getTree());
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "indexPropertiesPrefixed"

  public static class indexProperties_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "indexProperties"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:929:1: indexProperties : LPAREN indexPropertiesList RPAREN -> ^( TOK_INDEXPROPERTIES indexPropertiesList ) ;
  public final HiveParser.indexProperties_return indexProperties() throws RecognitionException {
    HiveParser.indexProperties_return retval = new HiveParser.indexProperties_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token LPAREN159 = null;
    Token RPAREN161 = null;
    HiveParser.indexPropertiesList_return indexPropertiesList160 = null;

    CommonTree LPAREN159_tree = null;
    CommonTree RPAREN161_tree = null;
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleSubtreeStream stream_indexPropertiesList =
        new RewriteRuleSubtreeStream(adaptor, "rule indexPropertiesList");
    pushMsg("index properties", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:932:5: ( LPAREN indexPropertiesList RPAREN -> ^( TOK_INDEXPROPERTIES indexPropertiesList ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:933:7: LPAREN indexPropertiesList RPAREN
      {
        LPAREN159 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_indexProperties3489);
        stream_LPAREN.add(LPAREN159);

        pushFollow(FOLLOW_indexPropertiesList_in_indexProperties3491);
        indexPropertiesList160 = indexPropertiesList();

        state._fsp--;

        stream_indexPropertiesList.add(indexPropertiesList160.getTree());

        RPAREN161 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_indexProperties3493);
        stream_RPAREN.add(RPAREN161);

        // AST REWRITE
        // elements: indexPropertiesList
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 933:41: -> ^( TOK_INDEXPROPERTIES indexPropertiesList )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:933:44: ^( TOK_INDEXPROPERTIES indexPropertiesList )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_INDEXPROPERTIES, "TOK_INDEXPROPERTIES"), root_1);

            adaptor.addChild(root_1, stream_indexPropertiesList.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "indexProperties"

  public static class indexPropertiesList_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "indexPropertiesList"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:936:1: indexPropertiesList : keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_INDEXPROPLIST ( keyValueProperty )+ ) ;
  public final HiveParser.indexPropertiesList_return indexPropertiesList() throws RecognitionException {
    HiveParser.indexPropertiesList_return retval = new HiveParser.indexPropertiesList_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token COMMA163 = null;
    HiveParser.keyValueProperty_return keyValueProperty162 = null;

    HiveParser.keyValueProperty_return keyValueProperty164 = null;

    CommonTree COMMA163_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleSubtreeStream stream_keyValueProperty = new RewriteRuleSubtreeStream(adaptor, "rule keyValueProperty");
    pushMsg("index properties list", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:939:5: ( keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_INDEXPROPLIST ( keyValueProperty )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:940:7: keyValueProperty ( COMMA keyValueProperty )*
      {
        pushFollow(FOLLOW_keyValueProperty_in_indexPropertiesList3534);
        keyValueProperty162 = keyValueProperty();

        state._fsp--;

        stream_keyValueProperty.add(keyValueProperty162.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:940:24: ( COMMA keyValueProperty )*
        loop50: do {
          int alt50 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt50 = 1;
            }
              break;
          }

          switch (alt50) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:940:25: COMMA keyValueProperty
            {
              COMMA163 = (Token) match(input, COMMA, FOLLOW_COMMA_in_indexPropertiesList3537);
              stream_COMMA.add(COMMA163);

              pushFollow(FOLLOW_keyValueProperty_in_indexPropertiesList3539);
              keyValueProperty164 = keyValueProperty();

              state._fsp--;

              stream_keyValueProperty.add(keyValueProperty164.getTree());
            }
              break;

            default:
              break loop50;
          }
        } while (true);

        // AST REWRITE
        // elements: keyValueProperty
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 940:50: -> ^( TOK_INDEXPROPLIST ( keyValueProperty )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:940:53: ^( TOK_INDEXPROPLIST ( keyValueProperty )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_INDEXPROPLIST, "TOK_INDEXPROPLIST"), root_1);

            if (!(stream_keyValueProperty.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_keyValueProperty.hasNext()) {
              adaptor.addChild(root_1, stream_keyValueProperty.nextTree());
            }
            stream_keyValueProperty.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "indexPropertiesList"

  public static class dropIndexStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "dropIndexStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:943:1: dropIndexStatement : KW_DROP KW_INDEX ( ifExists )? indexName= identifier KW_ON tab= tableName -> ^( TOK_DROPINDEX $indexName $tab ( ifExists )? ) ;
  public final HiveParser.dropIndexStatement_return dropIndexStatement() throws RecognitionException {
    HiveParser.dropIndexStatement_return retval = new HiveParser.dropIndexStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_DROP165 = null;
    Token KW_INDEX166 = null;
    Token KW_ON168 = null;
    HiveParser_IdentifiersParser.identifier_return indexName = null;

    HiveParser_FromClauseParser.tableName_return tab = null;

    HiveParser.ifExists_return ifExists167 = null;

    CommonTree KW_DROP165_tree = null;
    CommonTree KW_INDEX166_tree = null;
    CommonTree KW_ON168_tree = null;
    RewriteRuleTokenStream stream_KW_DROP = new RewriteRuleTokenStream(adaptor, "token KW_DROP");
    RewriteRuleTokenStream stream_KW_INDEX = new RewriteRuleTokenStream(adaptor, "token KW_INDEX");
    RewriteRuleTokenStream stream_KW_ON = new RewriteRuleTokenStream(adaptor, "token KW_ON");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_ifExists = new RewriteRuleSubtreeStream(adaptor, "rule ifExists");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    pushMsg("drop index statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:946:5: ( KW_DROP KW_INDEX ( ifExists )? indexName= identifier KW_ON tab= tableName -> ^( TOK_DROPINDEX $indexName $tab ( ifExists )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:946:7: KW_DROP KW_INDEX ( ifExists )? indexName= identifier KW_ON tab= tableName
      {
        KW_DROP165 = (Token) match(input, KW_DROP, FOLLOW_KW_DROP_in_dropIndexStatement3577);
        stream_KW_DROP.add(KW_DROP165);

        KW_INDEX166 = (Token) match(input, KW_INDEX, FOLLOW_KW_INDEX_in_dropIndexStatement3579);
        stream_KW_INDEX.add(KW_INDEX166);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:946:24: ( ifExists )?
        int alt51 = 2;
        switch (input.LA(1)) {
          case KW_IF: {
            alt51 = 1;
          }
            break;
        }

        switch (alt51) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:946:24: ifExists
          {
            pushFollow(FOLLOW_ifExists_in_dropIndexStatement3581);
            ifExists167 = ifExists();

            state._fsp--;

            stream_ifExists.add(ifExists167.getTree());
          }
            break;
        }

        pushFollow(FOLLOW_identifier_in_dropIndexStatement3586);
        indexName = identifier();

        state._fsp--;

        stream_identifier.add(indexName.getTree());

        KW_ON168 = (Token) match(input, KW_ON, FOLLOW_KW_ON_in_dropIndexStatement3588);
        stream_KW_ON.add(KW_ON168);

        pushFollow(FOLLOW_tableName_in_dropIndexStatement3592);
        tab = tableName();

        state._fsp--;

        stream_tableName.add(tab.getTree());

        // AST REWRITE
        // elements: ifExists, tab, indexName
        // token labels:
        // rule labels: tab, indexName, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_tab =
            new RewriteRuleSubtreeStream(adaptor, "rule tab", tab != null ? tab.tree : null);
        RewriteRuleSubtreeStream stream_indexName =
            new RewriteRuleSubtreeStream(adaptor, "rule indexName", indexName != null ? indexName.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 947:5: -> ^( TOK_DROPINDEX $indexName $tab ( ifExists )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:947:7: ^( TOK_DROPINDEX $indexName $tab ( ifExists )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DROPINDEX, "TOK_DROPINDEX"), root_1);

            adaptor.addChild(root_1, stream_indexName.nextTree());

            adaptor.addChild(root_1, stream_tab.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:947:39: ( ifExists )?
            if (stream_ifExists.hasNext()) {
              adaptor.addChild(root_1, stream_ifExists.nextTree());
            }
            stream_ifExists.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "dropIndexStatement"

  public static class dropTableStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "dropTableStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:950:1: dropTableStatement : KW_DROP KW_TABLE ( ifExists )? tableName ( KW_PURGE )? ( replicationClause )? -> ^( TOK_DROPTABLE tableName ( ifExists )? ( KW_PURGE )? ( replicationClause )? ) ;
  public final HiveParser.dropTableStatement_return dropTableStatement() throws RecognitionException {
    HiveParser.dropTableStatement_return retval = new HiveParser.dropTableStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_DROP169 = null;
    Token KW_TABLE170 = null;
    Token KW_PURGE173 = null;
    HiveParser.ifExists_return ifExists171 = null;

    HiveParser_FromClauseParser.tableName_return tableName172 = null;

    HiveParser.replicationClause_return replicationClause174 = null;

    CommonTree KW_DROP169_tree = null;
    CommonTree KW_TABLE170_tree = null;
    CommonTree KW_PURGE173_tree = null;
    RewriteRuleTokenStream stream_KW_DROP = new RewriteRuleTokenStream(adaptor, "token KW_DROP");
    RewriteRuleTokenStream stream_KW_PURGE = new RewriteRuleTokenStream(adaptor, "token KW_PURGE");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleSubtreeStream stream_ifExists = new RewriteRuleSubtreeStream(adaptor, "rule ifExists");
    RewriteRuleSubtreeStream stream_replicationClause = new RewriteRuleSubtreeStream(adaptor, "rule replicationClause");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    pushMsg("drop statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:953:5: ( KW_DROP KW_TABLE ( ifExists )? tableName ( KW_PURGE )? ( replicationClause )? -> ^( TOK_DROPTABLE tableName ( ifExists )? ( KW_PURGE )? ( replicationClause )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:953:7: KW_DROP KW_TABLE ( ifExists )? tableName ( KW_PURGE )? ( replicationClause )?
      {
        KW_DROP169 = (Token) match(input, KW_DROP, FOLLOW_KW_DROP_in_dropTableStatement3637);
        stream_KW_DROP.add(KW_DROP169);

        KW_TABLE170 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_dropTableStatement3639);
        stream_KW_TABLE.add(KW_TABLE170);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:953:24: ( ifExists )?
        int alt52 = 2;
        switch (input.LA(1)) {
          case KW_IF: {
            alt52 = 1;
          }
            break;
        }

        switch (alt52) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:953:24: ifExists
          {
            pushFollow(FOLLOW_ifExists_in_dropTableStatement3641);
            ifExists171 = ifExists();

            state._fsp--;

            stream_ifExists.add(ifExists171.getTree());
          }
            break;
        }

        pushFollow(FOLLOW_tableName_in_dropTableStatement3644);
        tableName172 = tableName();

        state._fsp--;

        stream_tableName.add(tableName172.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:953:44: ( KW_PURGE )?
        int alt53 = 2;
        switch (input.LA(1)) {
          case KW_PURGE: {
            alt53 = 1;
          }
            break;
        }

        switch (alt53) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:953:44: KW_PURGE
          {
            KW_PURGE173 = (Token) match(input, KW_PURGE, FOLLOW_KW_PURGE_in_dropTableStatement3646);
            stream_KW_PURGE.add(KW_PURGE173);
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:953:54: ( replicationClause )?
        int alt54 = 2;
        switch (input.LA(1)) {
          case KW_FOR: {
            alt54 = 1;
          }
            break;
        }

        switch (alt54) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:953:54: replicationClause
          {
            pushFollow(FOLLOW_replicationClause_in_dropTableStatement3649);
            replicationClause174 = replicationClause();

            state._fsp--;

            stream_replicationClause.add(replicationClause174.getTree());
          }
            break;
        }

        // AST REWRITE
        // elements: tableName, KW_PURGE, replicationClause, ifExists
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 954:5: -> ^( TOK_DROPTABLE tableName ( ifExists )? ( KW_PURGE )? ( replicationClause )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:954:8: ^( TOK_DROPTABLE tableName ( ifExists )? ( KW_PURGE )? ( replicationClause )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DROPTABLE, "TOK_DROPTABLE"), root_1);

            adaptor.addChild(root_1, stream_tableName.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:954:34: ( ifExists )?
            if (stream_ifExists.hasNext()) {
              adaptor.addChild(root_1, stream_ifExists.nextTree());
            }
            stream_ifExists.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:954:44: ( KW_PURGE )?
            if (stream_KW_PURGE.hasNext()) {
              adaptor.addChild(root_1, stream_KW_PURGE.nextNode());
            }
            stream_KW_PURGE.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:954:54: ( replicationClause )?
            if (stream_replicationClause.hasNext()) {
              adaptor.addChild(root_1, stream_replicationClause.nextTree());
            }
            stream_replicationClause.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "dropTableStatement"

  public static class alterStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:957:1: alterStatement : ( KW_ALTER KW_TABLE tableName alterTableStatementSuffix -> ^( TOK_ALTERTABLE tableName alterTableStatementSuffix ) | KW_ALTER KW_VIEW tableName ( KW_AS )? alterViewStatementSuffix -> ^( TOK_ALTERVIEW tableName alterViewStatementSuffix ) | KW_ALTER KW_INDEX alterIndexStatementSuffix -> alterIndexStatementSuffix | KW_ALTER ( KW_DATABASE | KW_SCHEMA ) alterDatabaseStatementSuffix -> alterDatabaseStatementSuffix );
  public final HiveParser.alterStatement_return alterStatement() throws RecognitionException {
    HiveParser.alterStatement_return retval = new HiveParser.alterStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_ALTER175 = null;
    Token KW_TABLE176 = null;
    Token KW_ALTER179 = null;
    Token KW_VIEW180 = null;
    Token KW_AS182 = null;
    Token KW_ALTER184 = null;
    Token KW_INDEX185 = null;
    Token KW_ALTER187 = null;
    Token KW_DATABASE188 = null;
    Token KW_SCHEMA189 = null;
    HiveParser_FromClauseParser.tableName_return tableName177 = null;

    HiveParser.alterTableStatementSuffix_return alterTableStatementSuffix178 = null;

    HiveParser_FromClauseParser.tableName_return tableName181 = null;

    HiveParser.alterViewStatementSuffix_return alterViewStatementSuffix183 = null;

    HiveParser.alterIndexStatementSuffix_return alterIndexStatementSuffix186 = null;

    HiveParser.alterDatabaseStatementSuffix_return alterDatabaseStatementSuffix190 = null;

    CommonTree KW_ALTER175_tree = null;
    CommonTree KW_TABLE176_tree = null;
    CommonTree KW_ALTER179_tree = null;
    CommonTree KW_VIEW180_tree = null;
    CommonTree KW_AS182_tree = null;
    CommonTree KW_ALTER184_tree = null;
    CommonTree KW_INDEX185_tree = null;
    CommonTree KW_ALTER187_tree = null;
    CommonTree KW_DATABASE188_tree = null;
    CommonTree KW_SCHEMA189_tree = null;
    RewriteRuleTokenStream stream_KW_SCHEMA = new RewriteRuleTokenStream(adaptor, "token KW_SCHEMA");
    RewriteRuleTokenStream stream_KW_VIEW = new RewriteRuleTokenStream(adaptor, "token KW_VIEW");
    RewriteRuleTokenStream stream_KW_INDEX = new RewriteRuleTokenStream(adaptor, "token KW_INDEX");
    RewriteRuleTokenStream stream_KW_DATABASE = new RewriteRuleTokenStream(adaptor, "token KW_DATABASE");
    RewriteRuleTokenStream stream_KW_ALTER = new RewriteRuleTokenStream(adaptor, "token KW_ALTER");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleTokenStream stream_KW_AS = new RewriteRuleTokenStream(adaptor, "token KW_AS");
    RewriteRuleSubtreeStream stream_alterTableStatementSuffix =
        new RewriteRuleSubtreeStream(adaptor, "rule alterTableStatementSuffix");
    RewriteRuleSubtreeStream stream_alterViewStatementSuffix =
        new RewriteRuleSubtreeStream(adaptor, "rule alterViewStatementSuffix");
    RewriteRuleSubtreeStream stream_alterDatabaseStatementSuffix =
        new RewriteRuleSubtreeStream(adaptor, "rule alterDatabaseStatementSuffix");
    RewriteRuleSubtreeStream stream_alterIndexStatementSuffix =
        new RewriteRuleSubtreeStream(adaptor, "rule alterIndexStatementSuffix");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    pushMsg("alter statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:960:5: ( KW_ALTER KW_TABLE tableName alterTableStatementSuffix -> ^( TOK_ALTERTABLE tableName alterTableStatementSuffix ) | KW_ALTER KW_VIEW tableName ( KW_AS )? alterViewStatementSuffix -> ^( TOK_ALTERVIEW tableName alterViewStatementSuffix ) | KW_ALTER KW_INDEX alterIndexStatementSuffix -> alterIndexStatementSuffix | KW_ALTER ( KW_DATABASE | KW_SCHEMA ) alterDatabaseStatementSuffix -> alterDatabaseStatementSuffix )
      int alt57 = 4;
      switch (input.LA(1)) {
        case KW_ALTER: {
          switch (input.LA(2)) {
            case KW_TABLE: {
              alt57 = 1;
            }
              break;
            case KW_VIEW: {
              alt57 = 2;
            }
              break;
            case KW_INDEX: {
              alt57 = 3;
            }
              break;
            case KW_DATABASE:
            case KW_SCHEMA: {
              alt57 = 4;
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 57, 1, input);

              throw nvae;
          }
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 57, 0, input);

          throw nvae;
      }

      switch (alt57) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:960:7: KW_ALTER KW_TABLE tableName alterTableStatementSuffix
        {
          KW_ALTER175 = (Token) match(input, KW_ALTER, FOLLOW_KW_ALTER_in_alterStatement3698);
          stream_KW_ALTER.add(KW_ALTER175);

          KW_TABLE176 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_alterStatement3700);
          stream_KW_TABLE.add(KW_TABLE176);

          pushFollow(FOLLOW_tableName_in_alterStatement3702);
          tableName177 = tableName();

          state._fsp--;

          stream_tableName.add(tableName177.getTree());

          pushFollow(FOLLOW_alterTableStatementSuffix_in_alterStatement3704);
          alterTableStatementSuffix178 = alterTableStatementSuffix();

          state._fsp--;

          stream_alterTableStatementSuffix.add(alterTableStatementSuffix178.getTree());

          // AST REWRITE
          // elements: alterTableStatementSuffix, tableName
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 960:61: -> ^( TOK_ALTERTABLE tableName alterTableStatementSuffix )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:960:64: ^( TOK_ALTERTABLE tableName alterTableStatementSuffix )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_ALTERTABLE, "TOK_ALTERTABLE"),
                  root_1);

              adaptor.addChild(root_1, stream_tableName.nextTree());

              adaptor.addChild(root_1, stream_alterTableStatementSuffix.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:961:7: KW_ALTER KW_VIEW tableName ( KW_AS )? alterViewStatementSuffix
        {
          KW_ALTER179 = (Token) match(input, KW_ALTER, FOLLOW_KW_ALTER_in_alterStatement3722);
          stream_KW_ALTER.add(KW_ALTER179);

          KW_VIEW180 = (Token) match(input, KW_VIEW, FOLLOW_KW_VIEW_in_alterStatement3724);
          stream_KW_VIEW.add(KW_VIEW180);

          pushFollow(FOLLOW_tableName_in_alterStatement3726);
          tableName181 = tableName();

          state._fsp--;

          stream_tableName.add(tableName181.getTree());

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:961:34: ( KW_AS )?
          int alt55 = 2;
          switch (input.LA(1)) {
            case KW_AS: {
              alt55 = 1;
            }
              break;
          }

          switch (alt55) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:961:34: KW_AS
            {
              KW_AS182 = (Token) match(input, KW_AS, FOLLOW_KW_AS_in_alterStatement3728);
              stream_KW_AS.add(KW_AS182);
            }
              break;
          }

          pushFollow(FOLLOW_alterViewStatementSuffix_in_alterStatement3731);
          alterViewStatementSuffix183 = alterViewStatementSuffix();

          state._fsp--;

          stream_alterViewStatementSuffix.add(alterViewStatementSuffix183.getTree());

          // AST REWRITE
          // elements: tableName, alterViewStatementSuffix
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 961:66: -> ^( TOK_ALTERVIEW tableName alterViewStatementSuffix )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:961:69: ^( TOK_ALTERVIEW tableName alterViewStatementSuffix )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_ALTERVIEW, "TOK_ALTERVIEW"), root_1);

              adaptor.addChild(root_1, stream_tableName.nextTree());

              adaptor.addChild(root_1, stream_alterViewStatementSuffix.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 3:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:962:7: KW_ALTER KW_INDEX alterIndexStatementSuffix
        {
          KW_ALTER184 = (Token) match(input, KW_ALTER, FOLLOW_KW_ALTER_in_alterStatement3749);
          stream_KW_ALTER.add(KW_ALTER184);

          KW_INDEX185 = (Token) match(input, KW_INDEX, FOLLOW_KW_INDEX_in_alterStatement3751);
          stream_KW_INDEX.add(KW_INDEX185);

          pushFollow(FOLLOW_alterIndexStatementSuffix_in_alterStatement3753);
          alterIndexStatementSuffix186 = alterIndexStatementSuffix();

          state._fsp--;

          stream_alterIndexStatementSuffix.add(alterIndexStatementSuffix186.getTree());

          // AST REWRITE
          // elements: alterIndexStatementSuffix
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 962:51: -> alterIndexStatementSuffix
          {
            adaptor.addChild(root_0, stream_alterIndexStatementSuffix.nextTree());
          }

          retval.tree = root_0;
        }
          break;
        case 4:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:963:7: KW_ALTER ( KW_DATABASE | KW_SCHEMA ) alterDatabaseStatementSuffix
        {
          KW_ALTER187 = (Token) match(input, KW_ALTER, FOLLOW_KW_ALTER_in_alterStatement3765);
          stream_KW_ALTER.add(KW_ALTER187);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:963:16: ( KW_DATABASE | KW_SCHEMA )
          int alt56 = 2;
          switch (input.LA(1)) {
            case KW_DATABASE: {
              alt56 = 1;
            }
              break;
            case KW_SCHEMA: {
              alt56 = 2;
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 56, 0, input);

              throw nvae;
          }

          switch (alt56) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:963:17: KW_DATABASE
            {
              KW_DATABASE188 = (Token) match(input, KW_DATABASE, FOLLOW_KW_DATABASE_in_alterStatement3768);
              stream_KW_DATABASE.add(KW_DATABASE188);
            }
              break;
            case 2:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:963:29: KW_SCHEMA
            {
              KW_SCHEMA189 = (Token) match(input, KW_SCHEMA, FOLLOW_KW_SCHEMA_in_alterStatement3770);
              stream_KW_SCHEMA.add(KW_SCHEMA189);
            }
              break;
          }

          pushFollow(FOLLOW_alterDatabaseStatementSuffix_in_alterStatement3773);
          alterDatabaseStatementSuffix190 = alterDatabaseStatementSuffix();

          state._fsp--;

          stream_alterDatabaseStatementSuffix.add(alterDatabaseStatementSuffix190.getTree());

          // AST REWRITE
          // elements: alterDatabaseStatementSuffix
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 963:69: -> alterDatabaseStatementSuffix
          {
            adaptor.addChild(root_0, stream_alterDatabaseStatementSuffix.nextTree());
          }

          retval.tree = root_0;
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatement"

  public static class alterTableStatementSuffix_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterTableStatementSuffix"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:966:1: alterTableStatementSuffix : ( alterStatementSuffixRename[true] | alterStatementSuffixUpdateStatsCol | alterStatementSuffixDropPartitions[true] | alterStatementSuffixAddPartitions[true] | alterStatementSuffixTouch | alterStatementSuffixArchive | alterStatementSuffixUnArchive | alterStatementSuffixProperties | alterStatementSuffixSkewedby | alterStatementSuffixExchangePartition | alterStatementPartitionKeyType | ( partitionSpec )? alterTblPartitionStatementSuffix -> alterTblPartitionStatementSuffix ( partitionSpec )? );
  public final HiveParser.alterTableStatementSuffix_return alterTableStatementSuffix() throws RecognitionException {
    HiveParser.alterTableStatementSuffix_return retval = new HiveParser.alterTableStatementSuffix_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.alterStatementSuffixRename_return alterStatementSuffixRename191 = null;

    HiveParser.alterStatementSuffixUpdateStatsCol_return alterStatementSuffixUpdateStatsCol192 = null;

    HiveParser.alterStatementSuffixDropPartitions_return alterStatementSuffixDropPartitions193 = null;

    HiveParser.alterStatementSuffixAddPartitions_return alterStatementSuffixAddPartitions194 = null;

    HiveParser.alterStatementSuffixTouch_return alterStatementSuffixTouch195 = null;

    HiveParser.alterStatementSuffixArchive_return alterStatementSuffixArchive196 = null;

    HiveParser.alterStatementSuffixUnArchive_return alterStatementSuffixUnArchive197 = null;

    HiveParser.alterStatementSuffixProperties_return alterStatementSuffixProperties198 = null;

    HiveParser.alterStatementSuffixSkewedby_return alterStatementSuffixSkewedby199 = null;

    HiveParser.alterStatementSuffixExchangePartition_return alterStatementSuffixExchangePartition200 = null;

    HiveParser.alterStatementPartitionKeyType_return alterStatementPartitionKeyType201 = null;

    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec202 = null;

    HiveParser.alterTblPartitionStatementSuffix_return alterTblPartitionStatementSuffix203 = null;

    RewriteRuleSubtreeStream stream_alterTblPartitionStatementSuffix =
        new RewriteRuleSubtreeStream(adaptor, "rule alterTblPartitionStatementSuffix");
    RewriteRuleSubtreeStream stream_partitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule partitionSpec");
    pushMsg("alter table statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:969:5: ( alterStatementSuffixRename[true] | alterStatementSuffixUpdateStatsCol | alterStatementSuffixDropPartitions[true] | alterStatementSuffixAddPartitions[true] | alterStatementSuffixTouch | alterStatementSuffixArchive | alterStatementSuffixUnArchive | alterStatementSuffixProperties | alterStatementSuffixSkewedby | alterStatementSuffixExchangePartition | alterStatementPartitionKeyType | ( partitionSpec )? alterTblPartitionStatementSuffix -> alterTblPartitionStatementSuffix ( partitionSpec )? )
      int alt59 = 12;
      switch (input.LA(1)) {
        case KW_RENAME: {
          switch (input.LA(2)) {
            case KW_TO: {
              switch (input.LA(3)) {
                case Identifier:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFAULT:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_METADATA:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NONE:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH: {
                  alt59 = 1;
                }
                  break;
                case KW_PARTITION: {
                  alt59 = 1;
                }
                  break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 59, 22, input);

                  throw nvae;
              }
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 59, 1, input);

              throw nvae;
          }
        }
          break;
        case KW_UPDATE: {
          switch (input.LA(2)) {
            case KW_STATISTICS: {
              switch (input.LA(3)) {
                case KW_FOR: {
                  alt59 = 2;
                }
                  break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 59, 23, input);

                  throw nvae;
              }
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 59, 2, input);

              throw nvae;
          }
        }
          break;
        case KW_DROP: {
          alt59 = 3;
        }
          break;
        case KW_ADD: {
          switch (input.LA(2)) {
            case KW_IF:
            case KW_PARTITION: {
              alt59 = 4;
            }
              break;
            case KW_COLUMNS: {
              alt59 = 12;
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 59, 4, input);

              throw nvae;
          }
        }
          break;
        case KW_TOUCH: {
          alt59 = 5;
        }
          break;
        case KW_ARCHIVE: {
          alt59 = 6;
        }
          break;
        case KW_UNARCHIVE: {
          alt59 = 7;
        }
          break;
        case KW_SET: {
          switch (input.LA(2)) {
            case KW_TBLPROPERTIES: {
              alt59 = 8;
            }
              break;
            case KW_FILEFORMAT:
            case KW_LOCATION:
            case KW_SERDE:
            case KW_SERDEPROPERTIES:
            case KW_SKEWED: {
              alt59 = 12;
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 59, 8, input);

              throw nvae;
          }
        }
          break;
        case KW_UNSET: {
          alt59 = 8;
        }
          break;
        case KW_SKEWED: {
          alt59 = 9;
        }
          break;
        case KW_NOT: {
          switch (input.LA(2)) {
            case KW_SKEWED:
            case KW_STORED: {
              alt59 = 9;
            }
              break;
            case KW_CLUSTERED:
            case KW_SORTED: {
              alt59 = 12;
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 59, 11, input);

              throw nvae;
          }
        }
          break;
        case KW_EXCHANGE: {
          alt59 = 10;
        }
          break;
        case KW_PARTITION: {
          switch (input.LA(2)) {
            case KW_COLUMN: {
              alt59 = 11;
            }
              break;
            case LPAREN: {
              alt59 = 12;
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 59, 13, input);

              throw nvae;
          }
        }
          break;
        case KW_CHANGE:
        case KW_CLUSTERED:
        case KW_COMPACT:
        case KW_CONCATENATE:
        case KW_DISABLE:
        case KW_ENABLE:
        case KW_INTO:
        case KW_REPLACE: {
          alt59 = 12;
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 59, 0, input);

          throw nvae;
      }

      switch (alt59) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:969:7: alterStatementSuffixRename[true]
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixRename_in_alterTableStatementSuffix3804);
          alterStatementSuffixRename191 = alterStatementSuffixRename(true);

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixRename191.getTree());
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:970:7: alterStatementSuffixUpdateStatsCol
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixUpdateStatsCol_in_alterTableStatementSuffix3813);
          alterStatementSuffixUpdateStatsCol192 = alterStatementSuffixUpdateStatsCol();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixUpdateStatsCol192.getTree());
        }
          break;
        case 3:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:971:7: alterStatementSuffixDropPartitions[true]
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixDropPartitions_in_alterTableStatementSuffix3821);
          alterStatementSuffixDropPartitions193 = alterStatementSuffixDropPartitions(true);

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixDropPartitions193.getTree());
        }
          break;
        case 4:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:972:7: alterStatementSuffixAddPartitions[true]
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixAddPartitions_in_alterTableStatementSuffix3830);
          alterStatementSuffixAddPartitions194 = alterStatementSuffixAddPartitions(true);

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixAddPartitions194.getTree());
        }
          break;
        case 5:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:973:7: alterStatementSuffixTouch
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixTouch_in_alterTableStatementSuffix3839);
          alterStatementSuffixTouch195 = alterStatementSuffixTouch();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixTouch195.getTree());
        }
          break;
        case 6:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:974:7: alterStatementSuffixArchive
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixArchive_in_alterTableStatementSuffix3847);
          alterStatementSuffixArchive196 = alterStatementSuffixArchive();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixArchive196.getTree());
        }
          break;
        case 7:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:975:7: alterStatementSuffixUnArchive
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixUnArchive_in_alterTableStatementSuffix3855);
          alterStatementSuffixUnArchive197 = alterStatementSuffixUnArchive();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixUnArchive197.getTree());
        }
          break;
        case 8:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:976:7: alterStatementSuffixProperties
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixProperties_in_alterTableStatementSuffix3863);
          alterStatementSuffixProperties198 = alterStatementSuffixProperties();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixProperties198.getTree());
        }
          break;
        case 9:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:977:7: alterStatementSuffixSkewedby
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixSkewedby_in_alterTableStatementSuffix3871);
          alterStatementSuffixSkewedby199 = alterStatementSuffixSkewedby();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixSkewedby199.getTree());
        }
          break;
        case 10:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:978:7: alterStatementSuffixExchangePartition
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixExchangePartition_in_alterTableStatementSuffix3879);
          alterStatementSuffixExchangePartition200 = alterStatementSuffixExchangePartition();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixExchangePartition200.getTree());
        }
          break;
        case 11:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:979:7: alterStatementPartitionKeyType
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementPartitionKeyType_in_alterTableStatementSuffix3887);
          alterStatementPartitionKeyType201 = alterStatementPartitionKeyType();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementPartitionKeyType201.getTree());
        }
          break;
        case 12:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:980:7: ( partitionSpec )? alterTblPartitionStatementSuffix
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:980:7: ( partitionSpec )?
          int alt58 = 2;
          switch (input.LA(1)) {
            case KW_PARTITION: {
              alt58 = 1;
            }
              break;
          }

          switch (alt58) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:980:7: partitionSpec
            {
              pushFollow(FOLLOW_partitionSpec_in_alterTableStatementSuffix3895);
              partitionSpec202 = partitionSpec();

              state._fsp--;

              stream_partitionSpec.add(partitionSpec202.getTree());
            }
              break;
          }

          pushFollow(FOLLOW_alterTblPartitionStatementSuffix_in_alterTableStatementSuffix3898);
          alterTblPartitionStatementSuffix203 = alterTblPartitionStatementSuffix();

          state._fsp--;

          stream_alterTblPartitionStatementSuffix.add(alterTblPartitionStatementSuffix203.getTree());

          // AST REWRITE
          // elements: alterTblPartitionStatementSuffix, partitionSpec
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 980:55: -> alterTblPartitionStatementSuffix ( partitionSpec )?
          {
            adaptor.addChild(root_0, stream_alterTblPartitionStatementSuffix.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:980:91: ( partitionSpec )?
            if (stream_partitionSpec.hasNext()) {
              adaptor.addChild(root_0, stream_partitionSpec.nextTree());
            }
            stream_partitionSpec.reset();
          }

          retval.tree = root_0;
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterTableStatementSuffix"

  public static class alterTblPartitionStatementSuffix_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterTblPartitionStatementSuffix"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:983:1: alterTblPartitionStatementSuffix : ( alterStatementSuffixFileFormat | alterStatementSuffixLocation | alterStatementSuffixProtectMode | alterStatementSuffixMergeFiles | alterStatementSuffixSerdeProperties | alterStatementSuffixRenamePart | alterStatementSuffixBucketNum | alterTblPartitionStatementSuffixSkewedLocation | alterStatementSuffixClusterbySortby | alterStatementSuffixCompact | alterStatementSuffixUpdateStatsCol | alterStatementSuffixRenameCol | alterStatementSuffixAddCol );
  public final HiveParser.alterTblPartitionStatementSuffix_return alterTblPartitionStatementSuffix()
      throws RecognitionException {
    HiveParser.alterTblPartitionStatementSuffix_return retval =
        new HiveParser.alterTblPartitionStatementSuffix_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.alterStatementSuffixFileFormat_return alterStatementSuffixFileFormat204 = null;

    HiveParser.alterStatementSuffixLocation_return alterStatementSuffixLocation205 = null;

    HiveParser.alterStatementSuffixProtectMode_return alterStatementSuffixProtectMode206 = null;

    HiveParser.alterStatementSuffixMergeFiles_return alterStatementSuffixMergeFiles207 = null;

    HiveParser.alterStatementSuffixSerdeProperties_return alterStatementSuffixSerdeProperties208 = null;

    HiveParser.alterStatementSuffixRenamePart_return alterStatementSuffixRenamePart209 = null;

    HiveParser.alterStatementSuffixBucketNum_return alterStatementSuffixBucketNum210 = null;

    HiveParser.alterTblPartitionStatementSuffixSkewedLocation_return alterTblPartitionStatementSuffixSkewedLocation211 =
        null;

    HiveParser.alterStatementSuffixClusterbySortby_return alterStatementSuffixClusterbySortby212 = null;

    HiveParser.alterStatementSuffixCompact_return alterStatementSuffixCompact213 = null;

    HiveParser.alterStatementSuffixUpdateStatsCol_return alterStatementSuffixUpdateStatsCol214 = null;

    HiveParser.alterStatementSuffixRenameCol_return alterStatementSuffixRenameCol215 = null;

    HiveParser.alterStatementSuffixAddCol_return alterStatementSuffixAddCol216 = null;

    pushMsg("alter table partition statement suffix", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:986:3: ( alterStatementSuffixFileFormat | alterStatementSuffixLocation | alterStatementSuffixProtectMode | alterStatementSuffixMergeFiles | alterStatementSuffixSerdeProperties | alterStatementSuffixRenamePart | alterStatementSuffixBucketNum | alterTblPartitionStatementSuffixSkewedLocation | alterStatementSuffixClusterbySortby | alterStatementSuffixCompact | alterStatementSuffixUpdateStatsCol | alterStatementSuffixRenameCol | alterStatementSuffixAddCol )
      int alt60 = 13;
      switch (input.LA(1)) {
        case KW_SET: {
          switch (input.LA(2)) {
            case KW_FILEFORMAT: {
              alt60 = 1;
            }
              break;
            case KW_SERDE:
            case KW_SERDEPROPERTIES: {
              alt60 = 5;
            }
              break;
            case KW_SKEWED: {
              alt60 = 8;
            }
              break;
            case KW_LOCATION: {
              alt60 = 2;
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 60, 1, input);

              throw nvae;
          }
        }
          break;
        case KW_DISABLE:
        case KW_ENABLE: {
          alt60 = 3;
        }
          break;
        case KW_CONCATENATE: {
          alt60 = 4;
        }
          break;
        case KW_RENAME: {
          alt60 = 6;
        }
          break;
        case KW_INTO: {
          alt60 = 7;
        }
          break;
        case KW_CLUSTERED:
        case KW_NOT: {
          alt60 = 9;
        }
          break;
        case KW_COMPACT: {
          alt60 = 10;
        }
          break;
        case KW_UPDATE: {
          alt60 = 11;
        }
          break;
        case KW_CHANGE: {
          alt60 = 12;
        }
          break;
        case KW_ADD:
        case KW_REPLACE: {
          alt60 = 13;
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 60, 0, input);

          throw nvae;
      }

      switch (alt60) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:986:5: alterStatementSuffixFileFormat
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixFileFormat_in_alterTblPartitionStatementSuffix3930);
          alterStatementSuffixFileFormat204 = alterStatementSuffixFileFormat();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixFileFormat204.getTree());
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:987:5: alterStatementSuffixLocation
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixLocation_in_alterTblPartitionStatementSuffix3936);
          alterStatementSuffixLocation205 = alterStatementSuffixLocation();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixLocation205.getTree());
        }
          break;
        case 3:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:988:5: alterStatementSuffixProtectMode
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixProtectMode_in_alterTblPartitionStatementSuffix3942);
          alterStatementSuffixProtectMode206 = alterStatementSuffixProtectMode();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixProtectMode206.getTree());
        }
          break;
        case 4:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:989:5: alterStatementSuffixMergeFiles
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixMergeFiles_in_alterTblPartitionStatementSuffix3948);
          alterStatementSuffixMergeFiles207 = alterStatementSuffixMergeFiles();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixMergeFiles207.getTree());
        }
          break;
        case 5:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:990:5: alterStatementSuffixSerdeProperties
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixSerdeProperties_in_alterTblPartitionStatementSuffix3954);
          alterStatementSuffixSerdeProperties208 = alterStatementSuffixSerdeProperties();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixSerdeProperties208.getTree());
        }
          break;
        case 6:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:991:5: alterStatementSuffixRenamePart
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixRenamePart_in_alterTblPartitionStatementSuffix3960);
          alterStatementSuffixRenamePart209 = alterStatementSuffixRenamePart();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixRenamePart209.getTree());
        }
          break;
        case 7:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:992:5: alterStatementSuffixBucketNum
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixBucketNum_in_alterTblPartitionStatementSuffix3966);
          alterStatementSuffixBucketNum210 = alterStatementSuffixBucketNum();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixBucketNum210.getTree());
        }
          break;
        case 8:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:993:5: alterTblPartitionStatementSuffixSkewedLocation
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterTblPartitionStatementSuffixSkewedLocation_in_alterTblPartitionStatementSuffix3972);
          alterTblPartitionStatementSuffixSkewedLocation211 = alterTblPartitionStatementSuffixSkewedLocation();

          state._fsp--;

          adaptor.addChild(root_0, alterTblPartitionStatementSuffixSkewedLocation211.getTree());
        }
          break;
        case 9:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:994:5: alterStatementSuffixClusterbySortby
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixClusterbySortby_in_alterTblPartitionStatementSuffix3978);
          alterStatementSuffixClusterbySortby212 = alterStatementSuffixClusterbySortby();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixClusterbySortby212.getTree());
        }
          break;
        case 10:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:995:5: alterStatementSuffixCompact
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixCompact_in_alterTblPartitionStatementSuffix3984);
          alterStatementSuffixCompact213 = alterStatementSuffixCompact();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixCompact213.getTree());
        }
          break;
        case 11:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:996:5: alterStatementSuffixUpdateStatsCol
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixUpdateStatsCol_in_alterTblPartitionStatementSuffix3990);
          alterStatementSuffixUpdateStatsCol214 = alterStatementSuffixUpdateStatsCol();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixUpdateStatsCol214.getTree());
        }
          break;
        case 12:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:997:5: alterStatementSuffixRenameCol
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixRenameCol_in_alterTblPartitionStatementSuffix3996);
          alterStatementSuffixRenameCol215 = alterStatementSuffixRenameCol();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixRenameCol215.getTree());
        }
          break;
        case 13:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:998:5: alterStatementSuffixAddCol
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixAddCol_in_alterTblPartitionStatementSuffix4002);
          alterStatementSuffixAddCol216 = alterStatementSuffixAddCol();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixAddCol216.getTree());
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterTblPartitionStatementSuffix"

  public static class alterStatementPartitionKeyType_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementPartitionKeyType"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1001:1: alterStatementPartitionKeyType : KW_PARTITION KW_COLUMN LPAREN columnNameType RPAREN -> ^( TOK_ALTERTABLE_PARTCOLTYPE columnNameType ) ;
  public final HiveParser.alterStatementPartitionKeyType_return alterStatementPartitionKeyType()
      throws RecognitionException {
    HiveParser.alterStatementPartitionKeyType_return retval = new HiveParser.alterStatementPartitionKeyType_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_PARTITION217 = null;
    Token KW_COLUMN218 = null;
    Token LPAREN219 = null;
    Token RPAREN221 = null;
    HiveParser.columnNameType_return columnNameType220 = null;

    CommonTree KW_PARTITION217_tree = null;
    CommonTree KW_COLUMN218_tree = null;
    CommonTree LPAREN219_tree = null;
    CommonTree RPAREN221_tree = null;
    RewriteRuleTokenStream stream_KW_PARTITION = new RewriteRuleTokenStream(adaptor, "token KW_PARTITION");
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleTokenStream stream_KW_COLUMN = new RewriteRuleTokenStream(adaptor, "token KW_COLUMN");
    RewriteRuleSubtreeStream stream_columnNameType = new RewriteRuleSubtreeStream(adaptor, "rule columnNameType");
    msgs.push("alter partition key type");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1004:2: ( KW_PARTITION KW_COLUMN LPAREN columnNameType RPAREN -> ^( TOK_ALTERTABLE_PARTCOLTYPE columnNameType ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1004:4: KW_PARTITION KW_COLUMN LPAREN columnNameType RPAREN
      {
        KW_PARTITION217 = (Token) match(input, KW_PARTITION, FOLLOW_KW_PARTITION_in_alterStatementPartitionKeyType4024);
        stream_KW_PARTITION.add(KW_PARTITION217);

        KW_COLUMN218 = (Token) match(input, KW_COLUMN, FOLLOW_KW_COLUMN_in_alterStatementPartitionKeyType4026);
        stream_KW_COLUMN.add(KW_COLUMN218);

        LPAREN219 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_alterStatementPartitionKeyType4028);
        stream_LPAREN.add(LPAREN219);

        pushFollow(FOLLOW_columnNameType_in_alterStatementPartitionKeyType4030);
        columnNameType220 = columnNameType();

        state._fsp--;

        stream_columnNameType.add(columnNameType220.getTree());

        RPAREN221 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_alterStatementPartitionKeyType4032);
        stream_RPAREN.add(RPAREN221);

        // AST REWRITE
        // elements: columnNameType
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1005:2: -> ^( TOK_ALTERTABLE_PARTCOLTYPE columnNameType )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1005:5: ^( TOK_ALTERTABLE_PARTCOLTYPE columnNameType )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERTABLE_PARTCOLTYPE, "TOK_ALTERTABLE_PARTCOLTYPE"), root_1);

            adaptor.addChild(root_1, stream_columnNameType.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      msgs.pop();
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementPartitionKeyType"

  public static class alterViewStatementSuffix_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterViewStatementSuffix"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1008:1: alterViewStatementSuffix : ( alterViewSuffixProperties | alterStatementSuffixRename[false] | alterStatementSuffixAddPartitions[false] | alterStatementSuffixDropPartitions[false] | selectStatementWithCTE );
  public final HiveParser.alterViewStatementSuffix_return alterViewStatementSuffix() throws RecognitionException {
    HiveParser.alterViewStatementSuffix_return retval = new HiveParser.alterViewStatementSuffix_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.alterViewSuffixProperties_return alterViewSuffixProperties222 = null;

    HiveParser.alterStatementSuffixRename_return alterStatementSuffixRename223 = null;

    HiveParser.alterStatementSuffixAddPartitions_return alterStatementSuffixAddPartitions224 = null;

    HiveParser.alterStatementSuffixDropPartitions_return alterStatementSuffixDropPartitions225 = null;

    HiveParser.selectStatementWithCTE_return selectStatementWithCTE226 = null;

    pushMsg("alter view statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1011:5: ( alterViewSuffixProperties | alterStatementSuffixRename[false] | alterStatementSuffixAddPartitions[false] | alterStatementSuffixDropPartitions[false] | selectStatementWithCTE )
      int alt61 = 5;
      switch (input.LA(1)) {
        case KW_SET:
        case KW_UNSET: {
          alt61 = 1;
        }
          break;
        case KW_RENAME: {
          alt61 = 2;
        }
          break;
        case KW_ADD: {
          alt61 = 3;
        }
          break;
        case KW_DROP: {
          alt61 = 4;
        }
          break;
        case KW_MAP:
        case KW_REDUCE:
        case KW_SELECT:
        case KW_WITH: {
          alt61 = 5;
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 61, 0, input);

          throw nvae;
      }

      switch (alt61) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1011:7: alterViewSuffixProperties
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterViewSuffixProperties_in_alterViewStatementSuffix4065);
          alterViewSuffixProperties222 = alterViewSuffixProperties();

          state._fsp--;

          adaptor.addChild(root_0, alterViewSuffixProperties222.getTree());
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1012:7: alterStatementSuffixRename[false]
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixRename_in_alterViewStatementSuffix4073);
          alterStatementSuffixRename223 = alterStatementSuffixRename(false);

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixRename223.getTree());
        }
          break;
        case 3:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1013:7: alterStatementSuffixAddPartitions[false]
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixAddPartitions_in_alterViewStatementSuffix4082);
          alterStatementSuffixAddPartitions224 = alterStatementSuffixAddPartitions(false);

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixAddPartitions224.getTree());
        }
          break;
        case 4:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1014:7: alterStatementSuffixDropPartitions[false]
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixDropPartitions_in_alterViewStatementSuffix4091);
          alterStatementSuffixDropPartitions225 = alterStatementSuffixDropPartitions(false);

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixDropPartitions225.getTree());
        }
          break;
        case 5:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1015:7: selectStatementWithCTE
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_selectStatementWithCTE_in_alterViewStatementSuffix4100);
          selectStatementWithCTE226 = selectStatementWithCTE();

          state._fsp--;

          adaptor.addChild(root_0, selectStatementWithCTE226.getTree());
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterViewStatementSuffix"

  public static class alterIndexStatementSuffix_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterIndexStatementSuffix"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1018:1: alterIndexStatementSuffix : indexName= identifier KW_ON tableName ( partitionSpec )? ( KW_REBUILD -> ^( TOK_ALTERINDEX_REBUILD tableName $indexName ( partitionSpec )? ) | KW_SET KW_IDXPROPERTIES indexProperties -> ^( TOK_ALTERINDEX_PROPERTIES tableName $indexName indexProperties ) ) ;
  public final HiveParser.alterIndexStatementSuffix_return alterIndexStatementSuffix() throws RecognitionException {
    HiveParser.alterIndexStatementSuffix_return retval = new HiveParser.alterIndexStatementSuffix_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_ON227 = null;
    Token KW_REBUILD230 = null;
    Token KW_SET231 = null;
    Token KW_IDXPROPERTIES232 = null;
    HiveParser_IdentifiersParser.identifier_return indexName = null;

    HiveParser_FromClauseParser.tableName_return tableName228 = null;

    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec229 = null;

    HiveParser.indexProperties_return indexProperties233 = null;

    CommonTree KW_ON227_tree = null;
    CommonTree KW_REBUILD230_tree = null;
    CommonTree KW_SET231_tree = null;
    CommonTree KW_IDXPROPERTIES232_tree = null;
    RewriteRuleTokenStream stream_KW_IDXPROPERTIES = new RewriteRuleTokenStream(adaptor, "token KW_IDXPROPERTIES");
    RewriteRuleTokenStream stream_KW_REBUILD = new RewriteRuleTokenStream(adaptor, "token KW_REBUILD");
    RewriteRuleTokenStream stream_KW_ON = new RewriteRuleTokenStream(adaptor, "token KW_ON");
    RewriteRuleTokenStream stream_KW_SET = new RewriteRuleTokenStream(adaptor, "token KW_SET");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_indexProperties = new RewriteRuleSubtreeStream(adaptor, "rule indexProperties");
    RewriteRuleSubtreeStream stream_partitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule partitionSpec");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    pushMsg("alter index statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1021:5: (indexName= identifier KW_ON tableName ( partitionSpec )? ( KW_REBUILD -> ^( TOK_ALTERINDEX_REBUILD tableName $indexName ( partitionSpec )? ) | KW_SET KW_IDXPROPERTIES indexProperties -> ^( TOK_ALTERINDEX_PROPERTIES tableName $indexName indexProperties ) ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1021:7: indexName= identifier KW_ON tableName ( partitionSpec )? ( KW_REBUILD -> ^( TOK_ALTERINDEX_REBUILD tableName $indexName ( partitionSpec )? ) | KW_SET KW_IDXPROPERTIES indexProperties -> ^( TOK_ALTERINDEX_PROPERTIES tableName $indexName indexProperties ) )
      {
        pushFollow(FOLLOW_identifier_in_alterIndexStatementSuffix4129);
        indexName = identifier();

        state._fsp--;

        stream_identifier.add(indexName.getTree());

        KW_ON227 = (Token) match(input, KW_ON, FOLLOW_KW_ON_in_alterIndexStatementSuffix4131);
        stream_KW_ON.add(KW_ON227);

        pushFollow(FOLLOW_tableName_in_alterIndexStatementSuffix4133);
        tableName228 = tableName();

        state._fsp--;

        stream_tableName.add(tableName228.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1021:44: ( partitionSpec )?
        int alt62 = 2;
        switch (input.LA(1)) {
          case KW_PARTITION: {
            alt62 = 1;
          }
            break;
        }

        switch (alt62) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1021:44: partitionSpec
          {
            pushFollow(FOLLOW_partitionSpec_in_alterIndexStatementSuffix4135);
            partitionSpec229 = partitionSpec();

            state._fsp--;

            stream_partitionSpec.add(partitionSpec229.getTree());
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1022:5: ( KW_REBUILD -> ^( TOK_ALTERINDEX_REBUILD tableName $indexName ( partitionSpec )? ) | KW_SET KW_IDXPROPERTIES indexProperties -> ^( TOK_ALTERINDEX_PROPERTIES tableName $indexName indexProperties ) )
        int alt63 = 2;
        switch (input.LA(1)) {
          case KW_REBUILD: {
            alt63 = 1;
          }
            break;
          case KW_SET: {
            alt63 = 2;
          }
            break;
          default:
            NoViableAltException nvae = new NoViableAltException("", 63, 0, input);

            throw nvae;
        }

        switch (alt63) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1023:7: KW_REBUILD
          {
            KW_REBUILD230 = (Token) match(input, KW_REBUILD, FOLLOW_KW_REBUILD_in_alterIndexStatementSuffix4150);
            stream_KW_REBUILD.add(KW_REBUILD230);

            // AST REWRITE
            // elements: indexName, partitionSpec, tableName
            // token labels:
            // rule labels: indexName, retval
            // token list labels:
            // rule list labels:
            // wildcard labels:
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_indexName =
                new RewriteRuleSubtreeStream(adaptor, "rule indexName", indexName != null ? indexName.tree : null);
            RewriteRuleSubtreeStream stream_retval =
                new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

            root_0 = (CommonTree) adaptor.nil();
            // 1024:7: -> ^( TOK_ALTERINDEX_REBUILD tableName $indexName ( partitionSpec )? )
            {
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1024:9: ^( TOK_ALTERINDEX_REBUILD tableName $indexName ( partitionSpec )? )
              {
                CommonTree root_1 = (CommonTree) adaptor.nil();
                root_1 = (CommonTree) adaptor
                    .becomeRoot((CommonTree) adaptor.create(TOK_ALTERINDEX_REBUILD, "TOK_ALTERINDEX_REBUILD"), root_1);

                adaptor.addChild(root_1, stream_tableName.nextTree());

                adaptor.addChild(root_1, stream_indexName.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1024:55: ( partitionSpec )?
                if (stream_partitionSpec.hasNext()) {
                  adaptor.addChild(root_1, stream_partitionSpec.nextTree());
                }
                stream_partitionSpec.reset();

                adaptor.addChild(root_0, root_1);
              }
            }

            retval.tree = root_0;
          }
            break;
          case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1026:7: KW_SET KW_IDXPROPERTIES indexProperties
          {
            KW_SET231 = (Token) match(input, KW_SET, FOLLOW_KW_SET_in_alterIndexStatementSuffix4183);
            stream_KW_SET.add(KW_SET231);

            KW_IDXPROPERTIES232 =
                (Token) match(input, KW_IDXPROPERTIES, FOLLOW_KW_IDXPROPERTIES_in_alterIndexStatementSuffix4185);
            stream_KW_IDXPROPERTIES.add(KW_IDXPROPERTIES232);

            pushFollow(FOLLOW_indexProperties_in_alterIndexStatementSuffix4193);
            indexProperties233 = indexProperties();

            state._fsp--;

            stream_indexProperties.add(indexProperties233.getTree());

            // AST REWRITE
            // elements: indexProperties, indexName, tableName
            // token labels:
            // rule labels: indexName, retval
            // token list labels:
            // rule list labels:
            // wildcard labels:
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_indexName =
                new RewriteRuleSubtreeStream(adaptor, "rule indexName", indexName != null ? indexName.tree : null);
            RewriteRuleSubtreeStream stream_retval =
                new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

            root_0 = (CommonTree) adaptor.nil();
            // 1028:7: -> ^( TOK_ALTERINDEX_PROPERTIES tableName $indexName indexProperties )
            {
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1028:9: ^( TOK_ALTERINDEX_PROPERTIES tableName $indexName indexProperties )
              {
                CommonTree root_1 = (CommonTree) adaptor.nil();
                root_1 = (CommonTree) adaptor.becomeRoot(
                    (CommonTree) adaptor.create(TOK_ALTERINDEX_PROPERTIES, "TOK_ALTERINDEX_PROPERTIES"), root_1);

                adaptor.addChild(root_1, stream_tableName.nextTree());

                adaptor.addChild(root_1, stream_indexName.nextTree());

                adaptor.addChild(root_1, stream_indexProperties.nextTree());

                adaptor.addChild(root_0, root_1);
              }
            }

            retval.tree = root_0;
          }
            break;
        }
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterIndexStatementSuffix"

  public static class alterDatabaseStatementSuffix_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterDatabaseStatementSuffix"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1032:1: alterDatabaseStatementSuffix : ( alterDatabaseSuffixProperties | alterDatabaseSuffixSetOwner );
  public final HiveParser.alterDatabaseStatementSuffix_return alterDatabaseStatementSuffix()
      throws RecognitionException {
    HiveParser.alterDatabaseStatementSuffix_return retval = new HiveParser.alterDatabaseStatementSuffix_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.alterDatabaseSuffixProperties_return alterDatabaseSuffixProperties234 = null;

    HiveParser.alterDatabaseSuffixSetOwner_return alterDatabaseSuffixSetOwner235 = null;

    pushMsg("alter database statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1035:5: ( alterDatabaseSuffixProperties | alterDatabaseSuffixSetOwner )
      int alt64 = 2;
      switch (input.LA(1)) {
        case Identifier: {
          switch (input.LA(2)) {
            case KW_SET: {
              switch (input.LA(3)) {
                case KW_DBPROPERTIES: {
                  alt64 = 1;
                }
                  break;
                case KW_OWNER: {
                  alt64 = 2;
                }
                  break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 64, 3, input);

                  throw nvae;
              }
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 64, 1, input);

              throw nvae;
          }
        }
          break;
        case KW_ADD:
        case KW_ADMIN:
        case KW_AFTER:
        case KW_ALL:
        case KW_ALTER:
        case KW_ANALYZE:
        case KW_ARCHIVE:
        case KW_ARRAY:
        case KW_AS:
        case KW_ASC:
        case KW_AUTHORIZATION:
        case KW_BEFORE:
        case KW_BETWEEN:
        case KW_BIGINT:
        case KW_BINARY:
        case KW_BOOLEAN:
        case KW_BOTH:
        case KW_BUCKET:
        case KW_BUCKETS:
        case KW_BY:
        case KW_CASCADE:
        case KW_CHANGE:
        case KW_CLUSTER:
        case KW_CLUSTERED:
        case KW_CLUSTERSTATUS:
        case KW_COLLECTION:
        case KW_COLUMNS:
        case KW_COMMENT:
        case KW_COMPACT:
        case KW_COMPACTIONS:
        case KW_COMPUTE:
        case KW_CONCATENATE:
        case KW_CONTINUE:
        case KW_CREATE:
        case KW_CUBE:
        case KW_CURSOR:
        case KW_DATA:
        case KW_DATABASES:
        case KW_DATE:
        case KW_DATETIME:
        case KW_DBPROPERTIES:
        case KW_DECIMAL:
        case KW_DEFAULT:
        case KW_DEFERRED:
        case KW_DEFINED:
        case KW_DELETE:
        case KW_DELIMITED:
        case KW_DEPENDENCY:
        case KW_DESC:
        case KW_DESCRIBE:
        case KW_DIRECTORIES:
        case KW_DIRECTORY:
        case KW_DISABLE:
        case KW_DISTRIBUTE:
        case KW_DOUBLE:
        case KW_DROP:
        case KW_ELEM_TYPE:
        case KW_ENABLE:
        case KW_ESCAPED:
        case KW_EXCLUSIVE:
        case KW_EXISTS:
        case KW_EXPLAIN:
        case KW_EXPORT:
        case KW_EXTERNAL:
        case KW_FALSE:
        case KW_FETCH:
        case KW_FIELDS:
        case KW_FILE:
        case KW_FILEFORMAT:
        case KW_FIRST:
        case KW_FLOAT:
        case KW_FOR:
        case KW_FORMAT:
        case KW_FORMATTED:
        case KW_FULL:
        case KW_FUNCTIONS:
        case KW_GRANT:
        case KW_GROUP:
        case KW_GROUPING:
        case KW_HOLD_DDLTIME:
        case KW_IDXPROPERTIES:
        case KW_IGNORE:
        case KW_IMPORT:
        case KW_IN:
        case KW_INDEX:
        case KW_INDEXES:
        case KW_INNER:
        case KW_INPATH:
        case KW_INPUTDRIVER:
        case KW_INPUTFORMAT:
        case KW_INSERT:
        case KW_INT:
        case KW_INTERSECT:
        case KW_INTO:
        case KW_IS:
        case KW_ITEMS:
        case KW_JAR:
        case KW_KEYS:
        case KW_KEY_TYPE:
        case KW_LATERAL:
        case KW_LEFT:
        case KW_LIKE:
        case KW_LIMIT:
        case KW_LINES:
        case KW_LOAD:
        case KW_LOCAL:
        case KW_LOCATION:
        case KW_LOCK:
        case KW_LOCKS:
        case KW_LOGICAL:
        case KW_LONG:
        case KW_MAPJOIN:
        case KW_MATERIALIZED:
        case KW_METADATA:
        case KW_MINUS:
        case KW_MSCK:
        case KW_NONE:
        case KW_NOSCAN:
        case KW_NO_DROP:
        case KW_NULL:
        case KW_OF:
        case KW_OFFLINE:
        case KW_OPTION:
        case KW_ORDER:
        case KW_OUT:
        case KW_OUTER:
        case KW_OUTPUTDRIVER:
        case KW_OUTPUTFORMAT:
        case KW_OVERWRITE:
        case KW_OWNER:
        case KW_PARTITION:
        case KW_PARTITIONED:
        case KW_PARTITIONS:
        case KW_PERCENT:
        case KW_PLUS:
        case KW_PRETTY:
        case KW_PRINCIPALS:
        case KW_PROCEDURE:
        case KW_PROTECTION:
        case KW_PURGE:
        case KW_RANGE:
        case KW_READ:
        case KW_READONLY:
        case KW_READS:
        case KW_REBUILD:
        case KW_RECORDREADER:
        case KW_RECORDWRITER:
        case KW_REGEXP:
        case KW_RELOAD:
        case KW_RENAME:
        case KW_REPAIR:
        case KW_REPLACE:
        case KW_REPLICATION:
        case KW_RESTRICT:
        case KW_REVOKE:
        case KW_REWRITE:
        case KW_RIGHT:
        case KW_RLIKE:
        case KW_ROLE:
        case KW_ROLES:
        case KW_ROLLUP:
        case KW_ROW:
        case KW_ROWS:
        case KW_SCHEMA:
        case KW_SCHEMAS:
        case KW_SEMI:
        case KW_SERDE:
        case KW_SERDEPROPERTIES:
        case KW_SERVER:
        case KW_SET:
        case KW_SETS:
        case KW_SHARED:
        case KW_SHOW:
        case KW_SHOW_DATABASE:
        case KW_SKEWED:
        case KW_SMALLINT:
        case KW_SORT:
        case KW_SORTED:
        case KW_SSL:
        case KW_STATISTICS:
        case KW_STORED:
        case KW_STREAMTABLE:
        case KW_STRING:
        case KW_STRUCT:
        case KW_TABLE:
        case KW_TABLES:
        case KW_TBLPROPERTIES:
        case KW_TEMPORARY:
        case KW_TERMINATED:
        case KW_TIMESTAMP:
        case KW_TINYINT:
        case KW_TO:
        case KW_TOUCH:
        case KW_TRANSACTIONS:
        case KW_TRIGGER:
        case KW_TRUE:
        case KW_TRUNCATE:
        case KW_UNARCHIVE:
        case KW_UNDO:
        case KW_UNION:
        case KW_UNIONTYPE:
        case KW_UNLOCK:
        case KW_UNSET:
        case KW_UNSIGNED:
        case KW_UPDATE:
        case KW_URI:
        case KW_USE:
        case KW_USER:
        case KW_USING:
        case KW_UTC:
        case KW_UTCTIMESTAMP:
        case KW_VALUES:
        case KW_VALUE_TYPE:
        case KW_VIEW:
        case KW_WHILE:
        case KW_WITH: {
          switch (input.LA(2)) {
            case KW_SET: {
              switch (input.LA(3)) {
                case KW_DBPROPERTIES: {
                  alt64 = 1;
                }
                  break;
                case KW_OWNER: {
                  alt64 = 2;
                }
                  break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 64, 4, input);

                  throw nvae;
              }
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 64, 2, input);

              throw nvae;
          }
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 64, 0, input);

          throw nvae;
      }

      switch (alt64) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1035:7: alterDatabaseSuffixProperties
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterDatabaseSuffixProperties_in_alterDatabaseStatementSuffix4244);
          alterDatabaseSuffixProperties234 = alterDatabaseSuffixProperties();

          state._fsp--;

          adaptor.addChild(root_0, alterDatabaseSuffixProperties234.getTree());
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1036:7: alterDatabaseSuffixSetOwner
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterDatabaseSuffixSetOwner_in_alterDatabaseStatementSuffix4252);
          alterDatabaseSuffixSetOwner235 = alterDatabaseSuffixSetOwner();

          state._fsp--;

          adaptor.addChild(root_0, alterDatabaseSuffixSetOwner235.getTree());
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterDatabaseStatementSuffix"

  public static class alterDatabaseSuffixProperties_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterDatabaseSuffixProperties"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1039:1: alterDatabaseSuffixProperties : name= identifier KW_SET KW_DBPROPERTIES dbProperties -> ^( TOK_ALTERDATABASE_PROPERTIES $name dbProperties ) ;
  public final HiveParser.alterDatabaseSuffixProperties_return alterDatabaseSuffixProperties()
      throws RecognitionException {
    HiveParser.alterDatabaseSuffixProperties_return retval = new HiveParser.alterDatabaseSuffixProperties_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_SET236 = null;
    Token KW_DBPROPERTIES237 = null;
    HiveParser_IdentifiersParser.identifier_return name = null;

    HiveParser.dbProperties_return dbProperties238 = null;

    CommonTree KW_SET236_tree = null;
    CommonTree KW_DBPROPERTIES237_tree = null;
    RewriteRuleTokenStream stream_KW_DBPROPERTIES = new RewriteRuleTokenStream(adaptor, "token KW_DBPROPERTIES");
    RewriteRuleTokenStream stream_KW_SET = new RewriteRuleTokenStream(adaptor, "token KW_SET");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_dbProperties = new RewriteRuleSubtreeStream(adaptor, "rule dbProperties");
    pushMsg("alter database properties statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1042:5: (name= identifier KW_SET KW_DBPROPERTIES dbProperties -> ^( TOK_ALTERDATABASE_PROPERTIES $name dbProperties ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1042:7: name= identifier KW_SET KW_DBPROPERTIES dbProperties
      {
        pushFollow(FOLLOW_identifier_in_alterDatabaseSuffixProperties4281);
        name = identifier();

        state._fsp--;

        stream_identifier.add(name.getTree());

        KW_SET236 = (Token) match(input, KW_SET, FOLLOW_KW_SET_in_alterDatabaseSuffixProperties4283);
        stream_KW_SET.add(KW_SET236);

        KW_DBPROPERTIES237 =
            (Token) match(input, KW_DBPROPERTIES, FOLLOW_KW_DBPROPERTIES_in_alterDatabaseSuffixProperties4285);
        stream_KW_DBPROPERTIES.add(KW_DBPROPERTIES237);

        pushFollow(FOLLOW_dbProperties_in_alterDatabaseSuffixProperties4287);
        dbProperties238 = dbProperties();

        state._fsp--;

        stream_dbProperties.add(dbProperties238.getTree());

        // AST REWRITE
        // elements: name, dbProperties
        // token labels:
        // rule labels: name, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_name =
            new RewriteRuleSubtreeStream(adaptor, "rule name", name != null ? name.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1043:5: -> ^( TOK_ALTERDATABASE_PROPERTIES $name dbProperties )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1043:8: ^( TOK_ALTERDATABASE_PROPERTIES $name dbProperties )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERDATABASE_PROPERTIES, "TOK_ALTERDATABASE_PROPERTIES"), root_1);

            adaptor.addChild(root_1, stream_name.nextTree());

            adaptor.addChild(root_1, stream_dbProperties.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterDatabaseSuffixProperties"

  public static class alterDatabaseSuffixSetOwner_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterDatabaseSuffixSetOwner"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1046:1: alterDatabaseSuffixSetOwner : dbName= identifier KW_SET KW_OWNER principalName -> ^( TOK_ALTERDATABASE_OWNER $dbName principalName ) ;
  public final HiveParser.alterDatabaseSuffixSetOwner_return alterDatabaseSuffixSetOwner() throws RecognitionException {
    HiveParser.alterDatabaseSuffixSetOwner_return retval = new HiveParser.alterDatabaseSuffixSetOwner_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_SET239 = null;
    Token KW_OWNER240 = null;
    HiveParser_IdentifiersParser.identifier_return dbName = null;

    HiveParser.principalName_return principalName241 = null;

    CommonTree KW_SET239_tree = null;
    CommonTree KW_OWNER240_tree = null;
    RewriteRuleTokenStream stream_KW_OWNER = new RewriteRuleTokenStream(adaptor, "token KW_OWNER");
    RewriteRuleTokenStream stream_KW_SET = new RewriteRuleTokenStream(adaptor, "token KW_SET");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_principalName = new RewriteRuleSubtreeStream(adaptor, "rule principalName");
    pushMsg("alter database set owner", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1049:5: (dbName= identifier KW_SET KW_OWNER principalName -> ^( TOK_ALTERDATABASE_OWNER $dbName principalName ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1049:7: dbName= identifier KW_SET KW_OWNER principalName
      {
        pushFollow(FOLLOW_identifier_in_alterDatabaseSuffixSetOwner4331);
        dbName = identifier();

        state._fsp--;

        stream_identifier.add(dbName.getTree());

        KW_SET239 = (Token) match(input, KW_SET, FOLLOW_KW_SET_in_alterDatabaseSuffixSetOwner4333);
        stream_KW_SET.add(KW_SET239);

        KW_OWNER240 = (Token) match(input, KW_OWNER, FOLLOW_KW_OWNER_in_alterDatabaseSuffixSetOwner4335);
        stream_KW_OWNER.add(KW_OWNER240);

        pushFollow(FOLLOW_principalName_in_alterDatabaseSuffixSetOwner4337);
        principalName241 = principalName();

        state._fsp--;

        stream_principalName.add(principalName241.getTree());

        // AST REWRITE
        // elements: dbName, principalName
        // token labels:
        // rule labels: dbName, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_dbName =
            new RewriteRuleSubtreeStream(adaptor, "rule dbName", dbName != null ? dbName.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1050:5: -> ^( TOK_ALTERDATABASE_OWNER $dbName principalName )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1050:8: ^( TOK_ALTERDATABASE_OWNER $dbName principalName )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_ALTERDATABASE_OWNER, "TOK_ALTERDATABASE_OWNER"), root_1);

            adaptor.addChild(root_1, stream_dbName.nextTree());

            adaptor.addChild(root_1, stream_principalName.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterDatabaseSuffixSetOwner"

  public static class alterStatementSuffixRename_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixRename"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1053:1: alterStatementSuffixRename[boolean table] : KW_RENAME KW_TO tableName -> { table }? ^( TOK_ALTERTABLE_RENAME tableName ) -> ^( TOK_ALTERVIEW_RENAME tableName ) ;
  public final HiveParser.alterStatementSuffixRename_return alterStatementSuffixRename(boolean table)
      throws RecognitionException {
    HiveParser.alterStatementSuffixRename_return retval = new HiveParser.alterStatementSuffixRename_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_RENAME242 = null;
    Token KW_TO243 = null;
    HiveParser_FromClauseParser.tableName_return tableName244 = null;

    CommonTree KW_RENAME242_tree = null;
    CommonTree KW_TO243_tree = null;
    RewriteRuleTokenStream stream_KW_RENAME = new RewriteRuleTokenStream(adaptor, "token KW_RENAME");
    RewriteRuleTokenStream stream_KW_TO = new RewriteRuleTokenStream(adaptor, "token KW_TO");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    pushMsg("rename statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1056:5: ( KW_RENAME KW_TO tableName -> { table }? ^( TOK_ALTERTABLE_RENAME tableName ) -> ^( TOK_ALTERVIEW_RENAME tableName ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1056:7: KW_RENAME KW_TO tableName
      {
        KW_RENAME242 = (Token) match(input, KW_RENAME, FOLLOW_KW_RENAME_in_alterStatementSuffixRename4380);
        stream_KW_RENAME.add(KW_RENAME242);

        KW_TO243 = (Token) match(input, KW_TO, FOLLOW_KW_TO_in_alterStatementSuffixRename4382);
        stream_KW_TO.add(KW_TO243);

        pushFollow(FOLLOW_tableName_in_alterStatementSuffixRename4384);
        tableName244 = tableName();

        state._fsp--;

        stream_tableName.add(tableName244.getTree());

        // AST REWRITE
        // elements: tableName, tableName
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1057:5: -> { table }? ^( TOK_ALTERTABLE_RENAME tableName )
        if (table) {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1057:19: ^( TOK_ALTERTABLE_RENAME tableName )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_ALTERTABLE_RENAME, "TOK_ALTERTABLE_RENAME"), root_1);

            adaptor.addChild(root_1, stream_tableName.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        } else // 1058:5: -> ^( TOK_ALTERVIEW_RENAME tableName )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1058:19: ^( TOK_ALTERVIEW_RENAME tableName )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_ALTERVIEW_RENAME, "TOK_ALTERVIEW_RENAME"), root_1);

            adaptor.addChild(root_1, stream_tableName.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixRename"

  public static class alterStatementSuffixAddCol_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixAddCol"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1061:1: alterStatementSuffixAddCol : (add= KW_ADD |replace= KW_REPLACE ) KW_COLUMNS LPAREN columnNameTypeList RPAREN ( restrictOrCascade )? -> {$add != null}? ^( TOK_ALTERTABLE_ADDCOLS columnNameTypeList ( restrictOrCascade )? ) -> ^( TOK_ALTERTABLE_REPLACECOLS columnNameTypeList ( restrictOrCascade )? ) ;
  public final HiveParser.alterStatementSuffixAddCol_return alterStatementSuffixAddCol() throws RecognitionException {
    HiveParser.alterStatementSuffixAddCol_return retval = new HiveParser.alterStatementSuffixAddCol_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token add = null;
    Token replace = null;
    Token KW_COLUMNS245 = null;
    Token LPAREN246 = null;
    Token RPAREN248 = null;
    HiveParser.columnNameTypeList_return columnNameTypeList247 = null;

    HiveParser.restrictOrCascade_return restrictOrCascade249 = null;

    CommonTree add_tree = null;
    CommonTree replace_tree = null;
    CommonTree KW_COLUMNS245_tree = null;
    CommonTree LPAREN246_tree = null;
    CommonTree RPAREN248_tree = null;
    RewriteRuleTokenStream stream_KW_COLUMNS = new RewriteRuleTokenStream(adaptor, "token KW_COLUMNS");
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleTokenStream stream_KW_REPLACE = new RewriteRuleTokenStream(adaptor, "token KW_REPLACE");
    RewriteRuleTokenStream stream_KW_ADD = new RewriteRuleTokenStream(adaptor, "token KW_ADD");
    RewriteRuleSubtreeStream stream_columnNameTypeList =
        new RewriteRuleSubtreeStream(adaptor, "rule columnNameTypeList");
    RewriteRuleSubtreeStream stream_restrictOrCascade = new RewriteRuleSubtreeStream(adaptor, "rule restrictOrCascade");
    pushMsg("add column statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1064:5: ( (add= KW_ADD |replace= KW_REPLACE ) KW_COLUMNS LPAREN columnNameTypeList RPAREN ( restrictOrCascade )? -> {$add != null}? ^( TOK_ALTERTABLE_ADDCOLS columnNameTypeList ( restrictOrCascade )? ) -> ^( TOK_ALTERTABLE_REPLACECOLS columnNameTypeList ( restrictOrCascade )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1064:7: (add= KW_ADD |replace= KW_REPLACE ) KW_COLUMNS LPAREN columnNameTypeList RPAREN ( restrictOrCascade )?
      {
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1064:7: (add= KW_ADD |replace= KW_REPLACE )
        int alt65 = 2;
        switch (input.LA(1)) {
          case KW_ADD: {
            alt65 = 1;
          }
            break;
          case KW_REPLACE: {
            alt65 = 2;
          }
            break;
          default:
            NoViableAltException nvae = new NoViableAltException("", 65, 0, input);

            throw nvae;
        }

        switch (alt65) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1064:8: add= KW_ADD
          {
            add = (Token) match(input, KW_ADD, FOLLOW_KW_ADD_in_alterStatementSuffixAddCol4451);
            stream_KW_ADD.add(add);
          }
            break;
          case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1064:21: replace= KW_REPLACE
          {
            replace = (Token) match(input, KW_REPLACE, FOLLOW_KW_REPLACE_in_alterStatementSuffixAddCol4457);
            stream_KW_REPLACE.add(replace);
          }
            break;
        }

        KW_COLUMNS245 = (Token) match(input, KW_COLUMNS, FOLLOW_KW_COLUMNS_in_alterStatementSuffixAddCol4460);
        stream_KW_COLUMNS.add(KW_COLUMNS245);

        LPAREN246 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_alterStatementSuffixAddCol4462);
        stream_LPAREN.add(LPAREN246);

        pushFollow(FOLLOW_columnNameTypeList_in_alterStatementSuffixAddCol4464);
        columnNameTypeList247 = columnNameTypeList();

        state._fsp--;

        stream_columnNameTypeList.add(columnNameTypeList247.getTree());

        RPAREN248 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_alterStatementSuffixAddCol4466);
        stream_RPAREN.add(RPAREN248);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1064:85: ( restrictOrCascade )?
        int alt66 = 2;
        switch (input.LA(1)) {
          case KW_CASCADE:
          case KW_RESTRICT: {
            alt66 = 1;
          }
            break;
        }

        switch (alt66) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1064:85: restrictOrCascade
          {
            pushFollow(FOLLOW_restrictOrCascade_in_alterStatementSuffixAddCol4468);
            restrictOrCascade249 = restrictOrCascade();

            state._fsp--;

            stream_restrictOrCascade.add(restrictOrCascade249.getTree());
          }
            break;
        }

        // AST REWRITE
        // elements: columnNameTypeList, restrictOrCascade, restrictOrCascade, columnNameTypeList
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1065:5: -> {$add != null}? ^( TOK_ALTERTABLE_ADDCOLS columnNameTypeList ( restrictOrCascade )? )
        if (add != null) {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1065:24: ^( TOK_ALTERTABLE_ADDCOLS columnNameTypeList ( restrictOrCascade )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_ALTERTABLE_ADDCOLS, "TOK_ALTERTABLE_ADDCOLS"), root_1);

            adaptor.addChild(root_1, stream_columnNameTypeList.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1065:68: ( restrictOrCascade )?
            if (stream_restrictOrCascade.hasNext()) {
              adaptor.addChild(root_1, stream_restrictOrCascade.nextTree());
            }
            stream_restrictOrCascade.reset();

            adaptor.addChild(root_0, root_1);
          }
        } else // 1066:5: -> ^( TOK_ALTERTABLE_REPLACECOLS columnNameTypeList ( restrictOrCascade )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1066:24: ^( TOK_ALTERTABLE_REPLACECOLS columnNameTypeList ( restrictOrCascade )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERTABLE_REPLACECOLS, "TOK_ALTERTABLE_REPLACECOLS"), root_1);

            adaptor.addChild(root_1, stream_columnNameTypeList.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1066:72: ( restrictOrCascade )?
            if (stream_restrictOrCascade.hasNext()) {
              adaptor.addChild(root_1, stream_restrictOrCascade.nextTree());
            }
            stream_restrictOrCascade.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixAddCol"

  public static class alterStatementSuffixRenameCol_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixRenameCol"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1069:1: alterStatementSuffixRenameCol : KW_CHANGE ( KW_COLUMN )? oldName= identifier newName= identifier colType ( KW_COMMENT comment= StringLiteral )? ( alterStatementChangeColPosition )? ( restrictOrCascade )? -> ^( TOK_ALTERTABLE_RENAMECOL $oldName $newName colType ( $comment)? ( alterStatementChangeColPosition )? ( restrictOrCascade )? ) ;
  public final HiveParser.alterStatementSuffixRenameCol_return alterStatementSuffixRenameCol()
      throws RecognitionException {
    HiveParser.alterStatementSuffixRenameCol_return retval = new HiveParser.alterStatementSuffixRenameCol_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token comment = null;
    Token KW_CHANGE250 = null;
    Token KW_COLUMN251 = null;
    Token KW_COMMENT253 = null;
    HiveParser_IdentifiersParser.identifier_return oldName = null;

    HiveParser_IdentifiersParser.identifier_return newName = null;

    HiveParser.colType_return colType252 = null;

    HiveParser.alterStatementChangeColPosition_return alterStatementChangeColPosition254 = null;

    HiveParser.restrictOrCascade_return restrictOrCascade255 = null;

    CommonTree comment_tree = null;
    CommonTree KW_CHANGE250_tree = null;
    CommonTree KW_COLUMN251_tree = null;
    CommonTree KW_COMMENT253_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_COMMENT = new RewriteRuleTokenStream(adaptor, "token KW_COMMENT");
    RewriteRuleTokenStream stream_KW_COLUMN = new RewriteRuleTokenStream(adaptor, "token KW_COLUMN");
    RewriteRuleTokenStream stream_KW_CHANGE = new RewriteRuleTokenStream(adaptor, "token KW_CHANGE");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_colType = new RewriteRuleSubtreeStream(adaptor, "rule colType");
    RewriteRuleSubtreeStream stream_alterStatementChangeColPosition =
        new RewriteRuleSubtreeStream(adaptor, "rule alterStatementChangeColPosition");
    RewriteRuleSubtreeStream stream_restrictOrCascade = new RewriteRuleSubtreeStream(adaptor, "rule restrictOrCascade");
    pushMsg("rename column name", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1072:5: ( KW_CHANGE ( KW_COLUMN )? oldName= identifier newName= identifier colType ( KW_COMMENT comment= StringLiteral )? ( alterStatementChangeColPosition )? ( restrictOrCascade )? -> ^( TOK_ALTERTABLE_RENAMECOL $oldName $newName colType ( $comment)? ( alterStatementChangeColPosition )? ( restrictOrCascade )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1072:7: KW_CHANGE ( KW_COLUMN )? oldName= identifier newName= identifier colType ( KW_COMMENT comment= StringLiteral )? ( alterStatementChangeColPosition )? ( restrictOrCascade )?
      {
        KW_CHANGE250 = (Token) match(input, KW_CHANGE, FOLLOW_KW_CHANGE_in_alterStatementSuffixRenameCol4544);
        stream_KW_CHANGE.add(KW_CHANGE250);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1072:17: ( KW_COLUMN )?
        int alt67 = 2;
        switch (input.LA(1)) {
          case KW_COLUMN: {
            alt67 = 1;
          }
            break;
        }

        switch (alt67) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1072:17: KW_COLUMN
          {
            KW_COLUMN251 = (Token) match(input, KW_COLUMN, FOLLOW_KW_COLUMN_in_alterStatementSuffixRenameCol4546);
            stream_KW_COLUMN.add(KW_COLUMN251);
          }
            break;
        }

        pushFollow(FOLLOW_identifier_in_alterStatementSuffixRenameCol4551);
        oldName = identifier();

        state._fsp--;

        stream_identifier.add(oldName.getTree());

        pushFollow(FOLLOW_identifier_in_alterStatementSuffixRenameCol4555);
        newName = identifier();

        state._fsp--;

        stream_identifier.add(newName.getTree());

        pushFollow(FOLLOW_colType_in_alterStatementSuffixRenameCol4557);
        colType252 = colType();

        state._fsp--;

        stream_colType.add(colType252.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1072:74: ( KW_COMMENT comment= StringLiteral )?
        int alt68 = 2;
        switch (input.LA(1)) {
          case KW_COMMENT: {
            alt68 = 1;
          }
            break;
        }

        switch (alt68) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1072:75: KW_COMMENT comment= StringLiteral
          {
            KW_COMMENT253 = (Token) match(input, KW_COMMENT, FOLLOW_KW_COMMENT_in_alterStatementSuffixRenameCol4560);
            stream_KW_COMMENT.add(KW_COMMENT253);

            comment = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_alterStatementSuffixRenameCol4564);
            stream_StringLiteral.add(comment);
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1072:110: ( alterStatementChangeColPosition )?
        int alt69 = 2;
        switch (input.LA(1)) {
          case KW_AFTER:
          case KW_FIRST: {
            alt69 = 1;
          }
            break;
        }

        switch (alt69) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1072:110: alterStatementChangeColPosition
          {
            pushFollow(FOLLOW_alterStatementChangeColPosition_in_alterStatementSuffixRenameCol4568);
            alterStatementChangeColPosition254 = alterStatementChangeColPosition();

            state._fsp--;

            stream_alterStatementChangeColPosition.add(alterStatementChangeColPosition254.getTree());
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1072:143: ( restrictOrCascade )?
        int alt70 = 2;
        switch (input.LA(1)) {
          case KW_CASCADE:
          case KW_RESTRICT: {
            alt70 = 1;
          }
            break;
        }

        switch (alt70) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1072:143: restrictOrCascade
          {
            pushFollow(FOLLOW_restrictOrCascade_in_alterStatementSuffixRenameCol4571);
            restrictOrCascade255 = restrictOrCascade();

            state._fsp--;

            stream_restrictOrCascade.add(restrictOrCascade255.getTree());
          }
            break;
        }

        // AST REWRITE
        // elements: newName, oldName, comment, alterStatementChangeColPosition, colType, restrictOrCascade
        // token labels: comment
        // rule labels: newName, oldName, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_comment = new RewriteRuleTokenStream(adaptor, "token comment", comment);
        RewriteRuleSubtreeStream stream_newName =
            new RewriteRuleSubtreeStream(adaptor, "rule newName", newName != null ? newName.tree : null);
        RewriteRuleSubtreeStream stream_oldName =
            new RewriteRuleSubtreeStream(adaptor, "rule oldName", oldName != null ? oldName.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1073:5: -> ^( TOK_ALTERTABLE_RENAMECOL $oldName $newName colType ( $comment)? ( alterStatementChangeColPosition )? ( restrictOrCascade )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1073:7: ^( TOK_ALTERTABLE_RENAMECOL $oldName $newName colType ( $comment)? ( alterStatementChangeColPosition )? ( restrictOrCascade )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_ALTERTABLE_RENAMECOL, "TOK_ALTERTABLE_RENAMECOL"), root_1);

            adaptor.addChild(root_1, stream_oldName.nextTree());

            adaptor.addChild(root_1, stream_newName.nextTree());

            adaptor.addChild(root_1, stream_colType.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1073:61: ( $comment)?
            if (stream_comment.hasNext()) {
              adaptor.addChild(root_1, stream_comment.nextNode());
            }
            stream_comment.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1073:70: ( alterStatementChangeColPosition )?
            if (stream_alterStatementChangeColPosition.hasNext()) {
              adaptor.addChild(root_1, stream_alterStatementChangeColPosition.nextTree());
            }
            stream_alterStatementChangeColPosition.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1073:103: ( restrictOrCascade )?
            if (stream_restrictOrCascade.hasNext()) {
              adaptor.addChild(root_1, stream_restrictOrCascade.nextTree());
            }
            stream_restrictOrCascade.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixRenameCol"

  public static class alterStatementSuffixUpdateStatsCol_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixUpdateStatsCol"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1076:1: alterStatementSuffixUpdateStatsCol : KW_UPDATE KW_STATISTICS KW_FOR ( KW_COLUMN )? colName= identifier KW_SET tableProperties ( KW_COMMENT comment= StringLiteral )? -> ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? ) ;
  public final HiveParser.alterStatementSuffixUpdateStatsCol_return alterStatementSuffixUpdateStatsCol()
      throws RecognitionException {
    HiveParser.alterStatementSuffixUpdateStatsCol_return retval =
        new HiveParser.alterStatementSuffixUpdateStatsCol_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token comment = null;
    Token KW_UPDATE256 = null;
    Token KW_STATISTICS257 = null;
    Token KW_FOR258 = null;
    Token KW_COLUMN259 = null;
    Token KW_SET260 = null;
    Token KW_COMMENT262 = null;
    HiveParser_IdentifiersParser.identifier_return colName = null;

    HiveParser.tableProperties_return tableProperties261 = null;

    CommonTree comment_tree = null;
    CommonTree KW_UPDATE256_tree = null;
    CommonTree KW_STATISTICS257_tree = null;
    CommonTree KW_FOR258_tree = null;
    CommonTree KW_COLUMN259_tree = null;
    CommonTree KW_SET260_tree = null;
    CommonTree KW_COMMENT262_tree = null;
    RewriteRuleTokenStream stream_KW_STATISTICS = new RewriteRuleTokenStream(adaptor, "token KW_STATISTICS");
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_FOR = new RewriteRuleTokenStream(adaptor, "token KW_FOR");
    RewriteRuleTokenStream stream_KW_UPDATE = new RewriteRuleTokenStream(adaptor, "token KW_UPDATE");
    RewriteRuleTokenStream stream_KW_COMMENT = new RewriteRuleTokenStream(adaptor, "token KW_COMMENT");
    RewriteRuleTokenStream stream_KW_COLUMN = new RewriteRuleTokenStream(adaptor, "token KW_COLUMN");
    RewriteRuleTokenStream stream_KW_SET = new RewriteRuleTokenStream(adaptor, "token KW_SET");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_tableProperties = new RewriteRuleSubtreeStream(adaptor, "rule tableProperties");
    pushMsg("update column statistics", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1079:5: ( KW_UPDATE KW_STATISTICS KW_FOR ( KW_COLUMN )? colName= identifier KW_SET tableProperties ( KW_COMMENT comment= StringLiteral )? -> ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1079:7: KW_UPDATE KW_STATISTICS KW_FOR ( KW_COLUMN )? colName= identifier KW_SET tableProperties ( KW_COMMENT comment= StringLiteral )?
      {
        KW_UPDATE256 = (Token) match(input, KW_UPDATE, FOLLOW_KW_UPDATE_in_alterStatementSuffixUpdateStatsCol4626);
        stream_KW_UPDATE.add(KW_UPDATE256);

        KW_STATISTICS257 =
            (Token) match(input, KW_STATISTICS, FOLLOW_KW_STATISTICS_in_alterStatementSuffixUpdateStatsCol4628);
        stream_KW_STATISTICS.add(KW_STATISTICS257);

        KW_FOR258 = (Token) match(input, KW_FOR, FOLLOW_KW_FOR_in_alterStatementSuffixUpdateStatsCol4630);
        stream_KW_FOR.add(KW_FOR258);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1079:38: ( KW_COLUMN )?
        int alt71 = 2;
        switch (input.LA(1)) {
          case KW_COLUMN: {
            alt71 = 1;
          }
            break;
        }

        switch (alt71) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1079:38: KW_COLUMN
          {
            KW_COLUMN259 = (Token) match(input, KW_COLUMN, FOLLOW_KW_COLUMN_in_alterStatementSuffixUpdateStatsCol4632);
            stream_KW_COLUMN.add(KW_COLUMN259);
          }
            break;
        }

        pushFollow(FOLLOW_identifier_in_alterStatementSuffixUpdateStatsCol4637);
        colName = identifier();

        state._fsp--;

        stream_identifier.add(colName.getTree());

        KW_SET260 = (Token) match(input, KW_SET, FOLLOW_KW_SET_in_alterStatementSuffixUpdateStatsCol4639);
        stream_KW_SET.add(KW_SET260);

        pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixUpdateStatsCol4641);
        tableProperties261 = tableProperties();

        state._fsp--;

        stream_tableProperties.add(tableProperties261.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1079:91: ( KW_COMMENT comment= StringLiteral )?
        int alt72 = 2;
        switch (input.LA(1)) {
          case KW_COMMENT: {
            alt72 = 1;
          }
            break;
        }

        switch (alt72) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1079:92: KW_COMMENT comment= StringLiteral
          {
            KW_COMMENT262 =
                (Token) match(input, KW_COMMENT, FOLLOW_KW_COMMENT_in_alterStatementSuffixUpdateStatsCol4644);
            stream_KW_COMMENT.add(KW_COMMENT262);

            comment =
                (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_alterStatementSuffixUpdateStatsCol4648);
            stream_StringLiteral.add(comment);
          }
            break;
        }

        // AST REWRITE
        // elements: comment, tableProperties, colName
        // token labels: comment
        // rule labels: colName, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_comment = new RewriteRuleTokenStream(adaptor, "token comment", comment);
        RewriteRuleSubtreeStream stream_colName =
            new RewriteRuleSubtreeStream(adaptor, "rule colName", colName != null ? colName.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1080:5: -> ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1080:7: ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERTABLE_UPDATECOLSTATS, "TOK_ALTERTABLE_UPDATECOLSTATS"), root_1);

            adaptor.addChild(root_1, stream_colName.nextTree());

            adaptor.addChild(root_1, stream_tableProperties.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1080:65: ( $comment)?
            if (stream_comment.hasNext()) {
              adaptor.addChild(root_1, stream_comment.nextNode());
            }
            stream_comment.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixUpdateStatsCol"

  public static class alterStatementChangeColPosition_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementChangeColPosition"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1083:1: alterStatementChangeColPosition : (first= KW_FIRST | KW_AFTER afterCol= identifier -> {$first != null}? ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION ) -> ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION $afterCol) );
  public final HiveParser.alterStatementChangeColPosition_return alterStatementChangeColPosition()
      throws RecognitionException {
    HiveParser.alterStatementChangeColPosition_return retval = new HiveParser.alterStatementChangeColPosition_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token first = null;
    Token KW_AFTER263 = null;
    HiveParser_IdentifiersParser.identifier_return afterCol = null;

    CommonTree first_tree = null;
    CommonTree KW_AFTER263_tree = null;
    RewriteRuleTokenStream stream_KW_AFTER = new RewriteRuleTokenStream(adaptor, "token KW_AFTER");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1084:5: (first= KW_FIRST | KW_AFTER afterCol= identifier -> {$first != null}? ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION ) -> ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION $afterCol) )
      int alt73 = 2;
      switch (input.LA(1)) {
        case KW_FIRST: {
          alt73 = 1;
        }
          break;
        case KW_AFTER: {
          alt73 = 2;
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 73, 0, input);

          throw nvae;
      }

      switch (alt73) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1084:7: first= KW_FIRST
        {
          root_0 = (CommonTree) adaptor.nil();

          first = (Token) match(input, KW_FIRST, FOLLOW_KW_FIRST_in_alterStatementChangeColPosition4687);
          first_tree = (CommonTree) adaptor.create(first);
          adaptor.addChild(root_0, first_tree);
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1084:22: KW_AFTER afterCol= identifier
        {
          KW_AFTER263 = (Token) match(input, KW_AFTER, FOLLOW_KW_AFTER_in_alterStatementChangeColPosition4689);
          stream_KW_AFTER.add(KW_AFTER263);

          pushFollow(FOLLOW_identifier_in_alterStatementChangeColPosition4693);
          afterCol = identifier();

          state._fsp--;

          stream_identifier.add(afterCol.getTree());

          // AST REWRITE
          // elements: afterCol
          // token labels:
          // rule labels: afterCol, retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_afterCol =
              new RewriteRuleSubtreeStream(adaptor, "rule afterCol", afterCol != null ? afterCol.tree : null);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1085:5: -> {$first != null}? ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION )
          if (first != null) {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1085:25: ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor
                  .create(TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION, "TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          } else // 1086:5: -> ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION $afterCol)
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1086:8: ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION $afterCol)
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor
                  .create(TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION, "TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION"), root_1);

              adaptor.addChild(root_1, stream_afterCol.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementChangeColPosition"

  public static class alterStatementSuffixAddPartitions_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixAddPartitions"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1089:1: alterStatementSuffixAddPartitions[boolean table] : KW_ADD ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ -> { table }? ^( TOK_ALTERTABLE_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ ) -> ^( TOK_ALTERVIEW_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ ) ;
  public final HiveParser.alterStatementSuffixAddPartitions_return alterStatementSuffixAddPartitions(boolean table)
      throws RecognitionException {
    HiveParser.alterStatementSuffixAddPartitions_return retval =
        new HiveParser.alterStatementSuffixAddPartitions_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_ADD264 = null;
    HiveParser.ifNotExists_return ifNotExists265 = null;

    HiveParser.alterStatementSuffixAddPartitionsElement_return alterStatementSuffixAddPartitionsElement266 = null;

    CommonTree KW_ADD264_tree = null;
    RewriteRuleTokenStream stream_KW_ADD = new RewriteRuleTokenStream(adaptor, "token KW_ADD");
    RewriteRuleSubtreeStream stream_ifNotExists = new RewriteRuleSubtreeStream(adaptor, "rule ifNotExists");
    RewriteRuleSubtreeStream stream_alterStatementSuffixAddPartitionsElement =
        new RewriteRuleSubtreeStream(adaptor, "rule alterStatementSuffixAddPartitionsElement");
    pushMsg("add partition statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1092:5: ( KW_ADD ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ -> { table }? ^( TOK_ALTERTABLE_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ ) -> ^( TOK_ALTERVIEW_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1092:7: KW_ADD ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+
      {
        KW_ADD264 = (Token) match(input, KW_ADD, FOLLOW_KW_ADD_in_alterStatementSuffixAddPartitions4746);
        stream_KW_ADD.add(KW_ADD264);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1092:14: ( ifNotExists )?
        int alt74 = 2;
        switch (input.LA(1)) {
          case KW_IF: {
            alt74 = 1;
          }
            break;
        }

        switch (alt74) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1092:14: ifNotExists
          {
            pushFollow(FOLLOW_ifNotExists_in_alterStatementSuffixAddPartitions4748);
            ifNotExists265 = ifNotExists();

            state._fsp--;

            stream_ifNotExists.add(ifNotExists265.getTree());
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1092:27: ( alterStatementSuffixAddPartitionsElement )+
        int cnt75 = 0;
        loop75: do {
          int alt75 = 2;
          switch (input.LA(1)) {
            case KW_PARTITION: {
              alt75 = 1;
            }
              break;
          }

          switch (alt75) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1092:27: alterStatementSuffixAddPartitionsElement
            {
              pushFollow(FOLLOW_alterStatementSuffixAddPartitionsElement_in_alterStatementSuffixAddPartitions4751);
              alterStatementSuffixAddPartitionsElement266 = alterStatementSuffixAddPartitionsElement();

              state._fsp--;

              stream_alterStatementSuffixAddPartitionsElement
                  .add(alterStatementSuffixAddPartitionsElement266.getTree());
            }
              break;

            default:
              if (cnt75 >= 1) {
                break loop75;
              }
              EarlyExitException eee = new EarlyExitException(75, input);
              throw eee;
          }
          cnt75++;
        } while (true);

        // AST REWRITE
        // elements: ifNotExists, ifNotExists, alterStatementSuffixAddPartitionsElement, alterStatementSuffixAddPartitionsElement
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1093:5: -> { table }? ^( TOK_ALTERTABLE_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ )
        if (table) {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1093:19: ^( TOK_ALTERTABLE_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_ALTERTABLE_ADDPARTS, "TOK_ALTERTABLE_ADDPARTS"), root_1);

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1093:45: ( ifNotExists )?
            if (stream_ifNotExists.hasNext()) {
              adaptor.addChild(root_1, stream_ifNotExists.nextTree());
            }
            stream_ifNotExists.reset();

            if (!(stream_alterStatementSuffixAddPartitionsElement.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_alterStatementSuffixAddPartitionsElement.hasNext()) {
              adaptor.addChild(root_1, stream_alterStatementSuffixAddPartitionsElement.nextTree());
            }
            stream_alterStatementSuffixAddPartitionsElement.reset();

            adaptor.addChild(root_0, root_1);
          }
        } else // 1094:5: -> ^( TOK_ALTERVIEW_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1094:19: ^( TOK_ALTERVIEW_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_ALTERVIEW_ADDPARTS, "TOK_ALTERVIEW_ADDPARTS"), root_1);

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1094:44: ( ifNotExists )?
            if (stream_ifNotExists.hasNext()) {
              adaptor.addChild(root_1, stream_ifNotExists.nextTree());
            }
            stream_ifNotExists.reset();

            if (!(stream_alterStatementSuffixAddPartitionsElement.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_alterStatementSuffixAddPartitionsElement.hasNext()) {
              adaptor.addChild(root_1, stream_alterStatementSuffixAddPartitionsElement.nextTree());
            }
            stream_alterStatementSuffixAddPartitionsElement.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixAddPartitions"

  public static class alterStatementSuffixAddPartitionsElement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixAddPartitionsElement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1097:1: alterStatementSuffixAddPartitionsElement : partitionSpec ( partitionFileFormat )? ( partitionSerdeProperties )? ( location )? ;
  public final HiveParser.alterStatementSuffixAddPartitionsElement_return alterStatementSuffixAddPartitionsElement()
      throws RecognitionException {
    HiveParser.alterStatementSuffixAddPartitionsElement_return retval =
        new HiveParser.alterStatementSuffixAddPartitionsElement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec267 = null;

    HiveParser.partitionFileFormat_return partitionFileFormat268 = null;

    HiveParser.partitionSerdeProperties_return partitionSerdeProperties269 = null;

    HiveParser.location_return location270 = null;

    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1098:5: ( partitionSpec ( partitionFileFormat )? ( partitionSerdeProperties )? ( location )? )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1098:7: partitionSpec ( partitionFileFormat )? ( partitionSerdeProperties )? ( location )?
      {
        root_0 = (CommonTree) adaptor.nil();

        pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixAddPartitionsElement4814);
        partitionSpec267 = partitionSpec();

        state._fsp--;

        adaptor.addChild(root_0, partitionSpec267.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1098:21: ( partitionFileFormat )?
        int alt76 = 2;
        switch (input.LA(1)) {
          case KW_FILEFORMAT: {
            alt76 = 1;
          }
            break;
        }

        switch (alt76) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1098:21: partitionFileFormat
          {
            pushFollow(FOLLOW_partitionFileFormat_in_alterStatementSuffixAddPartitionsElement4816);
            partitionFileFormat268 = partitionFileFormat();

            state._fsp--;

            adaptor.addChild(root_0, partitionFileFormat268.getTree());
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1098:42: ( partitionSerdeProperties )?
        int alt77 = 2;
        switch (input.LA(1)) {
          case KW_SERDEPROPERTIES: {
            alt77 = 1;
          }
            break;
        }

        switch (alt77) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1098:42: partitionSerdeProperties
          {
            pushFollow(FOLLOW_partitionSerdeProperties_in_alterStatementSuffixAddPartitionsElement4819);
            partitionSerdeProperties269 = partitionSerdeProperties();

            state._fsp--;

            adaptor.addChild(root_0, partitionSerdeProperties269.getTree());
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1098:68: ( location )?
        int alt78 = 2;
        switch (input.LA(1)) {
          case KW_LOCATION: {
            alt78 = 1;
          }
            break;
        }

        switch (alt78) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1098:68: location
          {
            pushFollow(FOLLOW_location_in_alterStatementSuffixAddPartitionsElement4822);
            location270 = location();

            state._fsp--;

            adaptor.addChild(root_0, location270.getTree());
          }
            break;
        }
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixAddPartitionsElement"

  public static class alterStatementSuffixTouch_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixTouch"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1101:1: alterStatementSuffixTouch : KW_TOUCH ( partitionSpec )* -> ^( TOK_ALTERTABLE_TOUCH ( partitionSpec )* ) ;
  public final HiveParser.alterStatementSuffixTouch_return alterStatementSuffixTouch() throws RecognitionException {
    HiveParser.alterStatementSuffixTouch_return retval = new HiveParser.alterStatementSuffixTouch_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_TOUCH271 = null;
    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec272 = null;

    CommonTree KW_TOUCH271_tree = null;
    RewriteRuleTokenStream stream_KW_TOUCH = new RewriteRuleTokenStream(adaptor, "token KW_TOUCH");
    RewriteRuleSubtreeStream stream_partitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule partitionSpec");
    pushMsg("touch statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1104:5: ( KW_TOUCH ( partitionSpec )* -> ^( TOK_ALTERTABLE_TOUCH ( partitionSpec )* ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1104:7: KW_TOUCH ( partitionSpec )*
      {
        KW_TOUCH271 = (Token) match(input, KW_TOUCH, FOLLOW_KW_TOUCH_in_alterStatementSuffixTouch4850);
        stream_KW_TOUCH.add(KW_TOUCH271);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1104:16: ( partitionSpec )*
        loop79: do {
          int alt79 = 2;
          switch (input.LA(1)) {
            case KW_PARTITION: {
              alt79 = 1;
            }
              break;
          }

          switch (alt79) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1104:17: partitionSpec
            {
              pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixTouch4853);
              partitionSpec272 = partitionSpec();

              state._fsp--;

              stream_partitionSpec.add(partitionSpec272.getTree());
            }
              break;

            default:
              break loop79;
          }
        } while (true);

        // AST REWRITE
        // elements: partitionSpec
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1105:5: -> ^( TOK_ALTERTABLE_TOUCH ( partitionSpec )* )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1105:8: ^( TOK_ALTERTABLE_TOUCH ( partitionSpec )* )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_ALTERTABLE_TOUCH, "TOK_ALTERTABLE_TOUCH"), root_1);

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1105:31: ( partitionSpec )*
            while (stream_partitionSpec.hasNext()) {
              adaptor.addChild(root_1, stream_partitionSpec.nextTree());
            }
            stream_partitionSpec.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixTouch"

  public static class alterStatementSuffixArchive_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixArchive"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1108:1: alterStatementSuffixArchive : KW_ARCHIVE ( partitionSpec )* -> ^( TOK_ALTERTABLE_ARCHIVE ( partitionSpec )* ) ;
  public final HiveParser.alterStatementSuffixArchive_return alterStatementSuffixArchive() throws RecognitionException {
    HiveParser.alterStatementSuffixArchive_return retval = new HiveParser.alterStatementSuffixArchive_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_ARCHIVE273 = null;
    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec274 = null;

    CommonTree KW_ARCHIVE273_tree = null;
    RewriteRuleTokenStream stream_KW_ARCHIVE = new RewriteRuleTokenStream(adaptor, "token KW_ARCHIVE");
    RewriteRuleSubtreeStream stream_partitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule partitionSpec");
    pushMsg("archive statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1111:5: ( KW_ARCHIVE ( partitionSpec )* -> ^( TOK_ALTERTABLE_ARCHIVE ( partitionSpec )* ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1111:7: KW_ARCHIVE ( partitionSpec )*
      {
        KW_ARCHIVE273 = (Token) match(input, KW_ARCHIVE, FOLLOW_KW_ARCHIVE_in_alterStatementSuffixArchive4897);
        stream_KW_ARCHIVE.add(KW_ARCHIVE273);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1111:18: ( partitionSpec )*
        loop80: do {
          int alt80 = 2;
          switch (input.LA(1)) {
            case KW_PARTITION: {
              alt80 = 1;
            }
              break;
          }

          switch (alt80) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1111:19: partitionSpec
            {
              pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixArchive4900);
              partitionSpec274 = partitionSpec();

              state._fsp--;

              stream_partitionSpec.add(partitionSpec274.getTree());
            }
              break;

            default:
              break loop80;
          }
        } while (true);

        // AST REWRITE
        // elements: partitionSpec
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1112:5: -> ^( TOK_ALTERTABLE_ARCHIVE ( partitionSpec )* )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1112:8: ^( TOK_ALTERTABLE_ARCHIVE ( partitionSpec )* )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_ALTERTABLE_ARCHIVE, "TOK_ALTERTABLE_ARCHIVE"), root_1);

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1112:33: ( partitionSpec )*
            while (stream_partitionSpec.hasNext()) {
              adaptor.addChild(root_1, stream_partitionSpec.nextTree());
            }
            stream_partitionSpec.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixArchive"

  public static class alterStatementSuffixUnArchive_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixUnArchive"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1115:1: alterStatementSuffixUnArchive : KW_UNARCHIVE ( partitionSpec )* -> ^( TOK_ALTERTABLE_UNARCHIVE ( partitionSpec )* ) ;
  public final HiveParser.alterStatementSuffixUnArchive_return alterStatementSuffixUnArchive()
      throws RecognitionException {
    HiveParser.alterStatementSuffixUnArchive_return retval = new HiveParser.alterStatementSuffixUnArchive_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_UNARCHIVE275 = null;
    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec276 = null;

    CommonTree KW_UNARCHIVE275_tree = null;
    RewriteRuleTokenStream stream_KW_UNARCHIVE = new RewriteRuleTokenStream(adaptor, "token KW_UNARCHIVE");
    RewriteRuleSubtreeStream stream_partitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule partitionSpec");
    pushMsg("unarchive statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1118:5: ( KW_UNARCHIVE ( partitionSpec )* -> ^( TOK_ALTERTABLE_UNARCHIVE ( partitionSpec )* ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1118:7: KW_UNARCHIVE ( partitionSpec )*
      {
        KW_UNARCHIVE275 = (Token) match(input, KW_UNARCHIVE, FOLLOW_KW_UNARCHIVE_in_alterStatementSuffixUnArchive4944);
        stream_KW_UNARCHIVE.add(KW_UNARCHIVE275);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1118:20: ( partitionSpec )*
        loop81: do {
          int alt81 = 2;
          switch (input.LA(1)) {
            case KW_PARTITION: {
              alt81 = 1;
            }
              break;
          }

          switch (alt81) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1118:21: partitionSpec
            {
              pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixUnArchive4947);
              partitionSpec276 = partitionSpec();

              state._fsp--;

              stream_partitionSpec.add(partitionSpec276.getTree());
            }
              break;

            default:
              break loop81;
          }
        } while (true);

        // AST REWRITE
        // elements: partitionSpec
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1119:5: -> ^( TOK_ALTERTABLE_UNARCHIVE ( partitionSpec )* )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1119:8: ^( TOK_ALTERTABLE_UNARCHIVE ( partitionSpec )* )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_ALTERTABLE_UNARCHIVE, "TOK_ALTERTABLE_UNARCHIVE"), root_1);

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1119:35: ( partitionSpec )*
            while (stream_partitionSpec.hasNext()) {
              adaptor.addChild(root_1, stream_partitionSpec.nextTree());
            }
            stream_partitionSpec.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixUnArchive"

  public static class partitionFileFormat_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "partitionFileFormat"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1122:1: partitionFileFormat : KW_FILEFORMAT fileFormat -> ^( TOK_PARTITIONFILEFORMAT fileFormat ) ;
  public final HiveParser.partitionFileFormat_return partitionFileFormat() throws RecognitionException {
    HiveParser.partitionFileFormat_return retval = new HiveParser.partitionFileFormat_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_FILEFORMAT277 = null;
    HiveParser.fileFormat_return fileFormat278 = null;

    CommonTree KW_FILEFORMAT277_tree = null;
    RewriteRuleTokenStream stream_KW_FILEFORMAT = new RewriteRuleTokenStream(adaptor, "token KW_FILEFORMAT");
    RewriteRuleSubtreeStream stream_fileFormat = new RewriteRuleSubtreeStream(adaptor, "rule fileFormat");
    pushMsg("partition fileformat", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1125:5: ( KW_FILEFORMAT fileFormat -> ^( TOK_PARTITIONFILEFORMAT fileFormat ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1125:7: KW_FILEFORMAT fileFormat
      {
        KW_FILEFORMAT277 = (Token) match(input, KW_FILEFORMAT, FOLLOW_KW_FILEFORMAT_in_partitionFileFormat4991);
        stream_KW_FILEFORMAT.add(KW_FILEFORMAT277);

        pushFollow(FOLLOW_fileFormat_in_partitionFileFormat4993);
        fileFormat278 = fileFormat();

        state._fsp--;

        stream_fileFormat.add(fileFormat278.getTree());

        // AST REWRITE
        // elements: fileFormat
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1125:32: -> ^( TOK_PARTITIONFILEFORMAT fileFormat )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1125:35: ^( TOK_PARTITIONFILEFORMAT fileFormat )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_PARTITIONFILEFORMAT, "TOK_PARTITIONFILEFORMAT"), root_1);

            adaptor.addChild(root_1, stream_fileFormat.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "partitionFileFormat"

  public static class partitionSerdeProperties_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "partitionSerdeProperties"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1128:1: partitionSerdeProperties : KW_SERDEPROPERTIES tableProperties -> ^( TOK_PARTITIONSERDEPROPERTIES tableProperties ) ;
  public final HiveParser.partitionSerdeProperties_return partitionSerdeProperties() throws RecognitionException {
    HiveParser.partitionSerdeProperties_return retval = new HiveParser.partitionSerdeProperties_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_SERDEPROPERTIES279 = null;
    HiveParser.tableProperties_return tableProperties280 = null;

    CommonTree KW_SERDEPROPERTIES279_tree = null;
    RewriteRuleTokenStream stream_KW_SERDEPROPERTIES = new RewriteRuleTokenStream(adaptor, "token KW_SERDEPROPERTIES");
    RewriteRuleSubtreeStream stream_tableProperties = new RewriteRuleSubtreeStream(adaptor, "rule tableProperties");
    pushMsg("partition serdeproperties", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1131:5: ( KW_SERDEPROPERTIES tableProperties -> ^( TOK_PARTITIONSERDEPROPERTIES tableProperties ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1131:7: KW_SERDEPROPERTIES tableProperties
      {
        KW_SERDEPROPERTIES279 =
            (Token) match(input, KW_SERDEPROPERTIES, FOLLOW_KW_SERDEPROPERTIES_in_partitionSerdeProperties5028);
        stream_KW_SERDEPROPERTIES.add(KW_SERDEPROPERTIES279);

        pushFollow(FOLLOW_tableProperties_in_partitionSerdeProperties5030);
        tableProperties280 = tableProperties();

        state._fsp--;

        stream_tableProperties.add(tableProperties280.getTree());

        // AST REWRITE
        // elements: tableProperties
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1131:42: -> ^( TOK_PARTITIONSERDEPROPERTIES tableProperties )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1131:45: ^( TOK_PARTITIONSERDEPROPERTIES tableProperties )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_PARTITIONSERDEPROPERTIES, "TOK_PARTITIONSERDEPROPERTIES"), root_1);

            adaptor.addChild(root_1, stream_tableProperties.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "partitionSerdeProperties"

  public static class alterStatementSuffixDropPartitions_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixDropPartitions"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1134:1: alterStatementSuffixDropPartitions[boolean table] : KW_DROP ( ifExists )? dropPartitionSpec ( COMMA dropPartitionSpec )* ( ignoreProtection )? ( KW_PURGE )? ( replicationClause )? -> { table }? ^( TOK_ALTERTABLE_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( ignoreProtection )? ( KW_PURGE )? ( replicationClause )? ) -> ^( TOK_ALTERVIEW_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( ignoreProtection )? ( replicationClause )? ) ;
  public final HiveParser.alterStatementSuffixDropPartitions_return alterStatementSuffixDropPartitions(boolean table)
      throws RecognitionException {
    HiveParser.alterStatementSuffixDropPartitions_return retval =
        new HiveParser.alterStatementSuffixDropPartitions_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_DROP281 = null;
    Token COMMA284 = null;
    Token KW_PURGE287 = null;
    HiveParser.ifExists_return ifExists282 = null;

    HiveParser_IdentifiersParser.dropPartitionSpec_return dropPartitionSpec283 = null;

    HiveParser_IdentifiersParser.dropPartitionSpec_return dropPartitionSpec285 = null;

    HiveParser.ignoreProtection_return ignoreProtection286 = null;

    HiveParser.replicationClause_return replicationClause288 = null;

    CommonTree KW_DROP281_tree = null;
    CommonTree COMMA284_tree = null;
    CommonTree KW_PURGE287_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleTokenStream stream_KW_DROP = new RewriteRuleTokenStream(adaptor, "token KW_DROP");
    RewriteRuleTokenStream stream_KW_PURGE = new RewriteRuleTokenStream(adaptor, "token KW_PURGE");
    RewriteRuleSubtreeStream stream_dropPartitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule dropPartitionSpec");
    RewriteRuleSubtreeStream stream_ifExists = new RewriteRuleSubtreeStream(adaptor, "rule ifExists");
    RewriteRuleSubtreeStream stream_ignoreProtection = new RewriteRuleSubtreeStream(adaptor, "rule ignoreProtection");
    RewriteRuleSubtreeStream stream_replicationClause = new RewriteRuleSubtreeStream(adaptor, "rule replicationClause");
    pushMsg("drop partition statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:5: ( KW_DROP ( ifExists )? dropPartitionSpec ( COMMA dropPartitionSpec )* ( ignoreProtection )? ( KW_PURGE )? ( replicationClause )? -> { table }? ^( TOK_ALTERTABLE_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( ignoreProtection )? ( KW_PURGE )? ( replicationClause )? ) -> ^( TOK_ALTERVIEW_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( ignoreProtection )? ( replicationClause )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:7: KW_DROP ( ifExists )? dropPartitionSpec ( COMMA dropPartitionSpec )* ( ignoreProtection )? ( KW_PURGE )? ( replicationClause )?
      {
        KW_DROP281 = (Token) match(input, KW_DROP, FOLLOW_KW_DROP_in_alterStatementSuffixDropPartitions5066);
        stream_KW_DROP.add(KW_DROP281);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:15: ( ifExists )?
        int alt82 = 2;
        switch (input.LA(1)) {
          case KW_IF: {
            alt82 = 1;
          }
            break;
        }

        switch (alt82) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:15: ifExists
          {
            pushFollow(FOLLOW_ifExists_in_alterStatementSuffixDropPartitions5068);
            ifExists282 = ifExists();

            state._fsp--;

            stream_ifExists.add(ifExists282.getTree());
          }
            break;
        }

        pushFollow(FOLLOW_dropPartitionSpec_in_alterStatementSuffixDropPartitions5071);
        dropPartitionSpec283 = dropPartitionSpec();

        state._fsp--;

        stream_dropPartitionSpec.add(dropPartitionSpec283.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:43: ( COMMA dropPartitionSpec )*
        loop83: do {
          int alt83 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt83 = 1;
            }
              break;
          }

          switch (alt83) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:44: COMMA dropPartitionSpec
            {
              COMMA284 = (Token) match(input, COMMA, FOLLOW_COMMA_in_alterStatementSuffixDropPartitions5074);
              stream_COMMA.add(COMMA284);

              pushFollow(FOLLOW_dropPartitionSpec_in_alterStatementSuffixDropPartitions5076);
              dropPartitionSpec285 = dropPartitionSpec();

              state._fsp--;

              stream_dropPartitionSpec.add(dropPartitionSpec285.getTree());
            }
              break;

            default:
              break loop83;
          }
        } while (true);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:70: ( ignoreProtection )?
        int alt84 = 2;
        switch (input.LA(1)) {
          case KW_IGNORE: {
            alt84 = 1;
          }
            break;
        }

        switch (alt84) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:70: ignoreProtection
          {
            pushFollow(FOLLOW_ignoreProtection_in_alterStatementSuffixDropPartitions5080);
            ignoreProtection286 = ignoreProtection();

            state._fsp--;

            stream_ignoreProtection.add(ignoreProtection286.getTree());
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:88: ( KW_PURGE )?
        int alt85 = 2;
        switch (input.LA(1)) {
          case KW_PURGE: {
            alt85 = 1;
          }
            break;
        }

        switch (alt85) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:88: KW_PURGE
          {
            KW_PURGE287 = (Token) match(input, KW_PURGE, FOLLOW_KW_PURGE_in_alterStatementSuffixDropPartitions5083);
            stream_KW_PURGE.add(KW_PURGE287);
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:98: ( replicationClause )?
        int alt86 = 2;
        switch (input.LA(1)) {
          case KW_FOR: {
            alt86 = 1;
          }
            break;
        }

        switch (alt86) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:98: replicationClause
          {
            pushFollow(FOLLOW_replicationClause_in_alterStatementSuffixDropPartitions5086);
            replicationClause288 = replicationClause();

            state._fsp--;

            stream_replicationClause.add(replicationClause288.getTree());
          }
            break;
        }

        // AST REWRITE
        // elements: replicationClause, ifExists, ignoreProtection, KW_PURGE, dropPartitionSpec, replicationClause, ignoreProtection, dropPartitionSpec, ifExists
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1138:5: -> { table }? ^( TOK_ALTERTABLE_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( ignoreProtection )? ( KW_PURGE )? ( replicationClause )? )
        if (table) {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1138:19: ^( TOK_ALTERTABLE_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( ignoreProtection )? ( KW_PURGE )? ( replicationClause )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_ALTERTABLE_DROPPARTS, "TOK_ALTERTABLE_DROPPARTS"), root_1);

            if (!(stream_dropPartitionSpec.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_dropPartitionSpec.hasNext()) {
              adaptor.addChild(root_1, stream_dropPartitionSpec.nextTree());
            }
            stream_dropPartitionSpec.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1138:65: ( ifExists )?
            if (stream_ifExists.hasNext()) {
              adaptor.addChild(root_1, stream_ifExists.nextTree());
            }
            stream_ifExists.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1138:75: ( ignoreProtection )?
            if (stream_ignoreProtection.hasNext()) {
              adaptor.addChild(root_1, stream_ignoreProtection.nextTree());
            }
            stream_ignoreProtection.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1138:93: ( KW_PURGE )?
            if (stream_KW_PURGE.hasNext()) {
              adaptor.addChild(root_1, stream_KW_PURGE.nextNode());
            }
            stream_KW_PURGE.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1138:103: ( replicationClause )?
            if (stream_replicationClause.hasNext()) {
              adaptor.addChild(root_1, stream_replicationClause.nextTree());
            }
            stream_replicationClause.reset();

            adaptor.addChild(root_0, root_1);
          }
        } else // 1139:5: -> ^( TOK_ALTERVIEW_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( ignoreProtection )? ( replicationClause )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1139:19: ^( TOK_ALTERVIEW_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( ignoreProtection )? ( replicationClause )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_ALTERVIEW_DROPPARTS, "TOK_ALTERVIEW_DROPPARTS"), root_1);

            if (!(stream_dropPartitionSpec.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_dropPartitionSpec.hasNext()) {
              adaptor.addChild(root_1, stream_dropPartitionSpec.nextTree());
            }
            stream_dropPartitionSpec.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1139:64: ( ifExists )?
            if (stream_ifExists.hasNext()) {
              adaptor.addChild(root_1, stream_ifExists.nextTree());
            }
            stream_ifExists.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1139:74: ( ignoreProtection )?
            if (stream_ignoreProtection.hasNext()) {
              adaptor.addChild(root_1, stream_ignoreProtection.nextTree());
            }
            stream_ignoreProtection.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1139:92: ( replicationClause )?
            if (stream_replicationClause.hasNext()) {
              adaptor.addChild(root_1, stream_replicationClause.nextTree());
            }
            stream_replicationClause.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixDropPartitions"

  public static class alterStatementSuffixProperties_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixProperties"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1142:1: alterStatementSuffixProperties : ( KW_SET KW_TBLPROPERTIES tableProperties -> ^( TOK_ALTERTABLE_PROPERTIES tableProperties ) | KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties -> ^( TOK_ALTERTABLE_DROPPROPERTIES tableProperties ( ifExists )? ) );
  public final HiveParser.alterStatementSuffixProperties_return alterStatementSuffixProperties()
      throws RecognitionException {
    HiveParser.alterStatementSuffixProperties_return retval = new HiveParser.alterStatementSuffixProperties_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_SET289 = null;
    Token KW_TBLPROPERTIES290 = null;
    Token KW_UNSET292 = null;
    Token KW_TBLPROPERTIES293 = null;
    HiveParser.tableProperties_return tableProperties291 = null;

    HiveParser.ifExists_return ifExists294 = null;

    HiveParser.tableProperties_return tableProperties295 = null;

    CommonTree KW_SET289_tree = null;
    CommonTree KW_TBLPROPERTIES290_tree = null;
    CommonTree KW_UNSET292_tree = null;
    CommonTree KW_TBLPROPERTIES293_tree = null;
    RewriteRuleTokenStream stream_KW_UNSET = new RewriteRuleTokenStream(adaptor, "token KW_UNSET");
    RewriteRuleTokenStream stream_KW_TBLPROPERTIES = new RewriteRuleTokenStream(adaptor, "token KW_TBLPROPERTIES");
    RewriteRuleTokenStream stream_KW_SET = new RewriteRuleTokenStream(adaptor, "token KW_SET");
    RewriteRuleSubtreeStream stream_tableProperties = new RewriteRuleSubtreeStream(adaptor, "rule tableProperties");
    RewriteRuleSubtreeStream stream_ifExists = new RewriteRuleSubtreeStream(adaptor, "rule ifExists");
    pushMsg("alter properties statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1145:5: ( KW_SET KW_TBLPROPERTIES tableProperties -> ^( TOK_ALTERTABLE_PROPERTIES tableProperties ) | KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties -> ^( TOK_ALTERTABLE_DROPPROPERTIES tableProperties ( ifExists )? ) )
      int alt88 = 2;
      switch (input.LA(1)) {
        case KW_SET: {
          alt88 = 1;
        }
          break;
        case KW_UNSET: {
          alt88 = 2;
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 88, 0, input);

          throw nvae;
      }

      switch (alt88) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1145:7: KW_SET KW_TBLPROPERTIES tableProperties
        {
          KW_SET289 = (Token) match(input, KW_SET, FOLLOW_KW_SET_in_alterStatementSuffixProperties5174);
          stream_KW_SET.add(KW_SET289);

          KW_TBLPROPERTIES290 =
              (Token) match(input, KW_TBLPROPERTIES, FOLLOW_KW_TBLPROPERTIES_in_alterStatementSuffixProperties5176);
          stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES290);

          pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixProperties5178);
          tableProperties291 = tableProperties();

          state._fsp--;

          stream_tableProperties.add(tableProperties291.getTree());

          // AST REWRITE
          // elements: tableProperties
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1146:5: -> ^( TOK_ALTERTABLE_PROPERTIES tableProperties )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1146:8: ^( TOK_ALTERTABLE_PROPERTIES tableProperties )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_ALTERTABLE_PROPERTIES, "TOK_ALTERTABLE_PROPERTIES"), root_1);

              adaptor.addChild(root_1, stream_tableProperties.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1147:7: KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties
        {
          KW_UNSET292 = (Token) match(input, KW_UNSET, FOLLOW_KW_UNSET_in_alterStatementSuffixProperties5198);
          stream_KW_UNSET.add(KW_UNSET292);

          KW_TBLPROPERTIES293 =
              (Token) match(input, KW_TBLPROPERTIES, FOLLOW_KW_TBLPROPERTIES_in_alterStatementSuffixProperties5200);
          stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES293);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1147:33: ( ifExists )?
          int alt87 = 2;
          switch (input.LA(1)) {
            case KW_IF: {
              alt87 = 1;
            }
              break;
          }

          switch (alt87) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1147:33: ifExists
            {
              pushFollow(FOLLOW_ifExists_in_alterStatementSuffixProperties5202);
              ifExists294 = ifExists();

              state._fsp--;

              stream_ifExists.add(ifExists294.getTree());
            }
              break;
          }

          pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixProperties5205);
          tableProperties295 = tableProperties();

          state._fsp--;

          stream_tableProperties.add(tableProperties295.getTree());

          // AST REWRITE
          // elements: tableProperties, ifExists
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1148:5: -> ^( TOK_ALTERTABLE_DROPPROPERTIES tableProperties ( ifExists )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1148:8: ^( TOK_ALTERTABLE_DROPPROPERTIES tableProperties ( ifExists )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_ALTERTABLE_DROPPROPERTIES, "TOK_ALTERTABLE_DROPPROPERTIES"), root_1);

              adaptor.addChild(root_1, stream_tableProperties.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1148:56: ( ifExists )?
              if (stream_ifExists.hasNext()) {
                adaptor.addChild(root_1, stream_ifExists.nextTree());
              }
              stream_ifExists.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixProperties"

  public static class alterViewSuffixProperties_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterViewSuffixProperties"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1151:1: alterViewSuffixProperties : ( KW_SET KW_TBLPROPERTIES tableProperties -> ^( TOK_ALTERVIEW_PROPERTIES tableProperties ) | KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties -> ^( TOK_ALTERVIEW_DROPPROPERTIES tableProperties ( ifExists )? ) );
  public final HiveParser.alterViewSuffixProperties_return alterViewSuffixProperties() throws RecognitionException {
    HiveParser.alterViewSuffixProperties_return retval = new HiveParser.alterViewSuffixProperties_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_SET296 = null;
    Token KW_TBLPROPERTIES297 = null;
    Token KW_UNSET299 = null;
    Token KW_TBLPROPERTIES300 = null;
    HiveParser.tableProperties_return tableProperties298 = null;

    HiveParser.ifExists_return ifExists301 = null;

    HiveParser.tableProperties_return tableProperties302 = null;

    CommonTree KW_SET296_tree = null;
    CommonTree KW_TBLPROPERTIES297_tree = null;
    CommonTree KW_UNSET299_tree = null;
    CommonTree KW_TBLPROPERTIES300_tree = null;
    RewriteRuleTokenStream stream_KW_UNSET = new RewriteRuleTokenStream(adaptor, "token KW_UNSET");
    RewriteRuleTokenStream stream_KW_TBLPROPERTIES = new RewriteRuleTokenStream(adaptor, "token KW_TBLPROPERTIES");
    RewriteRuleTokenStream stream_KW_SET = new RewriteRuleTokenStream(adaptor, "token KW_SET");
    RewriteRuleSubtreeStream stream_tableProperties = new RewriteRuleSubtreeStream(adaptor, "rule tableProperties");
    RewriteRuleSubtreeStream stream_ifExists = new RewriteRuleSubtreeStream(adaptor, "rule ifExists");
    pushMsg("alter view properties statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1154:5: ( KW_SET KW_TBLPROPERTIES tableProperties -> ^( TOK_ALTERVIEW_PROPERTIES tableProperties ) | KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties -> ^( TOK_ALTERVIEW_DROPPROPERTIES tableProperties ( ifExists )? ) )
      int alt90 = 2;
      switch (input.LA(1)) {
        case KW_SET: {
          alt90 = 1;
        }
          break;
        case KW_UNSET: {
          alt90 = 2;
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 90, 0, input);

          throw nvae;
      }

      switch (alt90) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1154:7: KW_SET KW_TBLPROPERTIES tableProperties
        {
          KW_SET296 = (Token) match(input, KW_SET, FOLLOW_KW_SET_in_alterViewSuffixProperties5247);
          stream_KW_SET.add(KW_SET296);

          KW_TBLPROPERTIES297 =
              (Token) match(input, KW_TBLPROPERTIES, FOLLOW_KW_TBLPROPERTIES_in_alterViewSuffixProperties5249);
          stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES297);

          pushFollow(FOLLOW_tableProperties_in_alterViewSuffixProperties5251);
          tableProperties298 = tableProperties();

          state._fsp--;

          stream_tableProperties.add(tableProperties298.getTree());

          // AST REWRITE
          // elements: tableProperties
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1155:5: -> ^( TOK_ALTERVIEW_PROPERTIES tableProperties )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1155:8: ^( TOK_ALTERVIEW_PROPERTIES tableProperties )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_ALTERVIEW_PROPERTIES, "TOK_ALTERVIEW_PROPERTIES"), root_1);

              adaptor.addChild(root_1, stream_tableProperties.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1156:7: KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties
        {
          KW_UNSET299 = (Token) match(input, KW_UNSET, FOLLOW_KW_UNSET_in_alterViewSuffixProperties5271);
          stream_KW_UNSET.add(KW_UNSET299);

          KW_TBLPROPERTIES300 =
              (Token) match(input, KW_TBLPROPERTIES, FOLLOW_KW_TBLPROPERTIES_in_alterViewSuffixProperties5273);
          stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES300);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1156:33: ( ifExists )?
          int alt89 = 2;
          switch (input.LA(1)) {
            case KW_IF: {
              alt89 = 1;
            }
              break;
          }

          switch (alt89) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1156:33: ifExists
            {
              pushFollow(FOLLOW_ifExists_in_alterViewSuffixProperties5275);
              ifExists301 = ifExists();

              state._fsp--;

              stream_ifExists.add(ifExists301.getTree());
            }
              break;
          }

          pushFollow(FOLLOW_tableProperties_in_alterViewSuffixProperties5278);
          tableProperties302 = tableProperties();

          state._fsp--;

          stream_tableProperties.add(tableProperties302.getTree());

          // AST REWRITE
          // elements: tableProperties, ifExists
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1157:5: -> ^( TOK_ALTERVIEW_DROPPROPERTIES tableProperties ( ifExists )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1157:8: ^( TOK_ALTERVIEW_DROPPROPERTIES tableProperties ( ifExists )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_ALTERVIEW_DROPPROPERTIES, "TOK_ALTERVIEW_DROPPROPERTIES"), root_1);

              adaptor.addChild(root_1, stream_tableProperties.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1157:55: ( ifExists )?
              if (stream_ifExists.hasNext()) {
                adaptor.addChild(root_1, stream_ifExists.nextTree());
              }
              stream_ifExists.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterViewSuffixProperties"

  public static class alterStatementSuffixSerdeProperties_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixSerdeProperties"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1160:1: alterStatementSuffixSerdeProperties : ( KW_SET KW_SERDE serdeName= StringLiteral ( KW_WITH KW_SERDEPROPERTIES tableProperties )? -> ^( TOK_ALTERTABLE_SERIALIZER $serdeName ( tableProperties )? ) | KW_SET KW_SERDEPROPERTIES tableProperties -> ^( TOK_ALTERTABLE_SERDEPROPERTIES tableProperties ) );
  public final HiveParser.alterStatementSuffixSerdeProperties_return alterStatementSuffixSerdeProperties()
      throws RecognitionException {
    HiveParser.alterStatementSuffixSerdeProperties_return retval =
        new HiveParser.alterStatementSuffixSerdeProperties_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token serdeName = null;
    Token KW_SET303 = null;
    Token KW_SERDE304 = null;
    Token KW_WITH305 = null;
    Token KW_SERDEPROPERTIES306 = null;
    Token KW_SET308 = null;
    Token KW_SERDEPROPERTIES309 = null;
    HiveParser.tableProperties_return tableProperties307 = null;

    HiveParser.tableProperties_return tableProperties310 = null;

    CommonTree serdeName_tree = null;
    CommonTree KW_SET303_tree = null;
    CommonTree KW_SERDE304_tree = null;
    CommonTree KW_WITH305_tree = null;
    CommonTree KW_SERDEPROPERTIES306_tree = null;
    CommonTree KW_SET308_tree = null;
    CommonTree KW_SERDEPROPERTIES309_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_WITH = new RewriteRuleTokenStream(adaptor, "token KW_WITH");
    RewriteRuleTokenStream stream_KW_SERDEPROPERTIES = new RewriteRuleTokenStream(adaptor, "token KW_SERDEPROPERTIES");
    RewriteRuleTokenStream stream_KW_SERDE = new RewriteRuleTokenStream(adaptor, "token KW_SERDE");
    RewriteRuleTokenStream stream_KW_SET = new RewriteRuleTokenStream(adaptor, "token KW_SET");
    RewriteRuleSubtreeStream stream_tableProperties = new RewriteRuleSubtreeStream(adaptor, "rule tableProperties");
    pushMsg("alter serdes statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1163:5: ( KW_SET KW_SERDE serdeName= StringLiteral ( KW_WITH KW_SERDEPROPERTIES tableProperties )? -> ^( TOK_ALTERTABLE_SERIALIZER $serdeName ( tableProperties )? ) | KW_SET KW_SERDEPROPERTIES tableProperties -> ^( TOK_ALTERTABLE_SERDEPROPERTIES tableProperties ) )
      int alt92 = 2;
      switch (input.LA(1)) {
        case KW_SET: {
          switch (input.LA(2)) {
            case KW_SERDE: {
              alt92 = 1;
            }
              break;
            case KW_SERDEPROPERTIES: {
              alt92 = 2;
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 92, 1, input);

              throw nvae;
          }
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 92, 0, input);

          throw nvae;
      }

      switch (alt92) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1163:7: KW_SET KW_SERDE serdeName= StringLiteral ( KW_WITH KW_SERDEPROPERTIES tableProperties )?
        {
          KW_SET303 = (Token) match(input, KW_SET, FOLLOW_KW_SET_in_alterStatementSuffixSerdeProperties5320);
          stream_KW_SET.add(KW_SET303);

          KW_SERDE304 = (Token) match(input, KW_SERDE, FOLLOW_KW_SERDE_in_alterStatementSuffixSerdeProperties5322);
          stream_KW_SERDE.add(KW_SERDE304);

          serdeName =
              (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_alterStatementSuffixSerdeProperties5326);
          stream_StringLiteral.add(serdeName);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1163:47: ( KW_WITH KW_SERDEPROPERTIES tableProperties )?
          int alt91 = 2;
          switch (input.LA(1)) {
            case KW_WITH: {
              alt91 = 1;
            }
              break;
          }

          switch (alt91) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1163:48: KW_WITH KW_SERDEPROPERTIES tableProperties
            {
              KW_WITH305 = (Token) match(input, KW_WITH, FOLLOW_KW_WITH_in_alterStatementSuffixSerdeProperties5329);
              stream_KW_WITH.add(KW_WITH305);

              KW_SERDEPROPERTIES306 = (Token) match(input, KW_SERDEPROPERTIES,
                  FOLLOW_KW_SERDEPROPERTIES_in_alterStatementSuffixSerdeProperties5331);
              stream_KW_SERDEPROPERTIES.add(KW_SERDEPROPERTIES306);

              pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixSerdeProperties5333);
              tableProperties307 = tableProperties();

              state._fsp--;

              stream_tableProperties.add(tableProperties307.getTree());
            }
              break;
          }

          // AST REWRITE
          // elements: serdeName, tableProperties
          // token labels: serdeName
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleTokenStream stream_serdeName = new RewriteRuleTokenStream(adaptor, "token serdeName", serdeName);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1164:5: -> ^( TOK_ALTERTABLE_SERIALIZER $serdeName ( tableProperties )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1164:8: ^( TOK_ALTERTABLE_SERIALIZER $serdeName ( tableProperties )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_ALTERTABLE_SERIALIZER, "TOK_ALTERTABLE_SERIALIZER"), root_1);

              adaptor.addChild(root_1, stream_serdeName.nextNode());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1164:47: ( tableProperties )?
              if (stream_tableProperties.hasNext()) {
                adaptor.addChild(root_1, stream_tableProperties.nextTree());
              }
              stream_tableProperties.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1165:7: KW_SET KW_SERDEPROPERTIES tableProperties
        {
          KW_SET308 = (Token) match(input, KW_SET, FOLLOW_KW_SET_in_alterStatementSuffixSerdeProperties5359);
          stream_KW_SET.add(KW_SET308);

          KW_SERDEPROPERTIES309 = (Token) match(input, KW_SERDEPROPERTIES,
              FOLLOW_KW_SERDEPROPERTIES_in_alterStatementSuffixSerdeProperties5361);
          stream_KW_SERDEPROPERTIES.add(KW_SERDEPROPERTIES309);

          pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixSerdeProperties5363);
          tableProperties310 = tableProperties();

          state._fsp--;

          stream_tableProperties.add(tableProperties310.getTree());

          // AST REWRITE
          // elements: tableProperties
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1166:5: -> ^( TOK_ALTERTABLE_SERDEPROPERTIES tableProperties )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1166:8: ^( TOK_ALTERTABLE_SERDEPROPERTIES tableProperties )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_ALTERTABLE_SERDEPROPERTIES, "TOK_ALTERTABLE_SERDEPROPERTIES"),
                  root_1);

              adaptor.addChild(root_1, stream_tableProperties.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixSerdeProperties"

  public static class tablePartitionPrefix_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "tablePartitionPrefix"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1169:1: tablePartitionPrefix : tableName ( partitionSpec )? -> ^( TOK_TABLE_PARTITION tableName ( partitionSpec )? ) ;
  public final HiveParser.tablePartitionPrefix_return tablePartitionPrefix() throws RecognitionException {
    HiveParser.tablePartitionPrefix_return retval = new HiveParser.tablePartitionPrefix_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser_FromClauseParser.tableName_return tableName311 = null;

    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec312 = null;

    RewriteRuleSubtreeStream stream_partitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule partitionSpec");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    pushMsg("table partition prefix", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1172:3: ( tableName ( partitionSpec )? -> ^( TOK_TABLE_PARTITION tableName ( partitionSpec )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1172:5: tableName ( partitionSpec )?
      {
        pushFollow(FOLLOW_tableName_in_tablePartitionPrefix5400);
        tableName311 = tableName();

        state._fsp--;

        stream_tableName.add(tableName311.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1172:15: ( partitionSpec )?
        int alt93 = 2;
        switch (input.LA(1)) {
          case KW_PARTITION: {
            alt93 = 1;
          }
            break;
        }

        switch (alt93) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1172:15: partitionSpec
          {
            pushFollow(FOLLOW_partitionSpec_in_tablePartitionPrefix5402);
            partitionSpec312 = partitionSpec();

            state._fsp--;

            stream_partitionSpec.add(partitionSpec312.getTree());
          }
            break;
        }

        // AST REWRITE
        // elements: tableName, partitionSpec
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1173:3: -> ^( TOK_TABLE_PARTITION tableName ( partitionSpec )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1173:5: ^( TOK_TABLE_PARTITION tableName ( partitionSpec )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_TABLE_PARTITION, "TOK_TABLE_PARTITION"), root_1);

            adaptor.addChild(root_1, stream_tableName.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1173:37: ( partitionSpec )?
            if (stream_partitionSpec.hasNext()) {
              adaptor.addChild(root_1, stream_partitionSpec.nextTree());
            }
            stream_partitionSpec.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "tablePartitionPrefix"

  public static class alterStatementSuffixFileFormat_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixFileFormat"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1176:1: alterStatementSuffixFileFormat : KW_SET KW_FILEFORMAT fileFormat -> ^( TOK_ALTERTABLE_FILEFORMAT fileFormat ) ;
  public final HiveParser.alterStatementSuffixFileFormat_return alterStatementSuffixFileFormat()
      throws RecognitionException {
    HiveParser.alterStatementSuffixFileFormat_return retval = new HiveParser.alterStatementSuffixFileFormat_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_SET313 = null;
    Token KW_FILEFORMAT314 = null;
    HiveParser.fileFormat_return fileFormat315 = null;

    CommonTree KW_SET313_tree = null;
    CommonTree KW_FILEFORMAT314_tree = null;
    RewriteRuleTokenStream stream_KW_FILEFORMAT = new RewriteRuleTokenStream(adaptor, "token KW_FILEFORMAT");
    RewriteRuleTokenStream stream_KW_SET = new RewriteRuleTokenStream(adaptor, "token KW_SET");
    RewriteRuleSubtreeStream stream_fileFormat = new RewriteRuleSubtreeStream(adaptor, "rule fileFormat");
    pushMsg("alter fileformat statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1179:2: ( KW_SET KW_FILEFORMAT fileFormat -> ^( TOK_ALTERTABLE_FILEFORMAT fileFormat ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1179:4: KW_SET KW_FILEFORMAT fileFormat
      {
        KW_SET313 = (Token) match(input, KW_SET, FOLLOW_KW_SET_in_alterStatementSuffixFileFormat5437);
        stream_KW_SET.add(KW_SET313);

        KW_FILEFORMAT314 =
            (Token) match(input, KW_FILEFORMAT, FOLLOW_KW_FILEFORMAT_in_alterStatementSuffixFileFormat5439);
        stream_KW_FILEFORMAT.add(KW_FILEFORMAT314);

        pushFollow(FOLLOW_fileFormat_in_alterStatementSuffixFileFormat5441);
        fileFormat315 = fileFormat();

        state._fsp--;

        stream_fileFormat.add(fileFormat315.getTree());

        // AST REWRITE
        // elements: fileFormat
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1180:2: -> ^( TOK_ALTERTABLE_FILEFORMAT fileFormat )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1180:5: ^( TOK_ALTERTABLE_FILEFORMAT fileFormat )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERTABLE_FILEFORMAT, "TOK_ALTERTABLE_FILEFORMAT"), root_1);

            adaptor.addChild(root_1, stream_fileFormat.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixFileFormat"

  public static class alterStatementSuffixClusterbySortby_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixClusterbySortby"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1183:1: alterStatementSuffixClusterbySortby : ( KW_NOT KW_CLUSTERED -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_CLUSTERED ) | KW_NOT KW_SORTED -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_SORTED ) | tableBuckets -> ^( TOK_ALTERTABLE_CLUSTER_SORT tableBuckets ) );
  public final HiveParser.alterStatementSuffixClusterbySortby_return alterStatementSuffixClusterbySortby()
      throws RecognitionException {
    HiveParser.alterStatementSuffixClusterbySortby_return retval =
        new HiveParser.alterStatementSuffixClusterbySortby_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_NOT316 = null;
    Token KW_CLUSTERED317 = null;
    Token KW_NOT318 = null;
    Token KW_SORTED319 = null;
    HiveParser.tableBuckets_return tableBuckets320 = null;

    CommonTree KW_NOT316_tree = null;
    CommonTree KW_CLUSTERED317_tree = null;
    CommonTree KW_NOT318_tree = null;
    CommonTree KW_SORTED319_tree = null;
    RewriteRuleTokenStream stream_KW_NOT = new RewriteRuleTokenStream(adaptor, "token KW_NOT");
    RewriteRuleTokenStream stream_KW_SORTED = new RewriteRuleTokenStream(adaptor, "token KW_SORTED");
    RewriteRuleTokenStream stream_KW_CLUSTERED = new RewriteRuleTokenStream(adaptor, "token KW_CLUSTERED");
    RewriteRuleSubtreeStream stream_tableBuckets = new RewriteRuleSubtreeStream(adaptor, "rule tableBuckets");
    pushMsg("alter partition cluster by sort by statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1186:3: ( KW_NOT KW_CLUSTERED -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_CLUSTERED ) | KW_NOT KW_SORTED -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_SORTED ) | tableBuckets -> ^( TOK_ALTERTABLE_CLUSTER_SORT tableBuckets ) )
      int alt94 = 3;
      switch (input.LA(1)) {
        case KW_NOT: {
          switch (input.LA(2)) {
            case KW_CLUSTERED: {
              alt94 = 1;
            }
              break;
            case KW_SORTED: {
              alt94 = 2;
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 94, 1, input);

              throw nvae;
          }
        }
          break;
        case KW_CLUSTERED: {
          alt94 = 3;
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 94, 0, input);

          throw nvae;
      }

      switch (alt94) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1186:5: KW_NOT KW_CLUSTERED
        {
          KW_NOT316 = (Token) match(input, KW_NOT, FOLLOW_KW_NOT_in_alterStatementSuffixClusterbySortby5472);
          stream_KW_NOT.add(KW_NOT316);

          KW_CLUSTERED317 =
              (Token) match(input, KW_CLUSTERED, FOLLOW_KW_CLUSTERED_in_alterStatementSuffixClusterbySortby5474);
          stream_KW_CLUSTERED.add(KW_CLUSTERED317);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1186:25: -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_CLUSTERED )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1186:28: ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_CLUSTERED )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_ALTERTABLE_CLUSTER_SORT, "TOK_ALTERTABLE_CLUSTER_SORT"), root_1);

              adaptor.addChild(root_1, (CommonTree) adaptor.create(TOK_NOT_CLUSTERED, "TOK_NOT_CLUSTERED"));

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1187:5: KW_NOT KW_SORTED
        {
          KW_NOT318 = (Token) match(input, KW_NOT, FOLLOW_KW_NOT_in_alterStatementSuffixClusterbySortby5488);
          stream_KW_NOT.add(KW_NOT318);

          KW_SORTED319 = (Token) match(input, KW_SORTED, FOLLOW_KW_SORTED_in_alterStatementSuffixClusterbySortby5490);
          stream_KW_SORTED.add(KW_SORTED319);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1187:22: -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_SORTED )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1187:25: ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_SORTED )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_ALTERTABLE_CLUSTER_SORT, "TOK_ALTERTABLE_CLUSTER_SORT"), root_1);

              adaptor.addChild(root_1, (CommonTree) adaptor.create(TOK_NOT_SORTED, "TOK_NOT_SORTED"));

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 3:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1188:5: tableBuckets
        {
          pushFollow(FOLLOW_tableBuckets_in_alterStatementSuffixClusterbySortby5504);
          tableBuckets320 = tableBuckets();

          state._fsp--;

          stream_tableBuckets.add(tableBuckets320.getTree());

          // AST REWRITE
          // elements: tableBuckets
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1188:18: -> ^( TOK_ALTERTABLE_CLUSTER_SORT tableBuckets )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1188:21: ^( TOK_ALTERTABLE_CLUSTER_SORT tableBuckets )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_ALTERTABLE_CLUSTER_SORT, "TOK_ALTERTABLE_CLUSTER_SORT"), root_1);

              adaptor.addChild(root_1, stream_tableBuckets.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixClusterbySortby"

  public static class alterTblPartitionStatementSuffixSkewedLocation_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterTblPartitionStatementSuffixSkewedLocation"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1191:1: alterTblPartitionStatementSuffixSkewedLocation : KW_SET KW_SKEWED KW_LOCATION skewedLocations -> ^( TOK_ALTERTABLE_SKEWED_LOCATION skewedLocations ) ;
  public final HiveParser.alterTblPartitionStatementSuffixSkewedLocation_return alterTblPartitionStatementSuffixSkewedLocation()
      throws RecognitionException {
    HiveParser.alterTblPartitionStatementSuffixSkewedLocation_return retval =
        new HiveParser.alterTblPartitionStatementSuffixSkewedLocation_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_SET321 = null;
    Token KW_SKEWED322 = null;
    Token KW_LOCATION323 = null;
    HiveParser.skewedLocations_return skewedLocations324 = null;

    CommonTree KW_SET321_tree = null;
    CommonTree KW_SKEWED322_tree = null;
    CommonTree KW_LOCATION323_tree = null;
    RewriteRuleTokenStream stream_KW_LOCATION = new RewriteRuleTokenStream(adaptor, "token KW_LOCATION");
    RewriteRuleTokenStream stream_KW_SKEWED = new RewriteRuleTokenStream(adaptor, "token KW_SKEWED");
    RewriteRuleTokenStream stream_KW_SET = new RewriteRuleTokenStream(adaptor, "token KW_SET");
    RewriteRuleSubtreeStream stream_skewedLocations = new RewriteRuleSubtreeStream(adaptor, "rule skewedLocations");
    pushMsg("alter partition skewed location", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1194:3: ( KW_SET KW_SKEWED KW_LOCATION skewedLocations -> ^( TOK_ALTERTABLE_SKEWED_LOCATION skewedLocations ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1194:5: KW_SET KW_SKEWED KW_LOCATION skewedLocations
      {
        KW_SET321 = (Token) match(input, KW_SET, FOLLOW_KW_SET_in_alterTblPartitionStatementSuffixSkewedLocation5535);
        stream_KW_SET.add(KW_SET321);

        KW_SKEWED322 =
            (Token) match(input, KW_SKEWED, FOLLOW_KW_SKEWED_in_alterTblPartitionStatementSuffixSkewedLocation5537);
        stream_KW_SKEWED.add(KW_SKEWED322);

        KW_LOCATION323 =
            (Token) match(input, KW_LOCATION, FOLLOW_KW_LOCATION_in_alterTblPartitionStatementSuffixSkewedLocation5539);
        stream_KW_LOCATION.add(KW_LOCATION323);

        pushFollow(FOLLOW_skewedLocations_in_alterTblPartitionStatementSuffixSkewedLocation5541);
        skewedLocations324 = skewedLocations();

        state._fsp--;

        stream_skewedLocations.add(skewedLocations324.getTree());

        // AST REWRITE
        // elements: skewedLocations
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1195:3: -> ^( TOK_ALTERTABLE_SKEWED_LOCATION skewedLocations )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1195:6: ^( TOK_ALTERTABLE_SKEWED_LOCATION skewedLocations )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERTABLE_SKEWED_LOCATION, "TOK_ALTERTABLE_SKEWED_LOCATION"), root_1);

            adaptor.addChild(root_1, stream_skewedLocations.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterTblPartitionStatementSuffixSkewedLocation"

  public static class skewedLocations_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "skewedLocations"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1198:1: skewedLocations : LPAREN skewedLocationsList RPAREN -> ^( TOK_SKEWED_LOCATIONS skewedLocationsList ) ;
  public final HiveParser.skewedLocations_return skewedLocations() throws RecognitionException {
    HiveParser.skewedLocations_return retval = new HiveParser.skewedLocations_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token LPAREN325 = null;
    Token RPAREN327 = null;
    HiveParser.skewedLocationsList_return skewedLocationsList326 = null;

    CommonTree LPAREN325_tree = null;
    CommonTree RPAREN327_tree = null;
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleSubtreeStream stream_skewedLocationsList =
        new RewriteRuleSubtreeStream(adaptor, "rule skewedLocationsList");
    pushMsg("skewed locations", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1201:5: ( LPAREN skewedLocationsList RPAREN -> ^( TOK_SKEWED_LOCATIONS skewedLocationsList ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1202:7: LPAREN skewedLocationsList RPAREN
      {
        LPAREN325 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_skewedLocations5584);
        stream_LPAREN.add(LPAREN325);

        pushFollow(FOLLOW_skewedLocationsList_in_skewedLocations5586);
        skewedLocationsList326 = skewedLocationsList();

        state._fsp--;

        stream_skewedLocationsList.add(skewedLocationsList326.getTree());

        RPAREN327 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_skewedLocations5588);
        stream_RPAREN.add(RPAREN327);

        // AST REWRITE
        // elements: skewedLocationsList
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1202:41: -> ^( TOK_SKEWED_LOCATIONS skewedLocationsList )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1202:44: ^( TOK_SKEWED_LOCATIONS skewedLocationsList )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_SKEWED_LOCATIONS, "TOK_SKEWED_LOCATIONS"), root_1);

            adaptor.addChild(root_1, stream_skewedLocationsList.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "skewedLocations"

  public static class skewedLocationsList_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "skewedLocationsList"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1205:1: skewedLocationsList : skewedLocationMap ( COMMA skewedLocationMap )* -> ^( TOK_SKEWED_LOCATION_LIST ( skewedLocationMap )+ ) ;
  public final HiveParser.skewedLocationsList_return skewedLocationsList() throws RecognitionException {
    HiveParser.skewedLocationsList_return retval = new HiveParser.skewedLocationsList_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token COMMA329 = null;
    HiveParser.skewedLocationMap_return skewedLocationMap328 = null;

    HiveParser.skewedLocationMap_return skewedLocationMap330 = null;

    CommonTree COMMA329_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleSubtreeStream stream_skewedLocationMap = new RewriteRuleSubtreeStream(adaptor, "rule skewedLocationMap");
    pushMsg("skewed locations list", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1208:5: ( skewedLocationMap ( COMMA skewedLocationMap )* -> ^( TOK_SKEWED_LOCATION_LIST ( skewedLocationMap )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1209:7: skewedLocationMap ( COMMA skewedLocationMap )*
      {
        pushFollow(FOLLOW_skewedLocationMap_in_skewedLocationsList5629);
        skewedLocationMap328 = skewedLocationMap();

        state._fsp--;

        stream_skewedLocationMap.add(skewedLocationMap328.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1209:25: ( COMMA skewedLocationMap )*
        loop95: do {
          int alt95 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt95 = 1;
            }
              break;
          }

          switch (alt95) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1209:26: COMMA skewedLocationMap
            {
              COMMA329 = (Token) match(input, COMMA, FOLLOW_COMMA_in_skewedLocationsList5632);
              stream_COMMA.add(COMMA329);

              pushFollow(FOLLOW_skewedLocationMap_in_skewedLocationsList5634);
              skewedLocationMap330 = skewedLocationMap();

              state._fsp--;

              stream_skewedLocationMap.add(skewedLocationMap330.getTree());
            }
              break;

            default:
              break loop95;
          }
        } while (true);

        // AST REWRITE
        // elements: skewedLocationMap
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1209:52: -> ^( TOK_SKEWED_LOCATION_LIST ( skewedLocationMap )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1209:55: ^( TOK_SKEWED_LOCATION_LIST ( skewedLocationMap )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_SKEWED_LOCATION_LIST, "TOK_SKEWED_LOCATION_LIST"), root_1);

            if (!(stream_skewedLocationMap.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_skewedLocationMap.hasNext()) {
              adaptor.addChild(root_1, stream_skewedLocationMap.nextTree());
            }
            stream_skewedLocationMap.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "skewedLocationsList"

  public static class skewedLocationMap_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "skewedLocationMap"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1212:1: skewedLocationMap : key= skewedValueLocationElement EQUAL value= StringLiteral -> ^( TOK_SKEWED_LOCATION_MAP $key $value) ;
  public final HiveParser.skewedLocationMap_return skewedLocationMap() throws RecognitionException {
    HiveParser.skewedLocationMap_return retval = new HiveParser.skewedLocationMap_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token value = null;
    Token EQUAL331 = null;
    HiveParser.skewedValueLocationElement_return key = null;

    CommonTree value_tree = null;
    CommonTree EQUAL331_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_EQUAL = new RewriteRuleTokenStream(adaptor, "token EQUAL");
    RewriteRuleSubtreeStream stream_skewedValueLocationElement =
        new RewriteRuleSubtreeStream(adaptor, "rule skewedValueLocationElement");
    pushMsg("specifying skewed location map", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1215:5: (key= skewedValueLocationElement EQUAL value= StringLiteral -> ^( TOK_SKEWED_LOCATION_MAP $key $value) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1216:7: key= skewedValueLocationElement EQUAL value= StringLiteral
      {
        pushFollow(FOLLOW_skewedValueLocationElement_in_skewedLocationMap5680);
        key = skewedValueLocationElement();

        state._fsp--;

        stream_skewedValueLocationElement.add(key.getTree());

        EQUAL331 = (Token) match(input, EQUAL, FOLLOW_EQUAL_in_skewedLocationMap5682);
        stream_EQUAL.add(EQUAL331);

        value = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_skewedLocationMap5686);
        stream_StringLiteral.add(value);

        // AST REWRITE
        // elements: key, value
        // token labels: value
        // rule labels: key, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_value = new RewriteRuleTokenStream(adaptor, "token value", value);
        RewriteRuleSubtreeStream stream_key =
            new RewriteRuleSubtreeStream(adaptor, "rule key", key != null ? key.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1216:64: -> ^( TOK_SKEWED_LOCATION_MAP $key $value)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1216:67: ^( TOK_SKEWED_LOCATION_MAP $key $value)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_SKEWED_LOCATION_MAP, "TOK_SKEWED_LOCATION_MAP"), root_1);

            adaptor.addChild(root_1, stream_key.nextTree());

            adaptor.addChild(root_1, stream_value.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "skewedLocationMap"

  public static class alterStatementSuffixLocation_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixLocation"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1219:1: alterStatementSuffixLocation : KW_SET location -> location ;
  public final HiveParser.alterStatementSuffixLocation_return alterStatementSuffixLocation()
      throws RecognitionException {
    HiveParser.alterStatementSuffixLocation_return retval = new HiveParser.alterStatementSuffixLocation_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_SET332 = null;
    HiveParser.location_return location333 = null;

    CommonTree KW_SET332_tree = null;
    RewriteRuleTokenStream stream_KW_SET = new RewriteRuleTokenStream(adaptor, "token KW_SET");
    RewriteRuleSubtreeStream stream_location = new RewriteRuleSubtreeStream(adaptor, "rule location");
    pushMsg("alter location", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1222:3: ( KW_SET location -> location )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1222:5: KW_SET location
      {
        KW_SET332 = (Token) match(input, KW_SET, FOLLOW_KW_SET_in_alterStatementSuffixLocation5723);
        stream_KW_SET.add(KW_SET332);

        pushFollow(FOLLOW_location_in_alterStatementSuffixLocation5725);
        location333 = location();

        state._fsp--;

        stream_location.add(location333.getTree());

        // AST REWRITE
        // elements: location
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1222:21: -> location
        {
          adaptor.addChild(root_0, stream_location.nextTree());
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixLocation"

  public static class alterStatementSuffixSkewedby_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixSkewedby"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1226:1: alterStatementSuffixSkewedby : ( tableSkewed -> ^( TOK_ALTERTABLE_SKEWED tableSkewed ) | KW_NOT KW_SKEWED -> ^( TOK_ALTERTABLE_SKEWED ) | KW_NOT storedAsDirs -> ^( TOK_ALTERTABLE_SKEWED storedAsDirs ) );
  public final HiveParser.alterStatementSuffixSkewedby_return alterStatementSuffixSkewedby()
      throws RecognitionException {
    HiveParser.alterStatementSuffixSkewedby_return retval = new HiveParser.alterStatementSuffixSkewedby_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_NOT335 = null;
    Token KW_SKEWED336 = null;
    Token KW_NOT337 = null;
    HiveParser.tableSkewed_return tableSkewed334 = null;

    HiveParser.storedAsDirs_return storedAsDirs338 = null;

    CommonTree KW_NOT335_tree = null;
    CommonTree KW_SKEWED336_tree = null;
    CommonTree KW_NOT337_tree = null;
    RewriteRuleTokenStream stream_KW_NOT = new RewriteRuleTokenStream(adaptor, "token KW_NOT");
    RewriteRuleTokenStream stream_KW_SKEWED = new RewriteRuleTokenStream(adaptor, "token KW_SKEWED");
    RewriteRuleSubtreeStream stream_tableSkewed = new RewriteRuleSubtreeStream(adaptor, "rule tableSkewed");
    RewriteRuleSubtreeStream stream_storedAsDirs = new RewriteRuleSubtreeStream(adaptor, "rule storedAsDirs");
    pushMsg("alter skewed by statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1229:2: ( tableSkewed -> ^( TOK_ALTERTABLE_SKEWED tableSkewed ) | KW_NOT KW_SKEWED -> ^( TOK_ALTERTABLE_SKEWED ) | KW_NOT storedAsDirs -> ^( TOK_ALTERTABLE_SKEWED storedAsDirs ) )
      int alt96 = 3;
      switch (input.LA(1)) {
        case KW_SKEWED: {
          alt96 = 1;
        }
          break;
        case KW_NOT: {
          switch (input.LA(2)) {
            case KW_SKEWED: {
              alt96 = 2;
            }
              break;
            case KW_STORED: {
              alt96 = 3;
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 96, 2, input);

              throw nvae;
          }
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 96, 0, input);

          throw nvae;
      }

      switch (alt96) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1229:4: tableSkewed
        {
          pushFollow(FOLLOW_tableSkewed_in_alterStatementSuffixSkewedby5752);
          tableSkewed334 = tableSkewed();

          state._fsp--;

          stream_tableSkewed.add(tableSkewed334.getTree());

          // AST REWRITE
          // elements: tableSkewed
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1230:2: -> ^( TOK_ALTERTABLE_SKEWED tableSkewed )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1230:4: ^( TOK_ALTERTABLE_SKEWED tableSkewed )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor
                  .becomeRoot((CommonTree) adaptor.create(TOK_ALTERTABLE_SKEWED, "TOK_ALTERTABLE_SKEWED"), root_1);

              adaptor.addChild(root_1, stream_tableSkewed.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1232:3: KW_NOT KW_SKEWED
        {
          KW_NOT335 = (Token) match(input, KW_NOT, FOLLOW_KW_NOT_in_alterStatementSuffixSkewedby5767);
          stream_KW_NOT.add(KW_NOT335);

          KW_SKEWED336 = (Token) match(input, KW_SKEWED, FOLLOW_KW_SKEWED_in_alterStatementSuffixSkewedby5769);
          stream_KW_SKEWED.add(KW_SKEWED336);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1233:2: -> ^( TOK_ALTERTABLE_SKEWED )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1233:4: ^( TOK_ALTERTABLE_SKEWED )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor
                  .becomeRoot((CommonTree) adaptor.create(TOK_ALTERTABLE_SKEWED, "TOK_ALTERTABLE_SKEWED"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 3:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1235:3: KW_NOT storedAsDirs
        {
          KW_NOT337 = (Token) match(input, KW_NOT, FOLLOW_KW_NOT_in_alterStatementSuffixSkewedby5782);
          stream_KW_NOT.add(KW_NOT337);

          pushFollow(FOLLOW_storedAsDirs_in_alterStatementSuffixSkewedby5784);
          storedAsDirs338 = storedAsDirs();

          state._fsp--;

          stream_storedAsDirs.add(storedAsDirs338.getTree());

          // AST REWRITE
          // elements: storedAsDirs
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1236:2: -> ^( TOK_ALTERTABLE_SKEWED storedAsDirs )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1236:4: ^( TOK_ALTERTABLE_SKEWED storedAsDirs )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor
                  .becomeRoot((CommonTree) adaptor.create(TOK_ALTERTABLE_SKEWED, "TOK_ALTERTABLE_SKEWED"), root_1);

              adaptor.addChild(root_1, stream_storedAsDirs.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixSkewedby"

  public static class alterStatementSuffixExchangePartition_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixExchangePartition"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1239:1: alterStatementSuffixExchangePartition : KW_EXCHANGE partitionSpec KW_WITH KW_TABLE exchangename= tableName -> ^( TOK_ALTERTABLE_EXCHANGEPARTITION partitionSpec $exchangename) ;
  public final HiveParser.alterStatementSuffixExchangePartition_return alterStatementSuffixExchangePartition()
      throws RecognitionException {
    HiveParser.alterStatementSuffixExchangePartition_return retval =
        new HiveParser.alterStatementSuffixExchangePartition_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_EXCHANGE339 = null;
    Token KW_WITH341 = null;
    Token KW_TABLE342 = null;
    HiveParser_FromClauseParser.tableName_return exchangename = null;

    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec340 = null;

    CommonTree KW_EXCHANGE339_tree = null;
    CommonTree KW_WITH341_tree = null;
    CommonTree KW_TABLE342_tree = null;
    RewriteRuleTokenStream stream_KW_WITH = new RewriteRuleTokenStream(adaptor, "token KW_WITH");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleTokenStream stream_KW_EXCHANGE = new RewriteRuleTokenStream(adaptor, "token KW_EXCHANGE");
    RewriteRuleSubtreeStream stream_partitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule partitionSpec");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    pushMsg("alter exchange partition", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1242:5: ( KW_EXCHANGE partitionSpec KW_WITH KW_TABLE exchangename= tableName -> ^( TOK_ALTERTABLE_EXCHANGEPARTITION partitionSpec $exchangename) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1242:7: KW_EXCHANGE partitionSpec KW_WITH KW_TABLE exchangename= tableName
      {
        KW_EXCHANGE339 =
            (Token) match(input, KW_EXCHANGE, FOLLOW_KW_EXCHANGE_in_alterStatementSuffixExchangePartition5815);
        stream_KW_EXCHANGE.add(KW_EXCHANGE339);

        pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixExchangePartition5817);
        partitionSpec340 = partitionSpec();

        state._fsp--;

        stream_partitionSpec.add(partitionSpec340.getTree());

        KW_WITH341 = (Token) match(input, KW_WITH, FOLLOW_KW_WITH_in_alterStatementSuffixExchangePartition5819);
        stream_KW_WITH.add(KW_WITH341);

        KW_TABLE342 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_alterStatementSuffixExchangePartition5821);
        stream_KW_TABLE.add(KW_TABLE342);

        pushFollow(FOLLOW_tableName_in_alterStatementSuffixExchangePartition5825);
        exchangename = tableName();

        state._fsp--;

        stream_tableName.add(exchangename.getTree());

        // AST REWRITE
        // elements: exchangename, partitionSpec
        // token labels:
        // rule labels: exchangename, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_exchangename =
            new RewriteRuleSubtreeStream(adaptor, "rule exchangename", exchangename != null ? exchangename.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1243:5: -> ^( TOK_ALTERTABLE_EXCHANGEPARTITION partitionSpec $exchangename)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1243:8: ^( TOK_ALTERTABLE_EXCHANGEPARTITION partitionSpec $exchangename)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERTABLE_EXCHANGEPARTITION, "TOK_ALTERTABLE_EXCHANGEPARTITION"),
                root_1);

            adaptor.addChild(root_1, stream_partitionSpec.nextTree());

            adaptor.addChild(root_1, stream_exchangename.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixExchangePartition"

  public static class alterStatementSuffixProtectMode_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixProtectMode"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1246:1: alterStatementSuffixProtectMode : alterProtectMode -> ^( TOK_ALTERTABLE_PROTECTMODE alterProtectMode ) ;
  public final HiveParser.alterStatementSuffixProtectMode_return alterStatementSuffixProtectMode()
      throws RecognitionException {
    HiveParser.alterStatementSuffixProtectMode_return retval = new HiveParser.alterStatementSuffixProtectMode_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.alterProtectMode_return alterProtectMode343 = null;

    RewriteRuleSubtreeStream stream_alterProtectMode = new RewriteRuleSubtreeStream(adaptor, "rule alterProtectMode");
    pushMsg("alter partition protect mode statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1249:5: ( alterProtectMode -> ^( TOK_ALTERTABLE_PROTECTMODE alterProtectMode ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1249:7: alterProtectMode
      {
        pushFollow(FOLLOW_alterProtectMode_in_alterStatementSuffixProtectMode5867);
        alterProtectMode343 = alterProtectMode();

        state._fsp--;

        stream_alterProtectMode.add(alterProtectMode343.getTree());

        // AST REWRITE
        // elements: alterProtectMode
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1250:5: -> ^( TOK_ALTERTABLE_PROTECTMODE alterProtectMode )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1250:8: ^( TOK_ALTERTABLE_PROTECTMODE alterProtectMode )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERTABLE_PROTECTMODE, "TOK_ALTERTABLE_PROTECTMODE"), root_1);

            adaptor.addChild(root_1, stream_alterProtectMode.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixProtectMode"

  public static class alterStatementSuffixRenamePart_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixRenamePart"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1253:1: alterStatementSuffixRenamePart : KW_RENAME KW_TO partitionSpec -> ^( TOK_ALTERTABLE_RENAMEPART partitionSpec ) ;
  public final HiveParser.alterStatementSuffixRenamePart_return alterStatementSuffixRenamePart()
      throws RecognitionException {
    HiveParser.alterStatementSuffixRenamePart_return retval = new HiveParser.alterStatementSuffixRenamePart_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_RENAME344 = null;
    Token KW_TO345 = null;
    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec346 = null;

    CommonTree KW_RENAME344_tree = null;
    CommonTree KW_TO345_tree = null;
    RewriteRuleTokenStream stream_KW_RENAME = new RewriteRuleTokenStream(adaptor, "token KW_RENAME");
    RewriteRuleTokenStream stream_KW_TO = new RewriteRuleTokenStream(adaptor, "token KW_TO");
    RewriteRuleSubtreeStream stream_partitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule partitionSpec");
    pushMsg("alter table rename partition statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1256:5: ( KW_RENAME KW_TO partitionSpec -> ^( TOK_ALTERTABLE_RENAMEPART partitionSpec ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1256:7: KW_RENAME KW_TO partitionSpec
      {
        KW_RENAME344 = (Token) match(input, KW_RENAME, FOLLOW_KW_RENAME_in_alterStatementSuffixRenamePart5906);
        stream_KW_RENAME.add(KW_RENAME344);

        KW_TO345 = (Token) match(input, KW_TO, FOLLOW_KW_TO_in_alterStatementSuffixRenamePart5908);
        stream_KW_TO.add(KW_TO345);

        pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixRenamePart5910);
        partitionSpec346 = partitionSpec();

        state._fsp--;

        stream_partitionSpec.add(partitionSpec346.getTree());

        // AST REWRITE
        // elements: partitionSpec
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1257:5: -> ^( TOK_ALTERTABLE_RENAMEPART partitionSpec )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1257:7: ^( TOK_ALTERTABLE_RENAMEPART partitionSpec )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERTABLE_RENAMEPART, "TOK_ALTERTABLE_RENAMEPART"), root_1);

            adaptor.addChild(root_1, stream_partitionSpec.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixRenamePart"

  public static class alterStatementSuffixStatsPart_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixStatsPart"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1260:1: alterStatementSuffixStatsPart : KW_UPDATE KW_STATISTICS KW_FOR ( KW_COLUMN )? colName= identifier KW_SET tableProperties ( KW_COMMENT comment= StringLiteral )? -> ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? ) ;
  public final HiveParser.alterStatementSuffixStatsPart_return alterStatementSuffixStatsPart()
      throws RecognitionException {
    HiveParser.alterStatementSuffixStatsPart_return retval = new HiveParser.alterStatementSuffixStatsPart_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token comment = null;
    Token KW_UPDATE347 = null;
    Token KW_STATISTICS348 = null;
    Token KW_FOR349 = null;
    Token KW_COLUMN350 = null;
    Token KW_SET351 = null;
    Token KW_COMMENT353 = null;
    HiveParser_IdentifiersParser.identifier_return colName = null;

    HiveParser.tableProperties_return tableProperties352 = null;

    CommonTree comment_tree = null;
    CommonTree KW_UPDATE347_tree = null;
    CommonTree KW_STATISTICS348_tree = null;
    CommonTree KW_FOR349_tree = null;
    CommonTree KW_COLUMN350_tree = null;
    CommonTree KW_SET351_tree = null;
    CommonTree KW_COMMENT353_tree = null;
    RewriteRuleTokenStream stream_KW_STATISTICS = new RewriteRuleTokenStream(adaptor, "token KW_STATISTICS");
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_FOR = new RewriteRuleTokenStream(adaptor, "token KW_FOR");
    RewriteRuleTokenStream stream_KW_UPDATE = new RewriteRuleTokenStream(adaptor, "token KW_UPDATE");
    RewriteRuleTokenStream stream_KW_COMMENT = new RewriteRuleTokenStream(adaptor, "token KW_COMMENT");
    RewriteRuleTokenStream stream_KW_COLUMN = new RewriteRuleTokenStream(adaptor, "token KW_COLUMN");
    RewriteRuleTokenStream stream_KW_SET = new RewriteRuleTokenStream(adaptor, "token KW_SET");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_tableProperties = new RewriteRuleSubtreeStream(adaptor, "rule tableProperties");
    pushMsg("alter table stats partition statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1263:5: ( KW_UPDATE KW_STATISTICS KW_FOR ( KW_COLUMN )? colName= identifier KW_SET tableProperties ( KW_COMMENT comment= StringLiteral )? -> ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1263:7: KW_UPDATE KW_STATISTICS KW_FOR ( KW_COLUMN )? colName= identifier KW_SET tableProperties ( KW_COMMENT comment= StringLiteral )?
      {
        KW_UPDATE347 = (Token) match(input, KW_UPDATE, FOLLOW_KW_UPDATE_in_alterStatementSuffixStatsPart5948);
        stream_KW_UPDATE.add(KW_UPDATE347);

        KW_STATISTICS348 =
            (Token) match(input, KW_STATISTICS, FOLLOW_KW_STATISTICS_in_alterStatementSuffixStatsPart5950);
        stream_KW_STATISTICS.add(KW_STATISTICS348);

        KW_FOR349 = (Token) match(input, KW_FOR, FOLLOW_KW_FOR_in_alterStatementSuffixStatsPart5952);
        stream_KW_FOR.add(KW_FOR349);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1263:38: ( KW_COLUMN )?
        int alt97 = 2;
        switch (input.LA(1)) {
          case KW_COLUMN: {
            alt97 = 1;
          }
            break;
        }

        switch (alt97) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1263:38: KW_COLUMN
          {
            KW_COLUMN350 = (Token) match(input, KW_COLUMN, FOLLOW_KW_COLUMN_in_alterStatementSuffixStatsPart5954);
            stream_KW_COLUMN.add(KW_COLUMN350);
          }
            break;
        }

        pushFollow(FOLLOW_identifier_in_alterStatementSuffixStatsPart5959);
        colName = identifier();

        state._fsp--;

        stream_identifier.add(colName.getTree());

        KW_SET351 = (Token) match(input, KW_SET, FOLLOW_KW_SET_in_alterStatementSuffixStatsPart5961);
        stream_KW_SET.add(KW_SET351);

        pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixStatsPart5963);
        tableProperties352 = tableProperties();

        state._fsp--;

        stream_tableProperties.add(tableProperties352.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1263:91: ( KW_COMMENT comment= StringLiteral )?
        int alt98 = 2;
        switch (input.LA(1)) {
          case KW_COMMENT: {
            alt98 = 1;
          }
            break;
        }

        switch (alt98) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1263:92: KW_COMMENT comment= StringLiteral
          {
            KW_COMMENT353 = (Token) match(input, KW_COMMENT, FOLLOW_KW_COMMENT_in_alterStatementSuffixStatsPart5966);
            stream_KW_COMMENT.add(KW_COMMENT353);

            comment = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_alterStatementSuffixStatsPart5970);
            stream_StringLiteral.add(comment);
          }
            break;
        }

        // AST REWRITE
        // elements: tableProperties, comment, colName
        // token labels: comment
        // rule labels: colName, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_comment = new RewriteRuleTokenStream(adaptor, "token comment", comment);
        RewriteRuleSubtreeStream stream_colName =
            new RewriteRuleSubtreeStream(adaptor, "rule colName", colName != null ? colName.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1264:5: -> ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1264:7: ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERTABLE_UPDATECOLSTATS, "TOK_ALTERTABLE_UPDATECOLSTATS"), root_1);

            adaptor.addChild(root_1, stream_colName.nextTree());

            adaptor.addChild(root_1, stream_tableProperties.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1264:65: ( $comment)?
            if (stream_comment.hasNext()) {
              adaptor.addChild(root_1, stream_comment.nextNode());
            }
            stream_comment.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixStatsPart"

  public static class alterStatementSuffixMergeFiles_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixMergeFiles"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1267:1: alterStatementSuffixMergeFiles : KW_CONCATENATE -> ^( TOK_ALTERTABLE_MERGEFILES ) ;
  public final HiveParser.alterStatementSuffixMergeFiles_return alterStatementSuffixMergeFiles()
      throws RecognitionException {
    HiveParser.alterStatementSuffixMergeFiles_return retval = new HiveParser.alterStatementSuffixMergeFiles_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_CONCATENATE354 = null;

    CommonTree KW_CONCATENATE354_tree = null;
    RewriteRuleTokenStream stream_KW_CONCATENATE = new RewriteRuleTokenStream(adaptor, "token KW_CONCATENATE");

    pushMsg("", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1270:5: ( KW_CONCATENATE -> ^( TOK_ALTERTABLE_MERGEFILES ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1270:7: KW_CONCATENATE
      {
        KW_CONCATENATE354 =
            (Token) match(input, KW_CONCATENATE, FOLLOW_KW_CONCATENATE_in_alterStatementSuffixMergeFiles6017);
        stream_KW_CONCATENATE.add(KW_CONCATENATE354);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1271:5: -> ^( TOK_ALTERTABLE_MERGEFILES )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1271:8: ^( TOK_ALTERTABLE_MERGEFILES )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERTABLE_MERGEFILES, "TOK_ALTERTABLE_MERGEFILES"), root_1);

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixMergeFiles"

  public static class alterProtectMode_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterProtectMode"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1274:1: alterProtectMode : ( KW_ENABLE alterProtectModeMode -> ^( TOK_ENABLE alterProtectModeMode ) | KW_DISABLE alterProtectModeMode -> ^( TOK_DISABLE alterProtectModeMode ) );
  public final HiveParser.alterProtectMode_return alterProtectMode() throws RecognitionException {
    HiveParser.alterProtectMode_return retval = new HiveParser.alterProtectMode_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_ENABLE355 = null;
    Token KW_DISABLE357 = null;
    HiveParser.alterProtectModeMode_return alterProtectModeMode356 = null;

    HiveParser.alterProtectModeMode_return alterProtectModeMode358 = null;

    CommonTree KW_ENABLE355_tree = null;
    CommonTree KW_DISABLE357_tree = null;
    RewriteRuleTokenStream stream_KW_DISABLE = new RewriteRuleTokenStream(adaptor, "token KW_DISABLE");
    RewriteRuleTokenStream stream_KW_ENABLE = new RewriteRuleTokenStream(adaptor, "token KW_ENABLE");
    RewriteRuleSubtreeStream stream_alterProtectModeMode =
        new RewriteRuleSubtreeStream(adaptor, "rule alterProtectModeMode");
    pushMsg("protect mode specification enable", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1277:5: ( KW_ENABLE alterProtectModeMode -> ^( TOK_ENABLE alterProtectModeMode ) | KW_DISABLE alterProtectModeMode -> ^( TOK_DISABLE alterProtectModeMode ) )
      int alt99 = 2;
      switch (input.LA(1)) {
        case KW_ENABLE: {
          alt99 = 1;
        }
          break;
        case KW_DISABLE: {
          alt99 = 2;
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 99, 0, input);

          throw nvae;
      }

      switch (alt99) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1277:7: KW_ENABLE alterProtectModeMode
        {
          KW_ENABLE355 = (Token) match(input, KW_ENABLE, FOLLOW_KW_ENABLE_in_alterProtectMode6054);
          stream_KW_ENABLE.add(KW_ENABLE355);

          pushFollow(FOLLOW_alterProtectModeMode_in_alterProtectMode6056);
          alterProtectModeMode356 = alterProtectModeMode();

          state._fsp--;

          stream_alterProtectModeMode.add(alterProtectModeMode356.getTree());

          // AST REWRITE
          // elements: alterProtectModeMode
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1277:39: -> ^( TOK_ENABLE alterProtectModeMode )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1277:42: ^( TOK_ENABLE alterProtectModeMode )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_ENABLE, "TOK_ENABLE"), root_1);

              adaptor.addChild(root_1, stream_alterProtectModeMode.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1278:7: KW_DISABLE alterProtectModeMode
        {
          KW_DISABLE357 = (Token) match(input, KW_DISABLE, FOLLOW_KW_DISABLE_in_alterProtectMode6073);
          stream_KW_DISABLE.add(KW_DISABLE357);

          pushFollow(FOLLOW_alterProtectModeMode_in_alterProtectMode6075);
          alterProtectModeMode358 = alterProtectModeMode();

          state._fsp--;

          stream_alterProtectModeMode.add(alterProtectModeMode358.getTree());

          // AST REWRITE
          // elements: alterProtectModeMode
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1278:40: -> ^( TOK_DISABLE alterProtectModeMode )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1278:43: ^( TOK_DISABLE alterProtectModeMode )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DISABLE, "TOK_DISABLE"), root_1);

              adaptor.addChild(root_1, stream_alterProtectModeMode.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterProtectMode"

  public static class alterProtectModeMode_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterProtectModeMode"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1281:1: alterProtectModeMode : ( KW_OFFLINE -> ^( TOK_OFFLINE ) | KW_NO_DROP ( KW_CASCADE )? -> ^( TOK_NO_DROP ( KW_CASCADE )? ) | KW_READONLY -> ^( TOK_READONLY ) );
  public final HiveParser.alterProtectModeMode_return alterProtectModeMode() throws RecognitionException {
    HiveParser.alterProtectModeMode_return retval = new HiveParser.alterProtectModeMode_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_OFFLINE359 = null;
    Token KW_NO_DROP360 = null;
    Token KW_CASCADE361 = null;
    Token KW_READONLY362 = null;

    CommonTree KW_OFFLINE359_tree = null;
    CommonTree KW_NO_DROP360_tree = null;
    CommonTree KW_CASCADE361_tree = null;
    CommonTree KW_READONLY362_tree = null;
    RewriteRuleTokenStream stream_KW_CASCADE = new RewriteRuleTokenStream(adaptor, "token KW_CASCADE");
    RewriteRuleTokenStream stream_KW_READONLY = new RewriteRuleTokenStream(adaptor, "token KW_READONLY");
    RewriteRuleTokenStream stream_KW_OFFLINE = new RewriteRuleTokenStream(adaptor, "token KW_OFFLINE");
    RewriteRuleTokenStream stream_KW_NO_DROP = new RewriteRuleTokenStream(adaptor, "token KW_NO_DROP");

    pushMsg("protect mode specification enable", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1284:5: ( KW_OFFLINE -> ^( TOK_OFFLINE ) | KW_NO_DROP ( KW_CASCADE )? -> ^( TOK_NO_DROP ( KW_CASCADE )? ) | KW_READONLY -> ^( TOK_READONLY ) )
      int alt101 = 3;
      switch (input.LA(1)) {
        case KW_OFFLINE: {
          alt101 = 1;
        }
          break;
        case KW_NO_DROP: {
          alt101 = 2;
        }
          break;
        case KW_READONLY: {
          alt101 = 3;
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 101, 0, input);

          throw nvae;
      }

      switch (alt101) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1284:7: KW_OFFLINE
        {
          KW_OFFLINE359 = (Token) match(input, KW_OFFLINE, FOLLOW_KW_OFFLINE_in_alterProtectModeMode6111);
          stream_KW_OFFLINE.add(KW_OFFLINE359);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1284:19: -> ^( TOK_OFFLINE )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1284:22: ^( TOK_OFFLINE )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_OFFLINE, "TOK_OFFLINE"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1285:7: KW_NO_DROP ( KW_CASCADE )?
        {
          KW_NO_DROP360 = (Token) match(input, KW_NO_DROP, FOLLOW_KW_NO_DROP_in_alterProtectModeMode6126);
          stream_KW_NO_DROP.add(KW_NO_DROP360);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1285:18: ( KW_CASCADE )?
          int alt100 = 2;
          switch (input.LA(1)) {
            case KW_CASCADE: {
              alt100 = 1;
            }
              break;
          }

          switch (alt100) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1285:18: KW_CASCADE
            {
              KW_CASCADE361 = (Token) match(input, KW_CASCADE, FOLLOW_KW_CASCADE_in_alterProtectModeMode6128);
              stream_KW_CASCADE.add(KW_CASCADE361);
            }
              break;
          }

          // AST REWRITE
          // elements: KW_CASCADE
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1285:30: -> ^( TOK_NO_DROP ( KW_CASCADE )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1285:33: ^( TOK_NO_DROP ( KW_CASCADE )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_NO_DROP, "TOK_NO_DROP"), root_1);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1285:47: ( KW_CASCADE )?
              if (stream_KW_CASCADE.hasNext()) {
                adaptor.addChild(root_1, stream_KW_CASCADE.nextNode());
              }
              stream_KW_CASCADE.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 3:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1286:7: KW_READONLY
        {
          KW_READONLY362 = (Token) match(input, KW_READONLY, FOLLOW_KW_READONLY_in_alterProtectModeMode6146);
          stream_KW_READONLY.add(KW_READONLY362);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1286:20: -> ^( TOK_READONLY )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1286:23: ^( TOK_READONLY )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_READONLY, "TOK_READONLY"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterProtectModeMode"

  public static class alterStatementSuffixBucketNum_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixBucketNum"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1289:1: alterStatementSuffixBucketNum : KW_INTO num= Number KW_BUCKETS -> ^( TOK_ALTERTABLE_BUCKETS $num) ;
  public final HiveParser.alterStatementSuffixBucketNum_return alterStatementSuffixBucketNum()
      throws RecognitionException {
    HiveParser.alterStatementSuffixBucketNum_return retval = new HiveParser.alterStatementSuffixBucketNum_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token num = null;
    Token KW_INTO363 = null;
    Token KW_BUCKETS364 = null;

    CommonTree num_tree = null;
    CommonTree KW_INTO363_tree = null;
    CommonTree KW_BUCKETS364_tree = null;
    RewriteRuleTokenStream stream_Number = new RewriteRuleTokenStream(adaptor, "token Number");
    RewriteRuleTokenStream stream_KW_INTO = new RewriteRuleTokenStream(adaptor, "token KW_INTO");
    RewriteRuleTokenStream stream_KW_BUCKETS = new RewriteRuleTokenStream(adaptor, "token KW_BUCKETS");

    pushMsg("", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1292:5: ( KW_INTO num= Number KW_BUCKETS -> ^( TOK_ALTERTABLE_BUCKETS $num) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1292:7: KW_INTO num= Number KW_BUCKETS
      {
        KW_INTO363 = (Token) match(input, KW_INTO, FOLLOW_KW_INTO_in_alterStatementSuffixBucketNum6180);
        stream_KW_INTO.add(KW_INTO363);

        num = (Token) match(input, Number, FOLLOW_Number_in_alterStatementSuffixBucketNum6184);
        stream_Number.add(num);

        KW_BUCKETS364 = (Token) match(input, KW_BUCKETS, FOLLOW_KW_BUCKETS_in_alterStatementSuffixBucketNum6186);
        stream_KW_BUCKETS.add(KW_BUCKETS364);

        // AST REWRITE
        // elements: num
        // token labels: num
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_num = new RewriteRuleTokenStream(adaptor, "token num", num);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1293:5: -> ^( TOK_ALTERTABLE_BUCKETS $num)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1293:8: ^( TOK_ALTERTABLE_BUCKETS $num)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_ALTERTABLE_BUCKETS, "TOK_ALTERTABLE_BUCKETS"), root_1);

            adaptor.addChild(root_1, stream_num.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixBucketNum"

  public static class alterStatementSuffixCompact_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixCompact"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1296:1: alterStatementSuffixCompact : KW_COMPACT compactType= StringLiteral -> ^( TOK_ALTERTABLE_COMPACT $compactType) ;
  public final HiveParser.alterStatementSuffixCompact_return alterStatementSuffixCompact() throws RecognitionException {
    HiveParser.alterStatementSuffixCompact_return retval = new HiveParser.alterStatementSuffixCompact_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token compactType = null;
    Token KW_COMPACT365 = null;

    CommonTree compactType_tree = null;
    CommonTree KW_COMPACT365_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_COMPACT = new RewriteRuleTokenStream(adaptor, "token KW_COMPACT");

    msgs.push("compaction request");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1299:5: ( KW_COMPACT compactType= StringLiteral -> ^( TOK_ALTERTABLE_COMPACT $compactType) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1299:7: KW_COMPACT compactType= StringLiteral
      {
        KW_COMPACT365 = (Token) match(input, KW_COMPACT, FOLLOW_KW_COMPACT_in_alterStatementSuffixCompact6226);
        stream_KW_COMPACT.add(KW_COMPACT365);

        compactType = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_alterStatementSuffixCompact6230);
        stream_StringLiteral.add(compactType);

        // AST REWRITE
        // elements: compactType
        // token labels: compactType
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_compactType =
            new RewriteRuleTokenStream(adaptor, "token compactType", compactType);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1300:5: -> ^( TOK_ALTERTABLE_COMPACT $compactType)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1300:8: ^( TOK_ALTERTABLE_COMPACT $compactType)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_ALTERTABLE_COMPACT, "TOK_ALTERTABLE_COMPACT"), root_1);

            adaptor.addChild(root_1, stream_compactType.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      msgs.pop();
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixCompact"

  public static class fileFormat_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "fileFormat"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1304:1: fileFormat : ( KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral KW_SERDE serdeCls= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )? -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt $serdeCls ( $inDriver)? ( $outDriver)? ) |genericSpec= identifier -> ^( TOK_FILEFORMAT_GENERIC $genericSpec) );
  public final HiveParser.fileFormat_return fileFormat() throws RecognitionException {
    HiveParser.fileFormat_return retval = new HiveParser.fileFormat_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token inFmt = null;
    Token outFmt = null;
    Token serdeCls = null;
    Token inDriver = null;
    Token outDriver = null;
    Token KW_INPUTFORMAT366 = null;
    Token KW_OUTPUTFORMAT367 = null;
    Token KW_SERDE368 = null;
    Token KW_INPUTDRIVER369 = null;
    Token KW_OUTPUTDRIVER370 = null;
    HiveParser_IdentifiersParser.identifier_return genericSpec = null;

    CommonTree inFmt_tree = null;
    CommonTree outFmt_tree = null;
    CommonTree serdeCls_tree = null;
    CommonTree inDriver_tree = null;
    CommonTree outDriver_tree = null;
    CommonTree KW_INPUTFORMAT366_tree = null;
    CommonTree KW_OUTPUTFORMAT367_tree = null;
    CommonTree KW_SERDE368_tree = null;
    CommonTree KW_INPUTDRIVER369_tree = null;
    CommonTree KW_OUTPUTDRIVER370_tree = null;
    RewriteRuleTokenStream stream_KW_INPUTFORMAT = new RewriteRuleTokenStream(adaptor, "token KW_INPUTFORMAT");
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_INPUTDRIVER = new RewriteRuleTokenStream(adaptor, "token KW_INPUTDRIVER");
    RewriteRuleTokenStream stream_KW_SERDE = new RewriteRuleTokenStream(adaptor, "token KW_SERDE");
    RewriteRuleTokenStream stream_KW_OUTPUTFORMAT = new RewriteRuleTokenStream(adaptor, "token KW_OUTPUTFORMAT");
    RewriteRuleTokenStream stream_KW_OUTPUTDRIVER = new RewriteRuleTokenStream(adaptor, "token KW_OUTPUTDRIVER");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    pushMsg("file format specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1307:5: ( KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral KW_SERDE serdeCls= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )? -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt $serdeCls ( $inDriver)? ( $outDriver)? ) |genericSpec= identifier -> ^( TOK_FILEFORMAT_GENERIC $genericSpec) )
      int alt103 = 2;
      switch (input.LA(1)) {
        case KW_INPUTFORMAT: {
          switch (input.LA(2)) {
            case StringLiteral: {
              alt103 = 1;
            }
              break;
            case EOF:
            case KW_LOCATION:
            case KW_PARTITION:
            case KW_SERDEPROPERTIES: {
              alt103 = 2;
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 103, 1, input);

              throw nvae;
          }
        }
          break;
        case Identifier:
        case KW_ADD:
        case KW_ADMIN:
        case KW_AFTER:
        case KW_ALL:
        case KW_ALTER:
        case KW_ANALYZE:
        case KW_ARCHIVE:
        case KW_ARRAY:
        case KW_AS:
        case KW_ASC:
        case KW_AUTHORIZATION:
        case KW_BEFORE:
        case KW_BETWEEN:
        case KW_BIGINT:
        case KW_BINARY:
        case KW_BOOLEAN:
        case KW_BOTH:
        case KW_BUCKET:
        case KW_BUCKETS:
        case KW_BY:
        case KW_CASCADE:
        case KW_CHANGE:
        case KW_CLUSTER:
        case KW_CLUSTERED:
        case KW_CLUSTERSTATUS:
        case KW_COLLECTION:
        case KW_COLUMNS:
        case KW_COMMENT:
        case KW_COMPACT:
        case KW_COMPACTIONS:
        case KW_COMPUTE:
        case KW_CONCATENATE:
        case KW_CONTINUE:
        case KW_CREATE:
        case KW_CUBE:
        case KW_CURSOR:
        case KW_DATA:
        case KW_DATABASES:
        case KW_DATE:
        case KW_DATETIME:
        case KW_DBPROPERTIES:
        case KW_DECIMAL:
        case KW_DEFAULT:
        case KW_DEFERRED:
        case KW_DEFINED:
        case KW_DELETE:
        case KW_DELIMITED:
        case KW_DEPENDENCY:
        case KW_DESC:
        case KW_DESCRIBE:
        case KW_DIRECTORIES:
        case KW_DIRECTORY:
        case KW_DISABLE:
        case KW_DISTRIBUTE:
        case KW_DOUBLE:
        case KW_DROP:
        case KW_ELEM_TYPE:
        case KW_ENABLE:
        case KW_ESCAPED:
        case KW_EXCLUSIVE:
        case KW_EXISTS:
        case KW_EXPLAIN:
        case KW_EXPORT:
        case KW_EXTERNAL:
        case KW_FALSE:
        case KW_FETCH:
        case KW_FIELDS:
        case KW_FILE:
        case KW_FILEFORMAT:
        case KW_FIRST:
        case KW_FLOAT:
        case KW_FOR:
        case KW_FORMAT:
        case KW_FORMATTED:
        case KW_FULL:
        case KW_FUNCTIONS:
        case KW_GRANT:
        case KW_GROUP:
        case KW_GROUPING:
        case KW_HOLD_DDLTIME:
        case KW_IDXPROPERTIES:
        case KW_IGNORE:
        case KW_IMPORT:
        case KW_IN:
        case KW_INDEX:
        case KW_INDEXES:
        case KW_INNER:
        case KW_INPATH:
        case KW_INPUTDRIVER:
        case KW_INSERT:
        case KW_INT:
        case KW_INTERSECT:
        case KW_INTO:
        case KW_IS:
        case KW_ITEMS:
        case KW_JAR:
        case KW_KEYS:
        case KW_KEY_TYPE:
        case KW_LATERAL:
        case KW_LEFT:
        case KW_LIKE:
        case KW_LIMIT:
        case KW_LINES:
        case KW_LOAD:
        case KW_LOCAL:
        case KW_LOCATION:
        case KW_LOCK:
        case KW_LOCKS:
        case KW_LOGICAL:
        case KW_LONG:
        case KW_MAPJOIN:
        case KW_MATERIALIZED:
        case KW_METADATA:
        case KW_MINUS:
        case KW_MSCK:
        case KW_NONE:
        case KW_NOSCAN:
        case KW_NO_DROP:
        case KW_NULL:
        case KW_OF:
        case KW_OFFLINE:
        case KW_OPTION:
        case KW_ORDER:
        case KW_OUT:
        case KW_OUTER:
        case KW_OUTPUTDRIVER:
        case KW_OUTPUTFORMAT:
        case KW_OVERWRITE:
        case KW_OWNER:
        case KW_PARTITION:
        case KW_PARTITIONED:
        case KW_PARTITIONS:
        case KW_PERCENT:
        case KW_PLUS:
        case KW_PRETTY:
        case KW_PRINCIPALS:
        case KW_PROCEDURE:
        case KW_PROTECTION:
        case KW_PURGE:
        case KW_RANGE:
        case KW_READ:
        case KW_READONLY:
        case KW_READS:
        case KW_REBUILD:
        case KW_RECORDREADER:
        case KW_RECORDWRITER:
        case KW_REGEXP:
        case KW_RELOAD:
        case KW_RENAME:
        case KW_REPAIR:
        case KW_REPLACE:
        case KW_REPLICATION:
        case KW_RESTRICT:
        case KW_REVOKE:
        case KW_REWRITE:
        case KW_RIGHT:
        case KW_RLIKE:
        case KW_ROLE:
        case KW_ROLES:
        case KW_ROLLUP:
        case KW_ROW:
        case KW_ROWS:
        case KW_SCHEMA:
        case KW_SCHEMAS:
        case KW_SEMI:
        case KW_SERDE:
        case KW_SERDEPROPERTIES:
        case KW_SERVER:
        case KW_SET:
        case KW_SETS:
        case KW_SHARED:
        case KW_SHOW:
        case KW_SHOW_DATABASE:
        case KW_SKEWED:
        case KW_SMALLINT:
        case KW_SORT:
        case KW_SORTED:
        case KW_SSL:
        case KW_STATISTICS:
        case KW_STORED:
        case KW_STREAMTABLE:
        case KW_STRING:
        case KW_STRUCT:
        case KW_TABLE:
        case KW_TABLES:
        case KW_TBLPROPERTIES:
        case KW_TEMPORARY:
        case KW_TERMINATED:
        case KW_TIMESTAMP:
        case KW_TINYINT:
        case KW_TO:
        case KW_TOUCH:
        case KW_TRANSACTIONS:
        case KW_TRIGGER:
        case KW_TRUE:
        case KW_TRUNCATE:
        case KW_UNARCHIVE:
        case KW_UNDO:
        case KW_UNION:
        case KW_UNIONTYPE:
        case KW_UNLOCK:
        case KW_UNSET:
        case KW_UNSIGNED:
        case KW_UPDATE:
        case KW_URI:
        case KW_USE:
        case KW_USER:
        case KW_USING:
        case KW_UTC:
        case KW_UTCTIMESTAMP:
        case KW_VALUES:
        case KW_VALUE_TYPE:
        case KW_VIEW:
        case KW_WHILE:
        case KW_WITH: {
          alt103 = 2;
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 103, 0, input);

          throw nvae;
      }

      switch (alt103) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1307:7: KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral KW_SERDE serdeCls= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )?
        {
          KW_INPUTFORMAT366 = (Token) match(input, KW_INPUTFORMAT, FOLLOW_KW_INPUTFORMAT_in_fileFormat6271);
          stream_KW_INPUTFORMAT.add(KW_INPUTFORMAT366);

          inFmt = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_fileFormat6275);
          stream_StringLiteral.add(inFmt);

          KW_OUTPUTFORMAT367 = (Token) match(input, KW_OUTPUTFORMAT, FOLLOW_KW_OUTPUTFORMAT_in_fileFormat6277);
          stream_KW_OUTPUTFORMAT.add(KW_OUTPUTFORMAT367);

          outFmt = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_fileFormat6281);
          stream_StringLiteral.add(outFmt);

          KW_SERDE368 = (Token) match(input, KW_SERDE, FOLLOW_KW_SERDE_in_fileFormat6283);
          stream_KW_SERDE.add(KW_SERDE368);

          serdeCls = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_fileFormat6287);
          stream_StringLiteral.add(serdeCls);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1307:111: ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )?
          int alt102 = 2;
          switch (input.LA(1)) {
            case KW_INPUTDRIVER: {
              alt102 = 1;
            }
              break;
          }

          switch (alt102) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1307:112: KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral
            {
              KW_INPUTDRIVER369 = (Token) match(input, KW_INPUTDRIVER, FOLLOW_KW_INPUTDRIVER_in_fileFormat6290);
              stream_KW_INPUTDRIVER.add(KW_INPUTDRIVER369);

              inDriver = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_fileFormat6294);
              stream_StringLiteral.add(inDriver);

              KW_OUTPUTDRIVER370 = (Token) match(input, KW_OUTPUTDRIVER, FOLLOW_KW_OUTPUTDRIVER_in_fileFormat6296);
              stream_KW_OUTPUTDRIVER.add(KW_OUTPUTDRIVER370);

              outDriver = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_fileFormat6300);
              stream_StringLiteral.add(outDriver);
            }
              break;
          }

          // AST REWRITE
          // elements: outFmt, inDriver, serdeCls, outDriver, inFmt
          // token labels: inFmt, inDriver, serdeCls, outDriver, outFmt
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleTokenStream stream_inFmt = new RewriteRuleTokenStream(adaptor, "token inFmt", inFmt);
          RewriteRuleTokenStream stream_inDriver = new RewriteRuleTokenStream(adaptor, "token inDriver", inDriver);
          RewriteRuleTokenStream stream_serdeCls = new RewriteRuleTokenStream(adaptor, "token serdeCls", serdeCls);
          RewriteRuleTokenStream stream_outDriver = new RewriteRuleTokenStream(adaptor, "token outDriver", outDriver);
          RewriteRuleTokenStream stream_outFmt = new RewriteRuleTokenStream(adaptor, "token outFmt", outFmt);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1308:7: -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt $serdeCls ( $inDriver)? ( $outDriver)? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1308:10: ^( TOK_TABLEFILEFORMAT $inFmt $outFmt $serdeCls ( $inDriver)? ( $outDriver)? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor
                  .becomeRoot((CommonTree) adaptor.create(TOK_TABLEFILEFORMAT, "TOK_TABLEFILEFORMAT"), root_1);

              adaptor.addChild(root_1, stream_inFmt.nextNode());

              adaptor.addChild(root_1, stream_outFmt.nextNode());

              adaptor.addChild(root_1, stream_serdeCls.nextNode());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1308:58: ( $inDriver)?
              if (stream_inDriver.hasNext()) {
                adaptor.addChild(root_1, stream_inDriver.nextNode());
              }
              stream_inDriver.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1308:69: ( $outDriver)?
              if (stream_outDriver.hasNext()) {
                adaptor.addChild(root_1, stream_outDriver.nextNode());
              }
              stream_outDriver.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1309:7: genericSpec= identifier
        {
          pushFollow(FOLLOW_identifier_in_fileFormat6341);
          genericSpec = identifier();

          state._fsp--;

          stream_identifier.add(genericSpec.getTree());

          // AST REWRITE
          // elements: genericSpec
          // token labels:
          // rule labels: genericSpec, retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_genericSpec =
              new RewriteRuleSubtreeStream(adaptor, "rule genericSpec", genericSpec != null ? genericSpec.tree : null);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1309:30: -> ^( TOK_FILEFORMAT_GENERIC $genericSpec)
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1309:33: ^( TOK_FILEFORMAT_GENERIC $genericSpec)
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor
                  .becomeRoot((CommonTree) adaptor.create(TOK_FILEFORMAT_GENERIC, "TOK_FILEFORMAT_GENERIC"), root_1);

              adaptor.addChild(root_1, stream_genericSpec.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "fileFormat"

  public static class tabTypeExpr_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "tabTypeExpr"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1312:1: tabTypeExpr : identifier ( DOT ^ ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier ) )* ;
  public final HiveParser.tabTypeExpr_return tabTypeExpr() throws RecognitionException {
    HiveParser.tabTypeExpr_return retval = new HiveParser.tabTypeExpr_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token DOT372 = null;
    Token KW_ELEM_TYPE373 = null;
    Token KW_KEY_TYPE374 = null;
    Token KW_VALUE_TYPE375 = null;
    HiveParser_IdentifiersParser.identifier_return identifier371 = null;

    HiveParser_IdentifiersParser.identifier_return identifier376 = null;

    CommonTree DOT372_tree = null;
    CommonTree KW_ELEM_TYPE373_tree = null;
    CommonTree KW_KEY_TYPE374_tree = null;
    CommonTree KW_VALUE_TYPE375_tree = null;

    pushMsg("specifying table types", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1316:4: ( identifier ( DOT ^ ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier ) )* )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1316:6: identifier ( DOT ^ ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier ) )*
      {
        root_0 = (CommonTree) adaptor.nil();

        pushFollow(FOLLOW_identifier_in_tabTypeExpr6377);
        identifier371 = identifier();

        state._fsp--;

        adaptor.addChild(root_0, identifier371.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1316:17: ( DOT ^ ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier ) )*
        loop105: do {
          int alt105 = 2;
          switch (input.LA(1)) {
            case DOT: {
              alt105 = 1;
            }
              break;
          }

          switch (alt105) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1316:18: DOT ^ ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier )
            {
              DOT372 = (Token) match(input, DOT, FOLLOW_DOT_in_tabTypeExpr6380);
              DOT372_tree = (CommonTree) adaptor.create(DOT372);
              root_0 = (CommonTree) adaptor.becomeRoot(DOT372_tree, root_0);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1316:23: ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier )
              int alt104 = 4;
              switch (input.LA(1)) {
                case KW_ELEM_TYPE: {
                  alt104 = 1;
                }
                  break;
                case KW_KEY_TYPE: {
                  alt104 = 2;
                }
                  break;
                case KW_VALUE_TYPE: {
                  alt104 = 3;
                }
                  break;
                case Identifier:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFAULT:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEYS:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_METADATA:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NONE:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITION:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUES:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH: {
                  alt104 = 4;
                }
                  break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 104, 0, input);

                  throw nvae;
              }

              switch (alt104) {
                case 1:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1316:24: KW_ELEM_TYPE
                {
                  KW_ELEM_TYPE373 = (Token) match(input, KW_ELEM_TYPE, FOLLOW_KW_ELEM_TYPE_in_tabTypeExpr6384);
                  KW_ELEM_TYPE373_tree = (CommonTree) adaptor.create(KW_ELEM_TYPE373);
                  adaptor.addChild(root_0, KW_ELEM_TYPE373_tree);
                }
                  break;
                case 2:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1316:39: KW_KEY_TYPE
                {
                  KW_KEY_TYPE374 = (Token) match(input, KW_KEY_TYPE, FOLLOW_KW_KEY_TYPE_in_tabTypeExpr6388);
                  KW_KEY_TYPE374_tree = (CommonTree) adaptor.create(KW_KEY_TYPE374);
                  adaptor.addChild(root_0, KW_KEY_TYPE374_tree);
                }
                  break;
                case 3:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1316:53: KW_VALUE_TYPE
                {
                  KW_VALUE_TYPE375 = (Token) match(input, KW_VALUE_TYPE, FOLLOW_KW_VALUE_TYPE_in_tabTypeExpr6392);
                  KW_VALUE_TYPE375_tree = (CommonTree) adaptor.create(KW_VALUE_TYPE375);
                  adaptor.addChild(root_0, KW_VALUE_TYPE375_tree);
                }
                  break;
                case 4:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1316:69: identifier
                {
                  pushFollow(FOLLOW_identifier_in_tabTypeExpr6396);
                  identifier376 = identifier();

                  state._fsp--;

                  adaptor.addChild(root_0, identifier376.getTree());
                }
                  break;
              }
            }
              break;

            default:
              break loop105;
          }
        } while (true);
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "tabTypeExpr"

  public static class descTabTypeExpr_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "descTabTypeExpr"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1319:1: descTabTypeExpr : identifier ( DOT ^ ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier ) )* ( identifier )? ;
  public final HiveParser.descTabTypeExpr_return descTabTypeExpr() throws RecognitionException {
    HiveParser.descTabTypeExpr_return retval = new HiveParser.descTabTypeExpr_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token DOT378 = null;
    Token KW_ELEM_TYPE379 = null;
    Token KW_KEY_TYPE380 = null;
    Token KW_VALUE_TYPE381 = null;
    HiveParser_IdentifiersParser.identifier_return identifier377 = null;

    HiveParser_IdentifiersParser.identifier_return identifier382 = null;

    HiveParser_IdentifiersParser.identifier_return identifier383 = null;

    CommonTree DOT378_tree = null;
    CommonTree KW_ELEM_TYPE379_tree = null;
    CommonTree KW_KEY_TYPE380_tree = null;
    CommonTree KW_VALUE_TYPE381_tree = null;

    pushMsg("specifying describe table types", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1323:4: ( identifier ( DOT ^ ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier ) )* ( identifier )? )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1323:6: identifier ( DOT ^ ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier ) )* ( identifier )?
      {
        root_0 = (CommonTree) adaptor.nil();

        pushFollow(FOLLOW_identifier_in_descTabTypeExpr6425);
        identifier377 = identifier();

        state._fsp--;

        adaptor.addChild(root_0, identifier377.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1323:17: ( DOT ^ ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier ) )*
        loop107: do {
          int alt107 = 2;
          switch (input.LA(1)) {
            case DOT: {
              alt107 = 1;
            }
              break;
          }

          switch (alt107) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1323:18: DOT ^ ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier )
            {
              DOT378 = (Token) match(input, DOT, FOLLOW_DOT_in_descTabTypeExpr6428);
              DOT378_tree = (CommonTree) adaptor.create(DOT378);
              root_0 = (CommonTree) adaptor.becomeRoot(DOT378_tree, root_0);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1323:23: ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier )
              int alt106 = 4;
              switch (input.LA(1)) {
                case KW_ELEM_TYPE: {
                  alt106 = 1;
                }
                  break;
                case KW_KEY_TYPE: {
                  alt106 = 2;
                }
                  break;
                case KW_VALUE_TYPE: {
                  alt106 = 3;
                }
                  break;
                case Identifier:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFAULT:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEYS:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_METADATA:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NONE:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITION:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUES:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH: {
                  alt106 = 4;
                }
                  break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 106, 0, input);

                  throw nvae;
              }

              switch (alt106) {
                case 1:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1323:24: KW_ELEM_TYPE
                {
                  KW_ELEM_TYPE379 = (Token) match(input, KW_ELEM_TYPE, FOLLOW_KW_ELEM_TYPE_in_descTabTypeExpr6432);
                  KW_ELEM_TYPE379_tree = (CommonTree) adaptor.create(KW_ELEM_TYPE379);
                  adaptor.addChild(root_0, KW_ELEM_TYPE379_tree);
                }
                  break;
                case 2:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1323:39: KW_KEY_TYPE
                {
                  KW_KEY_TYPE380 = (Token) match(input, KW_KEY_TYPE, FOLLOW_KW_KEY_TYPE_in_descTabTypeExpr6436);
                  KW_KEY_TYPE380_tree = (CommonTree) adaptor.create(KW_KEY_TYPE380);
                  adaptor.addChild(root_0, KW_KEY_TYPE380_tree);
                }
                  break;
                case 3:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1323:53: KW_VALUE_TYPE
                {
                  KW_VALUE_TYPE381 = (Token) match(input, KW_VALUE_TYPE, FOLLOW_KW_VALUE_TYPE_in_descTabTypeExpr6440);
                  KW_VALUE_TYPE381_tree = (CommonTree) adaptor.create(KW_VALUE_TYPE381);
                  adaptor.addChild(root_0, KW_VALUE_TYPE381_tree);
                }
                  break;
                case 4:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1323:69: identifier
                {
                  pushFollow(FOLLOW_identifier_in_descTabTypeExpr6444);
                  identifier382 = identifier();

                  state._fsp--;

                  adaptor.addChild(root_0, identifier382.getTree());
                }
                  break;
              }
            }
              break;

            default:
              break loop107;
          }
        } while (true);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1323:83: ( identifier )?
        int alt108 = 2;
        switch (input.LA(1)) {
          case Identifier:
          case KW_ADD:
          case KW_ADMIN:
          case KW_AFTER:
          case KW_ALL:
          case KW_ALTER:
          case KW_ANALYZE:
          case KW_ARCHIVE:
          case KW_ARRAY:
          case KW_AS:
          case KW_ASC:
          case KW_AUTHORIZATION:
          case KW_BEFORE:
          case KW_BETWEEN:
          case KW_BIGINT:
          case KW_BINARY:
          case KW_BOOLEAN:
          case KW_BOTH:
          case KW_BUCKET:
          case KW_BUCKETS:
          case KW_BY:
          case KW_CASCADE:
          case KW_CHANGE:
          case KW_CLUSTER:
          case KW_CLUSTERED:
          case KW_CLUSTERSTATUS:
          case KW_COLLECTION:
          case KW_COLUMNS:
          case KW_COMMENT:
          case KW_COMPACT:
          case KW_COMPACTIONS:
          case KW_COMPUTE:
          case KW_CONCATENATE:
          case KW_CONTINUE:
          case KW_CREATE:
          case KW_CUBE:
          case KW_CURSOR:
          case KW_DATA:
          case KW_DATABASES:
          case KW_DATE:
          case KW_DATETIME:
          case KW_DBPROPERTIES:
          case KW_DECIMAL:
          case KW_DEFAULT:
          case KW_DEFERRED:
          case KW_DEFINED:
          case KW_DELETE:
          case KW_DELIMITED:
          case KW_DEPENDENCY:
          case KW_DESC:
          case KW_DESCRIBE:
          case KW_DIRECTORIES:
          case KW_DIRECTORY:
          case KW_DISABLE:
          case KW_DISTRIBUTE:
          case KW_DOUBLE:
          case KW_DROP:
          case KW_ELEM_TYPE:
          case KW_ENABLE:
          case KW_ESCAPED:
          case KW_EXCLUSIVE:
          case KW_EXISTS:
          case KW_EXPLAIN:
          case KW_EXPORT:
          case KW_EXTERNAL:
          case KW_FALSE:
          case KW_FETCH:
          case KW_FIELDS:
          case KW_FILE:
          case KW_FILEFORMAT:
          case KW_FIRST:
          case KW_FLOAT:
          case KW_FOR:
          case KW_FORMAT:
          case KW_FORMATTED:
          case KW_FULL:
          case KW_FUNCTIONS:
          case KW_GRANT:
          case KW_GROUP:
          case KW_GROUPING:
          case KW_HOLD_DDLTIME:
          case KW_IDXPROPERTIES:
          case KW_IGNORE:
          case KW_IMPORT:
          case KW_IN:
          case KW_INDEX:
          case KW_INDEXES:
          case KW_INNER:
          case KW_INPATH:
          case KW_INPUTDRIVER:
          case KW_INPUTFORMAT:
          case KW_INSERT:
          case KW_INT:
          case KW_INTERSECT:
          case KW_INTO:
          case KW_IS:
          case KW_ITEMS:
          case KW_JAR:
          case KW_KEYS:
          case KW_KEY_TYPE:
          case KW_LATERAL:
          case KW_LEFT:
          case KW_LIKE:
          case KW_LIMIT:
          case KW_LINES:
          case KW_LOAD:
          case KW_LOCAL:
          case KW_LOCATION:
          case KW_LOCK:
          case KW_LOCKS:
          case KW_LOGICAL:
          case KW_LONG:
          case KW_MAPJOIN:
          case KW_MATERIALIZED:
          case KW_METADATA:
          case KW_MINUS:
          case KW_MSCK:
          case KW_NONE:
          case KW_NOSCAN:
          case KW_NO_DROP:
          case KW_NULL:
          case KW_OF:
          case KW_OFFLINE:
          case KW_OPTION:
          case KW_ORDER:
          case KW_OUT:
          case KW_OUTER:
          case KW_OUTPUTDRIVER:
          case KW_OUTPUTFORMAT:
          case KW_OVERWRITE:
          case KW_OWNER:
          case KW_PARTITIONED:
          case KW_PARTITIONS:
          case KW_PERCENT:
          case KW_PLUS:
          case KW_PRETTY:
          case KW_PRINCIPALS:
          case KW_PROCEDURE:
          case KW_PROTECTION:
          case KW_PURGE:
          case KW_RANGE:
          case KW_READ:
          case KW_READONLY:
          case KW_READS:
          case KW_REBUILD:
          case KW_RECORDREADER:
          case KW_RECORDWRITER:
          case KW_REGEXP:
          case KW_RELOAD:
          case KW_RENAME:
          case KW_REPAIR:
          case KW_REPLACE:
          case KW_REPLICATION:
          case KW_RESTRICT:
          case KW_REVOKE:
          case KW_REWRITE:
          case KW_RIGHT:
          case KW_RLIKE:
          case KW_ROLE:
          case KW_ROLES:
          case KW_ROLLUP:
          case KW_ROW:
          case KW_ROWS:
          case KW_SCHEMA:
          case KW_SCHEMAS:
          case KW_SEMI:
          case KW_SERDE:
          case KW_SERDEPROPERTIES:
          case KW_SERVER:
          case KW_SET:
          case KW_SETS:
          case KW_SHARED:
          case KW_SHOW:
          case KW_SHOW_DATABASE:
          case KW_SKEWED:
          case KW_SMALLINT:
          case KW_SORT:
          case KW_SORTED:
          case KW_SSL:
          case KW_STATISTICS:
          case KW_STORED:
          case KW_STREAMTABLE:
          case KW_STRING:
          case KW_STRUCT:
          case KW_TABLE:
          case KW_TABLES:
          case KW_TBLPROPERTIES:
          case KW_TEMPORARY:
          case KW_TERMINATED:
          case KW_TIMESTAMP:
          case KW_TINYINT:
          case KW_TO:
          case KW_TOUCH:
          case KW_TRANSACTIONS:
          case KW_TRIGGER:
          case KW_TRUE:
          case KW_TRUNCATE:
          case KW_UNARCHIVE:
          case KW_UNDO:
          case KW_UNION:
          case KW_UNIONTYPE:
          case KW_UNLOCK:
          case KW_UNSET:
          case KW_UNSIGNED:
          case KW_UPDATE:
          case KW_URI:
          case KW_USE:
          case KW_USER:
          case KW_USING:
          case KW_UTC:
          case KW_UTCTIMESTAMP:
          case KW_VALUES:
          case KW_VALUE_TYPE:
          case KW_VIEW:
          case KW_WHILE:
          case KW_WITH: {
            alt108 = 1;
          }
            break;
          case KW_PARTITION: {
            switch (input.LA(2)) {
              case EOF:
              case KW_PARTITION: {
                alt108 = 1;
              }
                break;
            }
          }
            break;
        }

        switch (alt108) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1323:83: identifier
          {
            pushFollow(FOLLOW_identifier_in_descTabTypeExpr6449);
            identifier383 = identifier();

            state._fsp--;

            adaptor.addChild(root_0, identifier383.getTree());
          }
            break;
        }
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "descTabTypeExpr"

  public static class partTypeExpr_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "partTypeExpr"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1326:1: partTypeExpr : tabTypeExpr ( partitionSpec )? -> ^( TOK_TABTYPE tabTypeExpr ( partitionSpec )? ) ;
  public final HiveParser.partTypeExpr_return partTypeExpr() throws RecognitionException {
    HiveParser.partTypeExpr_return retval = new HiveParser.partTypeExpr_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.tabTypeExpr_return tabTypeExpr384 = null;

    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec385 = null;

    RewriteRuleSubtreeStream stream_partitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule partitionSpec");
    RewriteRuleSubtreeStream stream_tabTypeExpr = new RewriteRuleSubtreeStream(adaptor, "rule tabTypeExpr");
    pushMsg("specifying table partitions", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1329:5: ( tabTypeExpr ( partitionSpec )? -> ^( TOK_TABTYPE tabTypeExpr ( partitionSpec )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1329:8: tabTypeExpr ( partitionSpec )?
      {
        pushFollow(FOLLOW_tabTypeExpr_in_partTypeExpr6477);
        tabTypeExpr384 = tabTypeExpr();

        state._fsp--;

        stream_tabTypeExpr.add(tabTypeExpr384.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1329:20: ( partitionSpec )?
        int alt109 = 2;
        switch (input.LA(1)) {
          case KW_PARTITION: {
            alt109 = 1;
          }
            break;
        }

        switch (alt109) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1329:20: partitionSpec
          {
            pushFollow(FOLLOW_partitionSpec_in_partTypeExpr6479);
            partitionSpec385 = partitionSpec();

            state._fsp--;

            stream_partitionSpec.add(partitionSpec385.getTree());
          }
            break;
        }

        // AST REWRITE
        // elements: partitionSpec, tabTypeExpr
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1329:35: -> ^( TOK_TABTYPE tabTypeExpr ( partitionSpec )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1329:38: ^( TOK_TABTYPE tabTypeExpr ( partitionSpec )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABTYPE, "TOK_TABTYPE"), root_1);

            adaptor.addChild(root_1, stream_tabTypeExpr.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1329:64: ( partitionSpec )?
            if (stream_partitionSpec.hasNext()) {
              adaptor.addChild(root_1, stream_partitionSpec.nextTree());
            }
            stream_partitionSpec.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "partTypeExpr"

  public static class descPartTypeExpr_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "descPartTypeExpr"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1332:1: descPartTypeExpr : descTabTypeExpr ( partitionSpec )? -> ^( TOK_TABTYPE descTabTypeExpr ( partitionSpec )? ) ;
  public final HiveParser.descPartTypeExpr_return descPartTypeExpr() throws RecognitionException {
    HiveParser.descPartTypeExpr_return retval = new HiveParser.descPartTypeExpr_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.descTabTypeExpr_return descTabTypeExpr386 = null;

    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec387 = null;

    RewriteRuleSubtreeStream stream_descTabTypeExpr = new RewriteRuleSubtreeStream(adaptor, "rule descTabTypeExpr");
    RewriteRuleSubtreeStream stream_partitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule partitionSpec");
    pushMsg("specifying describe table partitions", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1335:5: ( descTabTypeExpr ( partitionSpec )? -> ^( TOK_TABTYPE descTabTypeExpr ( partitionSpec )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1335:8: descTabTypeExpr ( partitionSpec )?
      {
        pushFollow(FOLLOW_descTabTypeExpr_in_descPartTypeExpr6519);
        descTabTypeExpr386 = descTabTypeExpr();

        state._fsp--;

        stream_descTabTypeExpr.add(descTabTypeExpr386.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1335:24: ( partitionSpec )?
        int alt110 = 2;
        switch (input.LA(1)) {
          case KW_PARTITION: {
            alt110 = 1;
          }
            break;
        }

        switch (alt110) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1335:24: partitionSpec
          {
            pushFollow(FOLLOW_partitionSpec_in_descPartTypeExpr6521);
            partitionSpec387 = partitionSpec();

            state._fsp--;

            stream_partitionSpec.add(partitionSpec387.getTree());
          }
            break;
        }

        // AST REWRITE
        // elements: partitionSpec, descTabTypeExpr
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1335:39: -> ^( TOK_TABTYPE descTabTypeExpr ( partitionSpec )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1335:42: ^( TOK_TABTYPE descTabTypeExpr ( partitionSpec )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABTYPE, "TOK_TABTYPE"), root_1);

            adaptor.addChild(root_1, stream_descTabTypeExpr.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1335:72: ( partitionSpec )?
            if (stream_partitionSpec.hasNext()) {
              adaptor.addChild(root_1, stream_partitionSpec.nextTree());
            }
            stream_partitionSpec.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "descPartTypeExpr"

  public static class descStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "descStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1338:1: descStatement : ( ( KW_DESCRIBE | KW_DESC ) ( KW_DATABASE | KW_SCHEMA ) ( KW_EXTENDED )? (dbName= identifier ) -> ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? ) | ( KW_DESCRIBE | KW_DESC ) (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED |descOptions= KW_PRETTY )? (parttype= descPartTypeExpr ) -> ^( TOK_DESCTABLE $parttype ( $descOptions)? ) | ( KW_DESCRIBE | KW_DESC ) KW_FUNCTION ( KW_EXTENDED )? (name= descFuncNames ) -> ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? ) );
  public final HiveParser.descStatement_return descStatement() throws RecognitionException {
    HiveParser.descStatement_return retval = new HiveParser.descStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token descOptions = null;
    Token KW_DESCRIBE388 = null;
    Token KW_DESC389 = null;
    Token KW_DATABASE390 = null;
    Token KW_SCHEMA391 = null;
    Token KW_EXTENDED392 = null;
    Token KW_DESCRIBE393 = null;
    Token KW_DESC394 = null;
    Token KW_DESCRIBE395 = null;
    Token KW_DESC396 = null;
    Token KW_FUNCTION397 = null;
    Token KW_EXTENDED398 = null;
    HiveParser_IdentifiersParser.identifier_return dbName = null;

    HiveParser.descPartTypeExpr_return parttype = null;

    HiveParser_IdentifiersParser.descFuncNames_return name = null;

    CommonTree descOptions_tree = null;
    CommonTree KW_DESCRIBE388_tree = null;
    CommonTree KW_DESC389_tree = null;
    CommonTree KW_DATABASE390_tree = null;
    CommonTree KW_SCHEMA391_tree = null;
    CommonTree KW_EXTENDED392_tree = null;
    CommonTree KW_DESCRIBE393_tree = null;
    CommonTree KW_DESC394_tree = null;
    CommonTree KW_DESCRIBE395_tree = null;
    CommonTree KW_DESC396_tree = null;
    CommonTree KW_FUNCTION397_tree = null;
    CommonTree KW_EXTENDED398_tree = null;
    RewriteRuleTokenStream stream_KW_SCHEMA = new RewriteRuleTokenStream(adaptor, "token KW_SCHEMA");
    RewriteRuleTokenStream stream_KW_PRETTY = new RewriteRuleTokenStream(adaptor, "token KW_PRETTY");
    RewriteRuleTokenStream stream_KW_DATABASE = new RewriteRuleTokenStream(adaptor, "token KW_DATABASE");
    RewriteRuleTokenStream stream_KW_EXTENDED = new RewriteRuleTokenStream(adaptor, "token KW_EXTENDED");
    RewriteRuleTokenStream stream_KW_DESC = new RewriteRuleTokenStream(adaptor, "token KW_DESC");
    RewriteRuleTokenStream stream_KW_FUNCTION = new RewriteRuleTokenStream(adaptor, "token KW_FUNCTION");
    RewriteRuleTokenStream stream_KW_FORMATTED = new RewriteRuleTokenStream(adaptor, "token KW_FORMATTED");
    RewriteRuleTokenStream stream_KW_DESCRIBE = new RewriteRuleTokenStream(adaptor, "token KW_DESCRIBE");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_descPartTypeExpr = new RewriteRuleSubtreeStream(adaptor, "rule descPartTypeExpr");
    RewriteRuleSubtreeStream stream_descFuncNames = new RewriteRuleSubtreeStream(adaptor, "rule descFuncNames");
    pushMsg("describe statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1341:5: ( ( KW_DESCRIBE | KW_DESC ) ( KW_DATABASE | KW_SCHEMA ) ( KW_EXTENDED )? (dbName= identifier ) -> ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? ) | ( KW_DESCRIBE | KW_DESC ) (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED |descOptions= KW_PRETTY )? (parttype= descPartTypeExpr ) -> ^( TOK_DESCTABLE $parttype ( $descOptions)? ) | ( KW_DESCRIBE | KW_DESC ) KW_FUNCTION ( KW_EXTENDED )? (name= descFuncNames ) -> ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? ) )
      int alt118 = 3;
      switch (input.LA(1)) {
        case KW_DESCRIBE: {
          switch (input.LA(2)) {
            case KW_DATABASE: {
              alt118 = 1;
            }
              break;
            case KW_SCHEMA: {
              switch (input.LA(3)) {
                case KW_EXTENDED: {
                  alt118 = 1;
                }
                  break;
                case Identifier: {
                  alt118 = 1;
                }
                  break;
                case KW_PARTITION: {
                  alt118 = 1;
                }
                  break;
                case EOF:
                case DOT: {
                  alt118 = 2;
                }
                  break;
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFAULT:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_METADATA:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NONE:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH: {
                  alt118 = 1;
                }
                  break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 118, 4, input);

                  throw nvae;
              }
            }
              break;
            case Identifier:
            case KW_ADD:
            case KW_ADMIN:
            case KW_AFTER:
            case KW_ALL:
            case KW_ALTER:
            case KW_ANALYZE:
            case KW_ARCHIVE:
            case KW_ARRAY:
            case KW_AS:
            case KW_ASC:
            case KW_AUTHORIZATION:
            case KW_BEFORE:
            case KW_BETWEEN:
            case KW_BIGINT:
            case KW_BINARY:
            case KW_BOOLEAN:
            case KW_BOTH:
            case KW_BUCKET:
            case KW_BUCKETS:
            case KW_BY:
            case KW_CASCADE:
            case KW_CHANGE:
            case KW_CLUSTER:
            case KW_CLUSTERED:
            case KW_CLUSTERSTATUS:
            case KW_COLLECTION:
            case KW_COLUMNS:
            case KW_COMMENT:
            case KW_COMPACT:
            case KW_COMPACTIONS:
            case KW_COMPUTE:
            case KW_CONCATENATE:
            case KW_CONTINUE:
            case KW_CREATE:
            case KW_CUBE:
            case KW_CURSOR:
            case KW_DATA:
            case KW_DATABASES:
            case KW_DATE:
            case KW_DATETIME:
            case KW_DBPROPERTIES:
            case KW_DECIMAL:
            case KW_DEFAULT:
            case KW_DEFERRED:
            case KW_DEFINED:
            case KW_DELETE:
            case KW_DELIMITED:
            case KW_DEPENDENCY:
            case KW_DESC:
            case KW_DESCRIBE:
            case KW_DIRECTORIES:
            case KW_DIRECTORY:
            case KW_DISABLE:
            case KW_DISTRIBUTE:
            case KW_DOUBLE:
            case KW_DROP:
            case KW_ELEM_TYPE:
            case KW_ENABLE:
            case KW_ESCAPED:
            case KW_EXCLUSIVE:
            case KW_EXISTS:
            case KW_EXPLAIN:
            case KW_EXPORT:
            case KW_EXTENDED:
            case KW_EXTERNAL:
            case KW_FALSE:
            case KW_FETCH:
            case KW_FIELDS:
            case KW_FILE:
            case KW_FILEFORMAT:
            case KW_FIRST:
            case KW_FLOAT:
            case KW_FOR:
            case KW_FORMAT:
            case KW_FORMATTED:
            case KW_FULL:
            case KW_FUNCTIONS:
            case KW_GRANT:
            case KW_GROUP:
            case KW_GROUPING:
            case KW_HOLD_DDLTIME:
            case KW_IDXPROPERTIES:
            case KW_IGNORE:
            case KW_IMPORT:
            case KW_IN:
            case KW_INDEX:
            case KW_INDEXES:
            case KW_INNER:
            case KW_INPATH:
            case KW_INPUTDRIVER:
            case KW_INPUTFORMAT:
            case KW_INSERT:
            case KW_INT:
            case KW_INTERSECT:
            case KW_INTO:
            case KW_IS:
            case KW_ITEMS:
            case KW_JAR:
            case KW_KEYS:
            case KW_KEY_TYPE:
            case KW_LATERAL:
            case KW_LEFT:
            case KW_LIKE:
            case KW_LIMIT:
            case KW_LINES:
            case KW_LOAD:
            case KW_LOCAL:
            case KW_LOCATION:
            case KW_LOCK:
            case KW_LOCKS:
            case KW_LOGICAL:
            case KW_LONG:
            case KW_MAPJOIN:
            case KW_MATERIALIZED:
            case KW_METADATA:
            case KW_MINUS:
            case KW_MSCK:
            case KW_NONE:
            case KW_NOSCAN:
            case KW_NO_DROP:
            case KW_NULL:
            case KW_OF:
            case KW_OFFLINE:
            case KW_OPTION:
            case KW_ORDER:
            case KW_OUT:
            case KW_OUTER:
            case KW_OUTPUTDRIVER:
            case KW_OUTPUTFORMAT:
            case KW_OVERWRITE:
            case KW_OWNER:
            case KW_PARTITION:
            case KW_PARTITIONED:
            case KW_PARTITIONS:
            case KW_PERCENT:
            case KW_PLUS:
            case KW_PRETTY:
            case KW_PRINCIPALS:
            case KW_PROCEDURE:
            case KW_PROTECTION:
            case KW_PURGE:
            case KW_RANGE:
            case KW_READ:
            case KW_READONLY:
            case KW_READS:
            case KW_REBUILD:
            case KW_RECORDREADER:
            case KW_RECORDWRITER:
            case KW_REGEXP:
            case KW_RELOAD:
            case KW_RENAME:
            case KW_REPAIR:
            case KW_REPLACE:
            case KW_REPLICATION:
            case KW_RESTRICT:
            case KW_REVOKE:
            case KW_REWRITE:
            case KW_RIGHT:
            case KW_RLIKE:
            case KW_ROLE:
            case KW_ROLES:
            case KW_ROLLUP:
            case KW_ROW:
            case KW_ROWS:
            case KW_SCHEMAS:
            case KW_SEMI:
            case KW_SERDE:
            case KW_SERDEPROPERTIES:
            case KW_SERVER:
            case KW_SET:
            case KW_SETS:
            case KW_SHARED:
            case KW_SHOW:
            case KW_SHOW_DATABASE:
            case KW_SKEWED:
            case KW_SMALLINT:
            case KW_SORT:
            case KW_SORTED:
            case KW_SSL:
            case KW_STATISTICS:
            case KW_STORED:
            case KW_STREAMTABLE:
            case KW_STRING:
            case KW_STRUCT:
            case KW_TABLE:
            case KW_TABLES:
            case KW_TBLPROPERTIES:
            case KW_TEMPORARY:
            case KW_TERMINATED:
            case KW_TIMESTAMP:
            case KW_TINYINT:
            case KW_TO:
            case KW_TOUCH:
            case KW_TRANSACTIONS:
            case KW_TRIGGER:
            case KW_TRUE:
            case KW_TRUNCATE:
            case KW_UNARCHIVE:
            case KW_UNDO:
            case KW_UNION:
            case KW_UNIONTYPE:
            case KW_UNLOCK:
            case KW_UNSET:
            case KW_UNSIGNED:
            case KW_UPDATE:
            case KW_URI:
            case KW_USE:
            case KW_USER:
            case KW_USING:
            case KW_UTC:
            case KW_UTCTIMESTAMP:
            case KW_VALUES:
            case KW_VALUE_TYPE:
            case KW_VIEW:
            case KW_WHILE:
            case KW_WITH: {
              alt118 = 2;
            }
              break;
            case KW_FUNCTION: {
              alt118 = 3;
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 118, 1, input);

              throw nvae;
          }
        }
          break;
        case KW_DESC: {
          switch (input.LA(2)) {
            case KW_DATABASE: {
              alt118 = 1;
            }
              break;
            case KW_SCHEMA: {
              switch (input.LA(3)) {
                case KW_EXTENDED: {
                  alt118 = 1;
                }
                  break;
                case Identifier: {
                  alt118 = 1;
                }
                  break;
                case KW_PARTITION: {
                  alt118 = 1;
                }
                  break;
                case EOF:
                case DOT: {
                  alt118 = 2;
                }
                  break;
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFAULT:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_METADATA:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NONE:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH: {
                  alt118 = 1;
                }
                  break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 118, 12, input);

                  throw nvae;
              }
            }
              break;
            case Identifier:
            case KW_ADD:
            case KW_ADMIN:
            case KW_AFTER:
            case KW_ALL:
            case KW_ALTER:
            case KW_ANALYZE:
            case KW_ARCHIVE:
            case KW_ARRAY:
            case KW_AS:
            case KW_ASC:
            case KW_AUTHORIZATION:
            case KW_BEFORE:
            case KW_BETWEEN:
            case KW_BIGINT:
            case KW_BINARY:
            case KW_BOOLEAN:
            case KW_BOTH:
            case KW_BUCKET:
            case KW_BUCKETS:
            case KW_BY:
            case KW_CASCADE:
            case KW_CHANGE:
            case KW_CLUSTER:
            case KW_CLUSTERED:
            case KW_CLUSTERSTATUS:
            case KW_COLLECTION:
            case KW_COLUMNS:
            case KW_COMMENT:
            case KW_COMPACT:
            case KW_COMPACTIONS:
            case KW_COMPUTE:
            case KW_CONCATENATE:
            case KW_CONTINUE:
            case KW_CREATE:
            case KW_CUBE:
            case KW_CURSOR:
            case KW_DATA:
            case KW_DATABASES:
            case KW_DATE:
            case KW_DATETIME:
            case KW_DBPROPERTIES:
            case KW_DECIMAL:
            case KW_DEFAULT:
            case KW_DEFERRED:
            case KW_DEFINED:
            case KW_DELETE:
            case KW_DELIMITED:
            case KW_DEPENDENCY:
            case KW_DESC:
            case KW_DESCRIBE:
            case KW_DIRECTORIES:
            case KW_DIRECTORY:
            case KW_DISABLE:
            case KW_DISTRIBUTE:
            case KW_DOUBLE:
            case KW_DROP:
            case KW_ELEM_TYPE:
            case KW_ENABLE:
            case KW_ESCAPED:
            case KW_EXCLUSIVE:
            case KW_EXISTS:
            case KW_EXPLAIN:
            case KW_EXPORT:
            case KW_EXTENDED:
            case KW_EXTERNAL:
            case KW_FALSE:
            case KW_FETCH:
            case KW_FIELDS:
            case KW_FILE:
            case KW_FILEFORMAT:
            case KW_FIRST:
            case KW_FLOAT:
            case KW_FOR:
            case KW_FORMAT:
            case KW_FORMATTED:
            case KW_FULL:
            case KW_FUNCTIONS:
            case KW_GRANT:
            case KW_GROUP:
            case KW_GROUPING:
            case KW_HOLD_DDLTIME:
            case KW_IDXPROPERTIES:
            case KW_IGNORE:
            case KW_IMPORT:
            case KW_IN:
            case KW_INDEX:
            case KW_INDEXES:
            case KW_INNER:
            case KW_INPATH:
            case KW_INPUTDRIVER:
            case KW_INPUTFORMAT:
            case KW_INSERT:
            case KW_INT:
            case KW_INTERSECT:
            case KW_INTO:
            case KW_IS:
            case KW_ITEMS:
            case KW_JAR:
            case KW_KEYS:
            case KW_KEY_TYPE:
            case KW_LATERAL:
            case KW_LEFT:
            case KW_LIKE:
            case KW_LIMIT:
            case KW_LINES:
            case KW_LOAD:
            case KW_LOCAL:
            case KW_LOCATION:
            case KW_LOCK:
            case KW_LOCKS:
            case KW_LOGICAL:
            case KW_LONG:
            case KW_MAPJOIN:
            case KW_MATERIALIZED:
            case KW_METADATA:
            case KW_MINUS:
            case KW_MSCK:
            case KW_NONE:
            case KW_NOSCAN:
            case KW_NO_DROP:
            case KW_NULL:
            case KW_OF:
            case KW_OFFLINE:
            case KW_OPTION:
            case KW_ORDER:
            case KW_OUT:
            case KW_OUTER:
            case KW_OUTPUTDRIVER:
            case KW_OUTPUTFORMAT:
            case KW_OVERWRITE:
            case KW_OWNER:
            case KW_PARTITION:
            case KW_PARTITIONED:
            case KW_PARTITIONS:
            case KW_PERCENT:
            case KW_PLUS:
            case KW_PRETTY:
            case KW_PRINCIPALS:
            case KW_PROCEDURE:
            case KW_PROTECTION:
            case KW_PURGE:
            case KW_RANGE:
            case KW_READ:
            case KW_READONLY:
            case KW_READS:
            case KW_REBUILD:
            case KW_RECORDREADER:
            case KW_RECORDWRITER:
            case KW_REGEXP:
            case KW_RELOAD:
            case KW_RENAME:
            case KW_REPAIR:
            case KW_REPLACE:
            case KW_REPLICATION:
            case KW_RESTRICT:
            case KW_REVOKE:
            case KW_REWRITE:
            case KW_RIGHT:
            case KW_RLIKE:
            case KW_ROLE:
            case KW_ROLES:
            case KW_ROLLUP:
            case KW_ROW:
            case KW_ROWS:
            case KW_SCHEMAS:
            case KW_SEMI:
            case KW_SERDE:
            case KW_SERDEPROPERTIES:
            case KW_SERVER:
            case KW_SET:
            case KW_SETS:
            case KW_SHARED:
            case KW_SHOW:
            case KW_SHOW_DATABASE:
            case KW_SKEWED:
            case KW_SMALLINT:
            case KW_SORT:
            case KW_SORTED:
            case KW_SSL:
            case KW_STATISTICS:
            case KW_STORED:
            case KW_STREAMTABLE:
            case KW_STRING:
            case KW_STRUCT:
            case KW_TABLE:
            case KW_TABLES:
            case KW_TBLPROPERTIES:
            case KW_TEMPORARY:
            case KW_TERMINATED:
            case KW_TIMESTAMP:
            case KW_TINYINT:
            case KW_TO:
            case KW_TOUCH:
            case KW_TRANSACTIONS:
            case KW_TRIGGER:
            case KW_TRUE:
            case KW_TRUNCATE:
            case KW_UNARCHIVE:
            case KW_UNDO:
            case KW_UNION:
            case KW_UNIONTYPE:
            case KW_UNLOCK:
            case KW_UNSET:
            case KW_UNSIGNED:
            case KW_UPDATE:
            case KW_URI:
            case KW_USE:
            case KW_USER:
            case KW_USING:
            case KW_UTC:
            case KW_UTCTIMESTAMP:
            case KW_VALUES:
            case KW_VALUE_TYPE:
            case KW_VIEW:
            case KW_WHILE:
            case KW_WITH: {
              alt118 = 2;
            }
              break;
            case KW_FUNCTION: {
              alt118 = 3;
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 118, 2, input);

              throw nvae;
          }
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 118, 0, input);

          throw nvae;
      }

      switch (alt118) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1341:7: ( KW_DESCRIBE | KW_DESC ) ( KW_DATABASE | KW_SCHEMA ) ( KW_EXTENDED )? (dbName= identifier )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1341:7: ( KW_DESCRIBE | KW_DESC )
          int alt111 = 2;
          switch (input.LA(1)) {
            case KW_DESCRIBE: {
              alt111 = 1;
            }
              break;
            case KW_DESC: {
              alt111 = 2;
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 111, 0, input);

              throw nvae;
          }

          switch (alt111) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1341:8: KW_DESCRIBE
            {
              KW_DESCRIBE388 = (Token) match(input, KW_DESCRIBE, FOLLOW_KW_DESCRIBE_in_descStatement6561);
              stream_KW_DESCRIBE.add(KW_DESCRIBE388);
            }
              break;
            case 2:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1341:20: KW_DESC
            {
              KW_DESC389 = (Token) match(input, KW_DESC, FOLLOW_KW_DESC_in_descStatement6563);
              stream_KW_DESC.add(KW_DESC389);
            }
              break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1341:29: ( KW_DATABASE | KW_SCHEMA )
          int alt112 = 2;
          switch (input.LA(1)) {
            case KW_DATABASE: {
              alt112 = 1;
            }
              break;
            case KW_SCHEMA: {
              alt112 = 2;
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 112, 0, input);

              throw nvae;
          }

          switch (alt112) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1341:30: KW_DATABASE
            {
              KW_DATABASE390 = (Token) match(input, KW_DATABASE, FOLLOW_KW_DATABASE_in_descStatement6567);
              stream_KW_DATABASE.add(KW_DATABASE390);
            }
              break;
            case 2:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1341:42: KW_SCHEMA
            {
              KW_SCHEMA391 = (Token) match(input, KW_SCHEMA, FOLLOW_KW_SCHEMA_in_descStatement6569);
              stream_KW_SCHEMA.add(KW_SCHEMA391);
            }
              break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1341:53: ( KW_EXTENDED )?
          int alt113 = 2;
          switch (input.LA(1)) {
            case KW_EXTENDED: {
              alt113 = 1;
            }
              break;
          }

          switch (alt113) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1341:53: KW_EXTENDED
            {
              KW_EXTENDED392 = (Token) match(input, KW_EXTENDED, FOLLOW_KW_EXTENDED_in_descStatement6572);
              stream_KW_EXTENDED.add(KW_EXTENDED392);
            }
              break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1341:66: (dbName= identifier )
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1341:67: dbName= identifier
          {
            pushFollow(FOLLOW_identifier_in_descStatement6578);
            dbName = identifier();

            state._fsp--;

            stream_identifier.add(dbName.getTree());
          }

          // AST REWRITE
          // elements: KW_EXTENDED, dbName
          // token labels:
          // rule labels: dbName, retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_dbName =
              new RewriteRuleSubtreeStream(adaptor, "rule dbName", dbName != null ? dbName.tree : null);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1341:86: -> ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1341:89: ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor
                  .becomeRoot((CommonTree) adaptor.create(TOK_DESCDATABASE, "TOK_DESCDATABASE"), root_1);

              adaptor.addChild(root_1, stream_dbName.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1341:116: ( KW_EXTENDED )?
              if (stream_KW_EXTENDED.hasNext()) {
                adaptor.addChild(root_1, stream_KW_EXTENDED.nextNode());
              }
              stream_KW_EXTENDED.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1342:7: ( KW_DESCRIBE | KW_DESC ) (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED |descOptions= KW_PRETTY )? (parttype= descPartTypeExpr )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1342:7: ( KW_DESCRIBE | KW_DESC )
          int alt114 = 2;
          switch (input.LA(1)) {
            case KW_DESCRIBE: {
              alt114 = 1;
            }
              break;
            case KW_DESC: {
              alt114 = 2;
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 114, 0, input);

              throw nvae;
          }

          switch (alt114) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1342:8: KW_DESCRIBE
            {
              KW_DESCRIBE393 = (Token) match(input, KW_DESCRIBE, FOLLOW_KW_DESCRIBE_in_descStatement6600);
              stream_KW_DESCRIBE.add(KW_DESCRIBE393);
            }
              break;
            case 2:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1342:20: KW_DESC
            {
              KW_DESC394 = (Token) match(input, KW_DESC, FOLLOW_KW_DESC_in_descStatement6602);
              stream_KW_DESC.add(KW_DESC394);
            }
              break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1342:29: (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED |descOptions= KW_PRETTY )?
          int alt115 = 4;
          switch (input.LA(1)) {
            case KW_FORMATTED: {
              switch (input.LA(2)) {
                case Identifier: {
                  alt115 = 1;
                }
                  break;
                case KW_PARTITION: {
                  alt115 = 1;
                }
                  break;
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFAULT:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_METADATA:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NONE:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH: {
                  alt115 = 1;
                }
                  break;
              }
            }
              break;
            case KW_EXTENDED: {
              alt115 = 2;
            }
              break;
            case KW_PRETTY: {
              switch (input.LA(2)) {
                case Identifier: {
                  alt115 = 3;
                }
                  break;
                case KW_PARTITION: {
                  alt115 = 3;
                }
                  break;
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFAULT:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_METADATA:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NONE:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH: {
                  alt115 = 3;
                }
                  break;
              }
            }
              break;
          }

          switch (alt115) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1342:30: descOptions= KW_FORMATTED
            {
              descOptions = (Token) match(input, KW_FORMATTED, FOLLOW_KW_FORMATTED_in_descStatement6608);
              stream_KW_FORMATTED.add(descOptions);
            }
              break;
            case 2:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1342:55: descOptions= KW_EXTENDED
            {
              descOptions = (Token) match(input, KW_EXTENDED, FOLLOW_KW_EXTENDED_in_descStatement6612);
              stream_KW_EXTENDED.add(descOptions);
            }
              break;
            case 3:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1342:79: descOptions= KW_PRETTY
            {
              descOptions = (Token) match(input, KW_PRETTY, FOLLOW_KW_PRETTY_in_descStatement6616);
              stream_KW_PRETTY.add(descOptions);
            }
              break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1342:103: (parttype= descPartTypeExpr )
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1342:104: parttype= descPartTypeExpr
          {
            pushFollow(FOLLOW_descPartTypeExpr_in_descStatement6623);
            parttype = descPartTypeExpr();

            state._fsp--;

            stream_descPartTypeExpr.add(parttype.getTree());
          }

          // AST REWRITE
          // elements: parttype, descOptions
          // token labels: descOptions
          // rule labels: parttype, retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleTokenStream stream_descOptions =
              new RewriteRuleTokenStream(adaptor, "token descOptions", descOptions);
          RewriteRuleSubtreeStream stream_parttype =
              new RewriteRuleSubtreeStream(adaptor, "rule parttype", parttype != null ? parttype.tree : null);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1342:131: -> ^( TOK_DESCTABLE $parttype ( $descOptions)? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1342:134: ^( TOK_DESCTABLE $parttype ( $descOptions)? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DESCTABLE, "TOK_DESCTABLE"), root_1);

              adaptor.addChild(root_1, stream_parttype.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1342:161: ( $descOptions)?
              if (stream_descOptions.hasNext()) {
                adaptor.addChild(root_1, stream_descOptions.nextNode());
              }
              stream_descOptions.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 3:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1343:7: ( KW_DESCRIBE | KW_DESC ) KW_FUNCTION ( KW_EXTENDED )? (name= descFuncNames )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1343:7: ( KW_DESCRIBE | KW_DESC )
          int alt116 = 2;
          switch (input.LA(1)) {
            case KW_DESCRIBE: {
              alt116 = 1;
            }
              break;
            case KW_DESC: {
              alt116 = 2;
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 116, 0, input);

              throw nvae;
          }

          switch (alt116) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1343:8: KW_DESCRIBE
            {
              KW_DESCRIBE395 = (Token) match(input, KW_DESCRIBE, FOLLOW_KW_DESCRIBE_in_descStatement6646);
              stream_KW_DESCRIBE.add(KW_DESCRIBE395);
            }
              break;
            case 2:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1343:20: KW_DESC
            {
              KW_DESC396 = (Token) match(input, KW_DESC, FOLLOW_KW_DESC_in_descStatement6648);
              stream_KW_DESC.add(KW_DESC396);
            }
              break;
          }

          KW_FUNCTION397 = (Token) match(input, KW_FUNCTION, FOLLOW_KW_FUNCTION_in_descStatement6651);
          stream_KW_FUNCTION.add(KW_FUNCTION397);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1343:41: ( KW_EXTENDED )?
          int alt117 = 2;
          switch (input.LA(1)) {
            case KW_EXTENDED: {
              alt117 = 1;
            }
              break;
          }

          switch (alt117) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1343:41: KW_EXTENDED
            {
              KW_EXTENDED398 = (Token) match(input, KW_EXTENDED, FOLLOW_KW_EXTENDED_in_descStatement6653);
              stream_KW_EXTENDED.add(KW_EXTENDED398);
            }
              break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1343:54: (name= descFuncNames )
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1343:55: name= descFuncNames
          {
            pushFollow(FOLLOW_descFuncNames_in_descStatement6659);
            name = descFuncNames();

            state._fsp--;

            stream_descFuncNames.add(name.getTree());
          }

          // AST REWRITE
          // elements: KW_EXTENDED, name
          // token labels:
          // rule labels: name, retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_name =
              new RewriteRuleSubtreeStream(adaptor, "rule name", name != null ? name.tree : null);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1343:75: -> ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1343:78: ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor
                  .becomeRoot((CommonTree) adaptor.create(TOK_DESCFUNCTION, "TOK_DESCFUNCTION"), root_1);

              adaptor.addChild(root_1, stream_name.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1343:103: ( KW_EXTENDED )?
              if (stream_KW_EXTENDED.hasNext()) {
                adaptor.addChild(root_1, stream_KW_EXTENDED.nextNode());
              }
              stream_KW_EXTENDED.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "descStatement"

  public static class analyzeStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "analyzeStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1347:1: analyzeStatement : KW_ANALYZE KW_TABLE (parttype= tableOrPartition ) KW_COMPUTE KW_STATISTICS ( (noscan= KW_NOSCAN ) | (partialscan= KW_PARTIALSCAN ) | ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? ) )? -> ^( TOK_ANALYZE $parttype ( $noscan)? ( $partialscan)? ( KW_COLUMNS )? ( $statsColumnName)? ) ;
  public final HiveParser.analyzeStatement_return analyzeStatement() throws RecognitionException {
    HiveParser.analyzeStatement_return retval = new HiveParser.analyzeStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token noscan = null;
    Token partialscan = null;
    Token KW_ANALYZE399 = null;
    Token KW_TABLE400 = null;
    Token KW_COMPUTE401 = null;
    Token KW_STATISTICS402 = null;
    Token KW_FOR403 = null;
    Token KW_COLUMNS404 = null;
    HiveParser_IdentifiersParser.tableOrPartition_return parttype = null;

    HiveParser.columnNameList_return statsColumnName = null;

    CommonTree noscan_tree = null;
    CommonTree partialscan_tree = null;
    CommonTree KW_ANALYZE399_tree = null;
    CommonTree KW_TABLE400_tree = null;
    CommonTree KW_COMPUTE401_tree = null;
    CommonTree KW_STATISTICS402_tree = null;
    CommonTree KW_FOR403_tree = null;
    CommonTree KW_COLUMNS404_tree = null;
    RewriteRuleTokenStream stream_KW_STATISTICS = new RewriteRuleTokenStream(adaptor, "token KW_STATISTICS");
    RewriteRuleTokenStream stream_KW_ANALYZE = new RewriteRuleTokenStream(adaptor, "token KW_ANALYZE");
    RewriteRuleTokenStream stream_KW_COLUMNS = new RewriteRuleTokenStream(adaptor, "token KW_COLUMNS");
    RewriteRuleTokenStream stream_KW_FOR = new RewriteRuleTokenStream(adaptor, "token KW_FOR");
    RewriteRuleTokenStream stream_KW_PARTIALSCAN = new RewriteRuleTokenStream(adaptor, "token KW_PARTIALSCAN");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleTokenStream stream_KW_COMPUTE = new RewriteRuleTokenStream(adaptor, "token KW_COMPUTE");
    RewriteRuleTokenStream stream_KW_NOSCAN = new RewriteRuleTokenStream(adaptor, "token KW_NOSCAN");
    RewriteRuleSubtreeStream stream_tableOrPartition = new RewriteRuleSubtreeStream(adaptor, "rule tableOrPartition");
    RewriteRuleSubtreeStream stream_columnNameList = new RewriteRuleSubtreeStream(adaptor, "rule columnNameList");
    pushMsg("analyze statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1350:5: ( KW_ANALYZE KW_TABLE (parttype= tableOrPartition ) KW_COMPUTE KW_STATISTICS ( (noscan= KW_NOSCAN ) | (partialscan= KW_PARTIALSCAN ) | ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? ) )? -> ^( TOK_ANALYZE $parttype ( $noscan)? ( $partialscan)? ( KW_COLUMNS )? ( $statsColumnName)? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1350:7: KW_ANALYZE KW_TABLE (parttype= tableOrPartition ) KW_COMPUTE KW_STATISTICS ( (noscan= KW_NOSCAN ) | (partialscan= KW_PARTIALSCAN ) | ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? ) )?
      {
        KW_ANALYZE399 = (Token) match(input, KW_ANALYZE, FOLLOW_KW_ANALYZE_in_analyzeStatement6700);
        stream_KW_ANALYZE.add(KW_ANALYZE399);

        KW_TABLE400 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_analyzeStatement6702);
        stream_KW_TABLE.add(KW_TABLE400);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1350:27: (parttype= tableOrPartition )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1350:28: parttype= tableOrPartition
        {
          pushFollow(FOLLOW_tableOrPartition_in_analyzeStatement6707);
          parttype = tableOrPartition();

          state._fsp--;

          stream_tableOrPartition.add(parttype.getTree());
        }

        KW_COMPUTE401 = (Token) match(input, KW_COMPUTE, FOLLOW_KW_COMPUTE_in_analyzeStatement6710);
        stream_KW_COMPUTE.add(KW_COMPUTE401);

        KW_STATISTICS402 = (Token) match(input, KW_STATISTICS, FOLLOW_KW_STATISTICS_in_analyzeStatement6712);
        stream_KW_STATISTICS.add(KW_STATISTICS402);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1350:80: ( (noscan= KW_NOSCAN ) | (partialscan= KW_PARTIALSCAN ) | ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? ) )?
        int alt120 = 4;
        switch (input.LA(1)) {
          case KW_NOSCAN: {
            alt120 = 1;
          }
            break;
          case KW_PARTIALSCAN: {
            alt120 = 2;
          }
            break;
          case KW_FOR: {
            alt120 = 3;
          }
            break;
        }

        switch (alt120) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1350:81: (noscan= KW_NOSCAN )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1350:81: (noscan= KW_NOSCAN )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1350:82: noscan= KW_NOSCAN
            {
              noscan = (Token) match(input, KW_NOSCAN, FOLLOW_KW_NOSCAN_in_analyzeStatement6718);
              stream_KW_NOSCAN.add(noscan);
            }
          }
            break;
          case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1350:102: (partialscan= KW_PARTIALSCAN )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1350:102: (partialscan= KW_PARTIALSCAN )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1350:103: partialscan= KW_PARTIALSCAN
            {
              partialscan = (Token) match(input, KW_PARTIALSCAN, FOLLOW_KW_PARTIALSCAN_in_analyzeStatement6726);
              stream_KW_PARTIALSCAN.add(partialscan);
            }
          }
            break;
          case 3:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:57: ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:57: ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:58: KW_FOR KW_COLUMNS (statsColumnName= columnNameList )?
            {
              KW_FOR403 = (Token) match(input, KW_FOR, FOLLOW_KW_FOR_in_analyzeStatement6787);
              stream_KW_FOR.add(KW_FOR403);

              KW_COLUMNS404 = (Token) match(input, KW_COLUMNS, FOLLOW_KW_COLUMNS_in_analyzeStatement6789);
              stream_KW_COLUMNS.add(KW_COLUMNS404);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:76: (statsColumnName= columnNameList )?
              int alt119 = 2;
              switch (input.LA(1)) {
                case Identifier:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFAULT:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_METADATA:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NONE:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITION:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH: {
                  alt119 = 1;
                }
                  break;
              }

              switch (alt119) {
                case 1:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:77: statsColumnName= columnNameList
                {
                  pushFollow(FOLLOW_columnNameList_in_analyzeStatement6794);
                  statsColumnName = columnNameList();

                  state._fsp--;

                  stream_columnNameList.add(statsColumnName.getTree());
                }
                  break;
              }
            }
          }
            break;
        }

        // AST REWRITE
        // elements: partialscan, noscan, KW_COLUMNS, statsColumnName, parttype
        // token labels: partialscan, noscan
        // rule labels: statsColumnName, parttype, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_partialscan =
            new RewriteRuleTokenStream(adaptor, "token partialscan", partialscan);
        RewriteRuleTokenStream stream_noscan = new RewriteRuleTokenStream(adaptor, "token noscan", noscan);
        RewriteRuleSubtreeStream stream_statsColumnName = new RewriteRuleSubtreeStream(adaptor, "rule statsColumnName",
            statsColumnName != null ? statsColumnName.tree : null);
        RewriteRuleSubtreeStream stream_parttype =
            new RewriteRuleSubtreeStream(adaptor, "rule parttype", parttype != null ? parttype.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1352:7: -> ^( TOK_ANALYZE $parttype ( $noscan)? ( $partialscan)? ( KW_COLUMNS )? ( $statsColumnName)? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1352:10: ^( TOK_ANALYZE $parttype ( $noscan)? ( $partialscan)? ( KW_COLUMNS )? ( $statsColumnName)? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_ANALYZE, "TOK_ANALYZE"), root_1);

            adaptor.addChild(root_1, stream_parttype.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1352:35: ( $noscan)?
            if (stream_noscan.hasNext()) {
              adaptor.addChild(root_1, stream_noscan.nextNode());
            }
            stream_noscan.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1352:44: ( $partialscan)?
            if (stream_partialscan.hasNext()) {
              adaptor.addChild(root_1, stream_partialscan.nextNode());
            }
            stream_partialscan.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1352:57: ( KW_COLUMNS )?
            if (stream_KW_COLUMNS.hasNext()) {
              adaptor.addChild(root_1, stream_KW_COLUMNS.nextNode());
            }
            stream_KW_COLUMNS.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1352:70: ( $statsColumnName)?
            if (stream_statsColumnName.hasNext()) {
              adaptor.addChild(root_1, stream_statsColumnName.nextTree());
            }
            stream_statsColumnName.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "analyzeStatement"

  public static class showStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "showStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1355:1: showStatement : ( KW_SHOW ( KW_DATABASES | KW_SCHEMAS ) ( KW_LIKE showStmtIdentifier )? -> ^( TOK_SHOWDATABASES ( showStmtIdentifier )? ) | KW_SHOW KW_TABLES ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )? -> ^( TOK_SHOWTABLES ( TOK_FROM $db_name)? ( showStmtIdentifier )? ) | KW_SHOW KW_COLUMNS ( KW_FROM | KW_IN ) tableName ( ( KW_FROM | KW_IN ) db_name= identifier )? -> ^( TOK_SHOWCOLUMNS tableName ( $db_name)? ) | KW_SHOW KW_FUNCTIONS ( KW_LIKE showFunctionIdentifier | showFunctionIdentifier )? -> ^( TOK_SHOWFUNCTIONS ( KW_LIKE )? ( showFunctionIdentifier )? ) | KW_SHOW KW_PARTITIONS tabName= tableName ( partitionSpec )? -> ^( TOK_SHOWPARTITIONS $tabName ( partitionSpec )? ) | KW_SHOW KW_CREATE KW_TABLE tabName= tableName -> ^( TOK_SHOW_CREATETABLE $tabName) | KW_SHOW KW_TABLE KW_EXTENDED ( ( KW_FROM | KW_IN ) db_name= identifier )? KW_LIKE showStmtIdentifier ( partitionSpec )? -> ^( TOK_SHOW_TABLESTATUS showStmtIdentifier ( $db_name)? ( partitionSpec )? ) | KW_SHOW KW_TBLPROPERTIES tableName ( LPAREN prptyName= StringLiteral RPAREN )? -> ^( TOK_SHOW_TBLPROPERTIES tableName ( $prptyName)? ) | KW_SHOW KW_LOCKS (parttype= partTypeExpr )? (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? ) | KW_SHOW KW_LOCKS ( KW_DATABASE | KW_SCHEMA ) (dbName= Identifier ) (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWDBLOCKS $dbName ( $isExtended)? ) | KW_SHOW (showOptions= KW_FORMATTED )? ( KW_INDEX | KW_INDEXES ) KW_ON showStmtIdentifier ( ( KW_FROM | KW_IN ) db_name= identifier )? -> ^( TOK_SHOWINDEXES showStmtIdentifier ( $showOptions)? ( $db_name)? ) | KW_SHOW KW_COMPACTIONS -> ^( TOK_SHOW_COMPACTIONS ) | KW_SHOW KW_TRANSACTIONS -> ^( TOK_SHOW_TRANSACTIONS ) | KW_SHOW KW_CONF StringLiteral -> ^( TOK_SHOWCONF StringLiteral ) );
  public final HiveParser.showStatement_return showStatement() throws RecognitionException {
    HiveParser.showStatement_return retval = new HiveParser.showStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token prptyName = null;
    Token isExtended = null;
    Token dbName = null;
    Token showOptions = null;
    Token KW_SHOW405 = null;
    Token KW_DATABASES406 = null;
    Token KW_SCHEMAS407 = null;
    Token KW_LIKE408 = null;
    Token KW_SHOW410 = null;
    Token KW_TABLES411 = null;
    Token KW_FROM412 = null;
    Token KW_IN413 = null;
    Token KW_LIKE414 = null;
    Token KW_SHOW417 = null;
    Token KW_COLUMNS418 = null;
    Token KW_FROM419 = null;
    Token KW_IN420 = null;
    Token KW_FROM422 = null;
    Token KW_IN423 = null;
    Token KW_SHOW424 = null;
    Token KW_FUNCTIONS425 = null;
    Token KW_LIKE426 = null;
    Token KW_SHOW429 = null;
    Token KW_PARTITIONS430 = null;
    Token KW_SHOW432 = null;
    Token KW_CREATE433 = null;
    Token KW_TABLE434 = null;
    Token KW_SHOW435 = null;
    Token KW_TABLE436 = null;
    Token KW_EXTENDED437 = null;
    Token KW_FROM438 = null;
    Token KW_IN439 = null;
    Token KW_LIKE440 = null;
    Token KW_SHOW443 = null;
    Token KW_TBLPROPERTIES444 = null;
    Token LPAREN446 = null;
    Token RPAREN447 = null;
    Token KW_SHOW448 = null;
    Token KW_LOCKS449 = null;
    Token KW_SHOW450 = null;
    Token KW_LOCKS451 = null;
    Token KW_DATABASE452 = null;
    Token KW_SCHEMA453 = null;
    Token KW_SHOW454 = null;
    Token KW_INDEX455 = null;
    Token KW_INDEXES456 = null;
    Token KW_ON457 = null;
    Token KW_FROM459 = null;
    Token KW_IN460 = null;
    Token KW_SHOW461 = null;
    Token KW_COMPACTIONS462 = null;
    Token KW_SHOW463 = null;
    Token KW_TRANSACTIONS464 = null;
    Token KW_SHOW465 = null;
    Token KW_CONF466 = null;
    Token StringLiteral467 = null;
    HiveParser_IdentifiersParser.identifier_return db_name = null;

    HiveParser_FromClauseParser.tableName_return tabName = null;

    HiveParser.partTypeExpr_return parttype = null;

    HiveParser.showStmtIdentifier_return showStmtIdentifier409 = null;

    HiveParser.showStmtIdentifier_return showStmtIdentifier415 = null;

    HiveParser.showStmtIdentifier_return showStmtIdentifier416 = null;

    HiveParser_FromClauseParser.tableName_return tableName421 = null;

    HiveParser.showFunctionIdentifier_return showFunctionIdentifier427 = null;

    HiveParser.showFunctionIdentifier_return showFunctionIdentifier428 = null;

    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec431 = null;

    HiveParser.showStmtIdentifier_return showStmtIdentifier441 = null;

    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec442 = null;

    HiveParser_FromClauseParser.tableName_return tableName445 = null;

    HiveParser.showStmtIdentifier_return showStmtIdentifier458 = null;

    CommonTree prptyName_tree = null;
    CommonTree isExtended_tree = null;
    CommonTree dbName_tree = null;
    CommonTree showOptions_tree = null;
    CommonTree KW_SHOW405_tree = null;
    CommonTree KW_DATABASES406_tree = null;
    CommonTree KW_SCHEMAS407_tree = null;
    CommonTree KW_LIKE408_tree = null;
    CommonTree KW_SHOW410_tree = null;
    CommonTree KW_TABLES411_tree = null;
    CommonTree KW_FROM412_tree = null;
    CommonTree KW_IN413_tree = null;
    CommonTree KW_LIKE414_tree = null;
    CommonTree KW_SHOW417_tree = null;
    CommonTree KW_COLUMNS418_tree = null;
    CommonTree KW_FROM419_tree = null;
    CommonTree KW_IN420_tree = null;
    CommonTree KW_FROM422_tree = null;
    CommonTree KW_IN423_tree = null;
    CommonTree KW_SHOW424_tree = null;
    CommonTree KW_FUNCTIONS425_tree = null;
    CommonTree KW_LIKE426_tree = null;
    CommonTree KW_SHOW429_tree = null;
    CommonTree KW_PARTITIONS430_tree = null;
    CommonTree KW_SHOW432_tree = null;
    CommonTree KW_CREATE433_tree = null;
    CommonTree KW_TABLE434_tree = null;
    CommonTree KW_SHOW435_tree = null;
    CommonTree KW_TABLE436_tree = null;
    CommonTree KW_EXTENDED437_tree = null;
    CommonTree KW_FROM438_tree = null;
    CommonTree KW_IN439_tree = null;
    CommonTree KW_LIKE440_tree = null;
    CommonTree KW_SHOW443_tree = null;
    CommonTree KW_TBLPROPERTIES444_tree = null;
    CommonTree LPAREN446_tree = null;
    CommonTree RPAREN447_tree = null;
    CommonTree KW_SHOW448_tree = null;
    CommonTree KW_LOCKS449_tree = null;
    CommonTree KW_SHOW450_tree = null;
    CommonTree KW_LOCKS451_tree = null;
    CommonTree KW_DATABASE452_tree = null;
    CommonTree KW_SCHEMA453_tree = null;
    CommonTree KW_SHOW454_tree = null;
    CommonTree KW_INDEX455_tree = null;
    CommonTree KW_INDEXES456_tree = null;
    CommonTree KW_ON457_tree = null;
    CommonTree KW_FROM459_tree = null;
    CommonTree KW_IN460_tree = null;
    CommonTree KW_SHOW461_tree = null;
    CommonTree KW_COMPACTIONS462_tree = null;
    CommonTree KW_SHOW463_tree = null;
    CommonTree KW_TRANSACTIONS464_tree = null;
    CommonTree KW_SHOW465_tree = null;
    CommonTree KW_CONF466_tree = null;
    CommonTree StringLiteral467_tree = null;
    RewriteRuleTokenStream stream_KW_DATABASE = new RewriteRuleTokenStream(adaptor, "token KW_DATABASE");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleTokenStream stream_KW_LIKE = new RewriteRuleTokenStream(adaptor, "token KW_LIKE");
    RewriteRuleTokenStream stream_KW_PARTITIONS = new RewriteRuleTokenStream(adaptor, "token KW_PARTITIONS");
    RewriteRuleTokenStream stream_KW_IN = new RewriteRuleTokenStream(adaptor, "token KW_IN");
    RewriteRuleTokenStream stream_KW_LOCKS = new RewriteRuleTokenStream(adaptor, "token KW_LOCKS");
    RewriteRuleTokenStream stream_Identifier = new RewriteRuleTokenStream(adaptor, "token Identifier");
    RewriteRuleTokenStream stream_KW_TABLES = new RewriteRuleTokenStream(adaptor, "token KW_TABLES");
    RewriteRuleTokenStream stream_KW_FUNCTIONS = new RewriteRuleTokenStream(adaptor, "token KW_FUNCTIONS");
    RewriteRuleTokenStream stream_KW_CREATE = new RewriteRuleTokenStream(adaptor, "token KW_CREATE");
    RewriteRuleTokenStream stream_KW_EXTENDED = new RewriteRuleTokenStream(adaptor, "token KW_EXTENDED");
    RewriteRuleTokenStream stream_KW_CONF = new RewriteRuleTokenStream(adaptor, "token KW_CONF");
    RewriteRuleTokenStream stream_KW_COLUMNS = new RewriteRuleTokenStream(adaptor, "token KW_COLUMNS");
    RewriteRuleTokenStream stream_KW_TRANSACTIONS = new RewriteRuleTokenStream(adaptor, "token KW_TRANSACTIONS");
    RewriteRuleTokenStream stream_KW_SCHEMAS = new RewriteRuleTokenStream(adaptor, "token KW_SCHEMAS");
    RewriteRuleTokenStream stream_KW_FROM = new RewriteRuleTokenStream(adaptor, "token KW_FROM");
    RewriteRuleTokenStream stream_KW_ON = new RewriteRuleTokenStream(adaptor, "token KW_ON");
    RewriteRuleTokenStream stream_KW_FORMATTED = new RewriteRuleTokenStream(adaptor, "token KW_FORMATTED");
    RewriteRuleTokenStream stream_KW_SCHEMA = new RewriteRuleTokenStream(adaptor, "token KW_SCHEMA");
    RewriteRuleTokenStream stream_KW_INDEX = new RewriteRuleTokenStream(adaptor, "token KW_INDEX");
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_KW_COMPACTIONS = new RewriteRuleTokenStream(adaptor, "token KW_COMPACTIONS");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleTokenStream stream_KW_DATABASES = new RewriteRuleTokenStream(adaptor, "token KW_DATABASES");
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_INDEXES = new RewriteRuleTokenStream(adaptor, "token KW_INDEXES");
    RewriteRuleTokenStream stream_KW_SHOW = new RewriteRuleTokenStream(adaptor, "token KW_SHOW");
    RewriteRuleTokenStream stream_KW_TBLPROPERTIES = new RewriteRuleTokenStream(adaptor, "token KW_TBLPROPERTIES");
    RewriteRuleSubtreeStream stream_showStmtIdentifier =
        new RewriteRuleSubtreeStream(adaptor, "rule showStmtIdentifier");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_showFunctionIdentifier =
        new RewriteRuleSubtreeStream(adaptor, "rule showFunctionIdentifier");
    RewriteRuleSubtreeStream stream_partTypeExpr = new RewriteRuleSubtreeStream(adaptor, "rule partTypeExpr");
    RewriteRuleSubtreeStream stream_partitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule partitionSpec");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    pushMsg("show statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1358:5: ( KW_SHOW ( KW_DATABASES | KW_SCHEMAS ) ( KW_LIKE showStmtIdentifier )? -> ^( TOK_SHOWDATABASES ( showStmtIdentifier )? ) | KW_SHOW KW_TABLES ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )? -> ^( TOK_SHOWTABLES ( TOK_FROM $db_name)? ( showStmtIdentifier )? ) | KW_SHOW KW_COLUMNS ( KW_FROM | KW_IN ) tableName ( ( KW_FROM | KW_IN ) db_name= identifier )? -> ^( TOK_SHOWCOLUMNS tableName ( $db_name)? ) | KW_SHOW KW_FUNCTIONS ( KW_LIKE showFunctionIdentifier | showFunctionIdentifier )? -> ^( TOK_SHOWFUNCTIONS ( KW_LIKE )? ( showFunctionIdentifier )? ) | KW_SHOW KW_PARTITIONS tabName= tableName ( partitionSpec )? -> ^( TOK_SHOWPARTITIONS $tabName ( partitionSpec )? ) | KW_SHOW KW_CREATE KW_TABLE tabName= tableName -> ^( TOK_SHOW_CREATETABLE $tabName) | KW_SHOW KW_TABLE KW_EXTENDED ( ( KW_FROM | KW_IN ) db_name= identifier )? KW_LIKE showStmtIdentifier ( partitionSpec )? -> ^( TOK_SHOW_TABLESTATUS showStmtIdentifier ( $db_name)? ( partitionSpec )? ) | KW_SHOW KW_TBLPROPERTIES tableName ( LPAREN prptyName= StringLiteral RPAREN )? -> ^( TOK_SHOW_TBLPROPERTIES tableName ( $prptyName)? ) | KW_SHOW KW_LOCKS (parttype= partTypeExpr )? (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? ) | KW_SHOW KW_LOCKS ( KW_DATABASE | KW_SCHEMA ) (dbName= Identifier ) (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWDBLOCKS $dbName ( $isExtended)? ) | KW_SHOW (showOptions= KW_FORMATTED )? ( KW_INDEX | KW_INDEXES ) KW_ON showStmtIdentifier ( ( KW_FROM | KW_IN ) db_name= identifier )? -> ^( TOK_SHOWINDEXES showStmtIdentifier ( $showOptions)? ( $db_name)? ) | KW_SHOW KW_COMPACTIONS -> ^( TOK_SHOW_COMPACTIONS ) | KW_SHOW KW_TRANSACTIONS -> ^( TOK_SHOW_TRANSACTIONS ) | KW_SHOW KW_CONF StringLiteral -> ^( TOK_SHOWCONF StringLiteral ) )
      int alt143 = 14;
      switch (input.LA(1)) {
        case KW_SHOW: {
          switch (input.LA(2)) {
            case KW_TABLES: {
              alt143 = 2;
            }
              break;
            case KW_COLUMNS: {
              alt143 = 3;
            }
              break;
            case KW_FUNCTIONS: {
              alt143 = 4;
            }
              break;
            case KW_PARTITIONS: {
              alt143 = 5;
            }
              break;
            case KW_CREATE: {
              alt143 = 6;
            }
              break;
            case KW_TABLE: {
              alt143 = 7;
            }
              break;
            case KW_TBLPROPERTIES: {
              alt143 = 8;
            }
              break;
            case KW_LOCKS: {
              switch (input.LA(3)) {
                case EOF:
                case Identifier:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFAULT:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTENDED:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_METADATA:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NONE:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITION:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH: {
                  alt143 = 9;
                }
                  break;
                case KW_SCHEMA: {
                  alt143 = 9;
                }
                  break;
                case KW_DATABASE: {
                  alt143 = 10;
                }
                  break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 143, 9, input);

                  throw nvae;
              }
            }
              break;
            case KW_COMPACTIONS: {
              alt143 = 12;
            }
              break;
            case KW_TRANSACTIONS: {
              alt143 = 13;
            }
              break;
            case KW_CONF: {
              alt143 = 14;
            }
              break;
            case KW_DATABASES:
            case KW_SCHEMAS: {
              alt143 = 1;
            }
              break;
            case KW_FORMATTED:
            case KW_INDEX:
            case KW_INDEXES: {
              alt143 = 11;
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 143, 1, input);

              throw nvae;
          }
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 143, 0, input);

          throw nvae;
      }

      switch (alt143) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1358:7: KW_SHOW ( KW_DATABASES | KW_SCHEMAS ) ( KW_LIKE showStmtIdentifier )?
        {
          KW_SHOW405 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showStatement6856);
          stream_KW_SHOW.add(KW_SHOW405);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1358:15: ( KW_DATABASES | KW_SCHEMAS )
          int alt121 = 2;
          switch (input.LA(1)) {
            case KW_DATABASES: {
              alt121 = 1;
            }
              break;
            case KW_SCHEMAS: {
              alt121 = 2;
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 121, 0, input);

              throw nvae;
          }

          switch (alt121) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1358:16: KW_DATABASES
            {
              KW_DATABASES406 = (Token) match(input, KW_DATABASES, FOLLOW_KW_DATABASES_in_showStatement6859);
              stream_KW_DATABASES.add(KW_DATABASES406);
            }
              break;
            case 2:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1358:29: KW_SCHEMAS
            {
              KW_SCHEMAS407 = (Token) match(input, KW_SCHEMAS, FOLLOW_KW_SCHEMAS_in_showStatement6861);
              stream_KW_SCHEMAS.add(KW_SCHEMAS407);
            }
              break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1358:41: ( KW_LIKE showStmtIdentifier )?
          int alt122 = 2;
          switch (input.LA(1)) {
            case KW_LIKE: {
              alt122 = 1;
            }
              break;
          }

          switch (alt122) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1358:42: KW_LIKE showStmtIdentifier
            {
              KW_LIKE408 = (Token) match(input, KW_LIKE, FOLLOW_KW_LIKE_in_showStatement6865);
              stream_KW_LIKE.add(KW_LIKE408);

              pushFollow(FOLLOW_showStmtIdentifier_in_showStatement6867);
              showStmtIdentifier409 = showStmtIdentifier();

              state._fsp--;

              stream_showStmtIdentifier.add(showStmtIdentifier409.getTree());
            }
              break;
          }

          // AST REWRITE
          // elements: showStmtIdentifier
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1358:71: -> ^( TOK_SHOWDATABASES ( showStmtIdentifier )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1358:74: ^( TOK_SHOWDATABASES ( showStmtIdentifier )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor
                  .becomeRoot((CommonTree) adaptor.create(TOK_SHOWDATABASES, "TOK_SHOWDATABASES"), root_1);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1358:94: ( showStmtIdentifier )?
              if (stream_showStmtIdentifier.hasNext()) {
                adaptor.addChild(root_1, stream_showStmtIdentifier.nextTree());
              }
              stream_showStmtIdentifier.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1359:7: KW_SHOW KW_TABLES ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )?
        {
          KW_SHOW410 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showStatement6886);
          stream_KW_SHOW.add(KW_SHOW410);

          KW_TABLES411 = (Token) match(input, KW_TABLES, FOLLOW_KW_TABLES_in_showStatement6888);
          stream_KW_TABLES.add(KW_TABLES411);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1359:25: ( ( KW_FROM | KW_IN ) db_name= identifier )?
          int alt124 = 2;
          switch (input.LA(1)) {
            case KW_FROM: {
              alt124 = 1;
            }
              break;
            case KW_IN: {
              switch (input.LA(2)) {
                case Identifier:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFAULT:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_METADATA:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NONE:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITION:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH: {
                  alt124 = 1;
                }
                  break;
              }
            }
              break;
          }

          switch (alt124) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1359:26: ( KW_FROM | KW_IN ) db_name= identifier
            {
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1359:26: ( KW_FROM | KW_IN )
              int alt123 = 2;
              switch (input.LA(1)) {
                case KW_FROM: {
                  alt123 = 1;
                }
                  break;
                case KW_IN: {
                  alt123 = 2;
                }
                  break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 123, 0, input);

                  throw nvae;
              }

              switch (alt123) {
                case 1:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1359:27: KW_FROM
                {
                  KW_FROM412 = (Token) match(input, KW_FROM, FOLLOW_KW_FROM_in_showStatement6892);
                  stream_KW_FROM.add(KW_FROM412);
                }
                  break;
                case 2:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1359:35: KW_IN
                {
                  KW_IN413 = (Token) match(input, KW_IN, FOLLOW_KW_IN_in_showStatement6894);
                  stream_KW_IN.add(KW_IN413);
                }
                  break;
              }

              pushFollow(FOLLOW_identifier_in_showStatement6899);
              db_name = identifier();

              state._fsp--;

              stream_identifier.add(db_name.getTree());
            }
              break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1359:63: ( KW_LIKE showStmtIdentifier | showStmtIdentifier )?
          int alt125 = 3;
          switch (input.LA(1)) {
            case KW_LIKE: {
              switch (input.LA(2)) {
                case Identifier:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFAULT:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_METADATA:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NONE:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITION:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH:
                case StringLiteral: {
                  alt125 = 1;
                }
                  break;
                case EOF: {
                  alt125 = 2;
                }
                  break;
              }
            }
              break;
            case Identifier:
            case KW_ADD:
            case KW_ADMIN:
            case KW_AFTER:
            case KW_ALL:
            case KW_ALTER:
            case KW_ANALYZE:
            case KW_ARCHIVE:
            case KW_ARRAY:
            case KW_AS:
            case KW_ASC:
            case KW_AUTHORIZATION:
            case KW_BEFORE:
            case KW_BETWEEN:
            case KW_BIGINT:
            case KW_BINARY:
            case KW_BOOLEAN:
            case KW_BOTH:
            case KW_BUCKET:
            case KW_BUCKETS:
            case KW_BY:
            case KW_CASCADE:
            case KW_CHANGE:
            case KW_CLUSTER:
            case KW_CLUSTERED:
            case KW_CLUSTERSTATUS:
            case KW_COLLECTION:
            case KW_COLUMNS:
            case KW_COMMENT:
            case KW_COMPACT:
            case KW_COMPACTIONS:
            case KW_COMPUTE:
            case KW_CONCATENATE:
            case KW_CONTINUE:
            case KW_CREATE:
            case KW_CUBE:
            case KW_CURSOR:
            case KW_DATA:
            case KW_DATABASES:
            case KW_DATE:
            case KW_DATETIME:
            case KW_DBPROPERTIES:
            case KW_DECIMAL:
            case KW_DEFAULT:
            case KW_DEFERRED:
            case KW_DEFINED:
            case KW_DELETE:
            case KW_DELIMITED:
            case KW_DEPENDENCY:
            case KW_DESC:
            case KW_DESCRIBE:
            case KW_DIRECTORIES:
            case KW_DIRECTORY:
            case KW_DISABLE:
            case KW_DISTRIBUTE:
            case KW_DOUBLE:
            case KW_DROP:
            case KW_ELEM_TYPE:
            case KW_ENABLE:
            case KW_ESCAPED:
            case KW_EXCLUSIVE:
            case KW_EXISTS:
            case KW_EXPLAIN:
            case KW_EXPORT:
            case KW_EXTERNAL:
            case KW_FALSE:
            case KW_FETCH:
            case KW_FIELDS:
            case KW_FILE:
            case KW_FILEFORMAT:
            case KW_FIRST:
            case KW_FLOAT:
            case KW_FOR:
            case KW_FORMAT:
            case KW_FORMATTED:
            case KW_FULL:
            case KW_FUNCTIONS:
            case KW_GRANT:
            case KW_GROUP:
            case KW_GROUPING:
            case KW_HOLD_DDLTIME:
            case KW_IDXPROPERTIES:
            case KW_IGNORE:
            case KW_IMPORT:
            case KW_IN:
            case KW_INDEX:
            case KW_INDEXES:
            case KW_INNER:
            case KW_INPATH:
            case KW_INPUTDRIVER:
            case KW_INPUTFORMAT:
            case KW_INSERT:
            case KW_INT:
            case KW_INTERSECT:
            case KW_INTO:
            case KW_IS:
            case KW_ITEMS:
            case KW_JAR:
            case KW_KEYS:
            case KW_KEY_TYPE:
            case KW_LATERAL:
            case KW_LEFT:
            case KW_LIMIT:
            case KW_LINES:
            case KW_LOAD:
            case KW_LOCAL:
            case KW_LOCATION:
            case KW_LOCK:
            case KW_LOCKS:
            case KW_LOGICAL:
            case KW_LONG:
            case KW_MAPJOIN:
            case KW_MATERIALIZED:
            case KW_METADATA:
            case KW_MINUS:
            case KW_MSCK:
            case KW_NONE:
            case KW_NOSCAN:
            case KW_NO_DROP:
            case KW_NULL:
            case KW_OF:
            case KW_OFFLINE:
            case KW_OPTION:
            case KW_ORDER:
            case KW_OUT:
            case KW_OUTER:
            case KW_OUTPUTDRIVER:
            case KW_OUTPUTFORMAT:
            case KW_OVERWRITE:
            case KW_OWNER:
            case KW_PARTITION:
            case KW_PARTITIONED:
            case KW_PARTITIONS:
            case KW_PERCENT:
            case KW_PLUS:
            case KW_PRETTY:
            case KW_PRINCIPALS:
            case KW_PROCEDURE:
            case KW_PROTECTION:
            case KW_PURGE:
            case KW_RANGE:
            case KW_READ:
            case KW_READONLY:
            case KW_READS:
            case KW_REBUILD:
            case KW_RECORDREADER:
            case KW_RECORDWRITER:
            case KW_REGEXP:
            case KW_RELOAD:
            case KW_RENAME:
            case KW_REPAIR:
            case KW_REPLACE:
            case KW_REPLICATION:
            case KW_RESTRICT:
            case KW_REVOKE:
            case KW_REWRITE:
            case KW_RIGHT:
            case KW_RLIKE:
            case KW_ROLE:
            case KW_ROLES:
            case KW_ROLLUP:
            case KW_ROW:
            case KW_ROWS:
            case KW_SCHEMA:
            case KW_SCHEMAS:
            case KW_SEMI:
            case KW_SERDE:
            case KW_SERDEPROPERTIES:
            case KW_SERVER:
            case KW_SET:
            case KW_SETS:
            case KW_SHARED:
            case KW_SHOW:
            case KW_SHOW_DATABASE:
            case KW_SKEWED:
            case KW_SMALLINT:
            case KW_SORT:
            case KW_SORTED:
            case KW_SSL:
            case KW_STATISTICS:
            case KW_STORED:
            case KW_STREAMTABLE:
            case KW_STRING:
            case KW_STRUCT:
            case KW_TABLE:
            case KW_TABLES:
            case KW_TBLPROPERTIES:
            case KW_TEMPORARY:
            case KW_TERMINATED:
            case KW_TIMESTAMP:
            case KW_TINYINT:
            case KW_TO:
            case KW_TOUCH:
            case KW_TRANSACTIONS:
            case KW_TRIGGER:
            case KW_TRUE:
            case KW_TRUNCATE:
            case KW_UNARCHIVE:
            case KW_UNDO:
            case KW_UNION:
            case KW_UNIONTYPE:
            case KW_UNLOCK:
            case KW_UNSET:
            case KW_UNSIGNED:
            case KW_UPDATE:
            case KW_URI:
            case KW_USE:
            case KW_USER:
            case KW_USING:
            case KW_UTC:
            case KW_UTCTIMESTAMP:
            case KW_VALUES:
            case KW_VALUE_TYPE:
            case KW_VIEW:
            case KW_WHILE:
            case KW_WITH:
            case StringLiteral: {
              alt125 = 2;
            }
              break;
          }

          switch (alt125) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1359:64: KW_LIKE showStmtIdentifier
            {
              KW_LIKE414 = (Token) match(input, KW_LIKE, FOLLOW_KW_LIKE_in_showStatement6904);
              stream_KW_LIKE.add(KW_LIKE414);

              pushFollow(FOLLOW_showStmtIdentifier_in_showStatement6906);
              showStmtIdentifier415 = showStmtIdentifier();

              state._fsp--;

              stream_showStmtIdentifier.add(showStmtIdentifier415.getTree());
            }
              break;
            case 2:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1359:91: showStmtIdentifier
            {
              pushFollow(FOLLOW_showStmtIdentifier_in_showStatement6908);
              showStmtIdentifier416 = showStmtIdentifier();

              state._fsp--;

              stream_showStmtIdentifier.add(showStmtIdentifier416.getTree());
            }
              break;
          }

          // AST REWRITE
          // elements: db_name, showStmtIdentifier
          // token labels:
          // rule labels: db_name, retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_db_name =
              new RewriteRuleSubtreeStream(adaptor, "rule db_name", db_name != null ? db_name.tree : null);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1359:113: -> ^( TOK_SHOWTABLES ( TOK_FROM $db_name)? ( showStmtIdentifier )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1359:116: ^( TOK_SHOWTABLES ( TOK_FROM $db_name)? ( showStmtIdentifier )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SHOWTABLES, "TOK_SHOWTABLES"),
                  root_1);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1359:133: ( TOK_FROM $db_name)?
              if (stream_db_name.hasNext()) {
                adaptor.addChild(root_1, (CommonTree) adaptor.create(TOK_FROM, "TOK_FROM"));

                adaptor.addChild(root_1, stream_db_name.nextTree());
              }
              stream_db_name.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1359:154: ( showStmtIdentifier )?
              if (stream_showStmtIdentifier.hasNext()) {
                adaptor.addChild(root_1, stream_showStmtIdentifier.nextTree());
              }
              stream_showStmtIdentifier.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 3:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:7: KW_SHOW KW_COLUMNS ( KW_FROM | KW_IN ) tableName ( ( KW_FROM | KW_IN ) db_name= identifier )?
        {
          KW_SHOW417 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showStatement6936);
          stream_KW_SHOW.add(KW_SHOW417);

          KW_COLUMNS418 = (Token) match(input, KW_COLUMNS, FOLLOW_KW_COLUMNS_in_showStatement6938);
          stream_KW_COLUMNS.add(KW_COLUMNS418);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:26: ( KW_FROM | KW_IN )
          int alt126 = 2;
          switch (input.LA(1)) {
            case KW_FROM: {
              alt126 = 1;
            }
              break;
            case KW_IN: {
              alt126 = 2;
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 126, 0, input);

              throw nvae;
          }

          switch (alt126) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:27: KW_FROM
            {
              KW_FROM419 = (Token) match(input, KW_FROM, FOLLOW_KW_FROM_in_showStatement6941);
              stream_KW_FROM.add(KW_FROM419);
            }
              break;
            case 2:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:35: KW_IN
            {
              KW_IN420 = (Token) match(input, KW_IN, FOLLOW_KW_IN_in_showStatement6943);
              stream_KW_IN.add(KW_IN420);
            }
              break;
          }

          pushFollow(FOLLOW_tableName_in_showStatement6946);
          tableName421 = tableName();

          state._fsp--;

          stream_tableName.add(tableName421.getTree());

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:52: ( ( KW_FROM | KW_IN ) db_name= identifier )?
          int alt128 = 2;
          switch (input.LA(1)) {
            case KW_FROM:
            case KW_IN: {
              alt128 = 1;
            }
              break;
          }

          switch (alt128) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:53: ( KW_FROM | KW_IN ) db_name= identifier
            {
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:53: ( KW_FROM | KW_IN )
              int alt127 = 2;
              switch (input.LA(1)) {
                case KW_FROM: {
                  alt127 = 1;
                }
                  break;
                case KW_IN: {
                  alt127 = 2;
                }
                  break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 127, 0, input);

                  throw nvae;
              }

              switch (alt127) {
                case 1:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:54: KW_FROM
                {
                  KW_FROM422 = (Token) match(input, KW_FROM, FOLLOW_KW_FROM_in_showStatement6950);
                  stream_KW_FROM.add(KW_FROM422);
                }
                  break;
                case 2:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:62: KW_IN
                {
                  KW_IN423 = (Token) match(input, KW_IN, FOLLOW_KW_IN_in_showStatement6952);
                  stream_KW_IN.add(KW_IN423);
                }
                  break;
              }

              pushFollow(FOLLOW_identifier_in_showStatement6957);
              db_name = identifier();

              state._fsp--;

              stream_identifier.add(db_name.getTree());
            }
              break;
          }

          // AST REWRITE
          // elements: db_name, tableName
          // token labels:
          // rule labels: db_name, retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_db_name =
              new RewriteRuleSubtreeStream(adaptor, "rule db_name", db_name != null ? db_name.tree : null);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1361:5: -> ^( TOK_SHOWCOLUMNS tableName ( $db_name)? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1361:8: ^( TOK_SHOWCOLUMNS tableName ( $db_name)? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SHOWCOLUMNS, "TOK_SHOWCOLUMNS"),
                  root_1);

              adaptor.addChild(root_1, stream_tableName.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1361:37: ( $db_name)?
              if (stream_db_name.hasNext()) {
                adaptor.addChild(root_1, stream_db_name.nextTree());
              }
              stream_db_name.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 4:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1362:7: KW_SHOW KW_FUNCTIONS ( KW_LIKE showFunctionIdentifier | showFunctionIdentifier )?
        {
          KW_SHOW424 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showStatement6983);
          stream_KW_SHOW.add(KW_SHOW424);

          KW_FUNCTIONS425 = (Token) match(input, KW_FUNCTIONS, FOLLOW_KW_FUNCTIONS_in_showStatement6985);
          stream_KW_FUNCTIONS.add(KW_FUNCTIONS425);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1362:28: ( KW_LIKE showFunctionIdentifier | showFunctionIdentifier )?
          int alt129 = 3;
          switch (input.LA(1)) {
            case KW_LIKE: {
              switch (input.LA(2)) {
                case Identifier:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFAULT:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_METADATA:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NONE:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITION:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH:
                case StringLiteral: {
                  alt129 = 1;
                }
                  break;
                case EOF:
                case DOT: {
                  alt129 = 2;
                }
                  break;
              }
            }
              break;
            case Identifier:
            case KW_ADD:
            case KW_ADMIN:
            case KW_AFTER:
            case KW_ALL:
            case KW_ALTER:
            case KW_ANALYZE:
            case KW_ARCHIVE:
            case KW_ARRAY:
            case KW_AS:
            case KW_ASC:
            case KW_AUTHORIZATION:
            case KW_BEFORE:
            case KW_BETWEEN:
            case KW_BIGINT:
            case KW_BINARY:
            case KW_BOOLEAN:
            case KW_BOTH:
            case KW_BUCKET:
            case KW_BUCKETS:
            case KW_BY:
            case KW_CASCADE:
            case KW_CHANGE:
            case KW_CLUSTER:
            case KW_CLUSTERED:
            case KW_CLUSTERSTATUS:
            case KW_COLLECTION:
            case KW_COLUMNS:
            case KW_COMMENT:
            case KW_COMPACT:
            case KW_COMPACTIONS:
            case KW_COMPUTE:
            case KW_CONCATENATE:
            case KW_CONTINUE:
            case KW_CREATE:
            case KW_CUBE:
            case KW_CURSOR:
            case KW_DATA:
            case KW_DATABASES:
            case KW_DATE:
            case KW_DATETIME:
            case KW_DBPROPERTIES:
            case KW_DECIMAL:
            case KW_DEFAULT:
            case KW_DEFERRED:
            case KW_DEFINED:
            case KW_DELETE:
            case KW_DELIMITED:
            case KW_DEPENDENCY:
            case KW_DESC:
            case KW_DESCRIBE:
            case KW_DIRECTORIES:
            case KW_DIRECTORY:
            case KW_DISABLE:
            case KW_DISTRIBUTE:
            case KW_DOUBLE:
            case KW_DROP:
            case KW_ELEM_TYPE:
            case KW_ENABLE:
            case KW_ESCAPED:
            case KW_EXCLUSIVE:
            case KW_EXISTS:
            case KW_EXPLAIN:
            case KW_EXPORT:
            case KW_EXTERNAL:
            case KW_FALSE:
            case KW_FETCH:
            case KW_FIELDS:
            case KW_FILE:
            case KW_FILEFORMAT:
            case KW_FIRST:
            case KW_FLOAT:
            case KW_FOR:
            case KW_FORMAT:
            case KW_FORMATTED:
            case KW_FULL:
            case KW_FUNCTIONS:
            case KW_GRANT:
            case KW_GROUP:
            case KW_GROUPING:
            case KW_HOLD_DDLTIME:
            case KW_IDXPROPERTIES:
            case KW_IGNORE:
            case KW_IMPORT:
            case KW_IN:
            case KW_INDEX:
            case KW_INDEXES:
            case KW_INNER:
            case KW_INPATH:
            case KW_INPUTDRIVER:
            case KW_INPUTFORMAT:
            case KW_INSERT:
            case KW_INT:
            case KW_INTERSECT:
            case KW_INTO:
            case KW_IS:
            case KW_ITEMS:
            case KW_JAR:
            case KW_KEYS:
            case KW_KEY_TYPE:
            case KW_LATERAL:
            case KW_LEFT:
            case KW_LIMIT:
            case KW_LINES:
            case KW_LOAD:
            case KW_LOCAL:
            case KW_LOCATION:
            case KW_LOCK:
            case KW_LOCKS:
            case KW_LOGICAL:
            case KW_LONG:
            case KW_MAPJOIN:
            case KW_MATERIALIZED:
            case KW_METADATA:
            case KW_MINUS:
            case KW_MSCK:
            case KW_NONE:
            case KW_NOSCAN:
            case KW_NO_DROP:
            case KW_NULL:
            case KW_OF:
            case KW_OFFLINE:
            case KW_OPTION:
            case KW_ORDER:
            case KW_OUT:
            case KW_OUTER:
            case KW_OUTPUTDRIVER:
            case KW_OUTPUTFORMAT:
            case KW_OVERWRITE:
            case KW_OWNER:
            case KW_PARTITION:
            case KW_PARTITIONED:
            case KW_PARTITIONS:
            case KW_PERCENT:
            case KW_PLUS:
            case KW_PRETTY:
            case KW_PRINCIPALS:
            case KW_PROCEDURE:
            case KW_PROTECTION:
            case KW_PURGE:
            case KW_RANGE:
            case KW_READ:
            case KW_READONLY:
            case KW_READS:
            case KW_REBUILD:
            case KW_RECORDREADER:
            case KW_RECORDWRITER:
            case KW_REGEXP:
            case KW_RELOAD:
            case KW_RENAME:
            case KW_REPAIR:
            case KW_REPLACE:
            case KW_REPLICATION:
            case KW_RESTRICT:
            case KW_REVOKE:
            case KW_REWRITE:
            case KW_RIGHT:
            case KW_RLIKE:
            case KW_ROLE:
            case KW_ROLES:
            case KW_ROLLUP:
            case KW_ROW:
            case KW_ROWS:
            case KW_SCHEMA:
            case KW_SCHEMAS:
            case KW_SEMI:
            case KW_SERDE:
            case KW_SERDEPROPERTIES:
            case KW_SERVER:
            case KW_SET:
            case KW_SETS:
            case KW_SHARED:
            case KW_SHOW:
            case KW_SHOW_DATABASE:
            case KW_SKEWED:
            case KW_SMALLINT:
            case KW_SORT:
            case KW_SORTED:
            case KW_SSL:
            case KW_STATISTICS:
            case KW_STORED:
            case KW_STREAMTABLE:
            case KW_STRING:
            case KW_STRUCT:
            case KW_TABLE:
            case KW_TABLES:
            case KW_TBLPROPERTIES:
            case KW_TEMPORARY:
            case KW_TERMINATED:
            case KW_TIMESTAMP:
            case KW_TINYINT:
            case KW_TO:
            case KW_TOUCH:
            case KW_TRANSACTIONS:
            case KW_TRIGGER:
            case KW_TRUE:
            case KW_TRUNCATE:
            case KW_UNARCHIVE:
            case KW_UNDO:
            case KW_UNION:
            case KW_UNIONTYPE:
            case KW_UNLOCK:
            case KW_UNSET:
            case KW_UNSIGNED:
            case KW_UPDATE:
            case KW_URI:
            case KW_USE:
            case KW_USER:
            case KW_USING:
            case KW_UTC:
            case KW_UTCTIMESTAMP:
            case KW_VALUES:
            case KW_VALUE_TYPE:
            case KW_VIEW:
            case KW_WHILE:
            case KW_WITH:
            case StringLiteral: {
              alt129 = 2;
            }
              break;
          }

          switch (alt129) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1362:29: KW_LIKE showFunctionIdentifier
            {
              KW_LIKE426 = (Token) match(input, KW_LIKE, FOLLOW_KW_LIKE_in_showStatement6988);
              stream_KW_LIKE.add(KW_LIKE426);

              pushFollow(FOLLOW_showFunctionIdentifier_in_showStatement6990);
              showFunctionIdentifier427 = showFunctionIdentifier();

              state._fsp--;

              stream_showFunctionIdentifier.add(showFunctionIdentifier427.getTree());
            }
              break;
            case 2:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1362:60: showFunctionIdentifier
            {
              pushFollow(FOLLOW_showFunctionIdentifier_in_showStatement6992);
              showFunctionIdentifier428 = showFunctionIdentifier();

              state._fsp--;

              stream_showFunctionIdentifier.add(showFunctionIdentifier428.getTree());
            }
              break;
          }

          // AST REWRITE
          // elements: KW_LIKE, showFunctionIdentifier
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1362:86: -> ^( TOK_SHOWFUNCTIONS ( KW_LIKE )? ( showFunctionIdentifier )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1362:89: ^( TOK_SHOWFUNCTIONS ( KW_LIKE )? ( showFunctionIdentifier )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor
                  .becomeRoot((CommonTree) adaptor.create(TOK_SHOWFUNCTIONS, "TOK_SHOWFUNCTIONS"), root_1);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1362:109: ( KW_LIKE )?
              if (stream_KW_LIKE.hasNext()) {
                adaptor.addChild(root_1, stream_KW_LIKE.nextNode());
              }
              stream_KW_LIKE.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1362:118: ( showFunctionIdentifier )?
              if (stream_showFunctionIdentifier.hasNext()) {
                adaptor.addChild(root_1, stream_showFunctionIdentifier.nextTree());
              }
              stream_showFunctionIdentifier.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 5:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1363:7: KW_SHOW KW_PARTITIONS tabName= tableName ( partitionSpec )?
        {
          KW_SHOW429 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showStatement7015);
          stream_KW_SHOW.add(KW_SHOW429);

          KW_PARTITIONS430 = (Token) match(input, KW_PARTITIONS, FOLLOW_KW_PARTITIONS_in_showStatement7017);
          stream_KW_PARTITIONS.add(KW_PARTITIONS430);

          pushFollow(FOLLOW_tableName_in_showStatement7021);
          tabName = tableName();

          state._fsp--;

          stream_tableName.add(tabName.getTree());

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1363:47: ( partitionSpec )?
          int alt130 = 2;
          switch (input.LA(1)) {
            case KW_PARTITION: {
              alt130 = 1;
            }
              break;
          }

          switch (alt130) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1363:47: partitionSpec
            {
              pushFollow(FOLLOW_partitionSpec_in_showStatement7023);
              partitionSpec431 = partitionSpec();

              state._fsp--;

              stream_partitionSpec.add(partitionSpec431.getTree());
            }
              break;
          }

          // AST REWRITE
          // elements: partitionSpec, tabName
          // token labels:
          // rule labels: tabName, retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_tabName =
              new RewriteRuleSubtreeStream(adaptor, "rule tabName", tabName != null ? tabName.tree : null);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1363:62: -> ^( TOK_SHOWPARTITIONS $tabName ( partitionSpec )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1363:65: ^( TOK_SHOWPARTITIONS $tabName ( partitionSpec )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor
                  .becomeRoot((CommonTree) adaptor.create(TOK_SHOWPARTITIONS, "TOK_SHOWPARTITIONS"), root_1);

              adaptor.addChild(root_1, stream_tabName.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1363:95: ( partitionSpec )?
              if (stream_partitionSpec.hasNext()) {
                adaptor.addChild(root_1, stream_partitionSpec.nextTree());
              }
              stream_partitionSpec.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 6:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1364:7: KW_SHOW KW_CREATE KW_TABLE tabName= tableName
        {
          KW_SHOW432 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showStatement7045);
          stream_KW_SHOW.add(KW_SHOW432);

          KW_CREATE433 = (Token) match(input, KW_CREATE, FOLLOW_KW_CREATE_in_showStatement7047);
          stream_KW_CREATE.add(KW_CREATE433);

          KW_TABLE434 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_showStatement7049);
          stream_KW_TABLE.add(KW_TABLE434);

          pushFollow(FOLLOW_tableName_in_showStatement7053);
          tabName = tableName();

          state._fsp--;

          stream_tableName.add(tabName.getTree());

          // AST REWRITE
          // elements: tabName
          // token labels:
          // rule labels: tabName, retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_tabName =
              new RewriteRuleSubtreeStream(adaptor, "rule tabName", tabName != null ? tabName.tree : null);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1364:52: -> ^( TOK_SHOW_CREATETABLE $tabName)
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1364:55: ^( TOK_SHOW_CREATETABLE $tabName)
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor
                  .becomeRoot((CommonTree) adaptor.create(TOK_SHOW_CREATETABLE, "TOK_SHOW_CREATETABLE"), root_1);

              adaptor.addChild(root_1, stream_tabName.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 7:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1365:7: KW_SHOW KW_TABLE KW_EXTENDED ( ( KW_FROM | KW_IN ) db_name= identifier )? KW_LIKE showStmtIdentifier ( partitionSpec )?
        {
          KW_SHOW435 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showStatement7070);
          stream_KW_SHOW.add(KW_SHOW435);

          KW_TABLE436 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_showStatement7072);
          stream_KW_TABLE.add(KW_TABLE436);

          KW_EXTENDED437 = (Token) match(input, KW_EXTENDED, FOLLOW_KW_EXTENDED_in_showStatement7074);
          stream_KW_EXTENDED.add(KW_EXTENDED437);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1365:36: ( ( KW_FROM | KW_IN ) db_name= identifier )?
          int alt132 = 2;
          switch (input.LA(1)) {
            case KW_FROM:
            case KW_IN: {
              alt132 = 1;
            }
              break;
          }

          switch (alt132) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1365:37: ( KW_FROM | KW_IN ) db_name= identifier
            {
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1365:37: ( KW_FROM | KW_IN )
              int alt131 = 2;
              switch (input.LA(1)) {
                case KW_FROM: {
                  alt131 = 1;
                }
                  break;
                case KW_IN: {
                  alt131 = 2;
                }
                  break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 131, 0, input);

                  throw nvae;
              }

              switch (alt131) {
                case 1:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1365:38: KW_FROM
                {
                  KW_FROM438 = (Token) match(input, KW_FROM, FOLLOW_KW_FROM_in_showStatement7078);
                  stream_KW_FROM.add(KW_FROM438);
                }
                  break;
                case 2:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1365:46: KW_IN
                {
                  KW_IN439 = (Token) match(input, KW_IN, FOLLOW_KW_IN_in_showStatement7080);
                  stream_KW_IN.add(KW_IN439);
                }
                  break;
              }

              pushFollow(FOLLOW_identifier_in_showStatement7085);
              db_name = identifier();

              state._fsp--;

              stream_identifier.add(db_name.getTree());
            }
              break;
          }

          KW_LIKE440 = (Token) match(input, KW_LIKE, FOLLOW_KW_LIKE_in_showStatement7089);
          stream_KW_LIKE.add(KW_LIKE440);

          pushFollow(FOLLOW_showStmtIdentifier_in_showStatement7091);
          showStmtIdentifier441 = showStmtIdentifier();

          state._fsp--;

          stream_showStmtIdentifier.add(showStmtIdentifier441.getTree());

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1365:101: ( partitionSpec )?
          int alt133 = 2;
          switch (input.LA(1)) {
            case KW_PARTITION: {
              alt133 = 1;
            }
              break;
          }

          switch (alt133) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1365:101: partitionSpec
            {
              pushFollow(FOLLOW_partitionSpec_in_showStatement7093);
              partitionSpec442 = partitionSpec();

              state._fsp--;

              stream_partitionSpec.add(partitionSpec442.getTree());
            }
              break;
          }

          // AST REWRITE
          // elements: db_name, showStmtIdentifier, partitionSpec
          // token labels:
          // rule labels: db_name, retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_db_name =
              new RewriteRuleSubtreeStream(adaptor, "rule db_name", db_name != null ? db_name.tree : null);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1366:5: -> ^( TOK_SHOW_TABLESTATUS showStmtIdentifier ( $db_name)? ( partitionSpec )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1366:8: ^( TOK_SHOW_TABLESTATUS showStmtIdentifier ( $db_name)? ( partitionSpec )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor
                  .becomeRoot((CommonTree) adaptor.create(TOK_SHOW_TABLESTATUS, "TOK_SHOW_TABLESTATUS"), root_1);

              adaptor.addChild(root_1, stream_showStmtIdentifier.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1366:51: ( $db_name)?
              if (stream_db_name.hasNext()) {
                adaptor.addChild(root_1, stream_db_name.nextTree());
              }
              stream_db_name.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1366:60: ( partitionSpec )?
              if (stream_partitionSpec.hasNext()) {
                adaptor.addChild(root_1, stream_partitionSpec.nextTree());
              }
              stream_partitionSpec.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 8:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1367:7: KW_SHOW KW_TBLPROPERTIES tableName ( LPAREN prptyName= StringLiteral RPAREN )?
        {
          KW_SHOW443 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showStatement7121);
          stream_KW_SHOW.add(KW_SHOW443);

          KW_TBLPROPERTIES444 = (Token) match(input, KW_TBLPROPERTIES, FOLLOW_KW_TBLPROPERTIES_in_showStatement7123);
          stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES444);

          pushFollow(FOLLOW_tableName_in_showStatement7125);
          tableName445 = tableName();

          state._fsp--;

          stream_tableName.add(tableName445.getTree());

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1367:42: ( LPAREN prptyName= StringLiteral RPAREN )?
          int alt134 = 2;
          switch (input.LA(1)) {
            case LPAREN: {
              alt134 = 1;
            }
              break;
          }

          switch (alt134) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1367:43: LPAREN prptyName= StringLiteral RPAREN
            {
              LPAREN446 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_showStatement7128);
              stream_LPAREN.add(LPAREN446);

              prptyName = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_showStatement7132);
              stream_StringLiteral.add(prptyName);

              RPAREN447 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_showStatement7134);
              stream_RPAREN.add(RPAREN447);
            }
              break;
          }

          // AST REWRITE
          // elements: prptyName, tableName
          // token labels: prptyName
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleTokenStream stream_prptyName = new RewriteRuleTokenStream(adaptor, "token prptyName", prptyName);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1367:83: -> ^( TOK_SHOW_TBLPROPERTIES tableName ( $prptyName)? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1367:86: ^( TOK_SHOW_TBLPROPERTIES tableName ( $prptyName)? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor
                  .becomeRoot((CommonTree) adaptor.create(TOK_SHOW_TBLPROPERTIES, "TOK_SHOW_TBLPROPERTIES"), root_1);

              adaptor.addChild(root_1, stream_tableName.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1367:122: ( $prptyName)?
              if (stream_prptyName.hasNext()) {
                adaptor.addChild(root_1, stream_prptyName.nextNode());
              }
              stream_prptyName.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 9:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1368:7: KW_SHOW KW_LOCKS (parttype= partTypeExpr )? (isExtended= KW_EXTENDED )?
        {
          KW_SHOW448 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showStatement7156);
          stream_KW_SHOW.add(KW_SHOW448);

          KW_LOCKS449 = (Token) match(input, KW_LOCKS, FOLLOW_KW_LOCKS_in_showStatement7158);
          stream_KW_LOCKS.add(KW_LOCKS449);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1368:24: (parttype= partTypeExpr )?
          int alt135 = 2;
          switch (input.LA(1)) {
            case Identifier:
            case KW_ADD:
            case KW_ADMIN:
            case KW_AFTER:
            case KW_ALL:
            case KW_ALTER:
            case KW_ANALYZE:
            case KW_ARCHIVE:
            case KW_ARRAY:
            case KW_AS:
            case KW_ASC:
            case KW_AUTHORIZATION:
            case KW_BEFORE:
            case KW_BETWEEN:
            case KW_BIGINT:
            case KW_BINARY:
            case KW_BOOLEAN:
            case KW_BOTH:
            case KW_BUCKET:
            case KW_BUCKETS:
            case KW_BY:
            case KW_CASCADE:
            case KW_CHANGE:
            case KW_CLUSTER:
            case KW_CLUSTERED:
            case KW_CLUSTERSTATUS:
            case KW_COLLECTION:
            case KW_COLUMNS:
            case KW_COMMENT:
            case KW_COMPACT:
            case KW_COMPACTIONS:
            case KW_COMPUTE:
            case KW_CONCATENATE:
            case KW_CONTINUE:
            case KW_CREATE:
            case KW_CUBE:
            case KW_CURSOR:
            case KW_DATA:
            case KW_DATABASES:
            case KW_DATE:
            case KW_DATETIME:
            case KW_DBPROPERTIES:
            case KW_DECIMAL:
            case KW_DEFAULT:
            case KW_DEFERRED:
            case KW_DEFINED:
            case KW_DELETE:
            case KW_DELIMITED:
            case KW_DEPENDENCY:
            case KW_DESC:
            case KW_DESCRIBE:
            case KW_DIRECTORIES:
            case KW_DIRECTORY:
            case KW_DISABLE:
            case KW_DISTRIBUTE:
            case KW_DOUBLE:
            case KW_DROP:
            case KW_ELEM_TYPE:
            case KW_ENABLE:
            case KW_ESCAPED:
            case KW_EXCLUSIVE:
            case KW_EXISTS:
            case KW_EXPLAIN:
            case KW_EXPORT:
            case KW_EXTERNAL:
            case KW_FALSE:
            case KW_FETCH:
            case KW_FIELDS:
            case KW_FILE:
            case KW_FILEFORMAT:
            case KW_FIRST:
            case KW_FLOAT:
            case KW_FOR:
            case KW_FORMAT:
            case KW_FORMATTED:
            case KW_FULL:
            case KW_FUNCTIONS:
            case KW_GRANT:
            case KW_GROUP:
            case KW_GROUPING:
            case KW_HOLD_DDLTIME:
            case KW_IDXPROPERTIES:
            case KW_IGNORE:
            case KW_IMPORT:
            case KW_IN:
            case KW_INDEX:
            case KW_INDEXES:
            case KW_INNER:
            case KW_INPATH:
            case KW_INPUTDRIVER:
            case KW_INPUTFORMAT:
            case KW_INSERT:
            case KW_INT:
            case KW_INTERSECT:
            case KW_INTO:
            case KW_IS:
            case KW_ITEMS:
            case KW_JAR:
            case KW_KEYS:
            case KW_KEY_TYPE:
            case KW_LATERAL:
            case KW_LEFT:
            case KW_LIKE:
            case KW_LIMIT:
            case KW_LINES:
            case KW_LOAD:
            case KW_LOCAL:
            case KW_LOCATION:
            case KW_LOCK:
            case KW_LOCKS:
            case KW_LOGICAL:
            case KW_LONG:
            case KW_MAPJOIN:
            case KW_MATERIALIZED:
            case KW_METADATA:
            case KW_MINUS:
            case KW_MSCK:
            case KW_NONE:
            case KW_NOSCAN:
            case KW_NO_DROP:
            case KW_NULL:
            case KW_OF:
            case KW_OFFLINE:
            case KW_OPTION:
            case KW_ORDER:
            case KW_OUT:
            case KW_OUTER:
            case KW_OUTPUTDRIVER:
            case KW_OUTPUTFORMAT:
            case KW_OVERWRITE:
            case KW_OWNER:
            case KW_PARTITION:
            case KW_PARTITIONED:
            case KW_PARTITIONS:
            case KW_PERCENT:
            case KW_PLUS:
            case KW_PRETTY:
            case KW_PRINCIPALS:
            case KW_PROCEDURE:
            case KW_PROTECTION:
            case KW_PURGE:
            case KW_RANGE:
            case KW_READ:
            case KW_READONLY:
            case KW_READS:
            case KW_REBUILD:
            case KW_RECORDREADER:
            case KW_RECORDWRITER:
            case KW_REGEXP:
            case KW_RELOAD:
            case KW_RENAME:
            case KW_REPAIR:
            case KW_REPLACE:
            case KW_REPLICATION:
            case KW_RESTRICT:
            case KW_REVOKE:
            case KW_REWRITE:
            case KW_RIGHT:
            case KW_RLIKE:
            case KW_ROLE:
            case KW_ROLES:
            case KW_ROLLUP:
            case KW_ROW:
            case KW_ROWS:
            case KW_SCHEMA:
            case KW_SCHEMAS:
            case KW_SEMI:
            case KW_SERDE:
            case KW_SERDEPROPERTIES:
            case KW_SERVER:
            case KW_SET:
            case KW_SETS:
            case KW_SHARED:
            case KW_SHOW:
            case KW_SHOW_DATABASE:
            case KW_SKEWED:
            case KW_SMALLINT:
            case KW_SORT:
            case KW_SORTED:
            case KW_SSL:
            case KW_STATISTICS:
            case KW_STORED:
            case KW_STREAMTABLE:
            case KW_STRING:
            case KW_STRUCT:
            case KW_TABLE:
            case KW_TABLES:
            case KW_TBLPROPERTIES:
            case KW_TEMPORARY:
            case KW_TERMINATED:
            case KW_TIMESTAMP:
            case KW_TINYINT:
            case KW_TO:
            case KW_TOUCH:
            case KW_TRANSACTIONS:
            case KW_TRIGGER:
            case KW_TRUE:
            case KW_TRUNCATE:
            case KW_UNARCHIVE:
            case KW_UNDO:
            case KW_UNION:
            case KW_UNIONTYPE:
            case KW_UNLOCK:
            case KW_UNSET:
            case KW_UNSIGNED:
            case KW_UPDATE:
            case KW_URI:
            case KW_USE:
            case KW_USER:
            case KW_USING:
            case KW_UTC:
            case KW_UTCTIMESTAMP:
            case KW_VALUES:
            case KW_VALUE_TYPE:
            case KW_VIEW:
            case KW_WHILE:
            case KW_WITH: {
              alt135 = 1;
            }
              break;
          }

          switch (alt135) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1368:25: parttype= partTypeExpr
            {
              pushFollow(FOLLOW_partTypeExpr_in_showStatement7163);
              parttype = partTypeExpr();

              state._fsp--;

              stream_partTypeExpr.add(parttype.getTree());
            }
              break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1368:49: (isExtended= KW_EXTENDED )?
          int alt136 = 2;
          switch (input.LA(1)) {
            case KW_EXTENDED: {
              alt136 = 1;
            }
              break;
          }

          switch (alt136) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1368:50: isExtended= KW_EXTENDED
            {
              isExtended = (Token) match(input, KW_EXTENDED, FOLLOW_KW_EXTENDED_in_showStatement7170);
              stream_KW_EXTENDED.add(isExtended);
            }
              break;
          }

          // AST REWRITE
          // elements: parttype, isExtended
          // token labels: isExtended
          // rule labels: parttype, retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleTokenStream stream_isExtended =
              new RewriteRuleTokenStream(adaptor, "token isExtended", isExtended);
          RewriteRuleSubtreeStream stream_parttype =
              new RewriteRuleSubtreeStream(adaptor, "rule parttype", parttype != null ? parttype.tree : null);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1368:75: -> ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1368:78: ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SHOWLOCKS, "TOK_SHOWLOCKS"), root_1);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1368:95: ( $parttype)?
              if (stream_parttype.hasNext()) {
                adaptor.addChild(root_1, stream_parttype.nextTree());
              }
              stream_parttype.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1368:106: ( $isExtended)?
              if (stream_isExtended.hasNext()) {
                adaptor.addChild(root_1, stream_isExtended.nextNode());
              }
              stream_isExtended.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 10:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1369:7: KW_SHOW KW_LOCKS ( KW_DATABASE | KW_SCHEMA ) (dbName= Identifier ) (isExtended= KW_EXTENDED )?
        {
          KW_SHOW450 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showStatement7194);
          stream_KW_SHOW.add(KW_SHOW450);

          KW_LOCKS451 = (Token) match(input, KW_LOCKS, FOLLOW_KW_LOCKS_in_showStatement7196);
          stream_KW_LOCKS.add(KW_LOCKS451);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1369:24: ( KW_DATABASE | KW_SCHEMA )
          int alt137 = 2;
          switch (input.LA(1)) {
            case KW_DATABASE: {
              alt137 = 1;
            }
              break;
            case KW_SCHEMA: {
              alt137 = 2;
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 137, 0, input);

              throw nvae;
          }

          switch (alt137) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1369:25: KW_DATABASE
            {
              KW_DATABASE452 = (Token) match(input, KW_DATABASE, FOLLOW_KW_DATABASE_in_showStatement7199);
              stream_KW_DATABASE.add(KW_DATABASE452);
            }
              break;
            case 2:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1369:37: KW_SCHEMA
            {
              KW_SCHEMA453 = (Token) match(input, KW_SCHEMA, FOLLOW_KW_SCHEMA_in_showStatement7201);
              stream_KW_SCHEMA.add(KW_SCHEMA453);
            }
              break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1369:48: (dbName= Identifier )
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1369:49: dbName= Identifier
          {
            dbName = (Token) match(input, Identifier, FOLLOW_Identifier_in_showStatement7207);
            stream_Identifier.add(dbName);
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1369:68: (isExtended= KW_EXTENDED )?
          int alt138 = 2;
          switch (input.LA(1)) {
            case KW_EXTENDED: {
              alt138 = 1;
            }
              break;
          }

          switch (alt138) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1369:69: isExtended= KW_EXTENDED
            {
              isExtended = (Token) match(input, KW_EXTENDED, FOLLOW_KW_EXTENDED_in_showStatement7213);
              stream_KW_EXTENDED.add(isExtended);
            }
              break;
          }

          // AST REWRITE
          // elements: isExtended, dbName
          // token labels: dbName, isExtended
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleTokenStream stream_dbName = new RewriteRuleTokenStream(adaptor, "token dbName", dbName);
          RewriteRuleTokenStream stream_isExtended =
              new RewriteRuleTokenStream(adaptor, "token isExtended", isExtended);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1369:94: -> ^( TOK_SHOWDBLOCKS $dbName ( $isExtended)? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1369:97: ^( TOK_SHOWDBLOCKS $dbName ( $isExtended)? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SHOWDBLOCKS, "TOK_SHOWDBLOCKS"),
                  root_1);

              adaptor.addChild(root_1, stream_dbName.nextNode());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1369:124: ( $isExtended)?
              if (stream_isExtended.hasNext()) {
                adaptor.addChild(root_1, stream_isExtended.nextNode());
              }
              stream_isExtended.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 11:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1370:7: KW_SHOW (showOptions= KW_FORMATTED )? ( KW_INDEX | KW_INDEXES ) KW_ON showStmtIdentifier ( ( KW_FROM | KW_IN ) db_name= identifier )?
        {
          KW_SHOW454 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showStatement7236);
          stream_KW_SHOW.add(KW_SHOW454);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1370:15: (showOptions= KW_FORMATTED )?
          int alt139 = 2;
          switch (input.LA(1)) {
            case KW_FORMATTED: {
              alt139 = 1;
            }
              break;
          }

          switch (alt139) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1370:16: showOptions= KW_FORMATTED
            {
              showOptions = (Token) match(input, KW_FORMATTED, FOLLOW_KW_FORMATTED_in_showStatement7241);
              stream_KW_FORMATTED.add(showOptions);
            }
              break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1370:43: ( KW_INDEX | KW_INDEXES )
          int alt140 = 2;
          switch (input.LA(1)) {
            case KW_INDEX: {
              alt140 = 1;
            }
              break;
            case KW_INDEXES: {
              alt140 = 2;
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 140, 0, input);

              throw nvae;
          }

          switch (alt140) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1370:44: KW_INDEX
            {
              KW_INDEX455 = (Token) match(input, KW_INDEX, FOLLOW_KW_INDEX_in_showStatement7246);
              stream_KW_INDEX.add(KW_INDEX455);
            }
              break;
            case 2:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1370:53: KW_INDEXES
            {
              KW_INDEXES456 = (Token) match(input, KW_INDEXES, FOLLOW_KW_INDEXES_in_showStatement7248);
              stream_KW_INDEXES.add(KW_INDEXES456);
            }
              break;
          }

          KW_ON457 = (Token) match(input, KW_ON, FOLLOW_KW_ON_in_showStatement7251);
          stream_KW_ON.add(KW_ON457);

          pushFollow(FOLLOW_showStmtIdentifier_in_showStatement7253);
          showStmtIdentifier458 = showStmtIdentifier();

          state._fsp--;

          stream_showStmtIdentifier.add(showStmtIdentifier458.getTree());

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1370:90: ( ( KW_FROM | KW_IN ) db_name= identifier )?
          int alt142 = 2;
          switch (input.LA(1)) {
            case KW_FROM:
            case KW_IN: {
              alt142 = 1;
            }
              break;
          }

          switch (alt142) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1370:91: ( KW_FROM | KW_IN ) db_name= identifier
            {
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1370:91: ( KW_FROM | KW_IN )
              int alt141 = 2;
              switch (input.LA(1)) {
                case KW_FROM: {
                  alt141 = 1;
                }
                  break;
                case KW_IN: {
                  alt141 = 2;
                }
                  break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 141, 0, input);

                  throw nvae;
              }

              switch (alt141) {
                case 1:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1370:92: KW_FROM
                {
                  KW_FROM459 = (Token) match(input, KW_FROM, FOLLOW_KW_FROM_in_showStatement7257);
                  stream_KW_FROM.add(KW_FROM459);
                }
                  break;
                case 2:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1370:100: KW_IN
                {
                  KW_IN460 = (Token) match(input, KW_IN, FOLLOW_KW_IN_in_showStatement7259);
                  stream_KW_IN.add(KW_IN460);
                }
                  break;
              }

              pushFollow(FOLLOW_identifier_in_showStatement7264);
              db_name = identifier();

              state._fsp--;

              stream_identifier.add(db_name.getTree());
            }
              break;
          }

          // AST REWRITE
          // elements: showOptions, db_name, showStmtIdentifier
          // token labels: showOptions
          // rule labels: db_name, retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleTokenStream stream_showOptions =
              new RewriteRuleTokenStream(adaptor, "token showOptions", showOptions);
          RewriteRuleSubtreeStream stream_db_name =
              new RewriteRuleSubtreeStream(adaptor, "rule db_name", db_name != null ? db_name.tree : null);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1371:5: -> ^( TOK_SHOWINDEXES showStmtIdentifier ( $showOptions)? ( $db_name)? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1371:8: ^( TOK_SHOWINDEXES showStmtIdentifier ( $showOptions)? ( $db_name)? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SHOWINDEXES, "TOK_SHOWINDEXES"),
                  root_1);

              adaptor.addChild(root_1, stream_showStmtIdentifier.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1371:46: ( $showOptions)?
              if (stream_showOptions.hasNext()) {
                adaptor.addChild(root_1, stream_showOptions.nextNode());
              }
              stream_showOptions.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1371:60: ( $db_name)?
              if (stream_db_name.hasNext()) {
                adaptor.addChild(root_1, stream_db_name.nextTree());
              }
              stream_db_name.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 12:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1372:7: KW_SHOW KW_COMPACTIONS
        {
          KW_SHOW461 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showStatement7294);
          stream_KW_SHOW.add(KW_SHOW461);

          KW_COMPACTIONS462 = (Token) match(input, KW_COMPACTIONS, FOLLOW_KW_COMPACTIONS_in_showStatement7296);
          stream_KW_COMPACTIONS.add(KW_COMPACTIONS462);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1372:30: -> ^( TOK_SHOW_COMPACTIONS )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1372:33: ^( TOK_SHOW_COMPACTIONS )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor
                  .becomeRoot((CommonTree) adaptor.create(TOK_SHOW_COMPACTIONS, "TOK_SHOW_COMPACTIONS"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 13:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1373:7: KW_SHOW KW_TRANSACTIONS
        {
          KW_SHOW463 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showStatement7310);
          stream_KW_SHOW.add(KW_SHOW463);

          KW_TRANSACTIONS464 = (Token) match(input, KW_TRANSACTIONS, FOLLOW_KW_TRANSACTIONS_in_showStatement7312);
          stream_KW_TRANSACTIONS.add(KW_TRANSACTIONS464);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1373:31: -> ^( TOK_SHOW_TRANSACTIONS )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1373:34: ^( TOK_SHOW_TRANSACTIONS )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor
                  .becomeRoot((CommonTree) adaptor.create(TOK_SHOW_TRANSACTIONS, "TOK_SHOW_TRANSACTIONS"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 14:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1374:7: KW_SHOW KW_CONF StringLiteral
        {
          KW_SHOW465 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showStatement7326);
          stream_KW_SHOW.add(KW_SHOW465);

          KW_CONF466 = (Token) match(input, KW_CONF, FOLLOW_KW_CONF_in_showStatement7328);
          stream_KW_CONF.add(KW_CONF466);

          StringLiteral467 = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_showStatement7330);
          stream_StringLiteral.add(StringLiteral467);

          // AST REWRITE
          // elements: StringLiteral
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1374:37: -> ^( TOK_SHOWCONF StringLiteral )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1374:40: ^( TOK_SHOWCONF StringLiteral )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SHOWCONF, "TOK_SHOWCONF"), root_1);

              adaptor.addChild(root_1, stream_StringLiteral.nextNode());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "showStatement"

  public static class lockStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "lockStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1377:1: lockStatement : KW_LOCK KW_TABLE tableName ( partitionSpec )? lockMode -> ^( TOK_LOCKTABLE tableName lockMode ( partitionSpec )? ) ;
  public final HiveParser.lockStatement_return lockStatement() throws RecognitionException {
    HiveParser.lockStatement_return retval = new HiveParser.lockStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_LOCK468 = null;
    Token KW_TABLE469 = null;
    HiveParser_FromClauseParser.tableName_return tableName470 = null;

    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec471 = null;

    HiveParser.lockMode_return lockMode472 = null;

    CommonTree KW_LOCK468_tree = null;
    CommonTree KW_TABLE469_tree = null;
    RewriteRuleTokenStream stream_KW_LOCK = new RewriteRuleTokenStream(adaptor, "token KW_LOCK");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleSubtreeStream stream_lockMode = new RewriteRuleSubtreeStream(adaptor, "rule lockMode");
    RewriteRuleSubtreeStream stream_partitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule partitionSpec");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    pushMsg("lock statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1380:5: ( KW_LOCK KW_TABLE tableName ( partitionSpec )? lockMode -> ^( TOK_LOCKTABLE tableName lockMode ( partitionSpec )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1380:7: KW_LOCK KW_TABLE tableName ( partitionSpec )? lockMode
      {
        KW_LOCK468 = (Token) match(input, KW_LOCK, FOLLOW_KW_LOCK_in_lockStatement7365);
        stream_KW_LOCK.add(KW_LOCK468);

        KW_TABLE469 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_lockStatement7367);
        stream_KW_TABLE.add(KW_TABLE469);

        pushFollow(FOLLOW_tableName_in_lockStatement7369);
        tableName470 = tableName();

        state._fsp--;

        stream_tableName.add(tableName470.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1380:34: ( partitionSpec )?
        int alt144 = 2;
        switch (input.LA(1)) {
          case KW_PARTITION: {
            alt144 = 1;
          }
            break;
        }

        switch (alt144) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1380:34: partitionSpec
          {
            pushFollow(FOLLOW_partitionSpec_in_lockStatement7371);
            partitionSpec471 = partitionSpec();

            state._fsp--;

            stream_partitionSpec.add(partitionSpec471.getTree());
          }
            break;
        }

        pushFollow(FOLLOW_lockMode_in_lockStatement7374);
        lockMode472 = lockMode();

        state._fsp--;

        stream_lockMode.add(lockMode472.getTree());

        // AST REWRITE
        // elements: tableName, partitionSpec, lockMode
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1380:58: -> ^( TOK_LOCKTABLE tableName lockMode ( partitionSpec )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1380:61: ^( TOK_LOCKTABLE tableName lockMode ( partitionSpec )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_LOCKTABLE, "TOK_LOCKTABLE"), root_1);

            adaptor.addChild(root_1, stream_tableName.nextTree());

            adaptor.addChild(root_1, stream_lockMode.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1380:96: ( partitionSpec )?
            if (stream_partitionSpec.hasNext()) {
              adaptor.addChild(root_1, stream_partitionSpec.nextTree());
            }
            stream_partitionSpec.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "lockStatement"

  public static class lockDatabase_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "lockDatabase"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1383:1: lockDatabase : KW_LOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= Identifier ) lockMode -> ^( TOK_LOCKDB $dbName lockMode ) ;
  public final HiveParser.lockDatabase_return lockDatabase() throws RecognitionException {
    HiveParser.lockDatabase_return retval = new HiveParser.lockDatabase_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token dbName = null;
    Token KW_LOCK473 = null;
    Token KW_DATABASE474 = null;
    Token KW_SCHEMA475 = null;
    HiveParser.lockMode_return lockMode476 = null;

    CommonTree dbName_tree = null;
    CommonTree KW_LOCK473_tree = null;
    CommonTree KW_DATABASE474_tree = null;
    CommonTree KW_SCHEMA475_tree = null;
    RewriteRuleTokenStream stream_KW_SCHEMA = new RewriteRuleTokenStream(adaptor, "token KW_SCHEMA");
    RewriteRuleTokenStream stream_Identifier = new RewriteRuleTokenStream(adaptor, "token Identifier");
    RewriteRuleTokenStream stream_KW_DATABASE = new RewriteRuleTokenStream(adaptor, "token KW_DATABASE");
    RewriteRuleTokenStream stream_KW_LOCK = new RewriteRuleTokenStream(adaptor, "token KW_LOCK");
    RewriteRuleSubtreeStream stream_lockMode = new RewriteRuleSubtreeStream(adaptor, "rule lockMode");
    pushMsg("lock database statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1386:5: ( KW_LOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= Identifier ) lockMode -> ^( TOK_LOCKDB $dbName lockMode ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1386:7: KW_LOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= Identifier ) lockMode
      {
        KW_LOCK473 = (Token) match(input, KW_LOCK, FOLLOW_KW_LOCK_in_lockDatabase7414);
        stream_KW_LOCK.add(KW_LOCK473);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1386:15: ( KW_DATABASE | KW_SCHEMA )
        int alt145 = 2;
        switch (input.LA(1)) {
          case KW_DATABASE: {
            alt145 = 1;
          }
            break;
          case KW_SCHEMA: {
            alt145 = 2;
          }
            break;
          default:
            NoViableAltException nvae = new NoViableAltException("", 145, 0, input);

            throw nvae;
        }

        switch (alt145) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1386:16: KW_DATABASE
          {
            KW_DATABASE474 = (Token) match(input, KW_DATABASE, FOLLOW_KW_DATABASE_in_lockDatabase7417);
            stream_KW_DATABASE.add(KW_DATABASE474);
          }
            break;
          case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1386:28: KW_SCHEMA
          {
            KW_SCHEMA475 = (Token) match(input, KW_SCHEMA, FOLLOW_KW_SCHEMA_in_lockDatabase7419);
            stream_KW_SCHEMA.add(KW_SCHEMA475);
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1386:39: (dbName= Identifier )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1386:40: dbName= Identifier
        {
          dbName = (Token) match(input, Identifier, FOLLOW_Identifier_in_lockDatabase7425);
          stream_Identifier.add(dbName);
        }

        pushFollow(FOLLOW_lockMode_in_lockDatabase7428);
        lockMode476 = lockMode();

        state._fsp--;

        stream_lockMode.add(lockMode476.getTree());

        // AST REWRITE
        // elements: lockMode, dbName
        // token labels: dbName
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_dbName = new RewriteRuleTokenStream(adaptor, "token dbName", dbName);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1386:68: -> ^( TOK_LOCKDB $dbName lockMode )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1386:71: ^( TOK_LOCKDB $dbName lockMode )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_LOCKDB, "TOK_LOCKDB"), root_1);

            adaptor.addChild(root_1, stream_dbName.nextNode());

            adaptor.addChild(root_1, stream_lockMode.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "lockDatabase"

  public static class lockMode_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "lockMode"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1389:1: lockMode : ( KW_SHARED | KW_EXCLUSIVE );
  public final HiveParser.lockMode_return lockMode() throws RecognitionException {
    HiveParser.lockMode_return retval = new HiveParser.lockMode_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token set477 = null;

    CommonTree set477_tree = null;

    pushMsg("lock mode", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1392:5: ( KW_SHARED | KW_EXCLUSIVE )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:
      {
        root_0 = (CommonTree) adaptor.nil();

        set477 = (Token) input.LT(1);

        if (input.LA(1) == KW_EXCLUSIVE || input.LA(1) == KW_SHARED) {
          input.consume();
          adaptor.addChild(root_0, (CommonTree) adaptor.create(set477));
          state.errorRecovery = false;
        } else {
          MismatchedSetException mse = new MismatchedSetException(null, input);
          throw mse;
        }
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "lockMode"

  public static class unlockStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "unlockStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1395:1: unlockStatement : KW_UNLOCK KW_TABLE tableName ( partitionSpec )? -> ^( TOK_UNLOCKTABLE tableName ( partitionSpec )? ) ;
  public final HiveParser.unlockStatement_return unlockStatement() throws RecognitionException {
    HiveParser.unlockStatement_return retval = new HiveParser.unlockStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_UNLOCK478 = null;
    Token KW_TABLE479 = null;
    HiveParser_FromClauseParser.tableName_return tableName480 = null;

    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec481 = null;

    CommonTree KW_UNLOCK478_tree = null;
    CommonTree KW_TABLE479_tree = null;
    RewriteRuleTokenStream stream_KW_UNLOCK = new RewriteRuleTokenStream(adaptor, "token KW_UNLOCK");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleSubtreeStream stream_partitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule partitionSpec");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    pushMsg("unlock statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1398:5: ( KW_UNLOCK KW_TABLE tableName ( partitionSpec )? -> ^( TOK_UNLOCKTABLE tableName ( partitionSpec )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1398:7: KW_UNLOCK KW_TABLE tableName ( partitionSpec )?
      {
        KW_UNLOCK478 = (Token) match(input, KW_UNLOCK, FOLLOW_KW_UNLOCK_in_unlockStatement7497);
        stream_KW_UNLOCK.add(KW_UNLOCK478);

        KW_TABLE479 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_unlockStatement7499);
        stream_KW_TABLE.add(KW_TABLE479);

        pushFollow(FOLLOW_tableName_in_unlockStatement7501);
        tableName480 = tableName();

        state._fsp--;

        stream_tableName.add(tableName480.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1398:36: ( partitionSpec )?
        int alt146 = 2;
        switch (input.LA(1)) {
          case KW_PARTITION: {
            alt146 = 1;
          }
            break;
        }

        switch (alt146) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1398:36: partitionSpec
          {
            pushFollow(FOLLOW_partitionSpec_in_unlockStatement7503);
            partitionSpec481 = partitionSpec();

            state._fsp--;

            stream_partitionSpec.add(partitionSpec481.getTree());
          }
            break;
        }

        // AST REWRITE
        // elements: partitionSpec, tableName
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1398:52: -> ^( TOK_UNLOCKTABLE tableName ( partitionSpec )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1398:55: ^( TOK_UNLOCKTABLE tableName ( partitionSpec )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_UNLOCKTABLE, "TOK_UNLOCKTABLE"),
                root_1);

            adaptor.addChild(root_1, stream_tableName.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1398:83: ( partitionSpec )?
            if (stream_partitionSpec.hasNext()) {
              adaptor.addChild(root_1, stream_partitionSpec.nextTree());
            }
            stream_partitionSpec.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "unlockStatement"

  public static class unlockDatabase_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "unlockDatabase"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1401:1: unlockDatabase : KW_UNLOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= Identifier ) -> ^( TOK_UNLOCKDB $dbName) ;
  public final HiveParser.unlockDatabase_return unlockDatabase() throws RecognitionException {
    HiveParser.unlockDatabase_return retval = new HiveParser.unlockDatabase_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token dbName = null;
    Token KW_UNLOCK482 = null;
    Token KW_DATABASE483 = null;
    Token KW_SCHEMA484 = null;

    CommonTree dbName_tree = null;
    CommonTree KW_UNLOCK482_tree = null;
    CommonTree KW_DATABASE483_tree = null;
    CommonTree KW_SCHEMA484_tree = null;
    RewriteRuleTokenStream stream_KW_SCHEMA = new RewriteRuleTokenStream(adaptor, "token KW_SCHEMA");
    RewriteRuleTokenStream stream_Identifier = new RewriteRuleTokenStream(adaptor, "token Identifier");
    RewriteRuleTokenStream stream_KW_DATABASE = new RewriteRuleTokenStream(adaptor, "token KW_DATABASE");
    RewriteRuleTokenStream stream_KW_UNLOCK = new RewriteRuleTokenStream(adaptor, "token KW_UNLOCK");

    pushMsg("unlock database statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1404:5: ( KW_UNLOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= Identifier ) -> ^( TOK_UNLOCKDB $dbName) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1404:7: KW_UNLOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= Identifier )
      {
        KW_UNLOCK482 = (Token) match(input, KW_UNLOCK, FOLLOW_KW_UNLOCK_in_unlockDatabase7543);
        stream_KW_UNLOCK.add(KW_UNLOCK482);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1404:17: ( KW_DATABASE | KW_SCHEMA )
        int alt147 = 2;
        switch (input.LA(1)) {
          case KW_DATABASE: {
            alt147 = 1;
          }
            break;
          case KW_SCHEMA: {
            alt147 = 2;
          }
            break;
          default:
            NoViableAltException nvae = new NoViableAltException("", 147, 0, input);

            throw nvae;
        }

        switch (alt147) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1404:18: KW_DATABASE
          {
            KW_DATABASE483 = (Token) match(input, KW_DATABASE, FOLLOW_KW_DATABASE_in_unlockDatabase7546);
            stream_KW_DATABASE.add(KW_DATABASE483);
          }
            break;
          case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1404:30: KW_SCHEMA
          {
            KW_SCHEMA484 = (Token) match(input, KW_SCHEMA, FOLLOW_KW_SCHEMA_in_unlockDatabase7548);
            stream_KW_SCHEMA.add(KW_SCHEMA484);
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1404:41: (dbName= Identifier )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1404:42: dbName= Identifier
        {
          dbName = (Token) match(input, Identifier, FOLLOW_Identifier_in_unlockDatabase7554);
          stream_Identifier.add(dbName);
        }

        // AST REWRITE
        // elements: dbName
        // token labels: dbName
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_dbName = new RewriteRuleTokenStream(adaptor, "token dbName", dbName);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1404:61: -> ^( TOK_UNLOCKDB $dbName)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1404:64: ^( TOK_UNLOCKDB $dbName)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_UNLOCKDB, "TOK_UNLOCKDB"), root_1);

            adaptor.addChild(root_1, stream_dbName.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "unlockDatabase"

  public static class createRoleStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "createRoleStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1407:1: createRoleStatement : KW_CREATE KW_ROLE roleName= identifier -> ^( TOK_CREATEROLE $roleName) ;
  public final HiveParser.createRoleStatement_return createRoleStatement() throws RecognitionException {
    HiveParser.createRoleStatement_return retval = new HiveParser.createRoleStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_CREATE485 = null;
    Token KW_ROLE486 = null;
    HiveParser_IdentifiersParser.identifier_return roleName = null;

    CommonTree KW_CREATE485_tree = null;
    CommonTree KW_ROLE486_tree = null;
    RewriteRuleTokenStream stream_KW_ROLE = new RewriteRuleTokenStream(adaptor, "token KW_ROLE");
    RewriteRuleTokenStream stream_KW_CREATE = new RewriteRuleTokenStream(adaptor, "token KW_CREATE");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    pushMsg("create role", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1410:5: ( KW_CREATE KW_ROLE roleName= identifier -> ^( TOK_CREATEROLE $roleName) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1410:7: KW_CREATE KW_ROLE roleName= identifier
      {
        KW_CREATE485 = (Token) match(input, KW_CREATE, FOLLOW_KW_CREATE_in_createRoleStatement7591);
        stream_KW_CREATE.add(KW_CREATE485);

        KW_ROLE486 = (Token) match(input, KW_ROLE, FOLLOW_KW_ROLE_in_createRoleStatement7593);
        stream_KW_ROLE.add(KW_ROLE486);

        pushFollow(FOLLOW_identifier_in_createRoleStatement7597);
        roleName = identifier();

        state._fsp--;

        stream_identifier.add(roleName.getTree());

        // AST REWRITE
        // elements: roleName
        // token labels:
        // rule labels: roleName, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_roleName =
            new RewriteRuleSubtreeStream(adaptor, "rule roleName", roleName != null ? roleName.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1411:5: -> ^( TOK_CREATEROLE $roleName)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1411:8: ^( TOK_CREATEROLE $roleName)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_CREATEROLE, "TOK_CREATEROLE"), root_1);

            adaptor.addChild(root_1, stream_roleName.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "createRoleStatement"

  public static class dropRoleStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "dropRoleStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1414:1: dropRoleStatement : KW_DROP KW_ROLE roleName= identifier -> ^( TOK_DROPROLE $roleName) ;
  public final HiveParser.dropRoleStatement_return dropRoleStatement() throws RecognitionException {
    HiveParser.dropRoleStatement_return retval = new HiveParser.dropRoleStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_DROP487 = null;
    Token KW_ROLE488 = null;
    HiveParser_IdentifiersParser.identifier_return roleName = null;

    CommonTree KW_DROP487_tree = null;
    CommonTree KW_ROLE488_tree = null;
    RewriteRuleTokenStream stream_KW_DROP = new RewriteRuleTokenStream(adaptor, "token KW_DROP");
    RewriteRuleTokenStream stream_KW_ROLE = new RewriteRuleTokenStream(adaptor, "token KW_ROLE");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    pushMsg("drop role", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1417:5: ( KW_DROP KW_ROLE roleName= identifier -> ^( TOK_DROPROLE $roleName) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1417:7: KW_DROP KW_ROLE roleName= identifier
      {
        KW_DROP487 = (Token) match(input, KW_DROP, FOLLOW_KW_DROP_in_dropRoleStatement7637);
        stream_KW_DROP.add(KW_DROP487);

        KW_ROLE488 = (Token) match(input, KW_ROLE, FOLLOW_KW_ROLE_in_dropRoleStatement7639);
        stream_KW_ROLE.add(KW_ROLE488);

        pushFollow(FOLLOW_identifier_in_dropRoleStatement7643);
        roleName = identifier();

        state._fsp--;

        stream_identifier.add(roleName.getTree());

        // AST REWRITE
        // elements: roleName
        // token labels:
        // rule labels: roleName, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_roleName =
            new RewriteRuleSubtreeStream(adaptor, "rule roleName", roleName != null ? roleName.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1418:5: -> ^( TOK_DROPROLE $roleName)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1418:8: ^( TOK_DROPROLE $roleName)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DROPROLE, "TOK_DROPROLE"), root_1);

            adaptor.addChild(root_1, stream_roleName.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "dropRoleStatement"

  public static class grantPrivileges_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "grantPrivileges"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1421:1: grantPrivileges : KW_GRANT privList= privilegeList ( privilegeObject )? KW_TO principalSpecification ( withGrantOption )? -> ^( TOK_GRANT $privList principalSpecification ( privilegeObject )? ( withGrantOption )? ) ;
  public final HiveParser.grantPrivileges_return grantPrivileges() throws RecognitionException {
    HiveParser.grantPrivileges_return retval = new HiveParser.grantPrivileges_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_GRANT489 = null;
    Token KW_TO491 = null;
    HiveParser.privilegeList_return privList = null;

    HiveParser.privilegeObject_return privilegeObject490 = null;

    HiveParser.principalSpecification_return principalSpecification492 = null;

    HiveParser.withGrantOption_return withGrantOption493 = null;

    CommonTree KW_GRANT489_tree = null;
    CommonTree KW_TO491_tree = null;
    RewriteRuleTokenStream stream_KW_TO = new RewriteRuleTokenStream(adaptor, "token KW_TO");
    RewriteRuleTokenStream stream_KW_GRANT = new RewriteRuleTokenStream(adaptor, "token KW_GRANT");
    RewriteRuleSubtreeStream stream_withGrantOption = new RewriteRuleSubtreeStream(adaptor, "rule withGrantOption");
    RewriteRuleSubtreeStream stream_privilegeList = new RewriteRuleSubtreeStream(adaptor, "rule privilegeList");
    RewriteRuleSubtreeStream stream_privilegeObject = new RewriteRuleSubtreeStream(adaptor, "rule privilegeObject");
    RewriteRuleSubtreeStream stream_principalSpecification =
        new RewriteRuleSubtreeStream(adaptor, "rule principalSpecification");
    pushMsg("grant privileges", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1424:5: ( KW_GRANT privList= privilegeList ( privilegeObject )? KW_TO principalSpecification ( withGrantOption )? -> ^( TOK_GRANT $privList principalSpecification ( privilegeObject )? ( withGrantOption )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1424:7: KW_GRANT privList= privilegeList ( privilegeObject )? KW_TO principalSpecification ( withGrantOption )?
      {
        KW_GRANT489 = (Token) match(input, KW_GRANT, FOLLOW_KW_GRANT_in_grantPrivileges7683);
        stream_KW_GRANT.add(KW_GRANT489);

        pushFollow(FOLLOW_privilegeList_in_grantPrivileges7687);
        privList = privilegeList();

        state._fsp--;

        stream_privilegeList.add(privList.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1425:7: ( privilegeObject )?
        int alt148 = 2;
        switch (input.LA(1)) {
          case KW_ON: {
            alt148 = 1;
          }
            break;
        }

        switch (alt148) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1425:7: privilegeObject
          {
            pushFollow(FOLLOW_privilegeObject_in_grantPrivileges7695);
            privilegeObject490 = privilegeObject();

            state._fsp--;

            stream_privilegeObject.add(privilegeObject490.getTree());
          }
            break;
        }

        KW_TO491 = (Token) match(input, KW_TO, FOLLOW_KW_TO_in_grantPrivileges7704);
        stream_KW_TO.add(KW_TO491);

        pushFollow(FOLLOW_principalSpecification_in_grantPrivileges7706);
        principalSpecification492 = principalSpecification();

        state._fsp--;

        stream_principalSpecification.add(principalSpecification492.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1427:7: ( withGrantOption )?
        int alt149 = 2;
        switch (input.LA(1)) {
          case KW_WITH: {
            alt149 = 1;
          }
            break;
        }

        switch (alt149) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1427:7: withGrantOption
          {
            pushFollow(FOLLOW_withGrantOption_in_grantPrivileges7714);
            withGrantOption493 = withGrantOption();

            state._fsp--;

            stream_withGrantOption.add(withGrantOption493.getTree());
          }
            break;
        }

        // AST REWRITE
        // elements: withGrantOption, privList, privilegeObject, principalSpecification
        // token labels:
        // rule labels: privList, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_privList =
            new RewriteRuleSubtreeStream(adaptor, "rule privList", privList != null ? privList.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1428:5: -> ^( TOK_GRANT $privList principalSpecification ( privilegeObject )? ( withGrantOption )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1428:8: ^( TOK_GRANT $privList principalSpecification ( privilegeObject )? ( withGrantOption )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_GRANT, "TOK_GRANT"), root_1);

            adaptor.addChild(root_1, stream_privList.nextTree());

            adaptor.addChild(root_1, stream_principalSpecification.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1428:53: ( privilegeObject )?
            if (stream_privilegeObject.hasNext()) {
              adaptor.addChild(root_1, stream_privilegeObject.nextTree());
            }
            stream_privilegeObject.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1428:70: ( withGrantOption )?
            if (stream_withGrantOption.hasNext()) {
              adaptor.addChild(root_1, stream_withGrantOption.nextTree());
            }
            stream_withGrantOption.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "grantPrivileges"

  public static class revokePrivileges_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "revokePrivileges"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1431:1: revokePrivileges : KW_REVOKE ( grantOptionFor )? privilegeList ( privilegeObject )? KW_FROM principalSpecification -> ^( TOK_REVOKE privilegeList principalSpecification ( privilegeObject )? ( grantOptionFor )? ) ;
  public final HiveParser.revokePrivileges_return revokePrivileges() throws RecognitionException {
    HiveParser.revokePrivileges_return retval = new HiveParser.revokePrivileges_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_REVOKE494 = null;
    Token KW_FROM498 = null;
    HiveParser.grantOptionFor_return grantOptionFor495 = null;

    HiveParser.privilegeList_return privilegeList496 = null;

    HiveParser.privilegeObject_return privilegeObject497 = null;

    HiveParser.principalSpecification_return principalSpecification499 = null;

    CommonTree KW_REVOKE494_tree = null;
    CommonTree KW_FROM498_tree = null;
    RewriteRuleTokenStream stream_KW_FROM = new RewriteRuleTokenStream(adaptor, "token KW_FROM");
    RewriteRuleTokenStream stream_KW_REVOKE = new RewriteRuleTokenStream(adaptor, "token KW_REVOKE");
    RewriteRuleSubtreeStream stream_grantOptionFor = new RewriteRuleSubtreeStream(adaptor, "rule grantOptionFor");
    RewriteRuleSubtreeStream stream_privilegeList = new RewriteRuleSubtreeStream(adaptor, "rule privilegeList");
    RewriteRuleSubtreeStream stream_privilegeObject = new RewriteRuleSubtreeStream(adaptor, "rule privilegeObject");
    RewriteRuleSubtreeStream stream_principalSpecification =
        new RewriteRuleSubtreeStream(adaptor, "rule principalSpecification");
    pushMsg("revoke privileges", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1434:5: ( KW_REVOKE ( grantOptionFor )? privilegeList ( privilegeObject )? KW_FROM principalSpecification -> ^( TOK_REVOKE privilegeList principalSpecification ( privilegeObject )? ( grantOptionFor )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1434:7: KW_REVOKE ( grantOptionFor )? privilegeList ( privilegeObject )? KW_FROM principalSpecification
      {
        KW_REVOKE494 = (Token) match(input, KW_REVOKE, FOLLOW_KW_REVOKE_in_revokePrivileges7763);
        stream_KW_REVOKE.add(KW_REVOKE494);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1434:17: ( grantOptionFor )?
        int alt150 = 2;
        switch (input.LA(1)) {
          case KW_GRANT: {
            alt150 = 1;
          }
            break;
        }

        switch (alt150) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1434:17: grantOptionFor
          {
            pushFollow(FOLLOW_grantOptionFor_in_revokePrivileges7765);
            grantOptionFor495 = grantOptionFor();

            state._fsp--;

            stream_grantOptionFor.add(grantOptionFor495.getTree());
          }
            break;
        }

        pushFollow(FOLLOW_privilegeList_in_revokePrivileges7768);
        privilegeList496 = privilegeList();

        state._fsp--;

        stream_privilegeList.add(privilegeList496.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1434:47: ( privilegeObject )?
        int alt151 = 2;
        switch (input.LA(1)) {
          case KW_ON: {
            alt151 = 1;
          }
            break;
        }

        switch (alt151) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1434:47: privilegeObject
          {
            pushFollow(FOLLOW_privilegeObject_in_revokePrivileges7770);
            privilegeObject497 = privilegeObject();

            state._fsp--;

            stream_privilegeObject.add(privilegeObject497.getTree());
          }
            break;
        }

        KW_FROM498 = (Token) match(input, KW_FROM, FOLLOW_KW_FROM_in_revokePrivileges7773);
        stream_KW_FROM.add(KW_FROM498);

        pushFollow(FOLLOW_principalSpecification_in_revokePrivileges7775);
        principalSpecification499 = principalSpecification();

        state._fsp--;

        stream_principalSpecification.add(principalSpecification499.getTree());

        // AST REWRITE
        // elements: grantOptionFor, privilegeObject, privilegeList, principalSpecification
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1435:5: -> ^( TOK_REVOKE privilegeList principalSpecification ( privilegeObject )? ( grantOptionFor )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1435:8: ^( TOK_REVOKE privilegeList principalSpecification ( privilegeObject )? ( grantOptionFor )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_REVOKE, "TOK_REVOKE"), root_1);

            adaptor.addChild(root_1, stream_privilegeList.nextTree());

            adaptor.addChild(root_1, stream_principalSpecification.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1435:58: ( privilegeObject )?
            if (stream_privilegeObject.hasNext()) {
              adaptor.addChild(root_1, stream_privilegeObject.nextTree());
            }
            stream_privilegeObject.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1435:75: ( grantOptionFor )?
            if (stream_grantOptionFor.hasNext()) {
              adaptor.addChild(root_1, stream_grantOptionFor.nextTree());
            }
            stream_grantOptionFor.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "revokePrivileges"

  public static class grantRole_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "grantRole"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1438:1: grantRole : KW_GRANT ( KW_ROLE )? identifier ( COMMA identifier )* KW_TO principalSpecification ( withAdminOption )? -> ^( TOK_GRANT_ROLE principalSpecification ( withAdminOption )? ( identifier )+ ) ;
  public final HiveParser.grantRole_return grantRole() throws RecognitionException {
    HiveParser.grantRole_return retval = new HiveParser.grantRole_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_GRANT500 = null;
    Token KW_ROLE501 = null;
    Token COMMA503 = null;
    Token KW_TO505 = null;
    HiveParser_IdentifiersParser.identifier_return identifier502 = null;

    HiveParser_IdentifiersParser.identifier_return identifier504 = null;

    HiveParser.principalSpecification_return principalSpecification506 = null;

    HiveParser.withAdminOption_return withAdminOption507 = null;

    CommonTree KW_GRANT500_tree = null;
    CommonTree KW_ROLE501_tree = null;
    CommonTree COMMA503_tree = null;
    CommonTree KW_TO505_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleTokenStream stream_KW_ROLE = new RewriteRuleTokenStream(adaptor, "token KW_ROLE");
    RewriteRuleTokenStream stream_KW_TO = new RewriteRuleTokenStream(adaptor, "token KW_TO");
    RewriteRuleTokenStream stream_KW_GRANT = new RewriteRuleTokenStream(adaptor, "token KW_GRANT");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_withAdminOption = new RewriteRuleSubtreeStream(adaptor, "rule withAdminOption");
    RewriteRuleSubtreeStream stream_principalSpecification =
        new RewriteRuleSubtreeStream(adaptor, "rule principalSpecification");
    pushMsg("grant role", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1441:5: ( KW_GRANT ( KW_ROLE )? identifier ( COMMA identifier )* KW_TO principalSpecification ( withAdminOption )? -> ^( TOK_GRANT_ROLE principalSpecification ( withAdminOption )? ( identifier )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1441:7: KW_GRANT ( KW_ROLE )? identifier ( COMMA identifier )* KW_TO principalSpecification ( withAdminOption )?
      {
        KW_GRANT500 = (Token) match(input, KW_GRANT, FOLLOW_KW_GRANT_in_grantRole7822);
        stream_KW_GRANT.add(KW_GRANT500);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1441:16: ( KW_ROLE )?
        int alt152 = 2;
        switch (input.LA(1)) {
          case KW_ROLE: {
            switch (input.LA(2)) {
              case Identifier:
              case KW_ADD:
              case KW_ADMIN:
              case KW_AFTER:
              case KW_ALL:
              case KW_ALTER:
              case KW_ANALYZE:
              case KW_ARCHIVE:
              case KW_ARRAY:
              case KW_AS:
              case KW_ASC:
              case KW_AUTHORIZATION:
              case KW_BEFORE:
              case KW_BETWEEN:
              case KW_BIGINT:
              case KW_BINARY:
              case KW_BOOLEAN:
              case KW_BOTH:
              case KW_BUCKET:
              case KW_BUCKETS:
              case KW_BY:
              case KW_CASCADE:
              case KW_CHANGE:
              case KW_CLUSTER:
              case KW_CLUSTERED:
              case KW_CLUSTERSTATUS:
              case KW_COLLECTION:
              case KW_COLUMNS:
              case KW_COMMENT:
              case KW_COMPACT:
              case KW_COMPACTIONS:
              case KW_COMPUTE:
              case KW_CONCATENATE:
              case KW_CONTINUE:
              case KW_CREATE:
              case KW_CUBE:
              case KW_CURSOR:
              case KW_DATA:
              case KW_DATABASES:
              case KW_DATE:
              case KW_DATETIME:
              case KW_DBPROPERTIES:
              case KW_DECIMAL:
              case KW_DEFAULT:
              case KW_DEFERRED:
              case KW_DEFINED:
              case KW_DELETE:
              case KW_DELIMITED:
              case KW_DEPENDENCY:
              case KW_DESC:
              case KW_DESCRIBE:
              case KW_DIRECTORIES:
              case KW_DIRECTORY:
              case KW_DISABLE:
              case KW_DISTRIBUTE:
              case KW_DOUBLE:
              case KW_DROP:
              case KW_ELEM_TYPE:
              case KW_ENABLE:
              case KW_ESCAPED:
              case KW_EXCLUSIVE:
              case KW_EXISTS:
              case KW_EXPLAIN:
              case KW_EXPORT:
              case KW_EXTERNAL:
              case KW_FALSE:
              case KW_FETCH:
              case KW_FIELDS:
              case KW_FILE:
              case KW_FILEFORMAT:
              case KW_FIRST:
              case KW_FLOAT:
              case KW_FOR:
              case KW_FORMAT:
              case KW_FORMATTED:
              case KW_FULL:
              case KW_FUNCTIONS:
              case KW_GRANT:
              case KW_GROUP:
              case KW_GROUPING:
              case KW_HOLD_DDLTIME:
              case KW_IDXPROPERTIES:
              case KW_IGNORE:
              case KW_IMPORT:
              case KW_IN:
              case KW_INDEX:
              case KW_INDEXES:
              case KW_INNER:
              case KW_INPATH:
              case KW_INPUTDRIVER:
              case KW_INPUTFORMAT:
              case KW_INSERT:
              case KW_INT:
              case KW_INTERSECT:
              case KW_INTO:
              case KW_IS:
              case KW_ITEMS:
              case KW_JAR:
              case KW_KEYS:
              case KW_KEY_TYPE:
              case KW_LATERAL:
              case KW_LEFT:
              case KW_LIKE:
              case KW_LIMIT:
              case KW_LINES:
              case KW_LOAD:
              case KW_LOCAL:
              case KW_LOCATION:
              case KW_LOCK:
              case KW_LOCKS:
              case KW_LOGICAL:
              case KW_LONG:
              case KW_MAPJOIN:
              case KW_MATERIALIZED:
              case KW_METADATA:
              case KW_MINUS:
              case KW_MSCK:
              case KW_NONE:
              case KW_NOSCAN:
              case KW_NO_DROP:
              case KW_NULL:
              case KW_OF:
              case KW_OFFLINE:
              case KW_OPTION:
              case KW_ORDER:
              case KW_OUT:
              case KW_OUTER:
              case KW_OUTPUTDRIVER:
              case KW_OUTPUTFORMAT:
              case KW_OVERWRITE:
              case KW_OWNER:
              case KW_PARTITION:
              case KW_PARTITIONED:
              case KW_PARTITIONS:
              case KW_PERCENT:
              case KW_PLUS:
              case KW_PRETTY:
              case KW_PRINCIPALS:
              case KW_PROCEDURE:
              case KW_PROTECTION:
              case KW_PURGE:
              case KW_RANGE:
              case KW_READ:
              case KW_READONLY:
              case KW_READS:
              case KW_REBUILD:
              case KW_RECORDREADER:
              case KW_RECORDWRITER:
              case KW_REGEXP:
              case KW_RELOAD:
              case KW_RENAME:
              case KW_REPAIR:
              case KW_REPLACE:
              case KW_REPLICATION:
              case KW_RESTRICT:
              case KW_REVOKE:
              case KW_REWRITE:
              case KW_RIGHT:
              case KW_RLIKE:
              case KW_ROLE:
              case KW_ROLES:
              case KW_ROLLUP:
              case KW_ROW:
              case KW_ROWS:
              case KW_SCHEMA:
              case KW_SCHEMAS:
              case KW_SEMI:
              case KW_SERDE:
              case KW_SERDEPROPERTIES:
              case KW_SERVER:
              case KW_SET:
              case KW_SETS:
              case KW_SHARED:
              case KW_SHOW:
              case KW_SHOW_DATABASE:
              case KW_SKEWED:
              case KW_SMALLINT:
              case KW_SORT:
              case KW_SORTED:
              case KW_SSL:
              case KW_STATISTICS:
              case KW_STORED:
              case KW_STREAMTABLE:
              case KW_STRING:
              case KW_STRUCT:
              case KW_TABLE:
              case KW_TABLES:
              case KW_TBLPROPERTIES:
              case KW_TEMPORARY:
              case KW_TERMINATED:
              case KW_TIMESTAMP:
              case KW_TINYINT:
              case KW_TOUCH:
              case KW_TRANSACTIONS:
              case KW_TRIGGER:
              case KW_TRUE:
              case KW_TRUNCATE:
              case KW_UNARCHIVE:
              case KW_UNDO:
              case KW_UNION:
              case KW_UNIONTYPE:
              case KW_UNLOCK:
              case KW_UNSET:
              case KW_UNSIGNED:
              case KW_UPDATE:
              case KW_URI:
              case KW_USE:
              case KW_USER:
              case KW_USING:
              case KW_UTC:
              case KW_UTCTIMESTAMP:
              case KW_VALUES:
              case KW_VALUE_TYPE:
              case KW_VIEW:
              case KW_WHILE:
              case KW_WITH: {
                alt152 = 1;
              }
                break;
              case KW_TO: {
                switch (input.LA(3)) {
                  case COMMA:
                  case KW_TO: {
                    alt152 = 1;
                  }
                    break;
                }
              }
                break;
            }
          }
            break;
        }

        switch (alt152) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1441:16: KW_ROLE
          {
            KW_ROLE501 = (Token) match(input, KW_ROLE, FOLLOW_KW_ROLE_in_grantRole7824);
            stream_KW_ROLE.add(KW_ROLE501);
          }
            break;
        }

        pushFollow(FOLLOW_identifier_in_grantRole7827);
        identifier502 = identifier();

        state._fsp--;

        stream_identifier.add(identifier502.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1441:36: ( COMMA identifier )*
        loop153: do {
          int alt153 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt153 = 1;
            }
              break;
          }

          switch (alt153) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1441:37: COMMA identifier
            {
              COMMA503 = (Token) match(input, COMMA, FOLLOW_COMMA_in_grantRole7830);
              stream_COMMA.add(COMMA503);

              pushFollow(FOLLOW_identifier_in_grantRole7832);
              identifier504 = identifier();

              state._fsp--;

              stream_identifier.add(identifier504.getTree());
            }
              break;

            default:
              break loop153;
          }
        } while (true);

        KW_TO505 = (Token) match(input, KW_TO, FOLLOW_KW_TO_in_grantRole7836);
        stream_KW_TO.add(KW_TO505);

        pushFollow(FOLLOW_principalSpecification_in_grantRole7838);
        principalSpecification506 = principalSpecification();

        state._fsp--;

        stream_principalSpecification.add(principalSpecification506.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1441:85: ( withAdminOption )?
        int alt154 = 2;
        switch (input.LA(1)) {
          case KW_WITH: {
            alt154 = 1;
          }
            break;
        }

        switch (alt154) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1441:85: withAdminOption
          {
            pushFollow(FOLLOW_withAdminOption_in_grantRole7840);
            withAdminOption507 = withAdminOption();

            state._fsp--;

            stream_withAdminOption.add(withAdminOption507.getTree());
          }
            break;
        }

        // AST REWRITE
        // elements: principalSpecification, withAdminOption, identifier
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1442:5: -> ^( TOK_GRANT_ROLE principalSpecification ( withAdminOption )? ( identifier )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1442:8: ^( TOK_GRANT_ROLE principalSpecification ( withAdminOption )? ( identifier )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_GRANT_ROLE, "TOK_GRANT_ROLE"), root_1);

            adaptor.addChild(root_1, stream_principalSpecification.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1442:48: ( withAdminOption )?
            if (stream_withAdminOption.hasNext()) {
              adaptor.addChild(root_1, stream_withAdminOption.nextTree());
            }
            stream_withAdminOption.reset();

            if (!(stream_identifier.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_identifier.hasNext()) {
              adaptor.addChild(root_1, stream_identifier.nextTree());
            }
            stream_identifier.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "grantRole"

  public static class revokeRole_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "revokeRole"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1445:1: revokeRole : KW_REVOKE ( adminOptionFor )? ( KW_ROLE )? identifier ( COMMA identifier )* KW_FROM principalSpecification -> ^( TOK_REVOKE_ROLE principalSpecification ( adminOptionFor )? ( identifier )+ ) ;
  public final HiveParser.revokeRole_return revokeRole() throws RecognitionException {
    HiveParser.revokeRole_return retval = new HiveParser.revokeRole_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_REVOKE508 = null;
    Token KW_ROLE510 = null;
    Token COMMA512 = null;
    Token KW_FROM514 = null;
    HiveParser.adminOptionFor_return adminOptionFor509 = null;

    HiveParser_IdentifiersParser.identifier_return identifier511 = null;

    HiveParser_IdentifiersParser.identifier_return identifier513 = null;

    HiveParser.principalSpecification_return principalSpecification515 = null;

    CommonTree KW_REVOKE508_tree = null;
    CommonTree KW_ROLE510_tree = null;
    CommonTree COMMA512_tree = null;
    CommonTree KW_FROM514_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleTokenStream stream_KW_ROLE = new RewriteRuleTokenStream(adaptor, "token KW_ROLE");
    RewriteRuleTokenStream stream_KW_FROM = new RewriteRuleTokenStream(adaptor, "token KW_FROM");
    RewriteRuleTokenStream stream_KW_REVOKE = new RewriteRuleTokenStream(adaptor, "token KW_REVOKE");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_adminOptionFor = new RewriteRuleSubtreeStream(adaptor, "rule adminOptionFor");
    RewriteRuleSubtreeStream stream_principalSpecification =
        new RewriteRuleSubtreeStream(adaptor, "rule principalSpecification");
    pushMsg("revoke role", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1448:5: ( KW_REVOKE ( adminOptionFor )? ( KW_ROLE )? identifier ( COMMA identifier )* KW_FROM principalSpecification -> ^( TOK_REVOKE_ROLE principalSpecification ( adminOptionFor )? ( identifier )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1448:7: KW_REVOKE ( adminOptionFor )? ( KW_ROLE )? identifier ( COMMA identifier )* KW_FROM principalSpecification
      {
        KW_REVOKE508 = (Token) match(input, KW_REVOKE, FOLLOW_KW_REVOKE_in_revokeRole7886);
        stream_KW_REVOKE.add(KW_REVOKE508);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1448:17: ( adminOptionFor )?
        int alt155 = 2;
        switch (input.LA(1)) {
          case KW_ADMIN: {
            switch (input.LA(2)) {
              case KW_OPTION: {
                alt155 = 1;
              }
                break;
            }
          }
            break;
        }

        switch (alt155) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1448:17: adminOptionFor
          {
            pushFollow(FOLLOW_adminOptionFor_in_revokeRole7888);
            adminOptionFor509 = adminOptionFor();

            state._fsp--;

            stream_adminOptionFor.add(adminOptionFor509.getTree());
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1448:33: ( KW_ROLE )?
        int alt156 = 2;
        switch (input.LA(1)) {
          case KW_ROLE: {
            switch (input.LA(2)) {
              case Identifier:
              case KW_ADD:
              case KW_ADMIN:
              case KW_AFTER:
              case KW_ALL:
              case KW_ALTER:
              case KW_ANALYZE:
              case KW_ARCHIVE:
              case KW_ARRAY:
              case KW_AS:
              case KW_ASC:
              case KW_AUTHORIZATION:
              case KW_BEFORE:
              case KW_BETWEEN:
              case KW_BIGINT:
              case KW_BINARY:
              case KW_BOOLEAN:
              case KW_BOTH:
              case KW_BUCKET:
              case KW_BUCKETS:
              case KW_BY:
              case KW_CASCADE:
              case KW_CHANGE:
              case KW_CLUSTER:
              case KW_CLUSTERED:
              case KW_CLUSTERSTATUS:
              case KW_COLLECTION:
              case KW_COLUMNS:
              case KW_COMMENT:
              case KW_COMPACT:
              case KW_COMPACTIONS:
              case KW_COMPUTE:
              case KW_CONCATENATE:
              case KW_CONTINUE:
              case KW_CREATE:
              case KW_CUBE:
              case KW_CURSOR:
              case KW_DATA:
              case KW_DATABASES:
              case KW_DATE:
              case KW_DATETIME:
              case KW_DBPROPERTIES:
              case KW_DECIMAL:
              case KW_DEFAULT:
              case KW_DEFERRED:
              case KW_DEFINED:
              case KW_DELETE:
              case KW_DELIMITED:
              case KW_DEPENDENCY:
              case KW_DESC:
              case KW_DESCRIBE:
              case KW_DIRECTORIES:
              case KW_DIRECTORY:
              case KW_DISABLE:
              case KW_DISTRIBUTE:
              case KW_DOUBLE:
              case KW_DROP:
              case KW_ELEM_TYPE:
              case KW_ENABLE:
              case KW_ESCAPED:
              case KW_EXCLUSIVE:
              case KW_EXISTS:
              case KW_EXPLAIN:
              case KW_EXPORT:
              case KW_EXTERNAL:
              case KW_FALSE:
              case KW_FETCH:
              case KW_FIELDS:
              case KW_FILE:
              case KW_FILEFORMAT:
              case KW_FIRST:
              case KW_FLOAT:
              case KW_FOR:
              case KW_FORMAT:
              case KW_FORMATTED:
              case KW_FULL:
              case KW_FUNCTIONS:
              case KW_GRANT:
              case KW_GROUP:
              case KW_GROUPING:
              case KW_HOLD_DDLTIME:
              case KW_IDXPROPERTIES:
              case KW_IGNORE:
              case KW_IMPORT:
              case KW_IN:
              case KW_INDEX:
              case KW_INDEXES:
              case KW_INNER:
              case KW_INPATH:
              case KW_INPUTDRIVER:
              case KW_INPUTFORMAT:
              case KW_INSERT:
              case KW_INT:
              case KW_INTERSECT:
              case KW_INTO:
              case KW_IS:
              case KW_ITEMS:
              case KW_JAR:
              case KW_KEYS:
              case KW_KEY_TYPE:
              case KW_LATERAL:
              case KW_LEFT:
              case KW_LIKE:
              case KW_LIMIT:
              case KW_LINES:
              case KW_LOAD:
              case KW_LOCAL:
              case KW_LOCATION:
              case KW_LOCK:
              case KW_LOCKS:
              case KW_LOGICAL:
              case KW_LONG:
              case KW_MAPJOIN:
              case KW_MATERIALIZED:
              case KW_METADATA:
              case KW_MINUS:
              case KW_MSCK:
              case KW_NONE:
              case KW_NOSCAN:
              case KW_NO_DROP:
              case KW_NULL:
              case KW_OF:
              case KW_OFFLINE:
              case KW_OPTION:
              case KW_ORDER:
              case KW_OUT:
              case KW_OUTER:
              case KW_OUTPUTDRIVER:
              case KW_OUTPUTFORMAT:
              case KW_OVERWRITE:
              case KW_OWNER:
              case KW_PARTITION:
              case KW_PARTITIONED:
              case KW_PARTITIONS:
              case KW_PERCENT:
              case KW_PLUS:
              case KW_PRETTY:
              case KW_PRINCIPALS:
              case KW_PROCEDURE:
              case KW_PROTECTION:
              case KW_PURGE:
              case KW_RANGE:
              case KW_READ:
              case KW_READONLY:
              case KW_READS:
              case KW_REBUILD:
              case KW_RECORDREADER:
              case KW_RECORDWRITER:
              case KW_REGEXP:
              case KW_RELOAD:
              case KW_RENAME:
              case KW_REPAIR:
              case KW_REPLACE:
              case KW_REPLICATION:
              case KW_RESTRICT:
              case KW_REVOKE:
              case KW_REWRITE:
              case KW_RIGHT:
              case KW_RLIKE:
              case KW_ROLE:
              case KW_ROLES:
              case KW_ROLLUP:
              case KW_ROW:
              case KW_ROWS:
              case KW_SCHEMA:
              case KW_SCHEMAS:
              case KW_SEMI:
              case KW_SERDE:
              case KW_SERDEPROPERTIES:
              case KW_SERVER:
              case KW_SET:
              case KW_SETS:
              case KW_SHARED:
              case KW_SHOW:
              case KW_SHOW_DATABASE:
              case KW_SKEWED:
              case KW_SMALLINT:
              case KW_SORT:
              case KW_SORTED:
              case KW_SSL:
              case KW_STATISTICS:
              case KW_STORED:
              case KW_STREAMTABLE:
              case KW_STRING:
              case KW_STRUCT:
              case KW_TABLE:
              case KW_TABLES:
              case KW_TBLPROPERTIES:
              case KW_TEMPORARY:
              case KW_TERMINATED:
              case KW_TIMESTAMP:
              case KW_TINYINT:
              case KW_TO:
              case KW_TOUCH:
              case KW_TRANSACTIONS:
              case KW_TRIGGER:
              case KW_TRUE:
              case KW_TRUNCATE:
              case KW_UNARCHIVE:
              case KW_UNDO:
              case KW_UNION:
              case KW_UNIONTYPE:
              case KW_UNLOCK:
              case KW_UNSET:
              case KW_UNSIGNED:
              case KW_UPDATE:
              case KW_URI:
              case KW_USE:
              case KW_USER:
              case KW_USING:
              case KW_UTC:
              case KW_UTCTIMESTAMP:
              case KW_VALUES:
              case KW_VALUE_TYPE:
              case KW_VIEW:
              case KW_WHILE:
              case KW_WITH: {
                alt156 = 1;
              }
                break;
            }
          }
            break;
        }

        switch (alt156) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1448:33: KW_ROLE
          {
            KW_ROLE510 = (Token) match(input, KW_ROLE, FOLLOW_KW_ROLE_in_revokeRole7891);
            stream_KW_ROLE.add(KW_ROLE510);
          }
            break;
        }

        pushFollow(FOLLOW_identifier_in_revokeRole7894);
        identifier511 = identifier();

        state._fsp--;

        stream_identifier.add(identifier511.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1448:53: ( COMMA identifier )*
        loop157: do {
          int alt157 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt157 = 1;
            }
              break;
          }

          switch (alt157) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1448:54: COMMA identifier
            {
              COMMA512 = (Token) match(input, COMMA, FOLLOW_COMMA_in_revokeRole7897);
              stream_COMMA.add(COMMA512);

              pushFollow(FOLLOW_identifier_in_revokeRole7899);
              identifier513 = identifier();

              state._fsp--;

              stream_identifier.add(identifier513.getTree());
            }
              break;

            default:
              break loop157;
          }
        } while (true);

        KW_FROM514 = (Token) match(input, KW_FROM, FOLLOW_KW_FROM_in_revokeRole7903);
        stream_KW_FROM.add(KW_FROM514);

        pushFollow(FOLLOW_principalSpecification_in_revokeRole7905);
        principalSpecification515 = principalSpecification();

        state._fsp--;

        stream_principalSpecification.add(principalSpecification515.getTree());

        // AST REWRITE
        // elements: adminOptionFor, identifier, principalSpecification
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1449:5: -> ^( TOK_REVOKE_ROLE principalSpecification ( adminOptionFor )? ( identifier )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1449:8: ^( TOK_REVOKE_ROLE principalSpecification ( adminOptionFor )? ( identifier )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_REVOKE_ROLE, "TOK_REVOKE_ROLE"),
                root_1);

            adaptor.addChild(root_1, stream_principalSpecification.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1449:49: ( adminOptionFor )?
            if (stream_adminOptionFor.hasNext()) {
              adaptor.addChild(root_1, stream_adminOptionFor.nextTree());
            }
            stream_adminOptionFor.reset();

            if (!(stream_identifier.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_identifier.hasNext()) {
              adaptor.addChild(root_1, stream_identifier.nextTree());
            }
            stream_identifier.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "revokeRole"

  public static class showRoleGrants_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "showRoleGrants"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1452:1: showRoleGrants : KW_SHOW KW_ROLE KW_GRANT principalName -> ^( TOK_SHOW_ROLE_GRANT principalName ) ;
  public final HiveParser.showRoleGrants_return showRoleGrants() throws RecognitionException {
    HiveParser.showRoleGrants_return retval = new HiveParser.showRoleGrants_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_SHOW516 = null;
    Token KW_ROLE517 = null;
    Token KW_GRANT518 = null;
    HiveParser.principalName_return principalName519 = null;

    CommonTree KW_SHOW516_tree = null;
    CommonTree KW_ROLE517_tree = null;
    CommonTree KW_GRANT518_tree = null;
    RewriteRuleTokenStream stream_KW_ROLE = new RewriteRuleTokenStream(adaptor, "token KW_ROLE");
    RewriteRuleTokenStream stream_KW_GRANT = new RewriteRuleTokenStream(adaptor, "token KW_GRANT");
    RewriteRuleTokenStream stream_KW_SHOW = new RewriteRuleTokenStream(adaptor, "token KW_SHOW");
    RewriteRuleSubtreeStream stream_principalName = new RewriteRuleSubtreeStream(adaptor, "rule principalName");
    pushMsg("show role grants", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1455:5: ( KW_SHOW KW_ROLE KW_GRANT principalName -> ^( TOK_SHOW_ROLE_GRANT principalName ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1455:7: KW_SHOW KW_ROLE KW_GRANT principalName
      {
        KW_SHOW516 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showRoleGrants7950);
        stream_KW_SHOW.add(KW_SHOW516);

        KW_ROLE517 = (Token) match(input, KW_ROLE, FOLLOW_KW_ROLE_in_showRoleGrants7952);
        stream_KW_ROLE.add(KW_ROLE517);

        KW_GRANT518 = (Token) match(input, KW_GRANT, FOLLOW_KW_GRANT_in_showRoleGrants7954);
        stream_KW_GRANT.add(KW_GRANT518);

        pushFollow(FOLLOW_principalName_in_showRoleGrants7956);
        principalName519 = principalName();

        state._fsp--;

        stream_principalName.add(principalName519.getTree());

        // AST REWRITE
        // elements: principalName
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1456:5: -> ^( TOK_SHOW_ROLE_GRANT principalName )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1456:8: ^( TOK_SHOW_ROLE_GRANT principalName )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_SHOW_ROLE_GRANT, "TOK_SHOW_ROLE_GRANT"), root_1);

            adaptor.addChild(root_1, stream_principalName.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "showRoleGrants"

  public static class showRoles_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "showRoles"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1460:1: showRoles : KW_SHOW KW_ROLES -> ^( TOK_SHOW_ROLES ) ;
  public final HiveParser.showRoles_return showRoles() throws RecognitionException {
    HiveParser.showRoles_return retval = new HiveParser.showRoles_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_SHOW520 = null;
    Token KW_ROLES521 = null;

    CommonTree KW_SHOW520_tree = null;
    CommonTree KW_ROLES521_tree = null;
    RewriteRuleTokenStream stream_KW_ROLES = new RewriteRuleTokenStream(adaptor, "token KW_ROLES");
    RewriteRuleTokenStream stream_KW_SHOW = new RewriteRuleTokenStream(adaptor, "token KW_SHOW");

    pushMsg("show roles", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1463:5: ( KW_SHOW KW_ROLES -> ^( TOK_SHOW_ROLES ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1463:7: KW_SHOW KW_ROLES
      {
        KW_SHOW520 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showRoles7996);
        stream_KW_SHOW.add(KW_SHOW520);

        KW_ROLES521 = (Token) match(input, KW_ROLES, FOLLOW_KW_ROLES_in_showRoles7998);
        stream_KW_ROLES.add(KW_ROLES521);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1464:5: -> ^( TOK_SHOW_ROLES )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1464:8: ^( TOK_SHOW_ROLES )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SHOW_ROLES, "TOK_SHOW_ROLES"), root_1);

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "showRoles"

  public static class showCurrentRole_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "showCurrentRole"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1467:1: showCurrentRole : KW_SHOW KW_CURRENT KW_ROLES -> ^( TOK_SHOW_SET_ROLE ) ;
  public final HiveParser.showCurrentRole_return showCurrentRole() throws RecognitionException {
    HiveParser.showCurrentRole_return retval = new HiveParser.showCurrentRole_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_SHOW522 = null;
    Token KW_CURRENT523 = null;
    Token KW_ROLES524 = null;

    CommonTree KW_SHOW522_tree = null;
    CommonTree KW_CURRENT523_tree = null;
    CommonTree KW_ROLES524_tree = null;
    RewriteRuleTokenStream stream_KW_ROLES = new RewriteRuleTokenStream(adaptor, "token KW_ROLES");
    RewriteRuleTokenStream stream_KW_SHOW = new RewriteRuleTokenStream(adaptor, "token KW_SHOW");
    RewriteRuleTokenStream stream_KW_CURRENT = new RewriteRuleTokenStream(adaptor, "token KW_CURRENT");

    pushMsg("show current role", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1470:5: ( KW_SHOW KW_CURRENT KW_ROLES -> ^( TOK_SHOW_SET_ROLE ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1470:7: KW_SHOW KW_CURRENT KW_ROLES
      {
        KW_SHOW522 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showCurrentRole8035);
        stream_KW_SHOW.add(KW_SHOW522);

        KW_CURRENT523 = (Token) match(input, KW_CURRENT, FOLLOW_KW_CURRENT_in_showCurrentRole8037);
        stream_KW_CURRENT.add(KW_CURRENT523);

        KW_ROLES524 = (Token) match(input, KW_ROLES, FOLLOW_KW_ROLES_in_showCurrentRole8039);
        stream_KW_ROLES.add(KW_ROLES524);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1471:5: -> ^( TOK_SHOW_SET_ROLE )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1471:8: ^( TOK_SHOW_SET_ROLE )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_SHOW_SET_ROLE, "TOK_SHOW_SET_ROLE"), root_1);

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "showCurrentRole"

  public static class setRole_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "setRole"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1474:1: setRole : KW_SET KW_ROLE roleName= identifier -> ^( TOK_SHOW_SET_ROLE $roleName) ;
  public final HiveParser.setRole_return setRole() throws RecognitionException {
    HiveParser.setRole_return retval = new HiveParser.setRole_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_SET525 = null;
    Token KW_ROLE526 = null;
    HiveParser_IdentifiersParser.identifier_return roleName = null;

    CommonTree KW_SET525_tree = null;
    CommonTree KW_ROLE526_tree = null;
    RewriteRuleTokenStream stream_KW_ROLE = new RewriteRuleTokenStream(adaptor, "token KW_ROLE");
    RewriteRuleTokenStream stream_KW_SET = new RewriteRuleTokenStream(adaptor, "token KW_SET");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    pushMsg("set role", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1477:5: ( KW_SET KW_ROLE roleName= identifier -> ^( TOK_SHOW_SET_ROLE $roleName) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1477:7: KW_SET KW_ROLE roleName= identifier
      {
        KW_SET525 = (Token) match(input, KW_SET, FOLLOW_KW_SET_in_setRole8076);
        stream_KW_SET.add(KW_SET525);

        KW_ROLE526 = (Token) match(input, KW_ROLE, FOLLOW_KW_ROLE_in_setRole8078);
        stream_KW_ROLE.add(KW_ROLE526);

        pushFollow(FOLLOW_identifier_in_setRole8082);
        roleName = identifier();

        state._fsp--;

        stream_identifier.add(roleName.getTree());

        // AST REWRITE
        // elements: roleName
        // token labels:
        // rule labels: roleName, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_roleName =
            new RewriteRuleSubtreeStream(adaptor, "rule roleName", roleName != null ? roleName.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1478:5: -> ^( TOK_SHOW_SET_ROLE $roleName)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1478:8: ^( TOK_SHOW_SET_ROLE $roleName)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_SHOW_SET_ROLE, "TOK_SHOW_SET_ROLE"), root_1);

            adaptor.addChild(root_1, stream_roleName.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "setRole"

  public static class showGrants_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "showGrants"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1481:1: showGrants : KW_SHOW KW_GRANT ( principalName )? ( KW_ON privilegeIncludeColObject )? -> ^( TOK_SHOW_GRANT ( principalName )? ( privilegeIncludeColObject )? ) ;
  public final HiveParser.showGrants_return showGrants() throws RecognitionException {
    HiveParser.showGrants_return retval = new HiveParser.showGrants_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_SHOW527 = null;
    Token KW_GRANT528 = null;
    Token KW_ON530 = null;
    HiveParser.principalName_return principalName529 = null;

    HiveParser.privilegeIncludeColObject_return privilegeIncludeColObject531 = null;

    CommonTree KW_SHOW527_tree = null;
    CommonTree KW_GRANT528_tree = null;
    CommonTree KW_ON530_tree = null;
    RewriteRuleTokenStream stream_KW_GRANT = new RewriteRuleTokenStream(adaptor, "token KW_GRANT");
    RewriteRuleTokenStream stream_KW_SHOW = new RewriteRuleTokenStream(adaptor, "token KW_SHOW");
    RewriteRuleTokenStream stream_KW_ON = new RewriteRuleTokenStream(adaptor, "token KW_ON");
    RewriteRuleSubtreeStream stream_privilegeIncludeColObject =
        new RewriteRuleSubtreeStream(adaptor, "rule privilegeIncludeColObject");
    RewriteRuleSubtreeStream stream_principalName = new RewriteRuleSubtreeStream(adaptor, "rule principalName");
    pushMsg("show grants", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1484:5: ( KW_SHOW KW_GRANT ( principalName )? ( KW_ON privilegeIncludeColObject )? -> ^( TOK_SHOW_GRANT ( principalName )? ( privilegeIncludeColObject )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1484:7: KW_SHOW KW_GRANT ( principalName )? ( KW_ON privilegeIncludeColObject )?
      {
        KW_SHOW527 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showGrants8122);
        stream_KW_SHOW.add(KW_SHOW527);

        KW_GRANT528 = (Token) match(input, KW_GRANT, FOLLOW_KW_GRANT_in_showGrants8124);
        stream_KW_GRANT.add(KW_GRANT528);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1484:24: ( principalName )?
        int alt158 = 2;
        switch (input.LA(1)) {
          case KW_GROUP:
          case KW_ROLE:
          case KW_USER: {
            alt158 = 1;
          }
            break;
        }

        switch (alt158) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1484:24: principalName
          {
            pushFollow(FOLLOW_principalName_in_showGrants8126);
            principalName529 = principalName();

            state._fsp--;

            stream_principalName.add(principalName529.getTree());
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1484:39: ( KW_ON privilegeIncludeColObject )?
        int alt159 = 2;
        switch (input.LA(1)) {
          case KW_ON: {
            alt159 = 1;
          }
            break;
        }

        switch (alt159) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1484:40: KW_ON privilegeIncludeColObject
          {
            KW_ON530 = (Token) match(input, KW_ON, FOLLOW_KW_ON_in_showGrants8130);
            stream_KW_ON.add(KW_ON530);

            pushFollow(FOLLOW_privilegeIncludeColObject_in_showGrants8132);
            privilegeIncludeColObject531 = privilegeIncludeColObject();

            state._fsp--;

            stream_privilegeIncludeColObject.add(privilegeIncludeColObject531.getTree());
          }
            break;
        }

        // AST REWRITE
        // elements: principalName, privilegeIncludeColObject
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1485:5: -> ^( TOK_SHOW_GRANT ( principalName )? ( privilegeIncludeColObject )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1485:8: ^( TOK_SHOW_GRANT ( principalName )? ( privilegeIncludeColObject )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SHOW_GRANT, "TOK_SHOW_GRANT"), root_1);

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1485:25: ( principalName )?
            if (stream_principalName.hasNext()) {
              adaptor.addChild(root_1, stream_principalName.nextTree());
            }
            stream_principalName.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1485:40: ( privilegeIncludeColObject )?
            if (stream_privilegeIncludeColObject.hasNext()) {
              adaptor.addChild(root_1, stream_privilegeIncludeColObject.nextTree());
            }
            stream_privilegeIncludeColObject.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "showGrants"

  public static class showRolePrincipals_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "showRolePrincipals"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1488:1: showRolePrincipals : KW_SHOW KW_PRINCIPALS roleName= identifier -> ^( TOK_SHOW_ROLE_PRINCIPALS $roleName) ;
  public final HiveParser.showRolePrincipals_return showRolePrincipals() throws RecognitionException {
    HiveParser.showRolePrincipals_return retval = new HiveParser.showRolePrincipals_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_SHOW532 = null;
    Token KW_PRINCIPALS533 = null;
    HiveParser_IdentifiersParser.identifier_return roleName = null;

    CommonTree KW_SHOW532_tree = null;
    CommonTree KW_PRINCIPALS533_tree = null;
    RewriteRuleTokenStream stream_KW_PRINCIPALS = new RewriteRuleTokenStream(adaptor, "token KW_PRINCIPALS");
    RewriteRuleTokenStream stream_KW_SHOW = new RewriteRuleTokenStream(adaptor, "token KW_SHOW");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    pushMsg("show role principals", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1491:5: ( KW_SHOW KW_PRINCIPALS roleName= identifier -> ^( TOK_SHOW_ROLE_PRINCIPALS $roleName) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1491:7: KW_SHOW KW_PRINCIPALS roleName= identifier
      {
        KW_SHOW532 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showRolePrincipals8177);
        stream_KW_SHOW.add(KW_SHOW532);

        KW_PRINCIPALS533 = (Token) match(input, KW_PRINCIPALS, FOLLOW_KW_PRINCIPALS_in_showRolePrincipals8179);
        stream_KW_PRINCIPALS.add(KW_PRINCIPALS533);

        pushFollow(FOLLOW_identifier_in_showRolePrincipals8183);
        roleName = identifier();

        state._fsp--;

        stream_identifier.add(roleName.getTree());

        // AST REWRITE
        // elements: roleName
        // token labels:
        // rule labels: roleName, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_roleName =
            new RewriteRuleSubtreeStream(adaptor, "rule roleName", roleName != null ? roleName.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1492:5: -> ^( TOK_SHOW_ROLE_PRINCIPALS $roleName)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1492:8: ^( TOK_SHOW_ROLE_PRINCIPALS $roleName)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_SHOW_ROLE_PRINCIPALS, "TOK_SHOW_ROLE_PRINCIPALS"), root_1);

            adaptor.addChild(root_1, stream_roleName.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "showRolePrincipals"

  public static class privilegeIncludeColObject_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "privilegeIncludeColObject"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1496:1: privilegeIncludeColObject : ( KW_ALL -> ^( TOK_RESOURCE_ALL ) | privObjectCols -> ^( TOK_PRIV_OBJECT_COL privObjectCols ) );
  public final HiveParser.privilegeIncludeColObject_return privilegeIncludeColObject() throws RecognitionException {
    HiveParser.privilegeIncludeColObject_return retval = new HiveParser.privilegeIncludeColObject_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_ALL534 = null;
    HiveParser.privObjectCols_return privObjectCols535 = null;

    CommonTree KW_ALL534_tree = null;
    RewriteRuleTokenStream stream_KW_ALL = new RewriteRuleTokenStream(adaptor, "token KW_ALL");
    RewriteRuleSubtreeStream stream_privObjectCols = new RewriteRuleSubtreeStream(adaptor, "rule privObjectCols");
    pushMsg("privilege object including columns", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1499:5: ( KW_ALL -> ^( TOK_RESOURCE_ALL ) | privObjectCols -> ^( TOK_PRIV_OBJECT_COL privObjectCols ) )
      int alt160 = 2;
      switch (input.LA(1)) {
        case KW_ALL: {
          alt160 = 1;
        }
          break;
        case Identifier:
        case KW_ADD:
        case KW_ADMIN:
        case KW_AFTER:
        case KW_ALTER:
        case KW_ANALYZE:
        case KW_ARCHIVE:
        case KW_ARRAY:
        case KW_AS:
        case KW_ASC:
        case KW_AUTHORIZATION:
        case KW_BEFORE:
        case KW_BETWEEN:
        case KW_BIGINT:
        case KW_BINARY:
        case KW_BOOLEAN:
        case KW_BOTH:
        case KW_BUCKET:
        case KW_BUCKETS:
        case KW_BY:
        case KW_CASCADE:
        case KW_CHANGE:
        case KW_CLUSTER:
        case KW_CLUSTERED:
        case KW_CLUSTERSTATUS:
        case KW_COLLECTION:
        case KW_COLUMNS:
        case KW_COMMENT:
        case KW_COMPACT:
        case KW_COMPACTIONS:
        case KW_COMPUTE:
        case KW_CONCATENATE:
        case KW_CONTINUE:
        case KW_CREATE:
        case KW_CUBE:
        case KW_CURSOR:
        case KW_DATA:
        case KW_DATABASE:
        case KW_DATABASES:
        case KW_DATE:
        case KW_DATETIME:
        case KW_DBPROPERTIES:
        case KW_DECIMAL:
        case KW_DEFAULT:
        case KW_DEFERRED:
        case KW_DEFINED:
        case KW_DELETE:
        case KW_DELIMITED:
        case KW_DEPENDENCY:
        case KW_DESC:
        case KW_DESCRIBE:
        case KW_DIRECTORIES:
        case KW_DIRECTORY:
        case KW_DISABLE:
        case KW_DISTRIBUTE:
        case KW_DOUBLE:
        case KW_DROP:
        case KW_ELEM_TYPE:
        case KW_ENABLE:
        case KW_ESCAPED:
        case KW_EXCLUSIVE:
        case KW_EXISTS:
        case KW_EXPLAIN:
        case KW_EXPORT:
        case KW_EXTERNAL:
        case KW_FALSE:
        case KW_FETCH:
        case KW_FIELDS:
        case KW_FILE:
        case KW_FILEFORMAT:
        case KW_FIRST:
        case KW_FLOAT:
        case KW_FOR:
        case KW_FORMAT:
        case KW_FORMATTED:
        case KW_FULL:
        case KW_FUNCTIONS:
        case KW_GRANT:
        case KW_GROUP:
        case KW_GROUPING:
        case KW_HOLD_DDLTIME:
        case KW_IDXPROPERTIES:
        case KW_IGNORE:
        case KW_IMPORT:
        case KW_IN:
        case KW_INDEX:
        case KW_INDEXES:
        case KW_INNER:
        case KW_INPATH:
        case KW_INPUTDRIVER:
        case KW_INPUTFORMAT:
        case KW_INSERT:
        case KW_INT:
        case KW_INTERSECT:
        case KW_INTO:
        case KW_IS:
        case KW_ITEMS:
        case KW_JAR:
        case KW_KEYS:
        case KW_KEY_TYPE:
        case KW_LATERAL:
        case KW_LEFT:
        case KW_LIKE:
        case KW_LIMIT:
        case KW_LINES:
        case KW_LOAD:
        case KW_LOCAL:
        case KW_LOCATION:
        case KW_LOCK:
        case KW_LOCKS:
        case KW_LOGICAL:
        case KW_LONG:
        case KW_MAPJOIN:
        case KW_MATERIALIZED:
        case KW_METADATA:
        case KW_MINUS:
        case KW_MSCK:
        case KW_NONE:
        case KW_NOSCAN:
        case KW_NO_DROP:
        case KW_NULL:
        case KW_OF:
        case KW_OFFLINE:
        case KW_OPTION:
        case KW_ORDER:
        case KW_OUT:
        case KW_OUTER:
        case KW_OUTPUTDRIVER:
        case KW_OUTPUTFORMAT:
        case KW_OVERWRITE:
        case KW_OWNER:
        case KW_PARTITION:
        case KW_PARTITIONED:
        case KW_PARTITIONS:
        case KW_PERCENT:
        case KW_PLUS:
        case KW_PRETTY:
        case KW_PRINCIPALS:
        case KW_PROCEDURE:
        case KW_PROTECTION:
        case KW_PURGE:
        case KW_RANGE:
        case KW_READ:
        case KW_READONLY:
        case KW_READS:
        case KW_REBUILD:
        case KW_RECORDREADER:
        case KW_RECORDWRITER:
        case KW_REGEXP:
        case KW_RELOAD:
        case KW_RENAME:
        case KW_REPAIR:
        case KW_REPLACE:
        case KW_REPLICATION:
        case KW_RESTRICT:
        case KW_REVOKE:
        case KW_REWRITE:
        case KW_RIGHT:
        case KW_RLIKE:
        case KW_ROLE:
        case KW_ROLES:
        case KW_ROLLUP:
        case KW_ROW:
        case KW_ROWS:
        case KW_SCHEMA:
        case KW_SCHEMAS:
        case KW_SEMI:
        case KW_SERDE:
        case KW_SERDEPROPERTIES:
        case KW_SERVER:
        case KW_SET:
        case KW_SETS:
        case KW_SHARED:
        case KW_SHOW:
        case KW_SHOW_DATABASE:
        case KW_SKEWED:
        case KW_SMALLINT:
        case KW_SORT:
        case KW_SORTED:
        case KW_SSL:
        case KW_STATISTICS:
        case KW_STORED:
        case KW_STREAMTABLE:
        case KW_STRING:
        case KW_STRUCT:
        case KW_TABLE:
        case KW_TABLES:
        case KW_TBLPROPERTIES:
        case KW_TEMPORARY:
        case KW_TERMINATED:
        case KW_TIMESTAMP:
        case KW_TINYINT:
        case KW_TO:
        case KW_TOUCH:
        case KW_TRANSACTIONS:
        case KW_TRIGGER:
        case KW_TRUE:
        case KW_TRUNCATE:
        case KW_UNARCHIVE:
        case KW_UNDO:
        case KW_UNION:
        case KW_UNIONTYPE:
        case KW_UNLOCK:
        case KW_UNSET:
        case KW_UNSIGNED:
        case KW_UPDATE:
        case KW_URI:
        case KW_USE:
        case KW_USER:
        case KW_USING:
        case KW_UTC:
        case KW_UTCTIMESTAMP:
        case KW_VALUES:
        case KW_VALUE_TYPE:
        case KW_VIEW:
        case KW_WHILE:
        case KW_WITH: {
          alt160 = 2;
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 160, 0, input);

          throw nvae;
      }

      switch (alt160) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1499:7: KW_ALL
        {
          KW_ALL534 = (Token) match(input, KW_ALL, FOLLOW_KW_ALL_in_privilegeIncludeColObject8224);
          stream_KW_ALL.add(KW_ALL534);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1499:14: -> ^( TOK_RESOURCE_ALL )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1499:17: ^( TOK_RESOURCE_ALL )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor
                  .becomeRoot((CommonTree) adaptor.create(TOK_RESOURCE_ALL, "TOK_RESOURCE_ALL"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1500:7: privObjectCols
        {
          pushFollow(FOLLOW_privObjectCols_in_privilegeIncludeColObject8238);
          privObjectCols535 = privObjectCols();

          state._fsp--;

          stream_privObjectCols.add(privObjectCols535.getTree());

          // AST REWRITE
          // elements: privObjectCols
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1500:22: -> ^( TOK_PRIV_OBJECT_COL privObjectCols )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1500:25: ^( TOK_PRIV_OBJECT_COL privObjectCols )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor
                  .becomeRoot((CommonTree) adaptor.create(TOK_PRIV_OBJECT_COL, "TOK_PRIV_OBJECT_COL"), root_1);

              adaptor.addChild(root_1, stream_privObjectCols.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "privilegeIncludeColObject"

  public static class privilegeObject_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "privilegeObject"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1503:1: privilegeObject : KW_ON privObject -> ^( TOK_PRIV_OBJECT privObject ) ;
  public final HiveParser.privilegeObject_return privilegeObject() throws RecognitionException {
    HiveParser.privilegeObject_return retval = new HiveParser.privilegeObject_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_ON536 = null;
    HiveParser.privObject_return privObject537 = null;

    CommonTree KW_ON536_tree = null;
    RewriteRuleTokenStream stream_KW_ON = new RewriteRuleTokenStream(adaptor, "token KW_ON");
    RewriteRuleSubtreeStream stream_privObject = new RewriteRuleSubtreeStream(adaptor, "rule privObject");
    pushMsg("privilege object", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1506:5: ( KW_ON privObject -> ^( TOK_PRIV_OBJECT privObject ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1506:7: KW_ON privObject
      {
        KW_ON536 = (Token) match(input, KW_ON, FOLLOW_KW_ON_in_privilegeObject8273);
        stream_KW_ON.add(KW_ON536);

        pushFollow(FOLLOW_privObject_in_privilegeObject8275);
        privObject537 = privObject();

        state._fsp--;

        stream_privObject.add(privObject537.getTree());

        // AST REWRITE
        // elements: privObject
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1506:24: -> ^( TOK_PRIV_OBJECT privObject )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1506:27: ^( TOK_PRIV_OBJECT privObject )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_PRIV_OBJECT, "TOK_PRIV_OBJECT"),
                root_1);

            adaptor.addChild(root_1, stream_privObject.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "privilegeObject"

  public static class privObject_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "privObject"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1510:1: privObject : ( ( KW_DATABASE | KW_SCHEMA ) identifier -> ^( TOK_DB_TYPE identifier ) | ( KW_TABLE )? tableName ( partitionSpec )? -> ^( TOK_TABLE_TYPE tableName ( partitionSpec )? ) | KW_URI (path= StringLiteral ) -> ^( TOK_URI_TYPE $path) | KW_SERVER identifier -> ^( TOK_SERVER_TYPE identifier ) );
  public final HiveParser.privObject_return privObject() throws RecognitionException {
    HiveParser.privObject_return retval = new HiveParser.privObject_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token path = null;
    Token KW_DATABASE538 = null;
    Token KW_SCHEMA539 = null;
    Token KW_TABLE541 = null;
    Token KW_URI544 = null;
    Token KW_SERVER545 = null;
    HiveParser_IdentifiersParser.identifier_return identifier540 = null;

    HiveParser_FromClauseParser.tableName_return tableName542 = null;

    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec543 = null;

    HiveParser_IdentifiersParser.identifier_return identifier546 = null;

    CommonTree path_tree = null;
    CommonTree KW_DATABASE538_tree = null;
    CommonTree KW_SCHEMA539_tree = null;
    CommonTree KW_TABLE541_tree = null;
    CommonTree KW_URI544_tree = null;
    CommonTree KW_SERVER545_tree = null;
    RewriteRuleTokenStream stream_KW_SERVER = new RewriteRuleTokenStream(adaptor, "token KW_SERVER");
    RewriteRuleTokenStream stream_KW_SCHEMA = new RewriteRuleTokenStream(adaptor, "token KW_SCHEMA");
    RewriteRuleTokenStream stream_KW_DATABASE = new RewriteRuleTokenStream(adaptor, "token KW_DATABASE");
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_URI = new RewriteRuleTokenStream(adaptor, "token KW_URI");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_partitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule partitionSpec");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1511:5: ( ( KW_DATABASE | KW_SCHEMA ) identifier -> ^( TOK_DB_TYPE identifier ) | ( KW_TABLE )? tableName ( partitionSpec )? -> ^( TOK_TABLE_TYPE tableName ( partitionSpec )? ) | KW_URI (path= StringLiteral ) -> ^( TOK_URI_TYPE $path) | KW_SERVER identifier -> ^( TOK_SERVER_TYPE identifier ) )
      int alt164 = 4;
      switch (input.LA(1)) {
        case KW_DATABASE: {
          alt164 = 1;
        }
          break;
        case KW_SCHEMA: {
          switch (input.LA(2)) {
            case Identifier:
            case KW_ADD:
            case KW_ADMIN:
            case KW_AFTER:
            case KW_ALL:
            case KW_ALTER:
            case KW_ANALYZE:
            case KW_ARCHIVE:
            case KW_ARRAY:
            case KW_AS:
            case KW_ASC:
            case KW_AUTHORIZATION:
            case KW_BEFORE:
            case KW_BETWEEN:
            case KW_BIGINT:
            case KW_BINARY:
            case KW_BOOLEAN:
            case KW_BOTH:
            case KW_BUCKET:
            case KW_BUCKETS:
            case KW_BY:
            case KW_CASCADE:
            case KW_CHANGE:
            case KW_CLUSTER:
            case KW_CLUSTERED:
            case KW_CLUSTERSTATUS:
            case KW_COLLECTION:
            case KW_COLUMNS:
            case KW_COMMENT:
            case KW_COMPACT:
            case KW_COMPACTIONS:
            case KW_COMPUTE:
            case KW_CONCATENATE:
            case KW_CONTINUE:
            case KW_CREATE:
            case KW_CUBE:
            case KW_CURSOR:
            case KW_DATA:
            case KW_DATABASES:
            case KW_DATE:
            case KW_DATETIME:
            case KW_DBPROPERTIES:
            case KW_DECIMAL:
            case KW_DEFAULT:
            case KW_DEFERRED:
            case KW_DEFINED:
            case KW_DELETE:
            case KW_DELIMITED:
            case KW_DEPENDENCY:
            case KW_DESC:
            case KW_DESCRIBE:
            case KW_DIRECTORIES:
            case KW_DIRECTORY:
            case KW_DISABLE:
            case KW_DISTRIBUTE:
            case KW_DOUBLE:
            case KW_DROP:
            case KW_ELEM_TYPE:
            case KW_ENABLE:
            case KW_ESCAPED:
            case KW_EXCLUSIVE:
            case KW_EXISTS:
            case KW_EXPLAIN:
            case KW_EXPORT:
            case KW_EXTERNAL:
            case KW_FALSE:
            case KW_FETCH:
            case KW_FIELDS:
            case KW_FILE:
            case KW_FILEFORMAT:
            case KW_FIRST:
            case KW_FLOAT:
            case KW_FOR:
            case KW_FORMAT:
            case KW_FORMATTED:
            case KW_FULL:
            case KW_FUNCTIONS:
            case KW_GRANT:
            case KW_GROUP:
            case KW_GROUPING:
            case KW_HOLD_DDLTIME:
            case KW_IDXPROPERTIES:
            case KW_IGNORE:
            case KW_IMPORT:
            case KW_IN:
            case KW_INDEX:
            case KW_INDEXES:
            case KW_INNER:
            case KW_INPATH:
            case KW_INPUTDRIVER:
            case KW_INPUTFORMAT:
            case KW_INSERT:
            case KW_INT:
            case KW_INTERSECT:
            case KW_INTO:
            case KW_IS:
            case KW_ITEMS:
            case KW_JAR:
            case KW_KEYS:
            case KW_KEY_TYPE:
            case KW_LATERAL:
            case KW_LEFT:
            case KW_LIKE:
            case KW_LIMIT:
            case KW_LINES:
            case KW_LOAD:
            case KW_LOCAL:
            case KW_LOCATION:
            case KW_LOCK:
            case KW_LOCKS:
            case KW_LOGICAL:
            case KW_LONG:
            case KW_MAPJOIN:
            case KW_MATERIALIZED:
            case KW_METADATA:
            case KW_MINUS:
            case KW_MSCK:
            case KW_NONE:
            case KW_NOSCAN:
            case KW_NO_DROP:
            case KW_NULL:
            case KW_OF:
            case KW_OFFLINE:
            case KW_OPTION:
            case KW_ORDER:
            case KW_OUT:
            case KW_OUTER:
            case KW_OUTPUTDRIVER:
            case KW_OUTPUTFORMAT:
            case KW_OVERWRITE:
            case KW_OWNER:
            case KW_PARTITIONED:
            case KW_PARTITIONS:
            case KW_PERCENT:
            case KW_PLUS:
            case KW_PRETTY:
            case KW_PRINCIPALS:
            case KW_PROCEDURE:
            case KW_PROTECTION:
            case KW_PURGE:
            case KW_RANGE:
            case KW_READ:
            case KW_READONLY:
            case KW_READS:
            case KW_REBUILD:
            case KW_RECORDREADER:
            case KW_RECORDWRITER:
            case KW_REGEXP:
            case KW_RELOAD:
            case KW_RENAME:
            case KW_REPAIR:
            case KW_REPLACE:
            case KW_REPLICATION:
            case KW_RESTRICT:
            case KW_REVOKE:
            case KW_REWRITE:
            case KW_RIGHT:
            case KW_RLIKE:
            case KW_ROLE:
            case KW_ROLES:
            case KW_ROLLUP:
            case KW_ROW:
            case KW_ROWS:
            case KW_SCHEMA:
            case KW_SCHEMAS:
            case KW_SEMI:
            case KW_SERDE:
            case KW_SERDEPROPERTIES:
            case KW_SERVER:
            case KW_SET:
            case KW_SETS:
            case KW_SHARED:
            case KW_SHOW:
            case KW_SHOW_DATABASE:
            case KW_SKEWED:
            case KW_SMALLINT:
            case KW_SORT:
            case KW_SORTED:
            case KW_SSL:
            case KW_STATISTICS:
            case KW_STORED:
            case KW_STREAMTABLE:
            case KW_STRING:
            case KW_STRUCT:
            case KW_TABLE:
            case KW_TABLES:
            case KW_TBLPROPERTIES:
            case KW_TEMPORARY:
            case KW_TERMINATED:
            case KW_TIMESTAMP:
            case KW_TINYINT:
            case KW_TOUCH:
            case KW_TRANSACTIONS:
            case KW_TRIGGER:
            case KW_TRUE:
            case KW_TRUNCATE:
            case KW_UNARCHIVE:
            case KW_UNDO:
            case KW_UNION:
            case KW_UNIONTYPE:
            case KW_UNLOCK:
            case KW_UNSET:
            case KW_UNSIGNED:
            case KW_UPDATE:
            case KW_URI:
            case KW_USE:
            case KW_USER:
            case KW_USING:
            case KW_UTC:
            case KW_UTCTIMESTAMP:
            case KW_VALUES:
            case KW_VALUE_TYPE:
            case KW_VIEW:
            case KW_WHILE:
            case KW_WITH: {
              alt164 = 1;
            }
              break;
            case KW_PARTITION: {
              switch (input.LA(3)) {
                case LPAREN: {
                  alt164 = 2;
                }
                  break;
                case KW_FROM:
                case KW_TO: {
                  alt164 = 1;
                }
                  break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 164, 9, input);

                  throw nvae;
              }
            }
              break;
            case DOT:
            case KW_FROM: {
              alt164 = 2;
            }
              break;
            case KW_TO: {
              switch (input.LA(3)) {
                case KW_FROM:
                case KW_TO: {
                  alt164 = 1;
                }
                  break;
                case KW_GROUP:
                case KW_ROLE:
                case KW_USER: {
                  alt164 = 2;
                }
                  break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 164, 11, input);

                  throw nvae;
              }
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 164, 2, input);

              throw nvae;
          }
        }
          break;
        case Identifier:
        case KW_ADD:
        case KW_ADMIN:
        case KW_AFTER:
        case KW_ALL:
        case KW_ALTER:
        case KW_ANALYZE:
        case KW_ARCHIVE:
        case KW_ARRAY:
        case KW_AS:
        case KW_ASC:
        case KW_AUTHORIZATION:
        case KW_BEFORE:
        case KW_BETWEEN:
        case KW_BIGINT:
        case KW_BINARY:
        case KW_BOOLEAN:
        case KW_BOTH:
        case KW_BUCKET:
        case KW_BUCKETS:
        case KW_BY:
        case KW_CASCADE:
        case KW_CHANGE:
        case KW_CLUSTER:
        case KW_CLUSTERED:
        case KW_CLUSTERSTATUS:
        case KW_COLLECTION:
        case KW_COLUMNS:
        case KW_COMMENT:
        case KW_COMPACT:
        case KW_COMPACTIONS:
        case KW_COMPUTE:
        case KW_CONCATENATE:
        case KW_CONTINUE:
        case KW_CREATE:
        case KW_CUBE:
        case KW_CURSOR:
        case KW_DATA:
        case KW_DATABASES:
        case KW_DATE:
        case KW_DATETIME:
        case KW_DBPROPERTIES:
        case KW_DECIMAL:
        case KW_DEFAULT:
        case KW_DEFERRED:
        case KW_DEFINED:
        case KW_DELETE:
        case KW_DELIMITED:
        case KW_DEPENDENCY:
        case KW_DESC:
        case KW_DESCRIBE:
        case KW_DIRECTORIES:
        case KW_DIRECTORY:
        case KW_DISABLE:
        case KW_DISTRIBUTE:
        case KW_DOUBLE:
        case KW_DROP:
        case KW_ELEM_TYPE:
        case KW_ENABLE:
        case KW_ESCAPED:
        case KW_EXCLUSIVE:
        case KW_EXISTS:
        case KW_EXPLAIN:
        case KW_EXPORT:
        case KW_EXTERNAL:
        case KW_FALSE:
        case KW_FETCH:
        case KW_FIELDS:
        case KW_FILE:
        case KW_FILEFORMAT:
        case KW_FIRST:
        case KW_FLOAT:
        case KW_FOR:
        case KW_FORMAT:
        case KW_FORMATTED:
        case KW_FULL:
        case KW_FUNCTIONS:
        case KW_GRANT:
        case KW_GROUP:
        case KW_GROUPING:
        case KW_HOLD_DDLTIME:
        case KW_IDXPROPERTIES:
        case KW_IGNORE:
        case KW_IMPORT:
        case KW_IN:
        case KW_INDEX:
        case KW_INDEXES:
        case KW_INNER:
        case KW_INPATH:
        case KW_INPUTDRIVER:
        case KW_INPUTFORMAT:
        case KW_INSERT:
        case KW_INT:
        case KW_INTERSECT:
        case KW_INTO:
        case KW_IS:
        case KW_ITEMS:
        case KW_JAR:
        case KW_KEYS:
        case KW_KEY_TYPE:
        case KW_LATERAL:
        case KW_LEFT:
        case KW_LIKE:
        case KW_LIMIT:
        case KW_LINES:
        case KW_LOAD:
        case KW_LOCAL:
        case KW_LOCATION:
        case KW_LOCK:
        case KW_LOCKS:
        case KW_LOGICAL:
        case KW_LONG:
        case KW_MAPJOIN:
        case KW_MATERIALIZED:
        case KW_METADATA:
        case KW_MINUS:
        case KW_MSCK:
        case KW_NONE:
        case KW_NOSCAN:
        case KW_NO_DROP:
        case KW_NULL:
        case KW_OF:
        case KW_OFFLINE:
        case KW_OPTION:
        case KW_ORDER:
        case KW_OUT:
        case KW_OUTER:
        case KW_OUTPUTDRIVER:
        case KW_OUTPUTFORMAT:
        case KW_OVERWRITE:
        case KW_OWNER:
        case KW_PARTITION:
        case KW_PARTITIONED:
        case KW_PARTITIONS:
        case KW_PERCENT:
        case KW_PLUS:
        case KW_PRETTY:
        case KW_PRINCIPALS:
        case KW_PROCEDURE:
        case KW_PROTECTION:
        case KW_PURGE:
        case KW_RANGE:
        case KW_READ:
        case KW_READONLY:
        case KW_READS:
        case KW_REBUILD:
        case KW_RECORDREADER:
        case KW_RECORDWRITER:
        case KW_REGEXP:
        case KW_RELOAD:
        case KW_RENAME:
        case KW_REPAIR:
        case KW_REPLACE:
        case KW_REPLICATION:
        case KW_RESTRICT:
        case KW_REVOKE:
        case KW_REWRITE:
        case KW_RIGHT:
        case KW_RLIKE:
        case KW_ROLE:
        case KW_ROLES:
        case KW_ROLLUP:
        case KW_ROW:
        case KW_ROWS:
        case KW_SCHEMAS:
        case KW_SEMI:
        case KW_SERDE:
        case KW_SERDEPROPERTIES:
        case KW_SET:
        case KW_SETS:
        case KW_SHARED:
        case KW_SHOW:
        case KW_SHOW_DATABASE:
        case KW_SKEWED:
        case KW_SMALLINT:
        case KW_SORT:
        case KW_SORTED:
        case KW_SSL:
        case KW_STATISTICS:
        case KW_STORED:
        case KW_STREAMTABLE:
        case KW_STRING:
        case KW_STRUCT:
        case KW_TABLE:
        case KW_TABLES:
        case KW_TBLPROPERTIES:
        case KW_TEMPORARY:
        case KW_TERMINATED:
        case KW_TIMESTAMP:
        case KW_TINYINT:
        case KW_TO:
        case KW_TOUCH:
        case KW_TRANSACTIONS:
        case KW_TRIGGER:
        case KW_TRUE:
        case KW_TRUNCATE:
        case KW_UNARCHIVE:
        case KW_UNDO:
        case KW_UNION:
        case KW_UNIONTYPE:
        case KW_UNLOCK:
        case KW_UNSET:
        case KW_UNSIGNED:
        case KW_UPDATE:
        case KW_USE:
        case KW_USER:
        case KW_USING:
        case KW_UTC:
        case KW_UTCTIMESTAMP:
        case KW_VALUES:
        case KW_VALUE_TYPE:
        case KW_VIEW:
        case KW_WHILE:
        case KW_WITH: {
          alt164 = 2;
        }
          break;
        case KW_URI: {
          switch (input.LA(2)) {
            case DOT:
            case KW_FROM:
            case KW_PARTITION:
            case KW_TO: {
              alt164 = 2;
            }
              break;
            case StringLiteral: {
              alt164 = 3;
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 164, 5, input);

              throw nvae;
          }
        }
          break;
        case KW_SERVER: {
          switch (input.LA(2)) {
            case DOT:
            case KW_FROM: {
              alt164 = 2;
            }
              break;
            case KW_PARTITION: {
              switch (input.LA(3)) {
                case LPAREN: {
                  alt164 = 2;
                }
                  break;
                case KW_FROM:
                case KW_TO: {
                  alt164 = 4;
                }
                  break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 164, 20, input);

                  throw nvae;
              }
            }
              break;
            case KW_TO: {
              switch (input.LA(3)) {
                case KW_GROUP:
                case KW_ROLE:
                case KW_USER: {
                  alt164 = 2;
                }
                  break;
                case KW_FROM:
                case KW_TO: {
                  alt164 = 4;
                }
                  break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 164, 21, input);

                  throw nvae;
              }
            }
              break;
            case Identifier:
            case KW_ADD:
            case KW_ADMIN:
            case KW_AFTER:
            case KW_ALL:
            case KW_ALTER:
            case KW_ANALYZE:
            case KW_ARCHIVE:
            case KW_ARRAY:
            case KW_AS:
            case KW_ASC:
            case KW_AUTHORIZATION:
            case KW_BEFORE:
            case KW_BETWEEN:
            case KW_BIGINT:
            case KW_BINARY:
            case KW_BOOLEAN:
            case KW_BOTH:
            case KW_BUCKET:
            case KW_BUCKETS:
            case KW_BY:
            case KW_CASCADE:
            case KW_CHANGE:
            case KW_CLUSTER:
            case KW_CLUSTERED:
            case KW_CLUSTERSTATUS:
            case KW_COLLECTION:
            case KW_COLUMNS:
            case KW_COMMENT:
            case KW_COMPACT:
            case KW_COMPACTIONS:
            case KW_COMPUTE:
            case KW_CONCATENATE:
            case KW_CONTINUE:
            case KW_CREATE:
            case KW_CUBE:
            case KW_CURSOR:
            case KW_DATA:
            case KW_DATABASES:
            case KW_DATE:
            case KW_DATETIME:
            case KW_DBPROPERTIES:
            case KW_DECIMAL:
            case KW_DEFAULT:
            case KW_DEFERRED:
            case KW_DEFINED:
            case KW_DELETE:
            case KW_DELIMITED:
            case KW_DEPENDENCY:
            case KW_DESC:
            case KW_DESCRIBE:
            case KW_DIRECTORIES:
            case KW_DIRECTORY:
            case KW_DISABLE:
            case KW_DISTRIBUTE:
            case KW_DOUBLE:
            case KW_DROP:
            case KW_ELEM_TYPE:
            case KW_ENABLE:
            case KW_ESCAPED:
            case KW_EXCLUSIVE:
            case KW_EXISTS:
            case KW_EXPLAIN:
            case KW_EXPORT:
            case KW_EXTERNAL:
            case KW_FALSE:
            case KW_FETCH:
            case KW_FIELDS:
            case KW_FILE:
            case KW_FILEFORMAT:
            case KW_FIRST:
            case KW_FLOAT:
            case KW_FOR:
            case KW_FORMAT:
            case KW_FORMATTED:
            case KW_FULL:
            case KW_FUNCTIONS:
            case KW_GRANT:
            case KW_GROUP:
            case KW_GROUPING:
            case KW_HOLD_DDLTIME:
            case KW_IDXPROPERTIES:
            case KW_IGNORE:
            case KW_IMPORT:
            case KW_IN:
            case KW_INDEX:
            case KW_INDEXES:
            case KW_INNER:
            case KW_INPATH:
            case KW_INPUTDRIVER:
            case KW_INPUTFORMAT:
            case KW_INSERT:
            case KW_INT:
            case KW_INTERSECT:
            case KW_INTO:
            case KW_IS:
            case KW_ITEMS:
            case KW_JAR:
            case KW_KEYS:
            case KW_KEY_TYPE:
            case KW_LATERAL:
            case KW_LEFT:
            case KW_LIKE:
            case KW_LIMIT:
            case KW_LINES:
            case KW_LOAD:
            case KW_LOCAL:
            case KW_LOCATION:
            case KW_LOCK:
            case KW_LOCKS:
            case KW_LOGICAL:
            case KW_LONG:
            case KW_MAPJOIN:
            case KW_MATERIALIZED:
            case KW_METADATA:
            case KW_MINUS:
            case KW_MSCK:
            case KW_NONE:
            case KW_NOSCAN:
            case KW_NO_DROP:
            case KW_NULL:
            case KW_OF:
            case KW_OFFLINE:
            case KW_OPTION:
            case KW_ORDER:
            case KW_OUT:
            case KW_OUTER:
            case KW_OUTPUTDRIVER:
            case KW_OUTPUTFORMAT:
            case KW_OVERWRITE:
            case KW_OWNER:
            case KW_PARTITIONED:
            case KW_PARTITIONS:
            case KW_PERCENT:
            case KW_PLUS:
            case KW_PRETTY:
            case KW_PRINCIPALS:
            case KW_PROCEDURE:
            case KW_PROTECTION:
            case KW_PURGE:
            case KW_RANGE:
            case KW_READ:
            case KW_READONLY:
            case KW_READS:
            case KW_REBUILD:
            case KW_RECORDREADER:
            case KW_RECORDWRITER:
            case KW_REGEXP:
            case KW_RELOAD:
            case KW_RENAME:
            case KW_REPAIR:
            case KW_REPLACE:
            case KW_REPLICATION:
            case KW_RESTRICT:
            case KW_REVOKE:
            case KW_REWRITE:
            case KW_RIGHT:
            case KW_RLIKE:
            case KW_ROLE:
            case KW_ROLES:
            case KW_ROLLUP:
            case KW_ROW:
            case KW_ROWS:
            case KW_SCHEMA:
            case KW_SCHEMAS:
            case KW_SEMI:
            case KW_SERDE:
            case KW_SERDEPROPERTIES:
            case KW_SERVER:
            case KW_SET:
            case KW_SETS:
            case KW_SHARED:
            case KW_SHOW:
            case KW_SHOW_DATABASE:
            case KW_SKEWED:
            case KW_SMALLINT:
            case KW_SORT:
            case KW_SORTED:
            case KW_SSL:
            case KW_STATISTICS:
            case KW_STORED:
            case KW_STREAMTABLE:
            case KW_STRING:
            case KW_STRUCT:
            case KW_TABLE:
            case KW_TABLES:
            case KW_TBLPROPERTIES:
            case KW_TEMPORARY:
            case KW_TERMINATED:
            case KW_TIMESTAMP:
            case KW_TINYINT:
            case KW_TOUCH:
            case KW_TRANSACTIONS:
            case KW_TRIGGER:
            case KW_TRUE:
            case KW_TRUNCATE:
            case KW_UNARCHIVE:
            case KW_UNDO:
            case KW_UNION:
            case KW_UNIONTYPE:
            case KW_UNLOCK:
            case KW_UNSET:
            case KW_UNSIGNED:
            case KW_UPDATE:
            case KW_URI:
            case KW_USE:
            case KW_USER:
            case KW_USING:
            case KW_UTC:
            case KW_UTCTIMESTAMP:
            case KW_VALUES:
            case KW_VALUE_TYPE:
            case KW_VIEW:
            case KW_WHILE:
            case KW_WITH: {
              alt164 = 4;
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 164, 6, input);

              throw nvae;
          }
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 164, 0, input);

          throw nvae;
      }

      switch (alt164) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1511:7: ( KW_DATABASE | KW_SCHEMA ) identifier
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1511:7: ( KW_DATABASE | KW_SCHEMA )
          int alt161 = 2;
          switch (input.LA(1)) {
            case KW_DATABASE: {
              alt161 = 1;
            }
              break;
            case KW_SCHEMA: {
              alt161 = 2;
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 161, 0, input);

              throw nvae;
          }

          switch (alt161) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1511:8: KW_DATABASE
            {
              KW_DATABASE538 = (Token) match(input, KW_DATABASE, FOLLOW_KW_DATABASE_in_privObject8302);
              stream_KW_DATABASE.add(KW_DATABASE538);
            }
              break;
            case 2:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1511:20: KW_SCHEMA
            {
              KW_SCHEMA539 = (Token) match(input, KW_SCHEMA, FOLLOW_KW_SCHEMA_in_privObject8304);
              stream_KW_SCHEMA.add(KW_SCHEMA539);
            }
              break;
          }

          pushFollow(FOLLOW_identifier_in_privObject8307);
          identifier540 = identifier();

          state._fsp--;

          stream_identifier.add(identifier540.getTree());

          // AST REWRITE
          // elements: identifier
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1511:42: -> ^( TOK_DB_TYPE identifier )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1511:45: ^( TOK_DB_TYPE identifier )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DB_TYPE, "TOK_DB_TYPE"), root_1);

              adaptor.addChild(root_1, stream_identifier.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1512:7: ( KW_TABLE )? tableName ( partitionSpec )?
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1512:7: ( KW_TABLE )?
          int alt162 = 2;
          switch (input.LA(1)) {
            case KW_TABLE: {
              switch (input.LA(2)) {
                case Identifier:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFAULT:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_METADATA:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NONE:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TOUCH:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH: {
                  alt162 = 1;
                }
                  break;
                case KW_PARTITION: {
                  switch (input.LA(3)) {
                    case DOT:
                    case KW_FROM:
                    case KW_PARTITION:
                    case KW_TO: {
                      alt162 = 1;
                    }
                      break;
                  }
                }
                  break;
                case KW_TO: {
                  switch (input.LA(3)) {
                    case DOT:
                    case KW_FROM:
                    case KW_PARTITION:
                    case KW_TO: {
                      alt162 = 1;
                    }
                      break;
                  }
                }
                  break;
              }
            }
              break;
          }

          switch (alt162) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1512:7: KW_TABLE
            {
              KW_TABLE541 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_privObject8323);
              stream_KW_TABLE.add(KW_TABLE541);
            }
              break;
          }

          pushFollow(FOLLOW_tableName_in_privObject8326);
          tableName542 = tableName();

          state._fsp--;

          stream_tableName.add(tableName542.getTree());

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1512:27: ( partitionSpec )?
          int alt163 = 2;
          switch (input.LA(1)) {
            case KW_PARTITION: {
              alt163 = 1;
            }
              break;
          }

          switch (alt163) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1512:27: partitionSpec
            {
              pushFollow(FOLLOW_partitionSpec_in_privObject8328);
              partitionSpec543 = partitionSpec();

              state._fsp--;

              stream_partitionSpec.add(partitionSpec543.getTree());
            }
              break;
          }

          // AST REWRITE
          // elements: partitionSpec, tableName
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1512:42: -> ^( TOK_TABLE_TYPE tableName ( partitionSpec )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1512:45: ^( TOK_TABLE_TYPE tableName ( partitionSpec )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABLE_TYPE, "TOK_TABLE_TYPE"),
                  root_1);

              adaptor.addChild(root_1, stream_tableName.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1512:72: ( partitionSpec )?
              if (stream_partitionSpec.hasNext()) {
                adaptor.addChild(root_1, stream_partitionSpec.nextTree());
              }
              stream_partitionSpec.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 3:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1513:7: KW_URI (path= StringLiteral )
        {
          KW_URI544 = (Token) match(input, KW_URI, FOLLOW_KW_URI_in_privObject8348);
          stream_KW_URI.add(KW_URI544);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1513:14: (path= StringLiteral )
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1513:15: path= StringLiteral
          {
            path = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_privObject8353);
            stream_StringLiteral.add(path);
          }

          // AST REWRITE
          // elements: path
          // token labels: path
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleTokenStream stream_path = new RewriteRuleTokenStream(adaptor, "token path", path);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1513:35: -> ^( TOK_URI_TYPE $path)
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1513:39: ^( TOK_URI_TYPE $path)
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_URI_TYPE, "TOK_URI_TYPE"), root_1);

              adaptor.addChild(root_1, stream_path.nextNode());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 4:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1514:7: KW_SERVER identifier
        {
          KW_SERVER545 = (Token) match(input, KW_SERVER, FOLLOW_KW_SERVER_in_privObject8372);
          stream_KW_SERVER.add(KW_SERVER545);

          pushFollow(FOLLOW_identifier_in_privObject8374);
          identifier546 = identifier();

          state._fsp--;

          stream_identifier.add(identifier546.getTree());

          // AST REWRITE
          // elements: identifier
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1514:28: -> ^( TOK_SERVER_TYPE identifier )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1514:31: ^( TOK_SERVER_TYPE identifier )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SERVER_TYPE, "TOK_SERVER_TYPE"),
                  root_1);

              adaptor.addChild(root_1, stream_identifier.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "privObject"

  public static class privObjectCols_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "privObjectCols"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1517:1: privObjectCols : ( ( KW_DATABASE | KW_SCHEMA ) identifier -> ^( TOK_DB_TYPE identifier ) | ( KW_TABLE )? tableName ( LPAREN cols= columnNameList RPAREN )? ( partitionSpec )? -> ^( TOK_TABLE_TYPE tableName ( $cols)? ( partitionSpec )? ) | KW_URI (path= StringLiteral ) -> ^( TOK_URI_TYPE $path) | KW_SERVER identifier -> ^( TOK_SERVER_TYPE identifier ) );
  public final HiveParser.privObjectCols_return privObjectCols() throws RecognitionException {
    HiveParser.privObjectCols_return retval = new HiveParser.privObjectCols_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token path = null;
    Token KW_DATABASE547 = null;
    Token KW_SCHEMA548 = null;
    Token KW_TABLE550 = null;
    Token LPAREN552 = null;
    Token RPAREN553 = null;
    Token KW_URI555 = null;
    Token KW_SERVER556 = null;
    HiveParser.columnNameList_return cols = null;

    HiveParser_IdentifiersParser.identifier_return identifier549 = null;

    HiveParser_FromClauseParser.tableName_return tableName551 = null;

    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec554 = null;

    HiveParser_IdentifiersParser.identifier_return identifier557 = null;

    CommonTree path_tree = null;
    CommonTree KW_DATABASE547_tree = null;
    CommonTree KW_SCHEMA548_tree = null;
    CommonTree KW_TABLE550_tree = null;
    CommonTree LPAREN552_tree = null;
    CommonTree RPAREN553_tree = null;
    CommonTree KW_URI555_tree = null;
    CommonTree KW_SERVER556_tree = null;
    RewriteRuleTokenStream stream_KW_SERVER = new RewriteRuleTokenStream(adaptor, "token KW_SERVER");
    RewriteRuleTokenStream stream_KW_SCHEMA = new RewriteRuleTokenStream(adaptor, "token KW_SCHEMA");
    RewriteRuleTokenStream stream_KW_DATABASE = new RewriteRuleTokenStream(adaptor, "token KW_DATABASE");
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_KW_URI = new RewriteRuleTokenStream(adaptor, "token KW_URI");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_columnNameList = new RewriteRuleSubtreeStream(adaptor, "rule columnNameList");
    RewriteRuleSubtreeStream stream_partitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule partitionSpec");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1518:5: ( ( KW_DATABASE | KW_SCHEMA ) identifier -> ^( TOK_DB_TYPE identifier ) | ( KW_TABLE )? tableName ( LPAREN cols= columnNameList RPAREN )? ( partitionSpec )? -> ^( TOK_TABLE_TYPE tableName ( $cols)? ( partitionSpec )? ) | KW_URI (path= StringLiteral ) -> ^( TOK_URI_TYPE $path) | KW_SERVER identifier -> ^( TOK_SERVER_TYPE identifier ) )
      int alt169 = 4;
      switch (input.LA(1)) {
        case KW_DATABASE: {
          alt169 = 1;
        }
          break;
        case KW_SCHEMA: {
          switch (input.LA(2)) {
            case Identifier:
            case KW_ADD:
            case KW_ADMIN:
            case KW_AFTER:
            case KW_ALL:
            case KW_ALTER:
            case KW_ANALYZE:
            case KW_ARCHIVE:
            case KW_ARRAY:
            case KW_AS:
            case KW_ASC:
            case KW_AUTHORIZATION:
            case KW_BEFORE:
            case KW_BETWEEN:
            case KW_BIGINT:
            case KW_BINARY:
            case KW_BOOLEAN:
            case KW_BOTH:
            case KW_BUCKET:
            case KW_BUCKETS:
            case KW_BY:
            case KW_CASCADE:
            case KW_CHANGE:
            case KW_CLUSTER:
            case KW_CLUSTERED:
            case KW_CLUSTERSTATUS:
            case KW_COLLECTION:
            case KW_COLUMNS:
            case KW_COMMENT:
            case KW_COMPACT:
            case KW_COMPACTIONS:
            case KW_COMPUTE:
            case KW_CONCATENATE:
            case KW_CONTINUE:
            case KW_CREATE:
            case KW_CUBE:
            case KW_CURSOR:
            case KW_DATA:
            case KW_DATABASES:
            case KW_DATE:
            case KW_DATETIME:
            case KW_DBPROPERTIES:
            case KW_DECIMAL:
            case KW_DEFAULT:
            case KW_DEFERRED:
            case KW_DEFINED:
            case KW_DELETE:
            case KW_DELIMITED:
            case KW_DEPENDENCY:
            case KW_DESC:
            case KW_DESCRIBE:
            case KW_DIRECTORIES:
            case KW_DIRECTORY:
            case KW_DISABLE:
            case KW_DISTRIBUTE:
            case KW_DOUBLE:
            case KW_DROP:
            case KW_ELEM_TYPE:
            case KW_ENABLE:
            case KW_ESCAPED:
            case KW_EXCLUSIVE:
            case KW_EXISTS:
            case KW_EXPLAIN:
            case KW_EXPORT:
            case KW_EXTERNAL:
            case KW_FALSE:
            case KW_FETCH:
            case KW_FIELDS:
            case KW_FILE:
            case KW_FILEFORMAT:
            case KW_FIRST:
            case KW_FLOAT:
            case KW_FOR:
            case KW_FORMAT:
            case KW_FORMATTED:
            case KW_FULL:
            case KW_FUNCTIONS:
            case KW_GRANT:
            case KW_GROUP:
            case KW_GROUPING:
            case KW_HOLD_DDLTIME:
            case KW_IDXPROPERTIES:
            case KW_IGNORE:
            case KW_IMPORT:
            case KW_IN:
            case KW_INDEX:
            case KW_INDEXES:
            case KW_INNER:
            case KW_INPATH:
            case KW_INPUTDRIVER:
            case KW_INPUTFORMAT:
            case KW_INSERT:
            case KW_INT:
            case KW_INTERSECT:
            case KW_INTO:
            case KW_IS:
            case KW_ITEMS:
            case KW_JAR:
            case KW_KEYS:
            case KW_KEY_TYPE:
            case KW_LATERAL:
            case KW_LEFT:
            case KW_LIKE:
            case KW_LIMIT:
            case KW_LINES:
            case KW_LOAD:
            case KW_LOCAL:
            case KW_LOCATION:
            case KW_LOCK:
            case KW_LOCKS:
            case KW_LOGICAL:
            case KW_LONG:
            case KW_MAPJOIN:
            case KW_MATERIALIZED:
            case KW_METADATA:
            case KW_MINUS:
            case KW_MSCK:
            case KW_NONE:
            case KW_NOSCAN:
            case KW_NO_DROP:
            case KW_NULL:
            case KW_OF:
            case KW_OFFLINE:
            case KW_OPTION:
            case KW_ORDER:
            case KW_OUT:
            case KW_OUTER:
            case KW_OUTPUTDRIVER:
            case KW_OUTPUTFORMAT:
            case KW_OVERWRITE:
            case KW_OWNER:
            case KW_PARTITIONED:
            case KW_PARTITIONS:
            case KW_PERCENT:
            case KW_PLUS:
            case KW_PRETTY:
            case KW_PRINCIPALS:
            case KW_PROCEDURE:
            case KW_PROTECTION:
            case KW_PURGE:
            case KW_RANGE:
            case KW_READ:
            case KW_READONLY:
            case KW_READS:
            case KW_REBUILD:
            case KW_RECORDREADER:
            case KW_RECORDWRITER:
            case KW_REGEXP:
            case KW_RELOAD:
            case KW_RENAME:
            case KW_REPAIR:
            case KW_REPLACE:
            case KW_REPLICATION:
            case KW_RESTRICT:
            case KW_REVOKE:
            case KW_REWRITE:
            case KW_RIGHT:
            case KW_RLIKE:
            case KW_ROLE:
            case KW_ROLES:
            case KW_ROLLUP:
            case KW_ROW:
            case KW_ROWS:
            case KW_SCHEMA:
            case KW_SCHEMAS:
            case KW_SEMI:
            case KW_SERDE:
            case KW_SERDEPROPERTIES:
            case KW_SERVER:
            case KW_SET:
            case KW_SETS:
            case KW_SHARED:
            case KW_SHOW:
            case KW_SHOW_DATABASE:
            case KW_SKEWED:
            case KW_SMALLINT:
            case KW_SORT:
            case KW_SORTED:
            case KW_SSL:
            case KW_STATISTICS:
            case KW_STORED:
            case KW_STREAMTABLE:
            case KW_STRING:
            case KW_STRUCT:
            case KW_TABLE:
            case KW_TABLES:
            case KW_TBLPROPERTIES:
            case KW_TEMPORARY:
            case KW_TERMINATED:
            case KW_TIMESTAMP:
            case KW_TINYINT:
            case KW_TO:
            case KW_TOUCH:
            case KW_TRANSACTIONS:
            case KW_TRIGGER:
            case KW_TRUE:
            case KW_TRUNCATE:
            case KW_UNARCHIVE:
            case KW_UNDO:
            case KW_UNION:
            case KW_UNIONTYPE:
            case KW_UNLOCK:
            case KW_UNSET:
            case KW_UNSIGNED:
            case KW_UPDATE:
            case KW_URI:
            case KW_USE:
            case KW_USER:
            case KW_USING:
            case KW_UTC:
            case KW_UTCTIMESTAMP:
            case KW_VALUES:
            case KW_VALUE_TYPE:
            case KW_VIEW:
            case KW_WHILE:
            case KW_WITH: {
              alt169 = 1;
            }
              break;
            case KW_PARTITION: {
              switch (input.LA(3)) {
                case LPAREN: {
                  alt169 = 2;
                }
                  break;
                case EOF: {
                  alt169 = 1;
                }
                  break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 169, 9, input);

                  throw nvae;
              }
            }
              break;
            case EOF:
            case DOT:
            case LPAREN: {
              alt169 = 2;
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 169, 2, input);

              throw nvae;
          }
        }
          break;
        case Identifier:
        case KW_ADD:
        case KW_ADMIN:
        case KW_AFTER:
        case KW_ALL:
        case KW_ALTER:
        case KW_ANALYZE:
        case KW_ARCHIVE:
        case KW_ARRAY:
        case KW_AS:
        case KW_ASC:
        case KW_AUTHORIZATION:
        case KW_BEFORE:
        case KW_BETWEEN:
        case KW_BIGINT:
        case KW_BINARY:
        case KW_BOOLEAN:
        case KW_BOTH:
        case KW_BUCKET:
        case KW_BUCKETS:
        case KW_BY:
        case KW_CASCADE:
        case KW_CHANGE:
        case KW_CLUSTER:
        case KW_CLUSTERED:
        case KW_CLUSTERSTATUS:
        case KW_COLLECTION:
        case KW_COLUMNS:
        case KW_COMMENT:
        case KW_COMPACT:
        case KW_COMPACTIONS:
        case KW_COMPUTE:
        case KW_CONCATENATE:
        case KW_CONTINUE:
        case KW_CREATE:
        case KW_CUBE:
        case KW_CURSOR:
        case KW_DATA:
        case KW_DATABASES:
        case KW_DATE:
        case KW_DATETIME:
        case KW_DBPROPERTIES:
        case KW_DECIMAL:
        case KW_DEFAULT:
        case KW_DEFERRED:
        case KW_DEFINED:
        case KW_DELETE:
        case KW_DELIMITED:
        case KW_DEPENDENCY:
        case KW_DESC:
        case KW_DESCRIBE:
        case KW_DIRECTORIES:
        case KW_DIRECTORY:
        case KW_DISABLE:
        case KW_DISTRIBUTE:
        case KW_DOUBLE:
        case KW_DROP:
        case KW_ELEM_TYPE:
        case KW_ENABLE:
        case KW_ESCAPED:
        case KW_EXCLUSIVE:
        case KW_EXISTS:
        case KW_EXPLAIN:
        case KW_EXPORT:
        case KW_EXTERNAL:
        case KW_FALSE:
        case KW_FETCH:
        case KW_FIELDS:
        case KW_FILE:
        case KW_FILEFORMAT:
        case KW_FIRST:
        case KW_FLOAT:
        case KW_FOR:
        case KW_FORMAT:
        case KW_FORMATTED:
        case KW_FULL:
        case KW_FUNCTIONS:
        case KW_GRANT:
        case KW_GROUP:
        case KW_GROUPING:
        case KW_HOLD_DDLTIME:
        case KW_IDXPROPERTIES:
        case KW_IGNORE:
        case KW_IMPORT:
        case KW_IN:
        case KW_INDEX:
        case KW_INDEXES:
        case KW_INNER:
        case KW_INPATH:
        case KW_INPUTDRIVER:
        case KW_INPUTFORMAT:
        case KW_INSERT:
        case KW_INT:
        case KW_INTERSECT:
        case KW_INTO:
        case KW_IS:
        case KW_ITEMS:
        case KW_JAR:
        case KW_KEYS:
        case KW_KEY_TYPE:
        case KW_LATERAL:
        case KW_LEFT:
        case KW_LIKE:
        case KW_LIMIT:
        case KW_LINES:
        case KW_LOAD:
        case KW_LOCAL:
        case KW_LOCATION:
        case KW_LOCK:
        case KW_LOCKS:
        case KW_LOGICAL:
        case KW_LONG:
        case KW_MAPJOIN:
        case KW_MATERIALIZED:
        case KW_METADATA:
        case KW_MINUS:
        case KW_MSCK:
        case KW_NONE:
        case KW_NOSCAN:
        case KW_NO_DROP:
        case KW_NULL:
        case KW_OF:
        case KW_OFFLINE:
        case KW_OPTION:
        case KW_ORDER:
        case KW_OUT:
        case KW_OUTER:
        case KW_OUTPUTDRIVER:
        case KW_OUTPUTFORMAT:
        case KW_OVERWRITE:
        case KW_OWNER:
        case KW_PARTITION:
        case KW_PARTITIONED:
        case KW_PARTITIONS:
        case KW_PERCENT:
        case KW_PLUS:
        case KW_PRETTY:
        case KW_PRINCIPALS:
        case KW_PROCEDURE:
        case KW_PROTECTION:
        case KW_PURGE:
        case KW_RANGE:
        case KW_READ:
        case KW_READONLY:
        case KW_READS:
        case KW_REBUILD:
        case KW_RECORDREADER:
        case KW_RECORDWRITER:
        case KW_REGEXP:
        case KW_RELOAD:
        case KW_RENAME:
        case KW_REPAIR:
        case KW_REPLACE:
        case KW_REPLICATION:
        case KW_RESTRICT:
        case KW_REVOKE:
        case KW_REWRITE:
        case KW_RIGHT:
        case KW_RLIKE:
        case KW_ROLE:
        case KW_ROLES:
        case KW_ROLLUP:
        case KW_ROW:
        case KW_ROWS:
        case KW_SCHEMAS:
        case KW_SEMI:
        case KW_SERDE:
        case KW_SERDEPROPERTIES:
        case KW_SET:
        case KW_SETS:
        case KW_SHARED:
        case KW_SHOW:
        case KW_SHOW_DATABASE:
        case KW_SKEWED:
        case KW_SMALLINT:
        case KW_SORT:
        case KW_SORTED:
        case KW_SSL:
        case KW_STATISTICS:
        case KW_STORED:
        case KW_STREAMTABLE:
        case KW_STRING:
        case KW_STRUCT:
        case KW_TABLE:
        case KW_TABLES:
        case KW_TBLPROPERTIES:
        case KW_TEMPORARY:
        case KW_TERMINATED:
        case KW_TIMESTAMP:
        case KW_TINYINT:
        case KW_TO:
        case KW_TOUCH:
        case KW_TRANSACTIONS:
        case KW_TRIGGER:
        case KW_TRUE:
        case KW_TRUNCATE:
        case KW_UNARCHIVE:
        case KW_UNDO:
        case KW_UNION:
        case KW_UNIONTYPE:
        case KW_UNLOCK:
        case KW_UNSET:
        case KW_UNSIGNED:
        case KW_UPDATE:
        case KW_USE:
        case KW_USER:
        case KW_USING:
        case KW_UTC:
        case KW_UTCTIMESTAMP:
        case KW_VALUES:
        case KW_VALUE_TYPE:
        case KW_VIEW:
        case KW_WHILE:
        case KW_WITH: {
          alt169 = 2;
        }
          break;
        case KW_URI: {
          switch (input.LA(2)) {
            case EOF:
            case DOT:
            case KW_PARTITION:
            case LPAREN: {
              alt169 = 2;
            }
              break;
            case StringLiteral: {
              alt169 = 3;
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 169, 5, input);

              throw nvae;
          }
        }
          break;
        case KW_SERVER: {
          switch (input.LA(2)) {
            case EOF:
            case DOT:
            case LPAREN: {
              alt169 = 2;
            }
              break;
            case KW_PARTITION: {
              switch (input.LA(3)) {
                case LPAREN: {
                  alt169 = 2;
                }
                  break;
                case EOF: {
                  alt169 = 4;
                }
                  break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 169, 21, input);

                  throw nvae;
              }
            }
              break;
            case Identifier:
            case KW_ADD:
            case KW_ADMIN:
            case KW_AFTER:
            case KW_ALL:
            case KW_ALTER:
            case KW_ANALYZE:
            case KW_ARCHIVE:
            case KW_ARRAY:
            case KW_AS:
            case KW_ASC:
            case KW_AUTHORIZATION:
            case KW_BEFORE:
            case KW_BETWEEN:
            case KW_BIGINT:
            case KW_BINARY:
            case KW_BOOLEAN:
            case KW_BOTH:
            case KW_BUCKET:
            case KW_BUCKETS:
            case KW_BY:
            case KW_CASCADE:
            case KW_CHANGE:
            case KW_CLUSTER:
            case KW_CLUSTERED:
            case KW_CLUSTERSTATUS:
            case KW_COLLECTION:
            case KW_COLUMNS:
            case KW_COMMENT:
            case KW_COMPACT:
            case KW_COMPACTIONS:
            case KW_COMPUTE:
            case KW_CONCATENATE:
            case KW_CONTINUE:
            case KW_CREATE:
            case KW_CUBE:
            case KW_CURSOR:
            case KW_DATA:
            case KW_DATABASES:
            case KW_DATE:
            case KW_DATETIME:
            case KW_DBPROPERTIES:
            case KW_DECIMAL:
            case KW_DEFAULT:
            case KW_DEFERRED:
            case KW_DEFINED:
            case KW_DELETE:
            case KW_DELIMITED:
            case KW_DEPENDENCY:
            case KW_DESC:
            case KW_DESCRIBE:
            case KW_DIRECTORIES:
            case KW_DIRECTORY:
            case KW_DISABLE:
            case KW_DISTRIBUTE:
            case KW_DOUBLE:
            case KW_DROP:
            case KW_ELEM_TYPE:
            case KW_ENABLE:
            case KW_ESCAPED:
            case KW_EXCLUSIVE:
            case KW_EXISTS:
            case KW_EXPLAIN:
            case KW_EXPORT:
            case KW_EXTERNAL:
            case KW_FALSE:
            case KW_FETCH:
            case KW_FIELDS:
            case KW_FILE:
            case KW_FILEFORMAT:
            case KW_FIRST:
            case KW_FLOAT:
            case KW_FOR:
            case KW_FORMAT:
            case KW_FORMATTED:
            case KW_FULL:
            case KW_FUNCTIONS:
            case KW_GRANT:
            case KW_GROUP:
            case KW_GROUPING:
            case KW_HOLD_DDLTIME:
            case KW_IDXPROPERTIES:
            case KW_IGNORE:
            case KW_IMPORT:
            case KW_IN:
            case KW_INDEX:
            case KW_INDEXES:
            case KW_INNER:
            case KW_INPATH:
            case KW_INPUTDRIVER:
            case KW_INPUTFORMAT:
            case KW_INSERT:
            case KW_INT:
            case KW_INTERSECT:
            case KW_INTO:
            case KW_IS:
            case KW_ITEMS:
            case KW_JAR:
            case KW_KEYS:
            case KW_KEY_TYPE:
            case KW_LATERAL:
            case KW_LEFT:
            case KW_LIKE:
            case KW_LIMIT:
            case KW_LINES:
            case KW_LOAD:
            case KW_LOCAL:
            case KW_LOCATION:
            case KW_LOCK:
            case KW_LOCKS:
            case KW_LOGICAL:
            case KW_LONG:
            case KW_MAPJOIN:
            case KW_MATERIALIZED:
            case KW_METADATA:
            case KW_MINUS:
            case KW_MSCK:
            case KW_NONE:
            case KW_NOSCAN:
            case KW_NO_DROP:
            case KW_NULL:
            case KW_OF:
            case KW_OFFLINE:
            case KW_OPTION:
            case KW_ORDER:
            case KW_OUT:
            case KW_OUTER:
            case KW_OUTPUTDRIVER:
            case KW_OUTPUTFORMAT:
            case KW_OVERWRITE:
            case KW_OWNER:
            case KW_PARTITIONED:
            case KW_PARTITIONS:
            case KW_PERCENT:
            case KW_PLUS:
            case KW_PRETTY:
            case KW_PRINCIPALS:
            case KW_PROCEDURE:
            case KW_PROTECTION:
            case KW_PURGE:
            case KW_RANGE:
            case KW_READ:
            case KW_READONLY:
            case KW_READS:
            case KW_REBUILD:
            case KW_RECORDREADER:
            case KW_RECORDWRITER:
            case KW_REGEXP:
            case KW_RELOAD:
            case KW_RENAME:
            case KW_REPAIR:
            case KW_REPLACE:
            case KW_REPLICATION:
            case KW_RESTRICT:
            case KW_REVOKE:
            case KW_REWRITE:
            case KW_RIGHT:
            case KW_RLIKE:
            case KW_ROLE:
            case KW_ROLES:
            case KW_ROLLUP:
            case KW_ROW:
            case KW_ROWS:
            case KW_SCHEMA:
            case KW_SCHEMAS:
            case KW_SEMI:
            case KW_SERDE:
            case KW_SERDEPROPERTIES:
            case KW_SERVER:
            case KW_SET:
            case KW_SETS:
            case KW_SHARED:
            case KW_SHOW:
            case KW_SHOW_DATABASE:
            case KW_SKEWED:
            case KW_SMALLINT:
            case KW_SORT:
            case KW_SORTED:
            case KW_SSL:
            case KW_STATISTICS:
            case KW_STORED:
            case KW_STREAMTABLE:
            case KW_STRING:
            case KW_STRUCT:
            case KW_TABLE:
            case KW_TABLES:
            case KW_TBLPROPERTIES:
            case KW_TEMPORARY:
            case KW_TERMINATED:
            case KW_TIMESTAMP:
            case KW_TINYINT:
            case KW_TO:
            case KW_TOUCH:
            case KW_TRANSACTIONS:
            case KW_TRIGGER:
            case KW_TRUE:
            case KW_TRUNCATE:
            case KW_UNARCHIVE:
            case KW_UNDO:
            case KW_UNION:
            case KW_UNIONTYPE:
            case KW_UNLOCK:
            case KW_UNSET:
            case KW_UNSIGNED:
            case KW_UPDATE:
            case KW_URI:
            case KW_USE:
            case KW_USER:
            case KW_USING:
            case KW_UTC:
            case KW_UTCTIMESTAMP:
            case KW_VALUES:
            case KW_VALUE_TYPE:
            case KW_VIEW:
            case KW_WHILE:
            case KW_WITH: {
              alt169 = 4;
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 169, 6, input);

              throw nvae;
          }
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 169, 0, input);

          throw nvae;
      }

      switch (alt169) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1518:7: ( KW_DATABASE | KW_SCHEMA ) identifier
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1518:7: ( KW_DATABASE | KW_SCHEMA )
          int alt165 = 2;
          switch (input.LA(1)) {
            case KW_DATABASE: {
              alt165 = 1;
            }
              break;
            case KW_SCHEMA: {
              alt165 = 2;
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 165, 0, input);

              throw nvae;
          }

          switch (alt165) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1518:8: KW_DATABASE
            {
              KW_DATABASE547 = (Token) match(input, KW_DATABASE, FOLLOW_KW_DATABASE_in_privObjectCols8400);
              stream_KW_DATABASE.add(KW_DATABASE547);
            }
              break;
            case 2:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1518:20: KW_SCHEMA
            {
              KW_SCHEMA548 = (Token) match(input, KW_SCHEMA, FOLLOW_KW_SCHEMA_in_privObjectCols8402);
              stream_KW_SCHEMA.add(KW_SCHEMA548);
            }
              break;
          }

          pushFollow(FOLLOW_identifier_in_privObjectCols8405);
          identifier549 = identifier();

          state._fsp--;

          stream_identifier.add(identifier549.getTree());

          // AST REWRITE
          // elements: identifier
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1518:42: -> ^( TOK_DB_TYPE identifier )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1518:45: ^( TOK_DB_TYPE identifier )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DB_TYPE, "TOK_DB_TYPE"), root_1);

              adaptor.addChild(root_1, stream_identifier.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1519:7: ( KW_TABLE )? tableName ( LPAREN cols= columnNameList RPAREN )? ( partitionSpec )?
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1519:7: ( KW_TABLE )?
          int alt166 = 2;
          switch (input.LA(1)) {
            case KW_TABLE: {
              switch (input.LA(2)) {
                case Identifier:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFAULT:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_METADATA:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NONE:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH: {
                  alt166 = 1;
                }
                  break;
                case KW_PARTITION: {
                  switch (input.LA(3)) {
                    case LPAREN: {
                      alt166 = 1;
                    }
                      break;
                    case EOF:
                    case DOT:
                    case KW_PARTITION: {
                      alt166 = 1;
                    }
                      break;
                  }
                }
                  break;
              }
            }
              break;
          }

          switch (alt166) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1519:7: KW_TABLE
            {
              KW_TABLE550 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_privObjectCols8421);
              stream_KW_TABLE.add(KW_TABLE550);
            }
              break;
          }

          pushFollow(FOLLOW_tableName_in_privObjectCols8424);
          tableName551 = tableName();

          state._fsp--;

          stream_tableName.add(tableName551.getTree());

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1519:27: ( LPAREN cols= columnNameList RPAREN )?
          int alt167 = 2;
          switch (input.LA(1)) {
            case LPAREN: {
              alt167 = 1;
            }
              break;
          }

          switch (alt167) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1519:28: LPAREN cols= columnNameList RPAREN
            {
              LPAREN552 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_privObjectCols8427);
              stream_LPAREN.add(LPAREN552);

              pushFollow(FOLLOW_columnNameList_in_privObjectCols8431);
              cols = columnNameList();

              state._fsp--;

              stream_columnNameList.add(cols.getTree());

              RPAREN553 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_privObjectCols8433);
              stream_RPAREN.add(RPAREN553);
            }
              break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1519:64: ( partitionSpec )?
          int alt168 = 2;
          switch (input.LA(1)) {
            case KW_PARTITION: {
              alt168 = 1;
            }
              break;
          }

          switch (alt168) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1519:64: partitionSpec
            {
              pushFollow(FOLLOW_partitionSpec_in_privObjectCols8437);
              partitionSpec554 = partitionSpec();

              state._fsp--;

              stream_partitionSpec.add(partitionSpec554.getTree());
            }
              break;
          }

          // AST REWRITE
          // elements: tableName, cols, partitionSpec
          // token labels:
          // rule labels: cols, retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_cols =
              new RewriteRuleSubtreeStream(adaptor, "rule cols", cols != null ? cols.tree : null);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1519:79: -> ^( TOK_TABLE_TYPE tableName ( $cols)? ( partitionSpec )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1519:82: ^( TOK_TABLE_TYPE tableName ( $cols)? ( partitionSpec )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABLE_TYPE, "TOK_TABLE_TYPE"),
                  root_1);

              adaptor.addChild(root_1, stream_tableName.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1519:110: ( $cols)?
              if (stream_cols.hasNext()) {
                adaptor.addChild(root_1, stream_cols.nextTree());
              }
              stream_cols.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1519:116: ( partitionSpec )?
              if (stream_partitionSpec.hasNext()) {
                adaptor.addChild(root_1, stream_partitionSpec.nextTree());
              }
              stream_partitionSpec.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 3:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1520:7: KW_URI (path= StringLiteral )
        {
          KW_URI555 = (Token) match(input, KW_URI, FOLLOW_KW_URI_in_privObjectCols8461);
          stream_KW_URI.add(KW_URI555);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1520:14: (path= StringLiteral )
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1520:15: path= StringLiteral
          {
            path = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_privObjectCols8466);
            stream_StringLiteral.add(path);
          }

          // AST REWRITE
          // elements: path
          // token labels: path
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleTokenStream stream_path = new RewriteRuleTokenStream(adaptor, "token path", path);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1520:35: -> ^( TOK_URI_TYPE $path)
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1520:39: ^( TOK_URI_TYPE $path)
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_URI_TYPE, "TOK_URI_TYPE"), root_1);

              adaptor.addChild(root_1, stream_path.nextNode());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 4:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1521:7: KW_SERVER identifier
        {
          KW_SERVER556 = (Token) match(input, KW_SERVER, FOLLOW_KW_SERVER_in_privObjectCols8485);
          stream_KW_SERVER.add(KW_SERVER556);

          pushFollow(FOLLOW_identifier_in_privObjectCols8487);
          identifier557 = identifier();

          state._fsp--;

          stream_identifier.add(identifier557.getTree());

          // AST REWRITE
          // elements: identifier
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1521:28: -> ^( TOK_SERVER_TYPE identifier )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1521:31: ^( TOK_SERVER_TYPE identifier )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SERVER_TYPE, "TOK_SERVER_TYPE"),
                  root_1);

              adaptor.addChild(root_1, stream_identifier.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "privObjectCols"

  public static class privilegeList_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "privilegeList"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1524:1: privilegeList : privlegeDef ( COMMA privlegeDef )* -> ^( TOK_PRIVILEGE_LIST ( privlegeDef )+ ) ;
  public final HiveParser.privilegeList_return privilegeList() throws RecognitionException {
    HiveParser.privilegeList_return retval = new HiveParser.privilegeList_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token COMMA559 = null;
    HiveParser.privlegeDef_return privlegeDef558 = null;

    HiveParser.privlegeDef_return privlegeDef560 = null;

    CommonTree COMMA559_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleSubtreeStream stream_privlegeDef = new RewriteRuleSubtreeStream(adaptor, "rule privlegeDef");
    pushMsg("grant privilege list", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1527:5: ( privlegeDef ( COMMA privlegeDef )* -> ^( TOK_PRIVILEGE_LIST ( privlegeDef )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1527:7: privlegeDef ( COMMA privlegeDef )*
      {
        pushFollow(FOLLOW_privlegeDef_in_privilegeList8522);
        privlegeDef558 = privlegeDef();

        state._fsp--;

        stream_privlegeDef.add(privlegeDef558.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1527:19: ( COMMA privlegeDef )*
        loop170: do {
          int alt170 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt170 = 1;
            }
              break;
          }

          switch (alt170) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1527:20: COMMA privlegeDef
            {
              COMMA559 = (Token) match(input, COMMA, FOLLOW_COMMA_in_privilegeList8525);
              stream_COMMA.add(COMMA559);

              pushFollow(FOLLOW_privlegeDef_in_privilegeList8527);
              privlegeDef560 = privlegeDef();

              state._fsp--;

              stream_privlegeDef.add(privlegeDef560.getTree());
            }
              break;

            default:
              break loop170;
          }
        } while (true);

        // AST REWRITE
        // elements: privlegeDef
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1528:5: -> ^( TOK_PRIVILEGE_LIST ( privlegeDef )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1528:8: ^( TOK_PRIVILEGE_LIST ( privlegeDef )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_PRIVILEGE_LIST, "TOK_PRIVILEGE_LIST"), root_1);

            if (!(stream_privlegeDef.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_privlegeDef.hasNext()) {
              adaptor.addChild(root_1, stream_privlegeDef.nextTree());
            }
            stream_privlegeDef.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "privilegeList"

  public static class privlegeDef_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "privlegeDef"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1531:1: privlegeDef : privilegeType ( LPAREN cols= columnNameList RPAREN )? -> ^( TOK_PRIVILEGE privilegeType ( $cols)? ) ;
  public final HiveParser.privlegeDef_return privlegeDef() throws RecognitionException {
    HiveParser.privlegeDef_return retval = new HiveParser.privlegeDef_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token LPAREN562 = null;
    Token RPAREN563 = null;
    HiveParser.columnNameList_return cols = null;

    HiveParser.privilegeType_return privilegeType561 = null;

    CommonTree LPAREN562_tree = null;
    CommonTree RPAREN563_tree = null;
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleSubtreeStream stream_columnNameList = new RewriteRuleSubtreeStream(adaptor, "rule columnNameList");
    RewriteRuleSubtreeStream stream_privilegeType = new RewriteRuleSubtreeStream(adaptor, "rule privilegeType");
    pushMsg("grant privilege", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1534:5: ( privilegeType ( LPAREN cols= columnNameList RPAREN )? -> ^( TOK_PRIVILEGE privilegeType ( $cols)? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1534:7: privilegeType ( LPAREN cols= columnNameList RPAREN )?
      {
        pushFollow(FOLLOW_privilegeType_in_privlegeDef8569);
        privilegeType561 = privilegeType();

        state._fsp--;

        stream_privilegeType.add(privilegeType561.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1534:21: ( LPAREN cols= columnNameList RPAREN )?
        int alt171 = 2;
        switch (input.LA(1)) {
          case LPAREN: {
            alt171 = 1;
          }
            break;
        }

        switch (alt171) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1534:22: LPAREN cols= columnNameList RPAREN
          {
            LPAREN562 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_privlegeDef8572);
            stream_LPAREN.add(LPAREN562);

            pushFollow(FOLLOW_columnNameList_in_privlegeDef8576);
            cols = columnNameList();

            state._fsp--;

            stream_columnNameList.add(cols.getTree());

            RPAREN563 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_privlegeDef8578);
            stream_RPAREN.add(RPAREN563);
          }
            break;
        }

        // AST REWRITE
        // elements: privilegeType, cols
        // token labels:
        // rule labels: cols, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_cols =
            new RewriteRuleSubtreeStream(adaptor, "rule cols", cols != null ? cols.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1535:5: -> ^( TOK_PRIVILEGE privilegeType ( $cols)? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1535:8: ^( TOK_PRIVILEGE privilegeType ( $cols)? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_PRIVILEGE, "TOK_PRIVILEGE"), root_1);

            adaptor.addChild(root_1, stream_privilegeType.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1535:39: ( $cols)?
            if (stream_cols.hasNext()) {
              adaptor.addChild(root_1, stream_cols.nextTree());
            }
            stream_cols.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "privlegeDef"

  public static class privilegeType_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "privilegeType"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1538:1: privilegeType : ( KW_ALL -> ^( TOK_PRIV_ALL ) | KW_ALTER -> ^( TOK_PRIV_ALTER_METADATA ) | KW_UPDATE -> ^( TOK_PRIV_ALTER_DATA ) | KW_CREATE -> ^( TOK_PRIV_CREATE ) | KW_DROP -> ^( TOK_PRIV_DROP ) | KW_INDEX -> ^( TOK_PRIV_INDEX ) | KW_LOCK -> ^( TOK_PRIV_LOCK ) | KW_SELECT -> ^( TOK_PRIV_SELECT ) | KW_SHOW_DATABASE -> ^( TOK_PRIV_SHOW_DATABASE ) | KW_INSERT -> ^( TOK_PRIV_INSERT ) | KW_DELETE -> ^( TOK_PRIV_DELETE ) );
  public final HiveParser.privilegeType_return privilegeType() throws RecognitionException {
    HiveParser.privilegeType_return retval = new HiveParser.privilegeType_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_ALL564 = null;
    Token KW_ALTER565 = null;
    Token KW_UPDATE566 = null;
    Token KW_CREATE567 = null;
    Token KW_DROP568 = null;
    Token KW_INDEX569 = null;
    Token KW_LOCK570 = null;
    Token KW_SELECT571 = null;
    Token KW_SHOW_DATABASE572 = null;
    Token KW_INSERT573 = null;
    Token KW_DELETE574 = null;

    CommonTree KW_ALL564_tree = null;
    CommonTree KW_ALTER565_tree = null;
    CommonTree KW_UPDATE566_tree = null;
    CommonTree KW_CREATE567_tree = null;
    CommonTree KW_DROP568_tree = null;
    CommonTree KW_INDEX569_tree = null;
    CommonTree KW_LOCK570_tree = null;
    CommonTree KW_SELECT571_tree = null;
    CommonTree KW_SHOW_DATABASE572_tree = null;
    CommonTree KW_INSERT573_tree = null;
    CommonTree KW_DELETE574_tree = null;
    RewriteRuleTokenStream stream_KW_DROP = new RewriteRuleTokenStream(adaptor, "token KW_DROP");
    RewriteRuleTokenStream stream_KW_DELETE = new RewriteRuleTokenStream(adaptor, "token KW_DELETE");
    RewriteRuleTokenStream stream_KW_SHOW_DATABASE = new RewriteRuleTokenStream(adaptor, "token KW_SHOW_DATABASE");
    RewriteRuleTokenStream stream_KW_CREATE = new RewriteRuleTokenStream(adaptor, "token KW_CREATE");
    RewriteRuleTokenStream stream_KW_INDEX = new RewriteRuleTokenStream(adaptor, "token KW_INDEX");
    RewriteRuleTokenStream stream_KW_ALTER = new RewriteRuleTokenStream(adaptor, "token KW_ALTER");
    RewriteRuleTokenStream stream_KW_UPDATE = new RewriteRuleTokenStream(adaptor, "token KW_UPDATE");
    RewriteRuleTokenStream stream_KW_LOCK = new RewriteRuleTokenStream(adaptor, "token KW_LOCK");
    RewriteRuleTokenStream stream_KW_INSERT = new RewriteRuleTokenStream(adaptor, "token KW_INSERT");
    RewriteRuleTokenStream stream_KW_SELECT = new RewriteRuleTokenStream(adaptor, "token KW_SELECT");
    RewriteRuleTokenStream stream_KW_ALL = new RewriteRuleTokenStream(adaptor, "token KW_ALL");

    pushMsg("privilege type", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1541:5: ( KW_ALL -> ^( TOK_PRIV_ALL ) | KW_ALTER -> ^( TOK_PRIV_ALTER_METADATA ) | KW_UPDATE -> ^( TOK_PRIV_ALTER_DATA ) | KW_CREATE -> ^( TOK_PRIV_CREATE ) | KW_DROP -> ^( TOK_PRIV_DROP ) | KW_INDEX -> ^( TOK_PRIV_INDEX ) | KW_LOCK -> ^( TOK_PRIV_LOCK ) | KW_SELECT -> ^( TOK_PRIV_SELECT ) | KW_SHOW_DATABASE -> ^( TOK_PRIV_SHOW_DATABASE ) | KW_INSERT -> ^( TOK_PRIV_INSERT ) | KW_DELETE -> ^( TOK_PRIV_DELETE ) )
      int alt172 = 11;
      switch (input.LA(1)) {
        case KW_ALL: {
          alt172 = 1;
        }
          break;
        case KW_ALTER: {
          alt172 = 2;
        }
          break;
        case KW_UPDATE: {
          alt172 = 3;
        }
          break;
        case KW_CREATE: {
          alt172 = 4;
        }
          break;
        case KW_DROP: {
          alt172 = 5;
        }
          break;
        case KW_INDEX: {
          alt172 = 6;
        }
          break;
        case KW_LOCK: {
          alt172 = 7;
        }
          break;
        case KW_SELECT: {
          alt172 = 8;
        }
          break;
        case KW_SHOW_DATABASE: {
          alt172 = 9;
        }
          break;
        case KW_INSERT: {
          alt172 = 10;
        }
          break;
        case KW_DELETE: {
          alt172 = 11;
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 172, 0, input);

          throw nvae;
      }

      switch (alt172) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1541:7: KW_ALL
        {
          KW_ALL564 = (Token) match(input, KW_ALL, FOLLOW_KW_ALL_in_privilegeType8623);
          stream_KW_ALL.add(KW_ALL564);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1541:14: -> ^( TOK_PRIV_ALL )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1541:17: ^( TOK_PRIV_ALL )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_PRIV_ALL, "TOK_PRIV_ALL"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1542:7: KW_ALTER
        {
          KW_ALTER565 = (Token) match(input, KW_ALTER, FOLLOW_KW_ALTER_in_privilegeType8637);
          stream_KW_ALTER.add(KW_ALTER565);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1542:16: -> ^( TOK_PRIV_ALTER_METADATA )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1542:19: ^( TOK_PRIV_ALTER_METADATA )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor
                  .becomeRoot((CommonTree) adaptor.create(TOK_PRIV_ALTER_METADATA, "TOK_PRIV_ALTER_METADATA"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 3:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1543:7: KW_UPDATE
        {
          KW_UPDATE566 = (Token) match(input, KW_UPDATE, FOLLOW_KW_UPDATE_in_privilegeType8651);
          stream_KW_UPDATE.add(KW_UPDATE566);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1543:17: -> ^( TOK_PRIV_ALTER_DATA )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1543:20: ^( TOK_PRIV_ALTER_DATA )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor
                  .becomeRoot((CommonTree) adaptor.create(TOK_PRIV_ALTER_DATA, "TOK_PRIV_ALTER_DATA"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 4:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1544:7: KW_CREATE
        {
          KW_CREATE567 = (Token) match(input, KW_CREATE, FOLLOW_KW_CREATE_in_privilegeType8665);
          stream_KW_CREATE.add(KW_CREATE567);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1544:17: -> ^( TOK_PRIV_CREATE )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1544:20: ^( TOK_PRIV_CREATE )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_PRIV_CREATE, "TOK_PRIV_CREATE"),
                  root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 5:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1545:7: KW_DROP
        {
          KW_DROP568 = (Token) match(input, KW_DROP, FOLLOW_KW_DROP_in_privilegeType8679);
          stream_KW_DROP.add(KW_DROP568);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1545:15: -> ^( TOK_PRIV_DROP )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1545:18: ^( TOK_PRIV_DROP )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_PRIV_DROP, "TOK_PRIV_DROP"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 6:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1546:7: KW_INDEX
        {
          KW_INDEX569 = (Token) match(input, KW_INDEX, FOLLOW_KW_INDEX_in_privilegeType8693);
          stream_KW_INDEX.add(KW_INDEX569);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1546:16: -> ^( TOK_PRIV_INDEX )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1546:19: ^( TOK_PRIV_INDEX )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_PRIV_INDEX, "TOK_PRIV_INDEX"),
                  root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 7:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1547:7: KW_LOCK
        {
          KW_LOCK570 = (Token) match(input, KW_LOCK, FOLLOW_KW_LOCK_in_privilegeType8707);
          stream_KW_LOCK.add(KW_LOCK570);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1547:15: -> ^( TOK_PRIV_LOCK )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1547:18: ^( TOK_PRIV_LOCK )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_PRIV_LOCK, "TOK_PRIV_LOCK"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 8:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1548:7: KW_SELECT
        {
          KW_SELECT571 = (Token) match(input, KW_SELECT, FOLLOW_KW_SELECT_in_privilegeType8721);
          stream_KW_SELECT.add(KW_SELECT571);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1548:17: -> ^( TOK_PRIV_SELECT )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1548:20: ^( TOK_PRIV_SELECT )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_PRIV_SELECT, "TOK_PRIV_SELECT"),
                  root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 9:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1549:7: KW_SHOW_DATABASE
        {
          KW_SHOW_DATABASE572 = (Token) match(input, KW_SHOW_DATABASE, FOLLOW_KW_SHOW_DATABASE_in_privilegeType8735);
          stream_KW_SHOW_DATABASE.add(KW_SHOW_DATABASE572);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1549:24: -> ^( TOK_PRIV_SHOW_DATABASE )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1549:27: ^( TOK_PRIV_SHOW_DATABASE )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor
                  .becomeRoot((CommonTree) adaptor.create(TOK_PRIV_SHOW_DATABASE, "TOK_PRIV_SHOW_DATABASE"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 10:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1550:7: KW_INSERT
        {
          KW_INSERT573 = (Token) match(input, KW_INSERT, FOLLOW_KW_INSERT_in_privilegeType8749);
          stream_KW_INSERT.add(KW_INSERT573);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1550:17: -> ^( TOK_PRIV_INSERT )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1550:20: ^( TOK_PRIV_INSERT )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_PRIV_INSERT, "TOK_PRIV_INSERT"),
                  root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 11:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1551:7: KW_DELETE
        {
          KW_DELETE574 = (Token) match(input, KW_DELETE, FOLLOW_KW_DELETE_in_privilegeType8763);
          stream_KW_DELETE.add(KW_DELETE574);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1551:17: -> ^( TOK_PRIV_DELETE )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1551:20: ^( TOK_PRIV_DELETE )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_PRIV_DELETE, "TOK_PRIV_DELETE"),
                  root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "privilegeType"

  public static class principalSpecification_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "principalSpecification"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1554:1: principalSpecification : principalName ( COMMA principalName )* -> ^( TOK_PRINCIPAL_NAME ( principalName )+ ) ;
  public final HiveParser.principalSpecification_return principalSpecification() throws RecognitionException {
    HiveParser.principalSpecification_return retval = new HiveParser.principalSpecification_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token COMMA576 = null;
    HiveParser.principalName_return principalName575 = null;

    HiveParser.principalName_return principalName577 = null;

    CommonTree COMMA576_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleSubtreeStream stream_principalName = new RewriteRuleSubtreeStream(adaptor, "rule principalName");
    pushMsg("user/group/role name list", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1557:5: ( principalName ( COMMA principalName )* -> ^( TOK_PRINCIPAL_NAME ( principalName )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1557:7: principalName ( COMMA principalName )*
      {
        pushFollow(FOLLOW_principalName_in_principalSpecification8796);
        principalName575 = principalName();

        state._fsp--;

        stream_principalName.add(principalName575.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1557:21: ( COMMA principalName )*
        loop173: do {
          int alt173 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt173 = 1;
            }
              break;
          }

          switch (alt173) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1557:22: COMMA principalName
            {
              COMMA576 = (Token) match(input, COMMA, FOLLOW_COMMA_in_principalSpecification8799);
              stream_COMMA.add(COMMA576);

              pushFollow(FOLLOW_principalName_in_principalSpecification8801);
              principalName577 = principalName();

              state._fsp--;

              stream_principalName.add(principalName577.getTree());
            }
              break;

            default:
              break loop173;
          }
        } while (true);

        // AST REWRITE
        // elements: principalName
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1557:44: -> ^( TOK_PRINCIPAL_NAME ( principalName )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1557:47: ^( TOK_PRINCIPAL_NAME ( principalName )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_PRINCIPAL_NAME, "TOK_PRINCIPAL_NAME"), root_1);

            if (!(stream_principalName.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_principalName.hasNext()) {
              adaptor.addChild(root_1, stream_principalName.nextTree());
            }
            stream_principalName.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "principalSpecification"

  public static class principalName_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "principalName"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1560:1: principalName : ( KW_USER principalIdentifier -> ^( TOK_USER principalIdentifier ) | KW_GROUP principalIdentifier -> ^( TOK_GROUP principalIdentifier ) | KW_ROLE identifier -> ^( TOK_ROLE identifier ) );
  public final HiveParser.principalName_return principalName() throws RecognitionException {
    HiveParser.principalName_return retval = new HiveParser.principalName_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_USER578 = null;
    Token KW_GROUP580 = null;
    Token KW_ROLE582 = null;
    HiveParser_IdentifiersParser.principalIdentifier_return principalIdentifier579 = null;

    HiveParser_IdentifiersParser.principalIdentifier_return principalIdentifier581 = null;

    HiveParser_IdentifiersParser.identifier_return identifier583 = null;

    CommonTree KW_USER578_tree = null;
    CommonTree KW_GROUP580_tree = null;
    CommonTree KW_ROLE582_tree = null;
    RewriteRuleTokenStream stream_KW_ROLE = new RewriteRuleTokenStream(adaptor, "token KW_ROLE");
    RewriteRuleTokenStream stream_KW_USER = new RewriteRuleTokenStream(adaptor, "token KW_USER");
    RewriteRuleTokenStream stream_KW_GROUP = new RewriteRuleTokenStream(adaptor, "token KW_GROUP");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_principalIdentifier =
        new RewriteRuleSubtreeStream(adaptor, "rule principalIdentifier");
    pushMsg("user|group|role name", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1563:5: ( KW_USER principalIdentifier -> ^( TOK_USER principalIdentifier ) | KW_GROUP principalIdentifier -> ^( TOK_GROUP principalIdentifier ) | KW_ROLE identifier -> ^( TOK_ROLE identifier ) )
      int alt174 = 3;
      switch (input.LA(1)) {
        case KW_USER: {
          alt174 = 1;
        }
          break;
        case KW_GROUP: {
          alt174 = 2;
        }
          break;
        case KW_ROLE: {
          alt174 = 3;
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 174, 0, input);

          throw nvae;
      }

      switch (alt174) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1563:7: KW_USER principalIdentifier
        {
          KW_USER578 = (Token) match(input, KW_USER, FOLLOW_KW_USER_in_principalName8839);
          stream_KW_USER.add(KW_USER578);

          pushFollow(FOLLOW_principalIdentifier_in_principalName8841);
          principalIdentifier579 = principalIdentifier();

          state._fsp--;

          stream_principalIdentifier.add(principalIdentifier579.getTree());

          // AST REWRITE
          // elements: principalIdentifier
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1563:35: -> ^( TOK_USER principalIdentifier )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1563:38: ^( TOK_USER principalIdentifier )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_USER, "TOK_USER"), root_1);

              adaptor.addChild(root_1, stream_principalIdentifier.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1564:7: KW_GROUP principalIdentifier
        {
          KW_GROUP580 = (Token) match(input, KW_GROUP, FOLLOW_KW_GROUP_in_principalName8857);
          stream_KW_GROUP.add(KW_GROUP580);

          pushFollow(FOLLOW_principalIdentifier_in_principalName8859);
          principalIdentifier581 = principalIdentifier();

          state._fsp--;

          stream_principalIdentifier.add(principalIdentifier581.getTree());

          // AST REWRITE
          // elements: principalIdentifier
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1564:36: -> ^( TOK_GROUP principalIdentifier )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1564:39: ^( TOK_GROUP principalIdentifier )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_GROUP, "TOK_GROUP"), root_1);

              adaptor.addChild(root_1, stream_principalIdentifier.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 3:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1565:7: KW_ROLE identifier
        {
          KW_ROLE582 = (Token) match(input, KW_ROLE, FOLLOW_KW_ROLE_in_principalName8875);
          stream_KW_ROLE.add(KW_ROLE582);

          pushFollow(FOLLOW_identifier_in_principalName8877);
          identifier583 = identifier();

          state._fsp--;

          stream_identifier.add(identifier583.getTree());

          // AST REWRITE
          // elements: identifier
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1565:26: -> ^( TOK_ROLE identifier )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1565:29: ^( TOK_ROLE identifier )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_ROLE, "TOK_ROLE"), root_1);

              adaptor.addChild(root_1, stream_identifier.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "principalName"

  public static class withGrantOption_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "withGrantOption"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1568:1: withGrantOption : KW_WITH KW_GRANT KW_OPTION -> ^( TOK_GRANT_WITH_OPTION ) ;
  public final HiveParser.withGrantOption_return withGrantOption() throws RecognitionException {
    HiveParser.withGrantOption_return retval = new HiveParser.withGrantOption_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_WITH584 = null;
    Token KW_GRANT585 = null;
    Token KW_OPTION586 = null;

    CommonTree KW_WITH584_tree = null;
    CommonTree KW_GRANT585_tree = null;
    CommonTree KW_OPTION586_tree = null;
    RewriteRuleTokenStream stream_KW_WITH = new RewriteRuleTokenStream(adaptor, "token KW_WITH");
    RewriteRuleTokenStream stream_KW_GRANT = new RewriteRuleTokenStream(adaptor, "token KW_GRANT");
    RewriteRuleTokenStream stream_KW_OPTION = new RewriteRuleTokenStream(adaptor, "token KW_OPTION");

    pushMsg("with grant option", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1571:5: ( KW_WITH KW_GRANT KW_OPTION -> ^( TOK_GRANT_WITH_OPTION ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1571:7: KW_WITH KW_GRANT KW_OPTION
      {
        KW_WITH584 = (Token) match(input, KW_WITH, FOLLOW_KW_WITH_in_withGrantOption8912);
        stream_KW_WITH.add(KW_WITH584);

        KW_GRANT585 = (Token) match(input, KW_GRANT, FOLLOW_KW_GRANT_in_withGrantOption8914);
        stream_KW_GRANT.add(KW_GRANT585);

        KW_OPTION586 = (Token) match(input, KW_OPTION, FOLLOW_KW_OPTION_in_withGrantOption8916);
        stream_KW_OPTION.add(KW_OPTION586);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1572:5: -> ^( TOK_GRANT_WITH_OPTION )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1572:8: ^( TOK_GRANT_WITH_OPTION )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_GRANT_WITH_OPTION, "TOK_GRANT_WITH_OPTION"), root_1);

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "withGrantOption"

  public static class grantOptionFor_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "grantOptionFor"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1575:1: grantOptionFor : KW_GRANT KW_OPTION KW_FOR -> ^( TOK_GRANT_OPTION_FOR ) ;
  public final HiveParser.grantOptionFor_return grantOptionFor() throws RecognitionException {
    HiveParser.grantOptionFor_return retval = new HiveParser.grantOptionFor_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_GRANT587 = null;
    Token KW_OPTION588 = null;
    Token KW_FOR589 = null;

    CommonTree KW_GRANT587_tree = null;
    CommonTree KW_OPTION588_tree = null;
    CommonTree KW_FOR589_tree = null;
    RewriteRuleTokenStream stream_KW_FOR = new RewriteRuleTokenStream(adaptor, "token KW_FOR");
    RewriteRuleTokenStream stream_KW_GRANT = new RewriteRuleTokenStream(adaptor, "token KW_GRANT");
    RewriteRuleTokenStream stream_KW_OPTION = new RewriteRuleTokenStream(adaptor, "token KW_OPTION");

    pushMsg("grant option for", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1578:5: ( KW_GRANT KW_OPTION KW_FOR -> ^( TOK_GRANT_OPTION_FOR ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1578:7: KW_GRANT KW_OPTION KW_FOR
      {
        KW_GRANT587 = (Token) match(input, KW_GRANT, FOLLOW_KW_GRANT_in_grantOptionFor8953);
        stream_KW_GRANT.add(KW_GRANT587);

        KW_OPTION588 = (Token) match(input, KW_OPTION, FOLLOW_KW_OPTION_in_grantOptionFor8955);
        stream_KW_OPTION.add(KW_OPTION588);

        KW_FOR589 = (Token) match(input, KW_FOR, FOLLOW_KW_FOR_in_grantOptionFor8957);
        stream_KW_FOR.add(KW_FOR589);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1579:5: -> ^( TOK_GRANT_OPTION_FOR )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1579:8: ^( TOK_GRANT_OPTION_FOR )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_GRANT_OPTION_FOR, "TOK_GRANT_OPTION_FOR"), root_1);

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "grantOptionFor"

  public static class adminOptionFor_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "adminOptionFor"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1582:1: adminOptionFor : KW_ADMIN KW_OPTION KW_FOR -> ^( TOK_ADMIN_OPTION_FOR ) ;
  public final HiveParser.adminOptionFor_return adminOptionFor() throws RecognitionException {
    HiveParser.adminOptionFor_return retval = new HiveParser.adminOptionFor_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_ADMIN590 = null;
    Token KW_OPTION591 = null;
    Token KW_FOR592 = null;

    CommonTree KW_ADMIN590_tree = null;
    CommonTree KW_OPTION591_tree = null;
    CommonTree KW_FOR592_tree = null;
    RewriteRuleTokenStream stream_KW_FOR = new RewriteRuleTokenStream(adaptor, "token KW_FOR");
    RewriteRuleTokenStream stream_KW_OPTION = new RewriteRuleTokenStream(adaptor, "token KW_OPTION");
    RewriteRuleTokenStream stream_KW_ADMIN = new RewriteRuleTokenStream(adaptor, "token KW_ADMIN");

    pushMsg("admin option for", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1585:5: ( KW_ADMIN KW_OPTION KW_FOR -> ^( TOK_ADMIN_OPTION_FOR ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1585:7: KW_ADMIN KW_OPTION KW_FOR
      {
        KW_ADMIN590 = (Token) match(input, KW_ADMIN, FOLLOW_KW_ADMIN_in_adminOptionFor8990);
        stream_KW_ADMIN.add(KW_ADMIN590);

        KW_OPTION591 = (Token) match(input, KW_OPTION, FOLLOW_KW_OPTION_in_adminOptionFor8992);
        stream_KW_OPTION.add(KW_OPTION591);

        KW_FOR592 = (Token) match(input, KW_FOR, FOLLOW_KW_FOR_in_adminOptionFor8994);
        stream_KW_FOR.add(KW_FOR592);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1586:5: -> ^( TOK_ADMIN_OPTION_FOR )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1586:8: ^( TOK_ADMIN_OPTION_FOR )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_ADMIN_OPTION_FOR, "TOK_ADMIN_OPTION_FOR"), root_1);

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "adminOptionFor"

  public static class withAdminOption_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "withAdminOption"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1589:1: withAdminOption : KW_WITH KW_ADMIN KW_OPTION -> ^( TOK_GRANT_WITH_ADMIN_OPTION ) ;
  public final HiveParser.withAdminOption_return withAdminOption() throws RecognitionException {
    HiveParser.withAdminOption_return retval = new HiveParser.withAdminOption_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_WITH593 = null;
    Token KW_ADMIN594 = null;
    Token KW_OPTION595 = null;

    CommonTree KW_WITH593_tree = null;
    CommonTree KW_ADMIN594_tree = null;
    CommonTree KW_OPTION595_tree = null;
    RewriteRuleTokenStream stream_KW_WITH = new RewriteRuleTokenStream(adaptor, "token KW_WITH");
    RewriteRuleTokenStream stream_KW_OPTION = new RewriteRuleTokenStream(adaptor, "token KW_OPTION");
    RewriteRuleTokenStream stream_KW_ADMIN = new RewriteRuleTokenStream(adaptor, "token KW_ADMIN");

    pushMsg("with admin option", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1592:5: ( KW_WITH KW_ADMIN KW_OPTION -> ^( TOK_GRANT_WITH_ADMIN_OPTION ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1592:7: KW_WITH KW_ADMIN KW_OPTION
      {
        KW_WITH593 = (Token) match(input, KW_WITH, FOLLOW_KW_WITH_in_withAdminOption9027);
        stream_KW_WITH.add(KW_WITH593);

        KW_ADMIN594 = (Token) match(input, KW_ADMIN, FOLLOW_KW_ADMIN_in_withAdminOption9029);
        stream_KW_ADMIN.add(KW_ADMIN594);

        KW_OPTION595 = (Token) match(input, KW_OPTION, FOLLOW_KW_OPTION_in_withAdminOption9031);
        stream_KW_OPTION.add(KW_OPTION595);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1593:5: -> ^( TOK_GRANT_WITH_ADMIN_OPTION )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1593:8: ^( TOK_GRANT_WITH_ADMIN_OPTION )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_GRANT_WITH_ADMIN_OPTION, "TOK_GRANT_WITH_ADMIN_OPTION"), root_1);

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "withAdminOption"

  public static class metastoreCheck_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "metastoreCheck"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1596:1: metastoreCheck : KW_MSCK (repair= KW_REPAIR )? ( KW_TABLE tableName ( partitionSpec )? ( COMMA partitionSpec )* )? -> ^( TOK_MSCK ( $repair)? ( tableName ( partitionSpec )* )? ) ;
  public final HiveParser.metastoreCheck_return metastoreCheck() throws RecognitionException {
    HiveParser.metastoreCheck_return retval = new HiveParser.metastoreCheck_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token repair = null;
    Token KW_MSCK596 = null;
    Token KW_TABLE597 = null;
    Token COMMA600 = null;
    HiveParser_FromClauseParser.tableName_return tableName598 = null;

    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec599 = null;

    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec601 = null;

    CommonTree repair_tree = null;
    CommonTree KW_MSCK596_tree = null;
    CommonTree KW_TABLE597_tree = null;
    CommonTree COMMA600_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleTokenStream stream_KW_REPAIR = new RewriteRuleTokenStream(adaptor, "token KW_REPAIR");
    RewriteRuleTokenStream stream_KW_MSCK = new RewriteRuleTokenStream(adaptor, "token KW_MSCK");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleSubtreeStream stream_partitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule partitionSpec");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    pushMsg("metastore check statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:5: ( KW_MSCK (repair= KW_REPAIR )? ( KW_TABLE tableName ( partitionSpec )? ( COMMA partitionSpec )* )? -> ^( TOK_MSCK ( $repair)? ( tableName ( partitionSpec )* )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:7: KW_MSCK (repair= KW_REPAIR )? ( KW_TABLE tableName ( partitionSpec )? ( COMMA partitionSpec )* )?
      {
        KW_MSCK596 = (Token) match(input, KW_MSCK, FOLLOW_KW_MSCK_in_metastoreCheck9068);
        stream_KW_MSCK.add(KW_MSCK596);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:15: (repair= KW_REPAIR )?
        int alt175 = 2;
        switch (input.LA(1)) {
          case KW_REPAIR: {
            alt175 = 1;
          }
            break;
        }

        switch (alt175) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:16: repair= KW_REPAIR
          {
            repair = (Token) match(input, KW_REPAIR, FOLLOW_KW_REPAIR_in_metastoreCheck9073);
            stream_KW_REPAIR.add(repair);
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:35: ( KW_TABLE tableName ( partitionSpec )? ( COMMA partitionSpec )* )?
        int alt178 = 2;
        switch (input.LA(1)) {
          case KW_TABLE: {
            alt178 = 1;
          }
            break;
        }

        switch (alt178) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:36: KW_TABLE tableName ( partitionSpec )? ( COMMA partitionSpec )*
          {
            KW_TABLE597 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_metastoreCheck9078);
            stream_KW_TABLE.add(KW_TABLE597);

            pushFollow(FOLLOW_tableName_in_metastoreCheck9080);
            tableName598 = tableName();

            state._fsp--;

            stream_tableName.add(tableName598.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:55: ( partitionSpec )?
            int alt176 = 2;
            switch (input.LA(1)) {
              case KW_PARTITION: {
                alt176 = 1;
              }
                break;
            }

            switch (alt176) {
              case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:55: partitionSpec
              {
                pushFollow(FOLLOW_partitionSpec_in_metastoreCheck9082);
                partitionSpec599 = partitionSpec();

                state._fsp--;

                stream_partitionSpec.add(partitionSpec599.getTree());
              }
                break;
            }

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:70: ( COMMA partitionSpec )*
            loop177: do {
              int alt177 = 2;
              switch (input.LA(1)) {
                case COMMA: {
                  alt177 = 1;
                }
                  break;
              }

              switch (alt177) {
                case 1:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:71: COMMA partitionSpec
                {
                  COMMA600 = (Token) match(input, COMMA, FOLLOW_COMMA_in_metastoreCheck9086);
                  stream_COMMA.add(COMMA600);

                  pushFollow(FOLLOW_partitionSpec_in_metastoreCheck9088);
                  partitionSpec601 = partitionSpec();

                  state._fsp--;

                  stream_partitionSpec.add(partitionSpec601.getTree());
                }
                  break;

                default:
                  break loop177;
              }
            } while (true);
          }
            break;
        }

        // AST REWRITE
        // elements: partitionSpec, repair, tableName
        // token labels: repair
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_repair = new RewriteRuleTokenStream(adaptor, "token repair", repair);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1600:5: -> ^( TOK_MSCK ( $repair)? ( tableName ( partitionSpec )* )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1600:8: ^( TOK_MSCK ( $repair)? ( tableName ( partitionSpec )* )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_MSCK, "TOK_MSCK"), root_1);

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1600:20: ( $repair)?
            if (stream_repair.hasNext()) {
              adaptor.addChild(root_1, stream_repair.nextNode());
            }
            stream_repair.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1600:28: ( tableName ( partitionSpec )* )?
            if (stream_partitionSpec.hasNext() || stream_tableName.hasNext()) {
              adaptor.addChild(root_1, stream_tableName.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1600:39: ( partitionSpec )*
              while (stream_partitionSpec.hasNext()) {
                adaptor.addChild(root_1, stream_partitionSpec.nextTree());
              }
              stream_partitionSpec.reset();
            }
            stream_partitionSpec.reset();
            stream_tableName.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "metastoreCheck"

  public static class resourceList_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "resourceList"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1603:1: resourceList : resource ( COMMA resource )* -> ^( TOK_RESOURCE_LIST ( resource )+ ) ;
  public final HiveParser.resourceList_return resourceList() throws RecognitionException {
    HiveParser.resourceList_return retval = new HiveParser.resourceList_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token COMMA603 = null;
    HiveParser.resource_return resource602 = null;

    HiveParser.resource_return resource604 = null;

    CommonTree COMMA603_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleSubtreeStream stream_resource = new RewriteRuleSubtreeStream(adaptor, "rule resource");
    pushMsg("resource list", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1606:3: ( resource ( COMMA resource )* -> ^( TOK_RESOURCE_LIST ( resource )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1607:3: resource ( COMMA resource )*
      {
        pushFollow(FOLLOW_resource_in_resourceList9141);
        resource602 = resource();

        state._fsp--;

        stream_resource.add(resource602.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1607:12: ( COMMA resource )*
        loop179: do {
          int alt179 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt179 = 1;
            }
              break;
          }

          switch (alt179) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1607:13: COMMA resource
            {
              COMMA603 = (Token) match(input, COMMA, FOLLOW_COMMA_in_resourceList9144);
              stream_COMMA.add(COMMA603);

              pushFollow(FOLLOW_resource_in_resourceList9146);
              resource604 = resource();

              state._fsp--;

              stream_resource.add(resource604.getTree());
            }
              break;

            default:
              break loop179;
          }
        } while (true);

        // AST REWRITE
        // elements: resource
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1607:30: -> ^( TOK_RESOURCE_LIST ( resource )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1607:33: ^( TOK_RESOURCE_LIST ( resource )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_RESOURCE_LIST, "TOK_RESOURCE_LIST"), root_1);

            if (!(stream_resource.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_resource.hasNext()) {
              adaptor.addChild(root_1, stream_resource.nextTree());
            }
            stream_resource.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "resourceList"

  public static class resource_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "resource"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1610:1: resource : resType= resourceType resPath= StringLiteral -> ^( TOK_RESOURCE_URI $resType $resPath) ;
  public final HiveParser.resource_return resource() throws RecognitionException {
    HiveParser.resource_return retval = new HiveParser.resource_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token resPath = null;
    HiveParser.resourceType_return resType = null;

    CommonTree resPath_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleSubtreeStream stream_resourceType = new RewriteRuleSubtreeStream(adaptor, "rule resourceType");
    pushMsg("resource", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1613:3: (resType= resourceType resPath= StringLiteral -> ^( TOK_RESOURCE_URI $resType $resPath) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1614:3: resType= resourceType resPath= StringLiteral
      {
        pushFollow(FOLLOW_resourceType_in_resource9184);
        resType = resourceType();

        state._fsp--;

        stream_resourceType.add(resType.getTree());

        resPath = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_resource9188);
        stream_StringLiteral.add(resPath);

        // AST REWRITE
        // elements: resType, resPath
        // token labels: resPath
        // rule labels: resType, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_resPath = new RewriteRuleTokenStream(adaptor, "token resPath", resPath);
        RewriteRuleSubtreeStream stream_resType =
            new RewriteRuleSubtreeStream(adaptor, "rule resType", resType != null ? resType.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1614:46: -> ^( TOK_RESOURCE_URI $resType $resPath)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1614:49: ^( TOK_RESOURCE_URI $resType $resPath)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_RESOURCE_URI, "TOK_RESOURCE_URI"),
                root_1);

            adaptor.addChild(root_1, stream_resType.nextTree());

            adaptor.addChild(root_1, stream_resPath.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "resource"

  public static class resourceType_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "resourceType"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1617:1: resourceType : ( KW_JAR -> ^( TOK_JAR ) | KW_FILE -> ^( TOK_FILE ) | KW_ARCHIVE -> ^( TOK_ARCHIVE ) );
  public final HiveParser.resourceType_return resourceType() throws RecognitionException {
    HiveParser.resourceType_return retval = new HiveParser.resourceType_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_JAR605 = null;
    Token KW_FILE606 = null;
    Token KW_ARCHIVE607 = null;

    CommonTree KW_JAR605_tree = null;
    CommonTree KW_FILE606_tree = null;
    CommonTree KW_ARCHIVE607_tree = null;
    RewriteRuleTokenStream stream_KW_ARCHIVE = new RewriteRuleTokenStream(adaptor, "token KW_ARCHIVE");
    RewriteRuleTokenStream stream_KW_JAR = new RewriteRuleTokenStream(adaptor, "token KW_JAR");
    RewriteRuleTokenStream stream_KW_FILE = new RewriteRuleTokenStream(adaptor, "token KW_FILE");

    pushMsg("resource type", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1620:3: ( KW_JAR -> ^( TOK_JAR ) | KW_FILE -> ^( TOK_FILE ) | KW_ARCHIVE -> ^( TOK_ARCHIVE ) )
      int alt180 = 3;
      switch (input.LA(1)) {
        case KW_JAR: {
          alt180 = 1;
        }
          break;
        case KW_FILE: {
          alt180 = 2;
        }
          break;
        case KW_ARCHIVE: {
          alt180 = 3;
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 180, 0, input);

          throw nvae;
      }

      switch (alt180) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1621:3: KW_JAR
        {
          KW_JAR605 = (Token) match(input, KW_JAR, FOLLOW_KW_JAR_in_resourceType9225);
          stream_KW_JAR.add(KW_JAR605);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1621:10: -> ^( TOK_JAR )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1621:13: ^( TOK_JAR )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_JAR, "TOK_JAR"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1623:3: KW_FILE
        {
          KW_FILE606 = (Token) match(input, KW_FILE, FOLLOW_KW_FILE_in_resourceType9239);
          stream_KW_FILE.add(KW_FILE606);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1623:11: -> ^( TOK_FILE )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1623:14: ^( TOK_FILE )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_FILE, "TOK_FILE"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 3:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1625:3: KW_ARCHIVE
        {
          KW_ARCHIVE607 = (Token) match(input, KW_ARCHIVE, FOLLOW_KW_ARCHIVE_in_resourceType9253);
          stream_KW_ARCHIVE.add(KW_ARCHIVE607);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1625:14: -> ^( TOK_ARCHIVE )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1625:17: ^( TOK_ARCHIVE )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_ARCHIVE, "TOK_ARCHIVE"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "resourceType"

  public static class createFunctionStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "createFunctionStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1628:1: createFunctionStatement : KW_CREATE (temp= KW_TEMPORARY )? KW_FUNCTION functionIdentifier KW_AS StringLiteral ( KW_USING rList= resourceList )? -> {$temp != null}? ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? TOK_TEMPORARY ) -> ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? ) ;
  public final HiveParser.createFunctionStatement_return createFunctionStatement() throws RecognitionException {
    HiveParser.createFunctionStatement_return retval = new HiveParser.createFunctionStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token temp = null;
    Token KW_CREATE608 = null;
    Token KW_FUNCTION609 = null;
    Token KW_AS611 = null;
    Token StringLiteral612 = null;
    Token KW_USING613 = null;
    HiveParser.resourceList_return rList = null;

    HiveParser_IdentifiersParser.functionIdentifier_return functionIdentifier610 = null;

    CommonTree temp_tree = null;
    CommonTree KW_CREATE608_tree = null;
    CommonTree KW_FUNCTION609_tree = null;
    CommonTree KW_AS611_tree = null;
    CommonTree StringLiteral612_tree = null;
    CommonTree KW_USING613_tree = null;
    RewriteRuleTokenStream stream_KW_TEMPORARY = new RewriteRuleTokenStream(adaptor, "token KW_TEMPORARY");
    RewriteRuleTokenStream stream_KW_CREATE = new RewriteRuleTokenStream(adaptor, "token KW_CREATE");
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_USING = new RewriteRuleTokenStream(adaptor, "token KW_USING");
    RewriteRuleTokenStream stream_KW_FUNCTION = new RewriteRuleTokenStream(adaptor, "token KW_FUNCTION");
    RewriteRuleTokenStream stream_KW_AS = new RewriteRuleTokenStream(adaptor, "token KW_AS");
    RewriteRuleSubtreeStream stream_functionIdentifier =
        new RewriteRuleSubtreeStream(adaptor, "rule functionIdentifier");
    RewriteRuleSubtreeStream stream_resourceList = new RewriteRuleSubtreeStream(adaptor, "rule resourceList");
    pushMsg("create function statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1631:5: ( KW_CREATE (temp= KW_TEMPORARY )? KW_FUNCTION functionIdentifier KW_AS StringLiteral ( KW_USING rList= resourceList )? -> {$temp != null}? ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? TOK_TEMPORARY ) -> ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1631:7: KW_CREATE (temp= KW_TEMPORARY )? KW_FUNCTION functionIdentifier KW_AS StringLiteral ( KW_USING rList= resourceList )?
      {
        KW_CREATE608 = (Token) match(input, KW_CREATE, FOLLOW_KW_CREATE_in_createFunctionStatement9284);
        stream_KW_CREATE.add(KW_CREATE608);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1631:17: (temp= KW_TEMPORARY )?
        int alt181 = 2;
        switch (input.LA(1)) {
          case KW_TEMPORARY: {
            alt181 = 1;
          }
            break;
        }

        switch (alt181) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1631:18: temp= KW_TEMPORARY
          {
            temp = (Token) match(input, KW_TEMPORARY, FOLLOW_KW_TEMPORARY_in_createFunctionStatement9289);
            stream_KW_TEMPORARY.add(temp);
          }
            break;
        }

        KW_FUNCTION609 = (Token) match(input, KW_FUNCTION, FOLLOW_KW_FUNCTION_in_createFunctionStatement9293);
        stream_KW_FUNCTION.add(KW_FUNCTION609);

        pushFollow(FOLLOW_functionIdentifier_in_createFunctionStatement9295);
        functionIdentifier610 = functionIdentifier();

        state._fsp--;

        stream_functionIdentifier.add(functionIdentifier610.getTree());

        KW_AS611 = (Token) match(input, KW_AS, FOLLOW_KW_AS_in_createFunctionStatement9297);
        stream_KW_AS.add(KW_AS611);

        StringLiteral612 = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_createFunctionStatement9299);
        stream_StringLiteral.add(StringLiteral612);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1632:7: ( KW_USING rList= resourceList )?
        int alt182 = 2;
        switch (input.LA(1)) {
          case KW_USING: {
            alt182 = 1;
          }
            break;
        }

        switch (alt182) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1632:8: KW_USING rList= resourceList
          {
            KW_USING613 = (Token) match(input, KW_USING, FOLLOW_KW_USING_in_createFunctionStatement9308);
            stream_KW_USING.add(KW_USING613);

            pushFollow(FOLLOW_resourceList_in_createFunctionStatement9312);
            rList = resourceList();

            state._fsp--;

            stream_resourceList.add(rList.getTree());
          }
            break;
        }

        // AST REWRITE
        // elements: functionIdentifier, StringLiteral, rList, functionIdentifier, StringLiteral, rList
        // token labels:
        // rule labels: rList, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_rList =
            new RewriteRuleSubtreeStream(adaptor, "rule rList", rList != null ? rList.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1633:5: -> {$temp != null}? ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? TOK_TEMPORARY )
        if (temp != null) {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1633:25: ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? TOK_TEMPORARY )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_CREATEFUNCTION, "TOK_CREATEFUNCTION"), root_1);

            adaptor.addChild(root_1, stream_functionIdentifier.nextTree());

            adaptor.addChild(root_1, stream_StringLiteral.nextNode());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1633:80: ( $rList)?
            if (stream_rList.hasNext()) {
              adaptor.addChild(root_1, stream_rList.nextTree());
            }
            stream_rList.reset();

            adaptor.addChild(root_1, (CommonTree) adaptor.create(TOK_TEMPORARY, "TOK_TEMPORARY"));

            adaptor.addChild(root_0, root_1);
          }
        } else // 1634:5: -> ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1634:25: ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_CREATEFUNCTION, "TOK_CREATEFUNCTION"), root_1);

            adaptor.addChild(root_1, stream_functionIdentifier.nextTree());

            adaptor.addChild(root_1, stream_StringLiteral.nextNode());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1634:80: ( $rList)?
            if (stream_rList.hasNext()) {
              adaptor.addChild(root_1, stream_rList.nextTree());
            }
            stream_rList.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "createFunctionStatement"

  public static class dropFunctionStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "dropFunctionStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1637:1: dropFunctionStatement : KW_DROP (temp= KW_TEMPORARY )? KW_FUNCTION ( ifExists )? functionIdentifier -> {$temp != null}? ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? TOK_TEMPORARY ) -> ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? ) ;
  public final HiveParser.dropFunctionStatement_return dropFunctionStatement() throws RecognitionException {
    HiveParser.dropFunctionStatement_return retval = new HiveParser.dropFunctionStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token temp = null;
    Token KW_DROP614 = null;
    Token KW_FUNCTION615 = null;
    HiveParser.ifExists_return ifExists616 = null;

    HiveParser_IdentifiersParser.functionIdentifier_return functionIdentifier617 = null;

    CommonTree temp_tree = null;
    CommonTree KW_DROP614_tree = null;
    CommonTree KW_FUNCTION615_tree = null;
    RewriteRuleTokenStream stream_KW_DROP = new RewriteRuleTokenStream(adaptor, "token KW_DROP");
    RewriteRuleTokenStream stream_KW_TEMPORARY = new RewriteRuleTokenStream(adaptor, "token KW_TEMPORARY");
    RewriteRuleTokenStream stream_KW_FUNCTION = new RewriteRuleTokenStream(adaptor, "token KW_FUNCTION");
    RewriteRuleSubtreeStream stream_ifExists = new RewriteRuleSubtreeStream(adaptor, "rule ifExists");
    RewriteRuleSubtreeStream stream_functionIdentifier =
        new RewriteRuleSubtreeStream(adaptor, "rule functionIdentifier");
    pushMsg("drop function statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1640:5: ( KW_DROP (temp= KW_TEMPORARY )? KW_FUNCTION ( ifExists )? functionIdentifier -> {$temp != null}? ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? TOK_TEMPORARY ) -> ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1640:7: KW_DROP (temp= KW_TEMPORARY )? KW_FUNCTION ( ifExists )? functionIdentifier
      {
        KW_DROP614 = (Token) match(input, KW_DROP, FOLLOW_KW_DROP_in_dropFunctionStatement9398);
        stream_KW_DROP.add(KW_DROP614);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1640:15: (temp= KW_TEMPORARY )?
        int alt183 = 2;
        switch (input.LA(1)) {
          case KW_TEMPORARY: {
            alt183 = 1;
          }
            break;
        }

        switch (alt183) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1640:16: temp= KW_TEMPORARY
          {
            temp = (Token) match(input, KW_TEMPORARY, FOLLOW_KW_TEMPORARY_in_dropFunctionStatement9403);
            stream_KW_TEMPORARY.add(temp);
          }
            break;
        }

        KW_FUNCTION615 = (Token) match(input, KW_FUNCTION, FOLLOW_KW_FUNCTION_in_dropFunctionStatement9407);
        stream_KW_FUNCTION.add(KW_FUNCTION615);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1640:48: ( ifExists )?
        int alt184 = 2;
        switch (input.LA(1)) {
          case KW_IF: {
            alt184 = 1;
          }
            break;
        }

        switch (alt184) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1640:48: ifExists
          {
            pushFollow(FOLLOW_ifExists_in_dropFunctionStatement9409);
            ifExists616 = ifExists();

            state._fsp--;

            stream_ifExists.add(ifExists616.getTree());
          }
            break;
        }

        pushFollow(FOLLOW_functionIdentifier_in_dropFunctionStatement9412);
        functionIdentifier617 = functionIdentifier();

        state._fsp--;

        stream_functionIdentifier.add(functionIdentifier617.getTree());

        // AST REWRITE
        // elements: functionIdentifier, ifExists, functionIdentifier, ifExists
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1641:5: -> {$temp != null}? ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? TOK_TEMPORARY )
        if (temp != null) {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1641:25: ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? TOK_TEMPORARY )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DROPFUNCTION, "TOK_DROPFUNCTION"),
                root_1);

            adaptor.addChild(root_1, stream_functionIdentifier.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1641:63: ( ifExists )?
            if (stream_ifExists.hasNext()) {
              adaptor.addChild(root_1, stream_ifExists.nextTree());
            }
            stream_ifExists.reset();

            adaptor.addChild(root_1, (CommonTree) adaptor.create(TOK_TEMPORARY, "TOK_TEMPORARY"));

            adaptor.addChild(root_0, root_1);
          }
        } else // 1642:5: -> ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1642:25: ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DROPFUNCTION, "TOK_DROPFUNCTION"),
                root_1);

            adaptor.addChild(root_1, stream_functionIdentifier.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1642:63: ( ifExists )?
            if (stream_ifExists.hasNext()) {
              adaptor.addChild(root_1, stream_ifExists.nextTree());
            }
            stream_ifExists.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "dropFunctionStatement"

  public static class reloadFunctionStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "reloadFunctionStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1645:1: reloadFunctionStatement : KW_RELOAD KW_FUNCTION -> ^( TOK_RELOADFUNCTION ) ;
  public final HiveParser.reloadFunctionStatement_return reloadFunctionStatement() throws RecognitionException {
    HiveParser.reloadFunctionStatement_return retval = new HiveParser.reloadFunctionStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_RELOAD618 = null;
    Token KW_FUNCTION619 = null;

    CommonTree KW_RELOAD618_tree = null;
    CommonTree KW_FUNCTION619_tree = null;
    RewriteRuleTokenStream stream_KW_FUNCTION = new RewriteRuleTokenStream(adaptor, "token KW_FUNCTION");
    RewriteRuleTokenStream stream_KW_RELOAD = new RewriteRuleTokenStream(adaptor, "token KW_RELOAD");

    pushMsg("reload function statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1648:5: ( KW_RELOAD KW_FUNCTION -> ^( TOK_RELOADFUNCTION ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1648:7: KW_RELOAD KW_FUNCTION
      {
        KW_RELOAD618 = (Token) match(input, KW_RELOAD, FOLLOW_KW_RELOAD_in_reloadFunctionStatement9490);
        stream_KW_RELOAD.add(KW_RELOAD618);

        KW_FUNCTION619 = (Token) match(input, KW_FUNCTION, FOLLOW_KW_FUNCTION_in_reloadFunctionStatement9492);
        stream_KW_FUNCTION.add(KW_FUNCTION619);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1648:29: -> ^( TOK_RELOADFUNCTION )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1648:32: ^( TOK_RELOADFUNCTION )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_RELOADFUNCTION, "TOK_RELOADFUNCTION"), root_1);

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "reloadFunctionStatement"

  public static class createMacroStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "createMacroStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1650:1: createMacroStatement : KW_CREATE KW_TEMPORARY KW_MACRO Identifier LPAREN ( columnNameTypeList )? RPAREN expression -> ^( TOK_CREATEMACRO Identifier ( columnNameTypeList )? expression ) ;
  public final HiveParser.createMacroStatement_return createMacroStatement() throws RecognitionException {
    HiveParser.createMacroStatement_return retval = new HiveParser.createMacroStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_CREATE620 = null;
    Token KW_TEMPORARY621 = null;
    Token KW_MACRO622 = null;
    Token Identifier623 = null;
    Token LPAREN624 = null;
    Token RPAREN626 = null;
    HiveParser.columnNameTypeList_return columnNameTypeList625 = null;

    HiveParser_IdentifiersParser.expression_return expression627 = null;

    CommonTree KW_CREATE620_tree = null;
    CommonTree KW_TEMPORARY621_tree = null;
    CommonTree KW_MACRO622_tree = null;
    CommonTree Identifier623_tree = null;
    CommonTree LPAREN624_tree = null;
    CommonTree RPAREN626_tree = null;
    RewriteRuleTokenStream stream_KW_TEMPORARY = new RewriteRuleTokenStream(adaptor, "token KW_TEMPORARY");
    RewriteRuleTokenStream stream_Identifier = new RewriteRuleTokenStream(adaptor, "token Identifier");
    RewriteRuleTokenStream stream_KW_CREATE = new RewriteRuleTokenStream(adaptor, "token KW_CREATE");
    RewriteRuleTokenStream stream_KW_MACRO = new RewriteRuleTokenStream(adaptor, "token KW_MACRO");
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleSubtreeStream stream_expression = new RewriteRuleSubtreeStream(adaptor, "rule expression");
    RewriteRuleSubtreeStream stream_columnNameTypeList =
        new RewriteRuleSubtreeStream(adaptor, "rule columnNameTypeList");
    pushMsg("create macro statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1653:5: ( KW_CREATE KW_TEMPORARY KW_MACRO Identifier LPAREN ( columnNameTypeList )? RPAREN expression -> ^( TOK_CREATEMACRO Identifier ( columnNameTypeList )? expression ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1653:7: KW_CREATE KW_TEMPORARY KW_MACRO Identifier LPAREN ( columnNameTypeList )? RPAREN expression
      {
        KW_CREATE620 = (Token) match(input, KW_CREATE, FOLLOW_KW_CREATE_in_createMacroStatement9520);
        stream_KW_CREATE.add(KW_CREATE620);

        KW_TEMPORARY621 = (Token) match(input, KW_TEMPORARY, FOLLOW_KW_TEMPORARY_in_createMacroStatement9522);
        stream_KW_TEMPORARY.add(KW_TEMPORARY621);

        KW_MACRO622 = (Token) match(input, KW_MACRO, FOLLOW_KW_MACRO_in_createMacroStatement9524);
        stream_KW_MACRO.add(KW_MACRO622);

        Identifier623 = (Token) match(input, Identifier, FOLLOW_Identifier_in_createMacroStatement9526);
        stream_Identifier.add(Identifier623);

        LPAREN624 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_createMacroStatement9534);
        stream_LPAREN.add(LPAREN624);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1654:14: ( columnNameTypeList )?
        int alt185 = 2;
        switch (input.LA(1)) {
          case Identifier:
          case KW_ADD:
          case KW_ADMIN:
          case KW_AFTER:
          case KW_ALL:
          case KW_ALTER:
          case KW_ANALYZE:
          case KW_ARCHIVE:
          case KW_ARRAY:
          case KW_AS:
          case KW_ASC:
          case KW_AUTHORIZATION:
          case KW_BEFORE:
          case KW_BETWEEN:
          case KW_BIGINT:
          case KW_BINARY:
          case KW_BOOLEAN:
          case KW_BOTH:
          case KW_BUCKET:
          case KW_BUCKETS:
          case KW_BY:
          case KW_CASCADE:
          case KW_CHANGE:
          case KW_CLUSTER:
          case KW_CLUSTERED:
          case KW_CLUSTERSTATUS:
          case KW_COLLECTION:
          case KW_COLUMNS:
          case KW_COMMENT:
          case KW_COMPACT:
          case KW_COMPACTIONS:
          case KW_COMPUTE:
          case KW_CONCATENATE:
          case KW_CONTINUE:
          case KW_CREATE:
          case KW_CUBE:
          case KW_CURSOR:
          case KW_DATA:
          case KW_DATABASES:
          case KW_DATE:
          case KW_DATETIME:
          case KW_DBPROPERTIES:
          case KW_DECIMAL:
          case KW_DEFAULT:
          case KW_DEFERRED:
          case KW_DEFINED:
          case KW_DELETE:
          case KW_DELIMITED:
          case KW_DEPENDENCY:
          case KW_DESC:
          case KW_DESCRIBE:
          case KW_DIRECTORIES:
          case KW_DIRECTORY:
          case KW_DISABLE:
          case KW_DISTRIBUTE:
          case KW_DOUBLE:
          case KW_DROP:
          case KW_ELEM_TYPE:
          case KW_ENABLE:
          case KW_ESCAPED:
          case KW_EXCLUSIVE:
          case KW_EXISTS:
          case KW_EXPLAIN:
          case KW_EXPORT:
          case KW_EXTERNAL:
          case KW_FALSE:
          case KW_FETCH:
          case KW_FIELDS:
          case KW_FILE:
          case KW_FILEFORMAT:
          case KW_FIRST:
          case KW_FLOAT:
          case KW_FOR:
          case KW_FORMAT:
          case KW_FORMATTED:
          case KW_FULL:
          case KW_FUNCTIONS:
          case KW_GRANT:
          case KW_GROUP:
          case KW_GROUPING:
          case KW_HOLD_DDLTIME:
          case KW_IDXPROPERTIES:
          case KW_IGNORE:
          case KW_IMPORT:
          case KW_IN:
          case KW_INDEX:
          case KW_INDEXES:
          case KW_INNER:
          case KW_INPATH:
          case KW_INPUTDRIVER:
          case KW_INPUTFORMAT:
          case KW_INSERT:
          case KW_INT:
          case KW_INTERSECT:
          case KW_INTO:
          case KW_IS:
          case KW_ITEMS:
          case KW_JAR:
          case KW_KEYS:
          case KW_KEY_TYPE:
          case KW_LATERAL:
          case KW_LEFT:
          case KW_LIKE:
          case KW_LIMIT:
          case KW_LINES:
          case KW_LOAD:
          case KW_LOCAL:
          case KW_LOCATION:
          case KW_LOCK:
          case KW_LOCKS:
          case KW_LOGICAL:
          case KW_LONG:
          case KW_MAPJOIN:
          case KW_MATERIALIZED:
          case KW_METADATA:
          case KW_MINUS:
          case KW_MSCK:
          case KW_NONE:
          case KW_NOSCAN:
          case KW_NO_DROP:
          case KW_NULL:
          case KW_OF:
          case KW_OFFLINE:
          case KW_OPTION:
          case KW_ORDER:
          case KW_OUT:
          case KW_OUTER:
          case KW_OUTPUTDRIVER:
          case KW_OUTPUTFORMAT:
          case KW_OVERWRITE:
          case KW_OWNER:
          case KW_PARTITION:
          case KW_PARTITIONED:
          case KW_PARTITIONS:
          case KW_PERCENT:
          case KW_PLUS:
          case KW_PRETTY:
          case KW_PRINCIPALS:
          case KW_PROCEDURE:
          case KW_PROTECTION:
          case KW_PURGE:
          case KW_RANGE:
          case KW_READ:
          case KW_READONLY:
          case KW_READS:
          case KW_REBUILD:
          case KW_RECORDREADER:
          case KW_RECORDWRITER:
          case KW_REGEXP:
          case KW_RELOAD:
          case KW_RENAME:
          case KW_REPAIR:
          case KW_REPLACE:
          case KW_REPLICATION:
          case KW_RESTRICT:
          case KW_REVOKE:
          case KW_REWRITE:
          case KW_RIGHT:
          case KW_RLIKE:
          case KW_ROLE:
          case KW_ROLES:
          case KW_ROLLUP:
          case KW_ROW:
          case KW_ROWS:
          case KW_SCHEMA:
          case KW_SCHEMAS:
          case KW_SEMI:
          case KW_SERDE:
          case KW_SERDEPROPERTIES:
          case KW_SERVER:
          case KW_SET:
          case KW_SETS:
          case KW_SHARED:
          case KW_SHOW:
          case KW_SHOW_DATABASE:
          case KW_SKEWED:
          case KW_SMALLINT:
          case KW_SORT:
          case KW_SORTED:
          case KW_SSL:
          case KW_STATISTICS:
          case KW_STORED:
          case KW_STREAMTABLE:
          case KW_STRING:
          case KW_STRUCT:
          case KW_TABLE:
          case KW_TABLES:
          case KW_TBLPROPERTIES:
          case KW_TEMPORARY:
          case KW_TERMINATED:
          case KW_TIMESTAMP:
          case KW_TINYINT:
          case KW_TO:
          case KW_TOUCH:
          case KW_TRANSACTIONS:
          case KW_TRIGGER:
          case KW_TRUE:
          case KW_TRUNCATE:
          case KW_UNARCHIVE:
          case KW_UNDO:
          case KW_UNION:
          case KW_UNIONTYPE:
          case KW_UNLOCK:
          case KW_UNSET:
          case KW_UNSIGNED:
          case KW_UPDATE:
          case KW_URI:
          case KW_USE:
          case KW_USER:
          case KW_USING:
          case KW_UTC:
          case KW_UTCTIMESTAMP:
          case KW_VALUES:
          case KW_VALUE_TYPE:
          case KW_VIEW:
          case KW_WHILE:
          case KW_WITH: {
            alt185 = 1;
          }
            break;
        }

        switch (alt185) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1654:14: columnNameTypeList
          {
            pushFollow(FOLLOW_columnNameTypeList_in_createMacroStatement9536);
            columnNameTypeList625 = columnNameTypeList();

            state._fsp--;

            stream_columnNameTypeList.add(columnNameTypeList625.getTree());
          }
            break;
        }

        RPAREN626 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_createMacroStatement9539);
        stream_RPAREN.add(RPAREN626);

        pushFollow(FOLLOW_expression_in_createMacroStatement9541);
        expression627 = expression();

        state._fsp--;

        stream_expression.add(expression627.getTree());

        // AST REWRITE
        // elements: columnNameTypeList, expression, Identifier
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1655:5: -> ^( TOK_CREATEMACRO Identifier ( columnNameTypeList )? expression )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1655:8: ^( TOK_CREATEMACRO Identifier ( columnNameTypeList )? expression )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_CREATEMACRO, "TOK_CREATEMACRO"),
                root_1);

            adaptor.addChild(root_1, stream_Identifier.nextNode());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1655:37: ( columnNameTypeList )?
            if (stream_columnNameTypeList.hasNext()) {
              adaptor.addChild(root_1, stream_columnNameTypeList.nextTree());
            }
            stream_columnNameTypeList.reset();

            adaptor.addChild(root_1, stream_expression.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "createMacroStatement"

  public static class dropMacroStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "dropMacroStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1658:1: dropMacroStatement : KW_DROP KW_TEMPORARY KW_MACRO ( ifExists )? Identifier -> ^( TOK_DROPMACRO Identifier ( ifExists )? ) ;
  public final HiveParser.dropMacroStatement_return dropMacroStatement() throws RecognitionException {
    HiveParser.dropMacroStatement_return retval = new HiveParser.dropMacroStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_DROP628 = null;
    Token KW_TEMPORARY629 = null;
    Token KW_MACRO630 = null;
    Token Identifier632 = null;
    HiveParser.ifExists_return ifExists631 = null;

    CommonTree KW_DROP628_tree = null;
    CommonTree KW_TEMPORARY629_tree = null;
    CommonTree KW_MACRO630_tree = null;
    CommonTree Identifier632_tree = null;
    RewriteRuleTokenStream stream_KW_DROP = new RewriteRuleTokenStream(adaptor, "token KW_DROP");
    RewriteRuleTokenStream stream_KW_TEMPORARY = new RewriteRuleTokenStream(adaptor, "token KW_TEMPORARY");
    RewriteRuleTokenStream stream_Identifier = new RewriteRuleTokenStream(adaptor, "token Identifier");
    RewriteRuleTokenStream stream_KW_MACRO = new RewriteRuleTokenStream(adaptor, "token KW_MACRO");
    RewriteRuleSubtreeStream stream_ifExists = new RewriteRuleSubtreeStream(adaptor, "rule ifExists");
    pushMsg("drop macro statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1661:5: ( KW_DROP KW_TEMPORARY KW_MACRO ( ifExists )? Identifier -> ^( TOK_DROPMACRO Identifier ( ifExists )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1661:7: KW_DROP KW_TEMPORARY KW_MACRO ( ifExists )? Identifier
      {
        KW_DROP628 = (Token) match(input, KW_DROP, FOLLOW_KW_DROP_in_dropMacroStatement9585);
        stream_KW_DROP.add(KW_DROP628);

        KW_TEMPORARY629 = (Token) match(input, KW_TEMPORARY, FOLLOW_KW_TEMPORARY_in_dropMacroStatement9587);
        stream_KW_TEMPORARY.add(KW_TEMPORARY629);

        KW_MACRO630 = (Token) match(input, KW_MACRO, FOLLOW_KW_MACRO_in_dropMacroStatement9589);
        stream_KW_MACRO.add(KW_MACRO630);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1661:37: ( ifExists )?
        int alt186 = 2;
        switch (input.LA(1)) {
          case KW_IF: {
            alt186 = 1;
          }
            break;
        }

        switch (alt186) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1661:37: ifExists
          {
            pushFollow(FOLLOW_ifExists_in_dropMacroStatement9591);
            ifExists631 = ifExists();

            state._fsp--;

            stream_ifExists.add(ifExists631.getTree());
          }
            break;
        }

        Identifier632 = (Token) match(input, Identifier, FOLLOW_Identifier_in_dropMacroStatement9594);
        stream_Identifier.add(Identifier632);

        // AST REWRITE
        // elements: ifExists, Identifier
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1662:5: -> ^( TOK_DROPMACRO Identifier ( ifExists )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1662:8: ^( TOK_DROPMACRO Identifier ( ifExists )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DROPMACRO, "TOK_DROPMACRO"), root_1);

            adaptor.addChild(root_1, stream_Identifier.nextNode());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1662:35: ( ifExists )?
            if (stream_ifExists.hasNext()) {
              adaptor.addChild(root_1, stream_ifExists.nextTree());
            }
            stream_ifExists.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "dropMacroStatement"

  public static class createViewStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "createViewStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1665:1: createViewStatement : KW_CREATE ( orReplace )? KW_VIEW ( ifNotExists )? name= tableName ( LPAREN columnNameCommentList RPAREN )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? KW_AS selectStatementWithCTE -> ^( TOK_CREATEVIEW $name ( orReplace )? ( ifNotExists )? ( columnNameCommentList )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? selectStatementWithCTE ) ;
  public final HiveParser.createViewStatement_return createViewStatement() throws RecognitionException {
    HiveParser.createViewStatement_return retval = new HiveParser.createViewStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_CREATE633 = null;
    Token KW_VIEW635 = null;
    Token LPAREN637 = null;
    Token RPAREN639 = null;
    Token KW_AS643 = null;
    HiveParser_FromClauseParser.tableName_return name = null;

    HiveParser.orReplace_return orReplace634 = null;

    HiveParser.ifNotExists_return ifNotExists636 = null;

    HiveParser.columnNameCommentList_return columnNameCommentList638 = null;

    HiveParser.tableComment_return tableComment640 = null;

    HiveParser.viewPartition_return viewPartition641 = null;

    HiveParser.tablePropertiesPrefixed_return tablePropertiesPrefixed642 = null;

    HiveParser.selectStatementWithCTE_return selectStatementWithCTE644 = null;

    CommonTree KW_CREATE633_tree = null;
    CommonTree KW_VIEW635_tree = null;
    CommonTree LPAREN637_tree = null;
    CommonTree RPAREN639_tree = null;
    CommonTree KW_AS643_tree = null;
    RewriteRuleTokenStream stream_KW_VIEW = new RewriteRuleTokenStream(adaptor, "token KW_VIEW");
    RewriteRuleTokenStream stream_KW_CREATE = new RewriteRuleTokenStream(adaptor, "token KW_CREATE");
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleTokenStream stream_KW_AS = new RewriteRuleTokenStream(adaptor, "token KW_AS");
    RewriteRuleSubtreeStream stream_columnNameCommentList =
        new RewriteRuleSubtreeStream(adaptor, "rule columnNameCommentList");
    RewriteRuleSubtreeStream stream_selectStatementWithCTE =
        new RewriteRuleSubtreeStream(adaptor, "rule selectStatementWithCTE");
    RewriteRuleSubtreeStream stream_orReplace = new RewriteRuleSubtreeStream(adaptor, "rule orReplace");
    RewriteRuleSubtreeStream stream_tablePropertiesPrefixed =
        new RewriteRuleSubtreeStream(adaptor, "rule tablePropertiesPrefixed");
    RewriteRuleSubtreeStream stream_ifNotExists = new RewriteRuleSubtreeStream(adaptor, "rule ifNotExists");
    RewriteRuleSubtreeStream stream_tableComment = new RewriteRuleSubtreeStream(adaptor, "rule tableComment");
    RewriteRuleSubtreeStream stream_viewPartition = new RewriteRuleSubtreeStream(adaptor, "rule viewPartition");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");

    pushMsg("create view statement", state);

    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1670:5: ( KW_CREATE ( orReplace )? KW_VIEW ( ifNotExists )? name= tableName ( LPAREN columnNameCommentList RPAREN )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? KW_AS selectStatementWithCTE -> ^( TOK_CREATEVIEW $name ( orReplace )? ( ifNotExists )? ( columnNameCommentList )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? selectStatementWithCTE ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1670:7: KW_CREATE ( orReplace )? KW_VIEW ( ifNotExists )? name= tableName ( LPAREN columnNameCommentList RPAREN )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? KW_AS selectStatementWithCTE
      {
        KW_CREATE633 = (Token) match(input, KW_CREATE, FOLLOW_KW_CREATE_in_createViewStatement9636);
        stream_KW_CREATE.add(KW_CREATE633);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1670:17: ( orReplace )?
        int alt187 = 2;
        switch (input.LA(1)) {
          case KW_OR: {
            alt187 = 1;
          }
            break;
        }

        switch (alt187) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1670:18: orReplace
          {
            pushFollow(FOLLOW_orReplace_in_createViewStatement9639);
            orReplace634 = orReplace();

            state._fsp--;

            stream_orReplace.add(orReplace634.getTree());
          }
            break;
        }

        KW_VIEW635 = (Token) match(input, KW_VIEW, FOLLOW_KW_VIEW_in_createViewStatement9643);
        stream_KW_VIEW.add(KW_VIEW635);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1670:38: ( ifNotExists )?
        int alt188 = 2;
        switch (input.LA(1)) {
          case KW_IF: {
            alt188 = 1;
          }
            break;
        }

        switch (alt188) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1670:39: ifNotExists
          {
            pushFollow(FOLLOW_ifNotExists_in_createViewStatement9646);
            ifNotExists636 = ifNotExists();

            state._fsp--;

            stream_ifNotExists.add(ifNotExists636.getTree());
          }
            break;
        }

        pushFollow(FOLLOW_tableName_in_createViewStatement9652);
        name = tableName();

        state._fsp--;

        stream_tableName.add(name.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1671:9: ( LPAREN columnNameCommentList RPAREN )?
        int alt189 = 2;
        switch (input.LA(1)) {
          case LPAREN: {
            alt189 = 1;
          }
            break;
        }

        switch (alt189) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1671:10: LPAREN columnNameCommentList RPAREN
          {
            LPAREN637 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_createViewStatement9663);
            stream_LPAREN.add(LPAREN637);

            pushFollow(FOLLOW_columnNameCommentList_in_createViewStatement9665);
            columnNameCommentList638 = columnNameCommentList();

            state._fsp--;

            stream_columnNameCommentList.add(columnNameCommentList638.getTree());

            RPAREN639 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_createViewStatement9667);
            stream_RPAREN.add(RPAREN639);
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1671:48: ( tableComment )?
        int alt190 = 2;
        switch (input.LA(1)) {
          case KW_COMMENT: {
            alt190 = 1;
          }
            break;
        }

        switch (alt190) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1671:48: tableComment
          {
            pushFollow(FOLLOW_tableComment_in_createViewStatement9671);
            tableComment640 = tableComment();

            state._fsp--;

            stream_tableComment.add(tableComment640.getTree());
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1671:62: ( viewPartition )?
        int alt191 = 2;
        switch (input.LA(1)) {
          case KW_PARTITIONED: {
            alt191 = 1;
          }
            break;
        }

        switch (alt191) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1671:62: viewPartition
          {
            pushFollow(FOLLOW_viewPartition_in_createViewStatement9674);
            viewPartition641 = viewPartition();

            state._fsp--;

            stream_viewPartition.add(viewPartition641.getTree());
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1672:9: ( tablePropertiesPrefixed )?
        int alt192 = 2;
        switch (input.LA(1)) {
          case KW_TBLPROPERTIES: {
            alt192 = 1;
          }
            break;
        }

        switch (alt192) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1672:9: tablePropertiesPrefixed
          {
            pushFollow(FOLLOW_tablePropertiesPrefixed_in_createViewStatement9685);
            tablePropertiesPrefixed642 = tablePropertiesPrefixed();

            state._fsp--;

            stream_tablePropertiesPrefixed.add(tablePropertiesPrefixed642.getTree());
          }
            break;
        }

        KW_AS643 = (Token) match(input, KW_AS, FOLLOW_KW_AS_in_createViewStatement9696);
        stream_KW_AS.add(KW_AS643);

        pushFollow(FOLLOW_selectStatementWithCTE_in_createViewStatement9706);
        selectStatementWithCTE644 = selectStatementWithCTE();

        state._fsp--;

        stream_selectStatementWithCTE.add(selectStatementWithCTE644.getTree());

        // AST REWRITE
        // elements: tablePropertiesPrefixed, ifNotExists, columnNameCommentList, orReplace, viewPartition, name, tableComment, selectStatementWithCTE
        // token labels:
        // rule labels: name, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_name =
            new RewriteRuleSubtreeStream(adaptor, "rule name", name != null ? name.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1675:5: -> ^( TOK_CREATEVIEW $name ( orReplace )? ( ifNotExists )? ( columnNameCommentList )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? selectStatementWithCTE )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1675:8: ^( TOK_CREATEVIEW $name ( orReplace )? ( ifNotExists )? ( columnNameCommentList )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? selectStatementWithCTE )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_CREATEVIEW, "TOK_CREATEVIEW"), root_1);

            adaptor.addChild(root_1, stream_name.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1675:31: ( orReplace )?
            if (stream_orReplace.hasNext()) {
              adaptor.addChild(root_1, stream_orReplace.nextTree());
            }
            stream_orReplace.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1676:10: ( ifNotExists )?
            if (stream_ifNotExists.hasNext()) {
              adaptor.addChild(root_1, stream_ifNotExists.nextTree());
            }
            stream_ifNotExists.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1677:10: ( columnNameCommentList )?
            if (stream_columnNameCommentList.hasNext()) {
              adaptor.addChild(root_1, stream_columnNameCommentList.nextTree());
            }
            stream_columnNameCommentList.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1678:10: ( tableComment )?
            if (stream_tableComment.hasNext()) {
              adaptor.addChild(root_1, stream_tableComment.nextTree());
            }
            stream_tableComment.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1679:10: ( viewPartition )?
            if (stream_viewPartition.hasNext()) {
              adaptor.addChild(root_1, stream_viewPartition.nextTree());
            }
            stream_viewPartition.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1680:10: ( tablePropertiesPrefixed )?
            if (stream_tablePropertiesPrefixed.hasNext()) {
              adaptor.addChild(root_1, stream_tablePropertiesPrefixed.nextTree());
            }
            stream_tablePropertiesPrefixed.reset();

            adaptor.addChild(root_1, stream_selectStatementWithCTE.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "createViewStatement"

  public static class viewPartition_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "viewPartition"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1685:1: viewPartition : KW_PARTITIONED KW_ON LPAREN columnNameList RPAREN -> ^( TOK_VIEWPARTCOLS columnNameList ) ;
  public final HiveParser.viewPartition_return viewPartition() throws RecognitionException {
    HiveParser.viewPartition_return retval = new HiveParser.viewPartition_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_PARTITIONED645 = null;
    Token KW_ON646 = null;
    Token LPAREN647 = null;
    Token RPAREN649 = null;
    HiveParser.columnNameList_return columnNameList648 = null;

    CommonTree KW_PARTITIONED645_tree = null;
    CommonTree KW_ON646_tree = null;
    CommonTree LPAREN647_tree = null;
    CommonTree RPAREN649_tree = null;
    RewriteRuleTokenStream stream_KW_PARTITIONED = new RewriteRuleTokenStream(adaptor, "token KW_PARTITIONED");
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_KW_ON = new RewriteRuleTokenStream(adaptor, "token KW_ON");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleSubtreeStream stream_columnNameList = new RewriteRuleSubtreeStream(adaptor, "rule columnNameList");
    pushMsg("view partition specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1688:5: ( KW_PARTITIONED KW_ON LPAREN columnNameList RPAREN -> ^( TOK_VIEWPARTCOLS columnNameList ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1688:7: KW_PARTITIONED KW_ON LPAREN columnNameList RPAREN
      {
        KW_PARTITIONED645 = (Token) match(input, KW_PARTITIONED, FOLLOW_KW_PARTITIONED_in_viewPartition9829);
        stream_KW_PARTITIONED.add(KW_PARTITIONED645);

        KW_ON646 = (Token) match(input, KW_ON, FOLLOW_KW_ON_in_viewPartition9831);
        stream_KW_ON.add(KW_ON646);

        LPAREN647 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_viewPartition9833);
        stream_LPAREN.add(LPAREN647);

        pushFollow(FOLLOW_columnNameList_in_viewPartition9835);
        columnNameList648 = columnNameList();

        state._fsp--;

        stream_columnNameList.add(columnNameList648.getTree());

        RPAREN649 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_viewPartition9837);
        stream_RPAREN.add(RPAREN649);

        // AST REWRITE
        // elements: columnNameList
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1689:5: -> ^( TOK_VIEWPARTCOLS columnNameList )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1689:8: ^( TOK_VIEWPARTCOLS columnNameList )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_VIEWPARTCOLS, "TOK_VIEWPARTCOLS"),
                root_1);

            adaptor.addChild(root_1, stream_columnNameList.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "viewPartition"

  public static class dropViewStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "dropViewStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1692:1: dropViewStatement : KW_DROP KW_VIEW ( ifExists )? viewName -> ^( TOK_DROPVIEW viewName ( ifExists )? ) ;
  public final HiveParser.dropViewStatement_return dropViewStatement() throws RecognitionException {
    HiveParser.dropViewStatement_return retval = new HiveParser.dropViewStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_DROP650 = null;
    Token KW_VIEW651 = null;
    HiveParser.ifExists_return ifExists652 = null;

    HiveParser_FromClauseParser.viewName_return viewName653 = null;

    CommonTree KW_DROP650_tree = null;
    CommonTree KW_VIEW651_tree = null;
    RewriteRuleTokenStream stream_KW_DROP = new RewriteRuleTokenStream(adaptor, "token KW_DROP");
    RewriteRuleTokenStream stream_KW_VIEW = new RewriteRuleTokenStream(adaptor, "token KW_VIEW");
    RewriteRuleSubtreeStream stream_viewName = new RewriteRuleSubtreeStream(adaptor, "rule viewName");
    RewriteRuleSubtreeStream stream_ifExists = new RewriteRuleSubtreeStream(adaptor, "rule ifExists");
    pushMsg("drop view statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1695:5: ( KW_DROP KW_VIEW ( ifExists )? viewName -> ^( TOK_DROPVIEW viewName ( ifExists )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1695:7: KW_DROP KW_VIEW ( ifExists )? viewName
      {
        KW_DROP650 = (Token) match(input, KW_DROP, FOLLOW_KW_DROP_in_dropViewStatement9876);
        stream_KW_DROP.add(KW_DROP650);

        KW_VIEW651 = (Token) match(input, KW_VIEW, FOLLOW_KW_VIEW_in_dropViewStatement9878);
        stream_KW_VIEW.add(KW_VIEW651);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1695:23: ( ifExists )?
        int alt193 = 2;
        switch (input.LA(1)) {
          case KW_IF: {
            alt193 = 1;
          }
            break;
        }

        switch (alt193) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1695:23: ifExists
          {
            pushFollow(FOLLOW_ifExists_in_dropViewStatement9880);
            ifExists652 = ifExists();

            state._fsp--;

            stream_ifExists.add(ifExists652.getTree());
          }
            break;
        }

        pushFollow(FOLLOW_viewName_in_dropViewStatement9883);
        viewName653 = viewName();

        state._fsp--;

        stream_viewName.add(viewName653.getTree());

        // AST REWRITE
        // elements: viewName, ifExists
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1695:42: -> ^( TOK_DROPVIEW viewName ( ifExists )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1695:45: ^( TOK_DROPVIEW viewName ( ifExists )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DROPVIEW, "TOK_DROPVIEW"), root_1);

            adaptor.addChild(root_1, stream_viewName.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1695:69: ( ifExists )?
            if (stream_ifExists.hasNext()) {
              adaptor.addChild(root_1, stream_ifExists.nextTree());
            }
            stream_ifExists.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "dropViewStatement"

  public static class showFunctionIdentifier_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "showFunctionIdentifier"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1698:1: showFunctionIdentifier : ( functionIdentifier | StringLiteral );
  public final HiveParser.showFunctionIdentifier_return showFunctionIdentifier() throws RecognitionException {
    HiveParser.showFunctionIdentifier_return retval = new HiveParser.showFunctionIdentifier_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token StringLiteral655 = null;
    HiveParser_IdentifiersParser.functionIdentifier_return functionIdentifier654 = null;

    CommonTree StringLiteral655_tree = null;

    pushMsg("identifier for show function statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1701:5: ( functionIdentifier | StringLiteral )
      int alt194 = 2;
      switch (input.LA(1)) {
        case Identifier:
        case KW_ADD:
        case KW_ADMIN:
        case KW_AFTER:
        case KW_ALL:
        case KW_ALTER:
        case KW_ANALYZE:
        case KW_ARCHIVE:
        case KW_ARRAY:
        case KW_AS:
        case KW_ASC:
        case KW_AUTHORIZATION:
        case KW_BEFORE:
        case KW_BETWEEN:
        case KW_BIGINT:
        case KW_BINARY:
        case KW_BOOLEAN:
        case KW_BOTH:
        case KW_BUCKET:
        case KW_BUCKETS:
        case KW_BY:
        case KW_CASCADE:
        case KW_CHANGE:
        case KW_CLUSTER:
        case KW_CLUSTERED:
        case KW_CLUSTERSTATUS:
        case KW_COLLECTION:
        case KW_COLUMNS:
        case KW_COMMENT:
        case KW_COMPACT:
        case KW_COMPACTIONS:
        case KW_COMPUTE:
        case KW_CONCATENATE:
        case KW_CONTINUE:
        case KW_CREATE:
        case KW_CUBE:
        case KW_CURSOR:
        case KW_DATA:
        case KW_DATABASES:
        case KW_DATE:
        case KW_DATETIME:
        case KW_DBPROPERTIES:
        case KW_DECIMAL:
        case KW_DEFAULT:
        case KW_DEFERRED:
        case KW_DEFINED:
        case KW_DELETE:
        case KW_DELIMITED:
        case KW_DEPENDENCY:
        case KW_DESC:
        case KW_DESCRIBE:
        case KW_DIRECTORIES:
        case KW_DIRECTORY:
        case KW_DISABLE:
        case KW_DISTRIBUTE:
        case KW_DOUBLE:
        case KW_DROP:
        case KW_ELEM_TYPE:
        case KW_ENABLE:
        case KW_ESCAPED:
        case KW_EXCLUSIVE:
        case KW_EXISTS:
        case KW_EXPLAIN:
        case KW_EXPORT:
        case KW_EXTERNAL:
        case KW_FALSE:
        case KW_FETCH:
        case KW_FIELDS:
        case KW_FILE:
        case KW_FILEFORMAT:
        case KW_FIRST:
        case KW_FLOAT:
        case KW_FOR:
        case KW_FORMAT:
        case KW_FORMATTED:
        case KW_FULL:
        case KW_FUNCTIONS:
        case KW_GRANT:
        case KW_GROUP:
        case KW_GROUPING:
        case KW_HOLD_DDLTIME:
        case KW_IDXPROPERTIES:
        case KW_IGNORE:
        case KW_IMPORT:
        case KW_IN:
        case KW_INDEX:
        case KW_INDEXES:
        case KW_INNER:
        case KW_INPATH:
        case KW_INPUTDRIVER:
        case KW_INPUTFORMAT:
        case KW_INSERT:
        case KW_INT:
        case KW_INTERSECT:
        case KW_INTO:
        case KW_IS:
        case KW_ITEMS:
        case KW_JAR:
        case KW_KEYS:
        case KW_KEY_TYPE:
        case KW_LATERAL:
        case KW_LEFT:
        case KW_LIKE:
        case KW_LIMIT:
        case KW_LINES:
        case KW_LOAD:
        case KW_LOCAL:
        case KW_LOCATION:
        case KW_LOCK:
        case KW_LOCKS:
        case KW_LOGICAL:
        case KW_LONG:
        case KW_MAPJOIN:
        case KW_MATERIALIZED:
        case KW_METADATA:
        case KW_MINUS:
        case KW_MSCK:
        case KW_NONE:
        case KW_NOSCAN:
        case KW_NO_DROP:
        case KW_NULL:
        case KW_OF:
        case KW_OFFLINE:
        case KW_OPTION:
        case KW_ORDER:
        case KW_OUT:
        case KW_OUTER:
        case KW_OUTPUTDRIVER:
        case KW_OUTPUTFORMAT:
        case KW_OVERWRITE:
        case KW_OWNER:
        case KW_PARTITION:
        case KW_PARTITIONED:
        case KW_PARTITIONS:
        case KW_PERCENT:
        case KW_PLUS:
        case KW_PRETTY:
        case KW_PRINCIPALS:
        case KW_PROCEDURE:
        case KW_PROTECTION:
        case KW_PURGE:
        case KW_RANGE:
        case KW_READ:
        case KW_READONLY:
        case KW_READS:
        case KW_REBUILD:
        case KW_RECORDREADER:
        case KW_RECORDWRITER:
        case KW_REGEXP:
        case KW_RELOAD:
        case KW_RENAME:
        case KW_REPAIR:
        case KW_REPLACE:
        case KW_REPLICATION:
        case KW_RESTRICT:
        case KW_REVOKE:
        case KW_REWRITE:
        case KW_RIGHT:
        case KW_RLIKE:
        case KW_ROLE:
        case KW_ROLES:
        case KW_ROLLUP:
        case KW_ROW:
        case KW_ROWS:
        case KW_SCHEMA:
        case KW_SCHEMAS:
        case KW_SEMI:
        case KW_SERDE:
        case KW_SERDEPROPERTIES:
        case KW_SERVER:
        case KW_SET:
        case KW_SETS:
        case KW_SHARED:
        case KW_SHOW:
        case KW_SHOW_DATABASE:
        case KW_SKEWED:
        case KW_SMALLINT:
        case KW_SORT:
        case KW_SORTED:
        case KW_SSL:
        case KW_STATISTICS:
        case KW_STORED:
        case KW_STREAMTABLE:
        case KW_STRING:
        case KW_STRUCT:
        case KW_TABLE:
        case KW_TABLES:
        case KW_TBLPROPERTIES:
        case KW_TEMPORARY:
        case KW_TERMINATED:
        case KW_TIMESTAMP:
        case KW_TINYINT:
        case KW_TO:
        case KW_TOUCH:
        case KW_TRANSACTIONS:
        case KW_TRIGGER:
        case KW_TRUE:
        case KW_TRUNCATE:
        case KW_UNARCHIVE:
        case KW_UNDO:
        case KW_UNION:
        case KW_UNIONTYPE:
        case KW_UNLOCK:
        case KW_UNSET:
        case KW_UNSIGNED:
        case KW_UPDATE:
        case KW_URI:
        case KW_USE:
        case KW_USER:
        case KW_USING:
        case KW_UTC:
        case KW_UTCTIMESTAMP:
        case KW_VALUES:
        case KW_VALUE_TYPE:
        case KW_VIEW:
        case KW_WHILE:
        case KW_WITH: {
          alt194 = 1;
        }
          break;
        case StringLiteral: {
          alt194 = 2;
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 194, 0, input);

          throw nvae;
      }

      switch (alt194) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1701:7: functionIdentifier
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_functionIdentifier_in_showFunctionIdentifier9921);
          functionIdentifier654 = functionIdentifier();

          state._fsp--;

          adaptor.addChild(root_0, functionIdentifier654.getTree());
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1702:7: StringLiteral
        {
          root_0 = (CommonTree) adaptor.nil();

          StringLiteral655 = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_showFunctionIdentifier9929);
          StringLiteral655_tree = (CommonTree) adaptor.create(StringLiteral655);
          adaptor.addChild(root_0, StringLiteral655_tree);
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "showFunctionIdentifier"

  public static class showStmtIdentifier_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "showStmtIdentifier"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1705:1: showStmtIdentifier : ( identifier | StringLiteral );
  public final HiveParser.showStmtIdentifier_return showStmtIdentifier() throws RecognitionException {
    HiveParser.showStmtIdentifier_return retval = new HiveParser.showStmtIdentifier_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token StringLiteral657 = null;
    HiveParser_IdentifiersParser.identifier_return identifier656 = null;

    CommonTree StringLiteral657_tree = null;

    pushMsg("identifier for show statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1708:5: ( identifier | StringLiteral )
      int alt195 = 2;
      switch (input.LA(1)) {
        case Identifier:
        case KW_ADD:
        case KW_ADMIN:
        case KW_AFTER:
        case KW_ALL:
        case KW_ALTER:
        case KW_ANALYZE:
        case KW_ARCHIVE:
        case KW_ARRAY:
        case KW_AS:
        case KW_ASC:
        case KW_AUTHORIZATION:
        case KW_BEFORE:
        case KW_BETWEEN:
        case KW_BIGINT:
        case KW_BINARY:
        case KW_BOOLEAN:
        case KW_BOTH:
        case KW_BUCKET:
        case KW_BUCKETS:
        case KW_BY:
        case KW_CASCADE:
        case KW_CHANGE:
        case KW_CLUSTER:
        case KW_CLUSTERED:
        case KW_CLUSTERSTATUS:
        case KW_COLLECTION:
        case KW_COLUMNS:
        case KW_COMMENT:
        case KW_COMPACT:
        case KW_COMPACTIONS:
        case KW_COMPUTE:
        case KW_CONCATENATE:
        case KW_CONTINUE:
        case KW_CREATE:
        case KW_CUBE:
        case KW_CURSOR:
        case KW_DATA:
        case KW_DATABASES:
        case KW_DATE:
        case KW_DATETIME:
        case KW_DBPROPERTIES:
        case KW_DECIMAL:
        case KW_DEFAULT:
        case KW_DEFERRED:
        case KW_DEFINED:
        case KW_DELETE:
        case KW_DELIMITED:
        case KW_DEPENDENCY:
        case KW_DESC:
        case KW_DESCRIBE:
        case KW_DIRECTORIES:
        case KW_DIRECTORY:
        case KW_DISABLE:
        case KW_DISTRIBUTE:
        case KW_DOUBLE:
        case KW_DROP:
        case KW_ELEM_TYPE:
        case KW_ENABLE:
        case KW_ESCAPED:
        case KW_EXCLUSIVE:
        case KW_EXISTS:
        case KW_EXPLAIN:
        case KW_EXPORT:
        case KW_EXTERNAL:
        case KW_FALSE:
        case KW_FETCH:
        case KW_FIELDS:
        case KW_FILE:
        case KW_FILEFORMAT:
        case KW_FIRST:
        case KW_FLOAT:
        case KW_FOR:
        case KW_FORMAT:
        case KW_FORMATTED:
        case KW_FULL:
        case KW_FUNCTIONS:
        case KW_GRANT:
        case KW_GROUP:
        case KW_GROUPING:
        case KW_HOLD_DDLTIME:
        case KW_IDXPROPERTIES:
        case KW_IGNORE:
        case KW_IMPORT:
        case KW_IN:
        case KW_INDEX:
        case KW_INDEXES:
        case KW_INNER:
        case KW_INPATH:
        case KW_INPUTDRIVER:
        case KW_INPUTFORMAT:
        case KW_INSERT:
        case KW_INT:
        case KW_INTERSECT:
        case KW_INTO:
        case KW_IS:
        case KW_ITEMS:
        case KW_JAR:
        case KW_KEYS:
        case KW_KEY_TYPE:
        case KW_LATERAL:
        case KW_LEFT:
        case KW_LIKE:
        case KW_LIMIT:
        case KW_LINES:
        case KW_LOAD:
        case KW_LOCAL:
        case KW_LOCATION:
        case KW_LOCK:
        case KW_LOCKS:
        case KW_LOGICAL:
        case KW_LONG:
        case KW_MAPJOIN:
        case KW_MATERIALIZED:
        case KW_METADATA:
        case KW_MINUS:
        case KW_MSCK:
        case KW_NONE:
        case KW_NOSCAN:
        case KW_NO_DROP:
        case KW_NULL:
        case KW_OF:
        case KW_OFFLINE:
        case KW_OPTION:
        case KW_ORDER:
        case KW_OUT:
        case KW_OUTER:
        case KW_OUTPUTDRIVER:
        case KW_OUTPUTFORMAT:
        case KW_OVERWRITE:
        case KW_OWNER:
        case KW_PARTITION:
        case KW_PARTITIONED:
        case KW_PARTITIONS:
        case KW_PERCENT:
        case KW_PLUS:
        case KW_PRETTY:
        case KW_PRINCIPALS:
        case KW_PROCEDURE:
        case KW_PROTECTION:
        case KW_PURGE:
        case KW_RANGE:
        case KW_READ:
        case KW_READONLY:
        case KW_READS:
        case KW_REBUILD:
        case KW_RECORDREADER:
        case KW_RECORDWRITER:
        case KW_REGEXP:
        case KW_RELOAD:
        case KW_RENAME:
        case KW_REPAIR:
        case KW_REPLACE:
        case KW_REPLICATION:
        case KW_RESTRICT:
        case KW_REVOKE:
        case KW_REWRITE:
        case KW_RIGHT:
        case KW_RLIKE:
        case KW_ROLE:
        case KW_ROLES:
        case KW_ROLLUP:
        case KW_ROW:
        case KW_ROWS:
        case KW_SCHEMA:
        case KW_SCHEMAS:
        case KW_SEMI:
        case KW_SERDE:
        case KW_SERDEPROPERTIES:
        case KW_SERVER:
        case KW_SET:
        case KW_SETS:
        case KW_SHARED:
        case KW_SHOW:
        case KW_SHOW_DATABASE:
        case KW_SKEWED:
        case KW_SMALLINT:
        case KW_SORT:
        case KW_SORTED:
        case KW_SSL:
        case KW_STATISTICS:
        case KW_STORED:
        case KW_STREAMTABLE:
        case KW_STRING:
        case KW_STRUCT:
        case KW_TABLE:
        case KW_TABLES:
        case KW_TBLPROPERTIES:
        case KW_TEMPORARY:
        case KW_TERMINATED:
        case KW_TIMESTAMP:
        case KW_TINYINT:
        case KW_TO:
        case KW_TOUCH:
        case KW_TRANSACTIONS:
        case KW_TRIGGER:
        case KW_TRUE:
        case KW_TRUNCATE:
        case KW_UNARCHIVE:
        case KW_UNDO:
        case KW_UNION:
        case KW_UNIONTYPE:
        case KW_UNLOCK:
        case KW_UNSET:
        case KW_UNSIGNED:
        case KW_UPDATE:
        case KW_URI:
        case KW_USE:
        case KW_USER:
        case KW_USING:
        case KW_UTC:
        case KW_UTCTIMESTAMP:
        case KW_VALUES:
        case KW_VALUE_TYPE:
        case KW_VIEW:
        case KW_WHILE:
        case KW_WITH: {
          alt195 = 1;
        }
          break;
        case StringLiteral: {
          alt195 = 2;
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 195, 0, input);

          throw nvae;
      }

      switch (alt195) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1708:7: identifier
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_identifier_in_showStmtIdentifier9956);
          identifier656 = identifier();

          state._fsp--;

          adaptor.addChild(root_0, identifier656.getTree());
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1709:7: StringLiteral
        {
          root_0 = (CommonTree) adaptor.nil();

          StringLiteral657 = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_showStmtIdentifier9964);
          StringLiteral657_tree = (CommonTree) adaptor.create(StringLiteral657);
          adaptor.addChild(root_0, StringLiteral657_tree);
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "showStmtIdentifier"

  public static class tableComment_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "tableComment"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1712:1: tableComment : KW_COMMENT comment= StringLiteral -> ^( TOK_TABLECOMMENT $comment) ;
  public final HiveParser.tableComment_return tableComment() throws RecognitionException {
    HiveParser.tableComment_return retval = new HiveParser.tableComment_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token comment = null;
    Token KW_COMMENT658 = null;

    CommonTree comment_tree = null;
    CommonTree KW_COMMENT658_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_COMMENT = new RewriteRuleTokenStream(adaptor, "token KW_COMMENT");

    pushMsg("table's comment", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1715:5: ( KW_COMMENT comment= StringLiteral -> ^( TOK_TABLECOMMENT $comment) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1716:7: KW_COMMENT comment= StringLiteral
      {
        KW_COMMENT658 = (Token) match(input, KW_COMMENT, FOLLOW_KW_COMMENT_in_tableComment9997);
        stream_KW_COMMENT.add(KW_COMMENT658);

        comment = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_tableComment10001);
        stream_StringLiteral.add(comment);

        // AST REWRITE
        // elements: comment
        // token labels: comment
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_comment = new RewriteRuleTokenStream(adaptor, "token comment", comment);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1716:41: -> ^( TOK_TABLECOMMENT $comment)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1716:44: ^( TOK_TABLECOMMENT $comment)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABLECOMMENT, "TOK_TABLECOMMENT"),
                root_1);

            adaptor.addChild(root_1, stream_comment.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "tableComment"

  public static class tablePartition_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "tablePartition"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1719:1: tablePartition : KW_PARTITIONED KW_BY LPAREN columnNameTypeList RPAREN -> ^( TOK_TABLEPARTCOLS columnNameTypeList ) ;
  public final HiveParser.tablePartition_return tablePartition() throws RecognitionException {
    HiveParser.tablePartition_return retval = new HiveParser.tablePartition_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_PARTITIONED659 = null;
    Token KW_BY660 = null;
    Token LPAREN661 = null;
    Token RPAREN663 = null;
    HiveParser.columnNameTypeList_return columnNameTypeList662 = null;

    CommonTree KW_PARTITIONED659_tree = null;
    CommonTree KW_BY660_tree = null;
    CommonTree LPAREN661_tree = null;
    CommonTree RPAREN663_tree = null;
    RewriteRuleTokenStream stream_KW_BY = new RewriteRuleTokenStream(adaptor, "token KW_BY");
    RewriteRuleTokenStream stream_KW_PARTITIONED = new RewriteRuleTokenStream(adaptor, "token KW_PARTITIONED");
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleSubtreeStream stream_columnNameTypeList =
        new RewriteRuleSubtreeStream(adaptor, "rule columnNameTypeList");
    pushMsg("table partition specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1722:5: ( KW_PARTITIONED KW_BY LPAREN columnNameTypeList RPAREN -> ^( TOK_TABLEPARTCOLS columnNameTypeList ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1722:7: KW_PARTITIONED KW_BY LPAREN columnNameTypeList RPAREN
      {
        KW_PARTITIONED659 = (Token) match(input, KW_PARTITIONED, FOLLOW_KW_PARTITIONED_in_tablePartition10038);
        stream_KW_PARTITIONED.add(KW_PARTITIONED659);

        KW_BY660 = (Token) match(input, KW_BY, FOLLOW_KW_BY_in_tablePartition10040);
        stream_KW_BY.add(KW_BY660);

        LPAREN661 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_tablePartition10042);
        stream_LPAREN.add(LPAREN661);

        pushFollow(FOLLOW_columnNameTypeList_in_tablePartition10044);
        columnNameTypeList662 = columnNameTypeList();

        state._fsp--;

        stream_columnNameTypeList.add(columnNameTypeList662.getTree());

        RPAREN663 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_tablePartition10046);
        stream_RPAREN.add(RPAREN663);

        // AST REWRITE
        // elements: columnNameTypeList
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1723:5: -> ^( TOK_TABLEPARTCOLS columnNameTypeList )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1723:8: ^( TOK_TABLEPARTCOLS columnNameTypeList )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_TABLEPARTCOLS, "TOK_TABLEPARTCOLS"), root_1);

            adaptor.addChild(root_1, stream_columnNameTypeList.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "tablePartition"

  public static class tableBuckets_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "tableBuckets"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1726:1: tableBuckets : KW_CLUSTERED KW_BY LPAREN bucketCols= columnNameList RPAREN ( KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN )? KW_INTO num= Number KW_BUCKETS -> ^( TOK_ALTERTABLE_BUCKETS $bucketCols ( $sortCols)? $num) ;
  public final HiveParser.tableBuckets_return tableBuckets() throws RecognitionException {
    HiveParser.tableBuckets_return retval = new HiveParser.tableBuckets_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token num = null;
    Token KW_CLUSTERED664 = null;
    Token KW_BY665 = null;
    Token LPAREN666 = null;
    Token RPAREN667 = null;
    Token KW_SORTED668 = null;
    Token KW_BY669 = null;
    Token LPAREN670 = null;
    Token RPAREN671 = null;
    Token KW_INTO672 = null;
    Token KW_BUCKETS673 = null;
    HiveParser.columnNameList_return bucketCols = null;

    HiveParser.columnNameOrderList_return sortCols = null;

    CommonTree num_tree = null;
    CommonTree KW_CLUSTERED664_tree = null;
    CommonTree KW_BY665_tree = null;
    CommonTree LPAREN666_tree = null;
    CommonTree RPAREN667_tree = null;
    CommonTree KW_SORTED668_tree = null;
    CommonTree KW_BY669_tree = null;
    CommonTree LPAREN670_tree = null;
    CommonTree RPAREN671_tree = null;
    CommonTree KW_INTO672_tree = null;
    CommonTree KW_BUCKETS673_tree = null;
    RewriteRuleTokenStream stream_KW_BY = new RewriteRuleTokenStream(adaptor, "token KW_BY");
    RewriteRuleTokenStream stream_KW_SORTED = new RewriteRuleTokenStream(adaptor, "token KW_SORTED");
    RewriteRuleTokenStream stream_Number = new RewriteRuleTokenStream(adaptor, "token Number");
    RewriteRuleTokenStream stream_KW_INTO = new RewriteRuleTokenStream(adaptor, "token KW_INTO");
    RewriteRuleTokenStream stream_KW_BUCKETS = new RewriteRuleTokenStream(adaptor, "token KW_BUCKETS");
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleTokenStream stream_KW_CLUSTERED = new RewriteRuleTokenStream(adaptor, "token KW_CLUSTERED");
    RewriteRuleSubtreeStream stream_columnNameOrderList =
        new RewriteRuleSubtreeStream(adaptor, "rule columnNameOrderList");
    RewriteRuleSubtreeStream stream_columnNameList = new RewriteRuleSubtreeStream(adaptor, "rule columnNameList");
    pushMsg("table buckets specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1729:5: ( KW_CLUSTERED KW_BY LPAREN bucketCols= columnNameList RPAREN ( KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN )? KW_INTO num= Number KW_BUCKETS -> ^( TOK_ALTERTABLE_BUCKETS $bucketCols ( $sortCols)? $num) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1730:7: KW_CLUSTERED KW_BY LPAREN bucketCols= columnNameList RPAREN ( KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN )? KW_INTO num= Number KW_BUCKETS
      {
        KW_CLUSTERED664 = (Token) match(input, KW_CLUSTERED, FOLLOW_KW_CLUSTERED_in_tableBuckets10091);
        stream_KW_CLUSTERED.add(KW_CLUSTERED664);

        KW_BY665 = (Token) match(input, KW_BY, FOLLOW_KW_BY_in_tableBuckets10093);
        stream_KW_BY.add(KW_BY665);

        LPAREN666 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_tableBuckets10095);
        stream_LPAREN.add(LPAREN666);

        pushFollow(FOLLOW_columnNameList_in_tableBuckets10099);
        bucketCols = columnNameList();

        state._fsp--;

        stream_columnNameList.add(bucketCols.getTree());

        RPAREN667 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_tableBuckets10101);
        stream_RPAREN.add(RPAREN667);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1730:66: ( KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN )?
        int alt196 = 2;
        switch (input.LA(1)) {
          case KW_SORTED: {
            alt196 = 1;
          }
            break;
        }

        switch (alt196) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1730:67: KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN
          {
            KW_SORTED668 = (Token) match(input, KW_SORTED, FOLLOW_KW_SORTED_in_tableBuckets10104);
            stream_KW_SORTED.add(KW_SORTED668);

            KW_BY669 = (Token) match(input, KW_BY, FOLLOW_KW_BY_in_tableBuckets10106);
            stream_KW_BY.add(KW_BY669);

            LPAREN670 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_tableBuckets10108);
            stream_LPAREN.add(LPAREN670);

            pushFollow(FOLLOW_columnNameOrderList_in_tableBuckets10112);
            sortCols = columnNameOrderList();

            state._fsp--;

            stream_columnNameOrderList.add(sortCols.getTree());

            RPAREN671 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_tableBuckets10114);
            stream_RPAREN.add(RPAREN671);
          }
            break;
        }

        KW_INTO672 = (Token) match(input, KW_INTO, FOLLOW_KW_INTO_in_tableBuckets10118);
        stream_KW_INTO.add(KW_INTO672);

        num = (Token) match(input, Number, FOLLOW_Number_in_tableBuckets10122);
        stream_Number.add(num);

        KW_BUCKETS673 = (Token) match(input, KW_BUCKETS, FOLLOW_KW_BUCKETS_in_tableBuckets10124);
        stream_KW_BUCKETS.add(KW_BUCKETS673);

        // AST REWRITE
        // elements: bucketCols, num, sortCols
        // token labels: num
        // rule labels: bucketCols, sortCols, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_num = new RewriteRuleTokenStream(adaptor, "token num", num);
        RewriteRuleSubtreeStream stream_bucketCols =
            new RewriteRuleSubtreeStream(adaptor, "rule bucketCols", bucketCols != null ? bucketCols.tree : null);
        RewriteRuleSubtreeStream stream_sortCols =
            new RewriteRuleSubtreeStream(adaptor, "rule sortCols", sortCols != null ? sortCols.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1731:5: -> ^( TOK_ALTERTABLE_BUCKETS $bucketCols ( $sortCols)? $num)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1731:8: ^( TOK_ALTERTABLE_BUCKETS $bucketCols ( $sortCols)? $num)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_ALTERTABLE_BUCKETS, "TOK_ALTERTABLE_BUCKETS"), root_1);

            adaptor.addChild(root_1, stream_bucketCols.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1731:46: ( $sortCols)?
            if (stream_sortCols.hasNext()) {
              adaptor.addChild(root_1, stream_sortCols.nextTree());
            }
            stream_sortCols.reset();

            adaptor.addChild(root_1, stream_num.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "tableBuckets"

  public static class tableSkewed_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "tableSkewed"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1734:1: tableSkewed : KW_SKEWED KW_BY LPAREN skewedCols= columnNameList RPAREN KW_ON LPAREN (skewedValues= skewedValueElement ) RPAREN ( storedAsDirs )? -> ^( TOK_TABLESKEWED $skewedCols $skewedValues ( storedAsDirs )? ) ;
  public final HiveParser.tableSkewed_return tableSkewed() throws RecognitionException {
    HiveParser.tableSkewed_return retval = new HiveParser.tableSkewed_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_SKEWED674 = null;
    Token KW_BY675 = null;
    Token LPAREN676 = null;
    Token RPAREN677 = null;
    Token KW_ON678 = null;
    Token LPAREN679 = null;
    Token RPAREN680 = null;
    HiveParser.columnNameList_return skewedCols = null;

    HiveParser.skewedValueElement_return skewedValues = null;

    HiveParser.storedAsDirs_return storedAsDirs681 = null;

    CommonTree KW_SKEWED674_tree = null;
    CommonTree KW_BY675_tree = null;
    CommonTree LPAREN676_tree = null;
    CommonTree RPAREN677_tree = null;
    CommonTree KW_ON678_tree = null;
    CommonTree LPAREN679_tree = null;
    CommonTree RPAREN680_tree = null;
    RewriteRuleTokenStream stream_KW_BY = new RewriteRuleTokenStream(adaptor, "token KW_BY");
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_KW_SKEWED = new RewriteRuleTokenStream(adaptor, "token KW_SKEWED");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleTokenStream stream_KW_ON = new RewriteRuleTokenStream(adaptor, "token KW_ON");
    RewriteRuleSubtreeStream stream_skewedValueElement =
        new RewriteRuleSubtreeStream(adaptor, "rule skewedValueElement");
    RewriteRuleSubtreeStream stream_columnNameList = new RewriteRuleSubtreeStream(adaptor, "rule columnNameList");
    RewriteRuleSubtreeStream stream_storedAsDirs = new RewriteRuleSubtreeStream(adaptor, "rule storedAsDirs");
    pushMsg("table skewed specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1737:5: ( KW_SKEWED KW_BY LPAREN skewedCols= columnNameList RPAREN KW_ON LPAREN (skewedValues= skewedValueElement ) RPAREN ( storedAsDirs )? -> ^( TOK_TABLESKEWED $skewedCols $skewedValues ( storedAsDirs )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1738:6: KW_SKEWED KW_BY LPAREN skewedCols= columnNameList RPAREN KW_ON LPAREN (skewedValues= skewedValueElement ) RPAREN ( storedAsDirs )?
      {
        KW_SKEWED674 = (Token) match(input, KW_SKEWED, FOLLOW_KW_SKEWED_in_tableSkewed10176);
        stream_KW_SKEWED.add(KW_SKEWED674);

        KW_BY675 = (Token) match(input, KW_BY, FOLLOW_KW_BY_in_tableSkewed10178);
        stream_KW_BY.add(KW_BY675);

        LPAREN676 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_tableSkewed10180);
        stream_LPAREN.add(LPAREN676);

        pushFollow(FOLLOW_columnNameList_in_tableSkewed10184);
        skewedCols = columnNameList();

        state._fsp--;

        stream_columnNameList.add(skewedCols.getTree());

        RPAREN677 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_tableSkewed10186);
        stream_RPAREN.add(RPAREN677);

        KW_ON678 = (Token) match(input, KW_ON, FOLLOW_KW_ON_in_tableSkewed10188);
        stream_KW_ON.add(KW_ON678);

        LPAREN679 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_tableSkewed10190);
        stream_LPAREN.add(LPAREN679);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1738:75: (skewedValues= skewedValueElement )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1738:76: skewedValues= skewedValueElement
        {
          pushFollow(FOLLOW_skewedValueElement_in_tableSkewed10195);
          skewedValues = skewedValueElement();

          state._fsp--;

          stream_skewedValueElement.add(skewedValues.getTree());
        }

        RPAREN680 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_tableSkewed10198);
        stream_RPAREN.add(RPAREN680);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1738:116: ( storedAsDirs )?
        int alt197 = 2;
        switch (input.LA(1)) {
          case KW_STORED: {
            switch (input.LA(2)) {
              case KW_AS: {
                switch (input.LA(3)) {
                  case KW_DIRECTORIES: {
                    alt197 = 1;
                  }
                    break;
                }
              }
                break;
            }
          }
            break;
        }

        switch (alt197) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1738:117: storedAsDirs
          {
            pushFollow(FOLLOW_storedAsDirs_in_tableSkewed10201);
            storedAsDirs681 = storedAsDirs();

            state._fsp--;

            stream_storedAsDirs.add(storedAsDirs681.getTree());
          }
            break;
        }

        // AST REWRITE
        // elements: skewedValues, storedAsDirs, skewedCols
        // token labels:
        // rule labels: skewedCols, skewedValues, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_skewedCols =
            new RewriteRuleSubtreeStream(adaptor, "rule skewedCols", skewedCols != null ? skewedCols.tree : null);
        RewriteRuleSubtreeStream stream_skewedValues =
            new RewriteRuleSubtreeStream(adaptor, "rule skewedValues", skewedValues != null ? skewedValues.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1739:5: -> ^( TOK_TABLESKEWED $skewedCols $skewedValues ( storedAsDirs )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1739:8: ^( TOK_TABLESKEWED $skewedCols $skewedValues ( storedAsDirs )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABLESKEWED, "TOK_TABLESKEWED"),
                root_1);

            adaptor.addChild(root_1, stream_skewedCols.nextTree());

            adaptor.addChild(root_1, stream_skewedValues.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1739:52: ( storedAsDirs )?
            if (stream_storedAsDirs.hasNext()) {
              adaptor.addChild(root_1, stream_storedAsDirs.nextTree());
            }
            stream_storedAsDirs.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "tableSkewed"

  public static class rowFormat_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "rowFormat"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1742:1: rowFormat : ( rowFormatSerde -> ^( TOK_SERDE rowFormatSerde ) | rowFormatDelimited -> ^( TOK_SERDE rowFormatDelimited ) | -> ^( TOK_SERDE ) );
  public final HiveParser.rowFormat_return rowFormat() throws RecognitionException {
    HiveParser.rowFormat_return retval = new HiveParser.rowFormat_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.rowFormatSerde_return rowFormatSerde682 = null;

    HiveParser.rowFormatDelimited_return rowFormatDelimited683 = null;

    RewriteRuleSubtreeStream stream_rowFormatSerde = new RewriteRuleSubtreeStream(adaptor, "rule rowFormatSerde");
    RewriteRuleSubtreeStream stream_rowFormatDelimited =
        new RewriteRuleSubtreeStream(adaptor, "rule rowFormatDelimited");
    pushMsg("serde specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1745:5: ( rowFormatSerde -> ^( TOK_SERDE rowFormatSerde ) | rowFormatDelimited -> ^( TOK_SERDE rowFormatDelimited ) | -> ^( TOK_SERDE ) )
      int alt198 = 3;
      switch (input.LA(1)) {
        case KW_ROW: {
          switch (input.LA(2)) {
            case KW_FORMAT: {
              switch (input.LA(3)) {
                case KW_SERDE: {
                  alt198 = 1;
                }
                  break;
                case KW_DELIMITED: {
                  alt198 = 2;
                }
                  break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 198, 23, input);

                  throw nvae;
              }
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 198, 1, input);

              throw nvae;
          }
        }
          break;
        case EOF:
        case KW_CLUSTER:
        case KW_DISTRIBUTE:
        case KW_FROM:
        case KW_GROUP:
        case KW_HAVING:
        case KW_INSERT:
        case KW_LATERAL:
        case KW_LIMIT:
        case KW_MAP:
        case KW_ORDER:
        case KW_RECORDREADER:
        case KW_RECORDWRITER:
        case KW_REDUCE:
        case KW_SELECT:
        case KW_SORT:
        case KW_UNION:
        case KW_USING:
        case KW_WHERE:
        case KW_WINDOW:
        case RPAREN: {
          alt198 = 3;
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 198, 0, input);

          throw nvae;
      }

      switch (alt198) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1745:7: rowFormatSerde
        {
          pushFollow(FOLLOW_rowFormatSerde_in_rowFormat10249);
          rowFormatSerde682 = rowFormatSerde();

          state._fsp--;

          stream_rowFormatSerde.add(rowFormatSerde682.getTree());

          // AST REWRITE
          // elements: rowFormatSerde
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1745:22: -> ^( TOK_SERDE rowFormatSerde )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1745:25: ^( TOK_SERDE rowFormatSerde )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SERDE, "TOK_SERDE"), root_1);

              adaptor.addChild(root_1, stream_rowFormatSerde.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1746:7: rowFormatDelimited
        {
          pushFollow(FOLLOW_rowFormatDelimited_in_rowFormat10265);
          rowFormatDelimited683 = rowFormatDelimited();

          state._fsp--;

          stream_rowFormatDelimited.add(rowFormatDelimited683.getTree());

          // AST REWRITE
          // elements: rowFormatDelimited
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1746:26: -> ^( TOK_SERDE rowFormatDelimited )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1746:29: ^( TOK_SERDE rowFormatDelimited )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SERDE, "TOK_SERDE"), root_1);

              adaptor.addChild(root_1, stream_rowFormatDelimited.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 3:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1747:9:
        {
          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1747:9: -> ^( TOK_SERDE )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1747:12: ^( TOK_SERDE )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SERDE, "TOK_SERDE"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "rowFormat"

  public static class recordReader_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "recordReader"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1750:1: recordReader : ( KW_RECORDREADER StringLiteral -> ^( TOK_RECORDREADER StringLiteral ) | -> ^( TOK_RECORDREADER ) );
  public final HiveParser.recordReader_return recordReader() throws RecognitionException {
    HiveParser.recordReader_return retval = new HiveParser.recordReader_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_RECORDREADER684 = null;
    Token StringLiteral685 = null;

    CommonTree KW_RECORDREADER684_tree = null;
    CommonTree StringLiteral685_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_RECORDREADER = new RewriteRuleTokenStream(adaptor, "token KW_RECORDREADER");

    pushMsg("record reader specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1753:5: ( KW_RECORDREADER StringLiteral -> ^( TOK_RECORDREADER StringLiteral ) | -> ^( TOK_RECORDREADER ) )
      int alt199 = 2;
      switch (input.LA(1)) {
        case KW_RECORDREADER: {
          alt199 = 1;
        }
          break;
        case EOF:
        case KW_CLUSTER:
        case KW_DISTRIBUTE:
        case KW_FROM:
        case KW_GROUP:
        case KW_HAVING:
        case KW_INSERT:
        case KW_LATERAL:
        case KW_LIMIT:
        case KW_MAP:
        case KW_ORDER:
        case KW_REDUCE:
        case KW_SELECT:
        case KW_SORT:
        case KW_UNION:
        case KW_WHERE:
        case KW_WINDOW:
        case RPAREN: {
          alt199 = 2;
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 199, 0, input);

          throw nvae;
      }

      switch (alt199) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1753:7: KW_RECORDREADER StringLiteral
        {
          KW_RECORDREADER684 = (Token) match(input, KW_RECORDREADER, FOLLOW_KW_RECORDREADER_in_recordReader10314);
          stream_KW_RECORDREADER.add(KW_RECORDREADER684);

          StringLiteral685 = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_recordReader10316);
          stream_StringLiteral.add(StringLiteral685);

          // AST REWRITE
          // elements: StringLiteral
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1753:37: -> ^( TOK_RECORDREADER StringLiteral )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1753:40: ^( TOK_RECORDREADER StringLiteral )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor
                  .becomeRoot((CommonTree) adaptor.create(TOK_RECORDREADER, "TOK_RECORDREADER"), root_1);

              adaptor.addChild(root_1, stream_StringLiteral.nextNode());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1754:9:
        {
          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1754:9: -> ^( TOK_RECORDREADER )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1754:12: ^( TOK_RECORDREADER )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor
                  .becomeRoot((CommonTree) adaptor.create(TOK_RECORDREADER, "TOK_RECORDREADER"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "recordReader"

  public static class recordWriter_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "recordWriter"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1757:1: recordWriter : ( KW_RECORDWRITER StringLiteral -> ^( TOK_RECORDWRITER StringLiteral ) | -> ^( TOK_RECORDWRITER ) );
  public final HiveParser.recordWriter_return recordWriter() throws RecognitionException {
    HiveParser.recordWriter_return retval = new HiveParser.recordWriter_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_RECORDWRITER686 = null;
    Token StringLiteral687 = null;

    CommonTree KW_RECORDWRITER686_tree = null;
    CommonTree StringLiteral687_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_RECORDWRITER = new RewriteRuleTokenStream(adaptor, "token KW_RECORDWRITER");

    pushMsg("record writer specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1760:5: ( KW_RECORDWRITER StringLiteral -> ^( TOK_RECORDWRITER StringLiteral ) | -> ^( TOK_RECORDWRITER ) )
      int alt200 = 2;
      switch (input.LA(1)) {
        case KW_RECORDWRITER: {
          alt200 = 1;
        }
          break;
        case KW_USING: {
          alt200 = 2;
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 200, 0, input);

          throw nvae;
      }

      switch (alt200) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1760:7: KW_RECORDWRITER StringLiteral
        {
          KW_RECORDWRITER686 = (Token) match(input, KW_RECORDWRITER, FOLLOW_KW_RECORDWRITER_in_recordWriter10365);
          stream_KW_RECORDWRITER.add(KW_RECORDWRITER686);

          StringLiteral687 = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_recordWriter10367);
          stream_StringLiteral.add(StringLiteral687);

          // AST REWRITE
          // elements: StringLiteral
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1760:37: -> ^( TOK_RECORDWRITER StringLiteral )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1760:40: ^( TOK_RECORDWRITER StringLiteral )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor
                  .becomeRoot((CommonTree) adaptor.create(TOK_RECORDWRITER, "TOK_RECORDWRITER"), root_1);

              adaptor.addChild(root_1, stream_StringLiteral.nextNode());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1761:9:
        {
          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1761:9: -> ^( TOK_RECORDWRITER )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1761:12: ^( TOK_RECORDWRITER )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor
                  .becomeRoot((CommonTree) adaptor.create(TOK_RECORDWRITER, "TOK_RECORDWRITER"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "recordWriter"

  public static class rowFormatSerde_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "rowFormatSerde"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1764:1: rowFormatSerde : KW_ROW KW_FORMAT KW_SERDE name= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )? -> ^( TOK_SERDENAME $name ( $serdeprops)? ) ;
  public final HiveParser.rowFormatSerde_return rowFormatSerde() throws RecognitionException {
    HiveParser.rowFormatSerde_return retval = new HiveParser.rowFormatSerde_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token name = null;
    Token KW_ROW688 = null;
    Token KW_FORMAT689 = null;
    Token KW_SERDE690 = null;
    Token KW_WITH691 = null;
    Token KW_SERDEPROPERTIES692 = null;
    HiveParser.tableProperties_return serdeprops = null;

    CommonTree name_tree = null;
    CommonTree KW_ROW688_tree = null;
    CommonTree KW_FORMAT689_tree = null;
    CommonTree KW_SERDE690_tree = null;
    CommonTree KW_WITH691_tree = null;
    CommonTree KW_SERDEPROPERTIES692_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_WITH = new RewriteRuleTokenStream(adaptor, "token KW_WITH");
    RewriteRuleTokenStream stream_KW_ROW = new RewriteRuleTokenStream(adaptor, "token KW_ROW");
    RewriteRuleTokenStream stream_KW_SERDEPROPERTIES = new RewriteRuleTokenStream(adaptor, "token KW_SERDEPROPERTIES");
    RewriteRuleTokenStream stream_KW_SERDE = new RewriteRuleTokenStream(adaptor, "token KW_SERDE");
    RewriteRuleTokenStream stream_KW_FORMAT = new RewriteRuleTokenStream(adaptor, "token KW_FORMAT");
    RewriteRuleSubtreeStream stream_tableProperties = new RewriteRuleSubtreeStream(adaptor, "rule tableProperties");
    pushMsg("serde format specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1767:5: ( KW_ROW KW_FORMAT KW_SERDE name= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )? -> ^( TOK_SERDENAME $name ( $serdeprops)? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1767:7: KW_ROW KW_FORMAT KW_SERDE name= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )?
      {
        KW_ROW688 = (Token) match(input, KW_ROW, FOLLOW_KW_ROW_in_rowFormatSerde10416);
        stream_KW_ROW.add(KW_ROW688);

        KW_FORMAT689 = (Token) match(input, KW_FORMAT, FOLLOW_KW_FORMAT_in_rowFormatSerde10418);
        stream_KW_FORMAT.add(KW_FORMAT689);

        KW_SERDE690 = (Token) match(input, KW_SERDE, FOLLOW_KW_SERDE_in_rowFormatSerde10420);
        stream_KW_SERDE.add(KW_SERDE690);

        name = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_rowFormatSerde10424);
        stream_StringLiteral.add(name);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1767:52: ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )?
        int alt201 = 2;
        switch (input.LA(1)) {
          case KW_WITH: {
            alt201 = 1;
          }
            break;
        }

        switch (alt201) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1767:53: KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties
          {
            KW_WITH691 = (Token) match(input, KW_WITH, FOLLOW_KW_WITH_in_rowFormatSerde10427);
            stream_KW_WITH.add(KW_WITH691);

            KW_SERDEPROPERTIES692 =
                (Token) match(input, KW_SERDEPROPERTIES, FOLLOW_KW_SERDEPROPERTIES_in_rowFormatSerde10429);
            stream_KW_SERDEPROPERTIES.add(KW_SERDEPROPERTIES692);

            pushFollow(FOLLOW_tableProperties_in_rowFormatSerde10433);
            serdeprops = tableProperties();

            state._fsp--;

            stream_tableProperties.add(serdeprops.getTree());
          }
            break;
        }

        // AST REWRITE
        // elements: serdeprops, name
        // token labels: name
        // rule labels: serdeprops, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_name = new RewriteRuleTokenStream(adaptor, "token name", name);
        RewriteRuleSubtreeStream stream_serdeprops =
            new RewriteRuleSubtreeStream(adaptor, "rule serdeprops", serdeprops != null ? serdeprops.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1768:5: -> ^( TOK_SERDENAME $name ( $serdeprops)? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1768:8: ^( TOK_SERDENAME $name ( $serdeprops)? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SERDENAME, "TOK_SERDENAME"), root_1);

            adaptor.addChild(root_1, stream_name.nextNode());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1768:31: ( $serdeprops)?
            if (stream_serdeprops.hasNext()) {
              adaptor.addChild(root_1, stream_serdeprops.nextTree());
            }
            stream_serdeprops.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "rowFormatSerde"

  public static class rowFormatDelimited_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "rowFormatDelimited"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1771:1: rowFormatDelimited : KW_ROW KW_FORMAT KW_DELIMITED ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? -> ^( TOK_SERDEPROPS ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? ) ;
  public final HiveParser.rowFormatDelimited_return rowFormatDelimited() throws RecognitionException {
    HiveParser.rowFormatDelimited_return retval = new HiveParser.rowFormatDelimited_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_ROW693 = null;
    Token KW_FORMAT694 = null;
    Token KW_DELIMITED695 = null;
    HiveParser.tableRowFormatFieldIdentifier_return tableRowFormatFieldIdentifier696 = null;

    HiveParser.tableRowFormatCollItemsIdentifier_return tableRowFormatCollItemsIdentifier697 = null;

    HiveParser.tableRowFormatMapKeysIdentifier_return tableRowFormatMapKeysIdentifier698 = null;

    HiveParser.tableRowFormatLinesIdentifier_return tableRowFormatLinesIdentifier699 = null;

    HiveParser.tableRowNullFormat_return tableRowNullFormat700 = null;

    CommonTree KW_ROW693_tree = null;
    CommonTree KW_FORMAT694_tree = null;
    CommonTree KW_DELIMITED695_tree = null;
    RewriteRuleTokenStream stream_KW_ROW = new RewriteRuleTokenStream(adaptor, "token KW_ROW");
    RewriteRuleTokenStream stream_KW_DELIMITED = new RewriteRuleTokenStream(adaptor, "token KW_DELIMITED");
    RewriteRuleTokenStream stream_KW_FORMAT = new RewriteRuleTokenStream(adaptor, "token KW_FORMAT");
    RewriteRuleSubtreeStream stream_tableRowNullFormat =
        new RewriteRuleSubtreeStream(adaptor, "rule tableRowNullFormat");
    RewriteRuleSubtreeStream stream_tableRowFormatFieldIdentifier =
        new RewriteRuleSubtreeStream(adaptor, "rule tableRowFormatFieldIdentifier");
    RewriteRuleSubtreeStream stream_tableRowFormatCollItemsIdentifier =
        new RewriteRuleSubtreeStream(adaptor, "rule tableRowFormatCollItemsIdentifier");
    RewriteRuleSubtreeStream stream_tableRowFormatMapKeysIdentifier =
        new RewriteRuleSubtreeStream(adaptor, "rule tableRowFormatMapKeysIdentifier");
    RewriteRuleSubtreeStream stream_tableRowFormatLinesIdentifier =
        new RewriteRuleSubtreeStream(adaptor, "rule tableRowFormatLinesIdentifier");
    pushMsg("serde properties specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1774:5: ( KW_ROW KW_FORMAT KW_DELIMITED ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? -> ^( TOK_SERDEPROPS ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1775:7: KW_ROW KW_FORMAT KW_DELIMITED ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )?
      {
        KW_ROW693 = (Token) match(input, KW_ROW, FOLLOW_KW_ROW_in_rowFormatDelimited10485);
        stream_KW_ROW.add(KW_ROW693);

        KW_FORMAT694 = (Token) match(input, KW_FORMAT, FOLLOW_KW_FORMAT_in_rowFormatDelimited10487);
        stream_KW_FORMAT.add(KW_FORMAT694);

        KW_DELIMITED695 = (Token) match(input, KW_DELIMITED, FOLLOW_KW_DELIMITED_in_rowFormatDelimited10489);
        stream_KW_DELIMITED.add(KW_DELIMITED695);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1775:37: ( tableRowFormatFieldIdentifier )?
        int alt202 = 2;
        switch (input.LA(1)) {
          case KW_FIELDS: {
            alt202 = 1;
          }
            break;
        }

        switch (alt202) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1775:37: tableRowFormatFieldIdentifier
          {
            pushFollow(FOLLOW_tableRowFormatFieldIdentifier_in_rowFormatDelimited10491);
            tableRowFormatFieldIdentifier696 = tableRowFormatFieldIdentifier();

            state._fsp--;

            stream_tableRowFormatFieldIdentifier.add(tableRowFormatFieldIdentifier696.getTree());
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1775:68: ( tableRowFormatCollItemsIdentifier )?
        int alt203 = 2;
        switch (input.LA(1)) {
          case KW_COLLECTION: {
            alt203 = 1;
          }
            break;
        }

        switch (alt203) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1775:68: tableRowFormatCollItemsIdentifier
          {
            pushFollow(FOLLOW_tableRowFormatCollItemsIdentifier_in_rowFormatDelimited10494);
            tableRowFormatCollItemsIdentifier697 = tableRowFormatCollItemsIdentifier();

            state._fsp--;

            stream_tableRowFormatCollItemsIdentifier.add(tableRowFormatCollItemsIdentifier697.getTree());
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1775:103: ( tableRowFormatMapKeysIdentifier )?
        int alt204 = 2;
        alt204 = dfa204.predict(input);
        switch (alt204) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1775:103: tableRowFormatMapKeysIdentifier
          {
            pushFollow(FOLLOW_tableRowFormatMapKeysIdentifier_in_rowFormatDelimited10497);
            tableRowFormatMapKeysIdentifier698 = tableRowFormatMapKeysIdentifier();

            state._fsp--;

            stream_tableRowFormatMapKeysIdentifier.add(tableRowFormatMapKeysIdentifier698.getTree());
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1775:136: ( tableRowFormatLinesIdentifier )?
        int alt205 = 2;
        switch (input.LA(1)) {
          case KW_LINES: {
            alt205 = 1;
          }
            break;
        }

        switch (alt205) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1775:136: tableRowFormatLinesIdentifier
          {
            pushFollow(FOLLOW_tableRowFormatLinesIdentifier_in_rowFormatDelimited10500);
            tableRowFormatLinesIdentifier699 = tableRowFormatLinesIdentifier();

            state._fsp--;

            stream_tableRowFormatLinesIdentifier.add(tableRowFormatLinesIdentifier699.getTree());
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1775:167: ( tableRowNullFormat )?
        int alt206 = 2;
        switch (input.LA(1)) {
          case KW_NULL: {
            alt206 = 1;
          }
            break;
        }

        switch (alt206) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1775:167: tableRowNullFormat
          {
            pushFollow(FOLLOW_tableRowNullFormat_in_rowFormatDelimited10503);
            tableRowNullFormat700 = tableRowNullFormat();

            state._fsp--;

            stream_tableRowNullFormat.add(tableRowNullFormat700.getTree());
          }
            break;
        }

        // AST REWRITE
        // elements: tableRowFormatCollItemsIdentifier, tableRowFormatLinesIdentifier, tableRowNullFormat, tableRowFormatFieldIdentifier, tableRowFormatMapKeysIdentifier
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1776:5: -> ^( TOK_SERDEPROPS ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1776:8: ^( TOK_SERDEPROPS ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SERDEPROPS, "TOK_SERDEPROPS"), root_1);

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1776:25: ( tableRowFormatFieldIdentifier )?
            if (stream_tableRowFormatFieldIdentifier.hasNext()) {
              adaptor.addChild(root_1, stream_tableRowFormatFieldIdentifier.nextTree());
            }
            stream_tableRowFormatFieldIdentifier.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1776:56: ( tableRowFormatCollItemsIdentifier )?
            if (stream_tableRowFormatCollItemsIdentifier.hasNext()) {
              adaptor.addChild(root_1, stream_tableRowFormatCollItemsIdentifier.nextTree());
            }
            stream_tableRowFormatCollItemsIdentifier.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1776:91: ( tableRowFormatMapKeysIdentifier )?
            if (stream_tableRowFormatMapKeysIdentifier.hasNext()) {
              adaptor.addChild(root_1, stream_tableRowFormatMapKeysIdentifier.nextTree());
            }
            stream_tableRowFormatMapKeysIdentifier.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1776:124: ( tableRowFormatLinesIdentifier )?
            if (stream_tableRowFormatLinesIdentifier.hasNext()) {
              adaptor.addChild(root_1, stream_tableRowFormatLinesIdentifier.nextTree());
            }
            stream_tableRowFormatLinesIdentifier.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1776:155: ( tableRowNullFormat )?
            if (stream_tableRowNullFormat.hasNext()) {
              adaptor.addChild(root_1, stream_tableRowNullFormat.nextTree());
            }
            stream_tableRowNullFormat.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "rowFormatDelimited"

  public static class tableRowFormat_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "tableRowFormat"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1779:1: tableRowFormat : ( rowFormatDelimited -> ^( TOK_TABLEROWFORMAT rowFormatDelimited ) | rowFormatSerde -> ^( TOK_TABLESERIALIZER rowFormatSerde ) );
  public final HiveParser.tableRowFormat_return tableRowFormat() throws RecognitionException {
    HiveParser.tableRowFormat_return retval = new HiveParser.tableRowFormat_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.rowFormatDelimited_return rowFormatDelimited701 = null;

    HiveParser.rowFormatSerde_return rowFormatSerde702 = null;

    RewriteRuleSubtreeStream stream_rowFormatSerde = new RewriteRuleSubtreeStream(adaptor, "rule rowFormatSerde");
    RewriteRuleSubtreeStream stream_rowFormatDelimited =
        new RewriteRuleSubtreeStream(adaptor, "rule rowFormatDelimited");
    pushMsg("table row format specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1782:5: ( rowFormatDelimited -> ^( TOK_TABLEROWFORMAT rowFormatDelimited ) | rowFormatSerde -> ^( TOK_TABLESERIALIZER rowFormatSerde ) )
      int alt207 = 2;
      switch (input.LA(1)) {
        case KW_ROW: {
          switch (input.LA(2)) {
            case KW_FORMAT: {
              switch (input.LA(3)) {
                case KW_DELIMITED: {
                  alt207 = 1;
                }
                  break;
                case KW_SERDE: {
                  alt207 = 2;
                }
                  break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 207, 2, input);

                  throw nvae;
              }
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 207, 1, input);

              throw nvae;
          }
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 207, 0, input);

          throw nvae;
      }

      switch (alt207) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1783:7: rowFormatDelimited
        {
          pushFollow(FOLLOW_rowFormatDelimited_in_tableRowFormat10562);
          rowFormatDelimited701 = rowFormatDelimited();

          state._fsp--;

          stream_rowFormatDelimited.add(rowFormatDelimited701.getTree());

          // AST REWRITE
          // elements: rowFormatDelimited
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1784:5: -> ^( TOK_TABLEROWFORMAT rowFormatDelimited )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1784:8: ^( TOK_TABLEROWFORMAT rowFormatDelimited )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor
                  .becomeRoot((CommonTree) adaptor.create(TOK_TABLEROWFORMAT, "TOK_TABLEROWFORMAT"), root_1);

              adaptor.addChild(root_1, stream_rowFormatDelimited.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1785:7: rowFormatSerde
        {
          pushFollow(FOLLOW_rowFormatSerde_in_tableRowFormat10582);
          rowFormatSerde702 = rowFormatSerde();

          state._fsp--;

          stream_rowFormatSerde.add(rowFormatSerde702.getTree());

          // AST REWRITE
          // elements: rowFormatSerde
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1786:5: -> ^( TOK_TABLESERIALIZER rowFormatSerde )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1786:8: ^( TOK_TABLESERIALIZER rowFormatSerde )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor
                  .becomeRoot((CommonTree) adaptor.create(TOK_TABLESERIALIZER, "TOK_TABLESERIALIZER"), root_1);

              adaptor.addChild(root_1, stream_rowFormatSerde.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "tableRowFormat"

  public static class tablePropertiesPrefixed_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "tablePropertiesPrefixed"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1789:1: tablePropertiesPrefixed : KW_TBLPROPERTIES ! tableProperties ;
  public final HiveParser.tablePropertiesPrefixed_return tablePropertiesPrefixed() throws RecognitionException {
    HiveParser.tablePropertiesPrefixed_return retval = new HiveParser.tablePropertiesPrefixed_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_TBLPROPERTIES703 = null;
    HiveParser.tableProperties_return tableProperties704 = null;

    CommonTree KW_TBLPROPERTIES703_tree = null;

    pushMsg("table properties with prefix", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1792:5: ( KW_TBLPROPERTIES ! tableProperties )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1793:9: KW_TBLPROPERTIES ! tableProperties
      {
        root_0 = (CommonTree) adaptor.nil();

        KW_TBLPROPERTIES703 =
            (Token) match(input, KW_TBLPROPERTIES, FOLLOW_KW_TBLPROPERTIES_in_tablePropertiesPrefixed10629);

        pushFollow(FOLLOW_tableProperties_in_tablePropertiesPrefixed10632);
        tableProperties704 = tableProperties();

        state._fsp--;

        adaptor.addChild(root_0, tableProperties704.getTree());
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "tablePropertiesPrefixed"

  public static class tableProperties_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "tableProperties"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1796:1: tableProperties : LPAREN tablePropertiesList RPAREN -> ^( TOK_TABLEPROPERTIES tablePropertiesList ) ;
  public final HiveParser.tableProperties_return tableProperties() throws RecognitionException {
    HiveParser.tableProperties_return retval = new HiveParser.tableProperties_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token LPAREN705 = null;
    Token RPAREN707 = null;
    HiveParser.tablePropertiesList_return tablePropertiesList706 = null;

    CommonTree LPAREN705_tree = null;
    CommonTree RPAREN707_tree = null;
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleSubtreeStream stream_tablePropertiesList =
        new RewriteRuleSubtreeStream(adaptor, "rule tablePropertiesList");
    pushMsg("table properties", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1799:5: ( LPAREN tablePropertiesList RPAREN -> ^( TOK_TABLEPROPERTIES tablePropertiesList ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1800:7: LPAREN tablePropertiesList RPAREN
      {
        LPAREN705 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_tableProperties10665);
        stream_LPAREN.add(LPAREN705);

        pushFollow(FOLLOW_tablePropertiesList_in_tableProperties10667);
        tablePropertiesList706 = tablePropertiesList();

        state._fsp--;

        stream_tablePropertiesList.add(tablePropertiesList706.getTree());

        RPAREN707 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_tableProperties10669);
        stream_RPAREN.add(RPAREN707);

        // AST REWRITE
        // elements: tablePropertiesList
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1800:41: -> ^( TOK_TABLEPROPERTIES tablePropertiesList )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1800:44: ^( TOK_TABLEPROPERTIES tablePropertiesList )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_TABLEPROPERTIES, "TOK_TABLEPROPERTIES"), root_1);

            adaptor.addChild(root_1, stream_tablePropertiesList.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "tableProperties"

  public static class tablePropertiesList_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "tablePropertiesList"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1803:1: tablePropertiesList : ( keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_TABLEPROPLIST ( keyValueProperty )+ ) | keyProperty ( COMMA keyProperty )* -> ^( TOK_TABLEPROPLIST ( keyProperty )+ ) );
  public final HiveParser.tablePropertiesList_return tablePropertiesList() throws RecognitionException {
    HiveParser.tablePropertiesList_return retval = new HiveParser.tablePropertiesList_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token COMMA709 = null;
    Token COMMA712 = null;
    HiveParser.keyValueProperty_return keyValueProperty708 = null;

    HiveParser.keyValueProperty_return keyValueProperty710 = null;

    HiveParser.keyProperty_return keyProperty711 = null;

    HiveParser.keyProperty_return keyProperty713 = null;

    CommonTree COMMA709_tree = null;
    CommonTree COMMA712_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleSubtreeStream stream_keyValueProperty = new RewriteRuleSubtreeStream(adaptor, "rule keyValueProperty");
    RewriteRuleSubtreeStream stream_keyProperty = new RewriteRuleSubtreeStream(adaptor, "rule keyProperty");
    pushMsg("table properties list", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1806:5: ( keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_TABLEPROPLIST ( keyValueProperty )+ ) | keyProperty ( COMMA keyProperty )* -> ^( TOK_TABLEPROPLIST ( keyProperty )+ ) )
      int alt210 = 2;
      switch (input.LA(1)) {
        case StringLiteral: {
          switch (input.LA(2)) {
            case EQUAL: {
              alt210 = 1;
            }
              break;
            case COMMA:
            case RPAREN: {
              alt210 = 2;
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 210, 1, input);

              throw nvae;
          }
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 210, 0, input);

          throw nvae;
      }

      switch (alt210) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1807:7: keyValueProperty ( COMMA keyValueProperty )*
        {
          pushFollow(FOLLOW_keyValueProperty_in_tablePropertiesList10710);
          keyValueProperty708 = keyValueProperty();

          state._fsp--;

          stream_keyValueProperty.add(keyValueProperty708.getTree());

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1807:24: ( COMMA keyValueProperty )*
          loop208: do {
            int alt208 = 2;
            switch (input.LA(1)) {
              case COMMA: {
                alt208 = 1;
              }
                break;
            }

            switch (alt208) {
              case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1807:25: COMMA keyValueProperty
              {
                COMMA709 = (Token) match(input, COMMA, FOLLOW_COMMA_in_tablePropertiesList10713);
                stream_COMMA.add(COMMA709);

                pushFollow(FOLLOW_keyValueProperty_in_tablePropertiesList10715);
                keyValueProperty710 = keyValueProperty();

                state._fsp--;

                stream_keyValueProperty.add(keyValueProperty710.getTree());
              }
                break;

              default:
                break loop208;
            }
          } while (true);

          // AST REWRITE
          // elements: keyValueProperty
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1807:50: -> ^( TOK_TABLEPROPLIST ( keyValueProperty )+ )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1807:53: ^( TOK_TABLEPROPLIST ( keyValueProperty )+ )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor
                  .becomeRoot((CommonTree) adaptor.create(TOK_TABLEPROPLIST, "TOK_TABLEPROPLIST"), root_1);

              if (!(stream_keyValueProperty.hasNext())) {
                throw new RewriteEarlyExitException();
              }
              while (stream_keyValueProperty.hasNext()) {
                adaptor.addChild(root_1, stream_keyValueProperty.nextTree());
              }
              stream_keyValueProperty.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1809:7: keyProperty ( COMMA keyProperty )*
        {
          pushFollow(FOLLOW_keyProperty_in_tablePropertiesList10740);
          keyProperty711 = keyProperty();

          state._fsp--;

          stream_keyProperty.add(keyProperty711.getTree());

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1809:19: ( COMMA keyProperty )*
          loop209: do {
            int alt209 = 2;
            switch (input.LA(1)) {
              case COMMA: {
                alt209 = 1;
              }
                break;
            }

            switch (alt209) {
              case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1809:20: COMMA keyProperty
              {
                COMMA712 = (Token) match(input, COMMA, FOLLOW_COMMA_in_tablePropertiesList10743);
                stream_COMMA.add(COMMA712);

                pushFollow(FOLLOW_keyProperty_in_tablePropertiesList10745);
                keyProperty713 = keyProperty();

                state._fsp--;

                stream_keyProperty.add(keyProperty713.getTree());
              }
                break;

              default:
                break loop209;
            }
          } while (true);

          // AST REWRITE
          // elements: keyProperty
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1809:40: -> ^( TOK_TABLEPROPLIST ( keyProperty )+ )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1809:43: ^( TOK_TABLEPROPLIST ( keyProperty )+ )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor
                  .becomeRoot((CommonTree) adaptor.create(TOK_TABLEPROPLIST, "TOK_TABLEPROPLIST"), root_1);

              if (!(stream_keyProperty.hasNext())) {
                throw new RewriteEarlyExitException();
              }
              while (stream_keyProperty.hasNext()) {
                adaptor.addChild(root_1, stream_keyProperty.nextTree());
              }
              stream_keyProperty.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "tablePropertiesList"

  public static class keyValueProperty_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "keyValueProperty"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1812:1: keyValueProperty : key= StringLiteral EQUAL value= StringLiteral -> ^( TOK_TABLEPROPERTY $key $value) ;
  public final HiveParser.keyValueProperty_return keyValueProperty() throws RecognitionException {
    HiveParser.keyValueProperty_return retval = new HiveParser.keyValueProperty_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token key = null;
    Token value = null;
    Token EQUAL714 = null;

    CommonTree key_tree = null;
    CommonTree value_tree = null;
    CommonTree EQUAL714_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_EQUAL = new RewriteRuleTokenStream(adaptor, "token EQUAL");

    pushMsg("specifying key/value property", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1815:5: (key= StringLiteral EQUAL value= StringLiteral -> ^( TOK_TABLEPROPERTY $key $value) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1816:7: key= StringLiteral EQUAL value= StringLiteral
      {
        key = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_keyValueProperty10791);
        stream_StringLiteral.add(key);

        EQUAL714 = (Token) match(input, EQUAL, FOLLOW_EQUAL_in_keyValueProperty10793);
        stream_EQUAL.add(EQUAL714);

        value = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_keyValueProperty10797);
        stream_StringLiteral.add(value);

        // AST REWRITE
        // elements: value, key
        // token labels: value, key
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_value = new RewriteRuleTokenStream(adaptor, "token value", value);
        RewriteRuleTokenStream stream_key = new RewriteRuleTokenStream(adaptor, "token key", key);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1816:51: -> ^( TOK_TABLEPROPERTY $key $value)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1816:54: ^( TOK_TABLEPROPERTY $key $value)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_TABLEPROPERTY, "TOK_TABLEPROPERTY"), root_1);

            adaptor.addChild(root_1, stream_key.nextNode());

            adaptor.addChild(root_1, stream_value.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "keyValueProperty"

  public static class keyProperty_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "keyProperty"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1819:1: keyProperty : key= StringLiteral -> ^( TOK_TABLEPROPERTY $key TOK_NULL ) ;
  public final HiveParser.keyProperty_return keyProperty() throws RecognitionException {
    HiveParser.keyProperty_return retval = new HiveParser.keyProperty_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token key = null;

    CommonTree key_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");

    pushMsg("specifying key property", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1822:5: (key= StringLiteral -> ^( TOK_TABLEPROPERTY $key TOK_NULL ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1823:7: key= StringLiteral
      {
        key = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_keyProperty10844);
        stream_StringLiteral.add(key);

        // AST REWRITE
        // elements: key
        // token labels: key
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_key = new RewriteRuleTokenStream(adaptor, "token key", key);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1823:25: -> ^( TOK_TABLEPROPERTY $key TOK_NULL )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1823:28: ^( TOK_TABLEPROPERTY $key TOK_NULL )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_TABLEPROPERTY, "TOK_TABLEPROPERTY"), root_1);

            adaptor.addChild(root_1, stream_key.nextNode());

            adaptor.addChild(root_1, (CommonTree) adaptor.create(TOK_NULL, "TOK_NULL"));

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "keyProperty"

  public static class tableRowFormatFieldIdentifier_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "tableRowFormatFieldIdentifier"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1826:1: tableRowFormatFieldIdentifier : KW_FIELDS KW_TERMINATED KW_BY fldIdnt= StringLiteral ( KW_ESCAPED KW_BY fldEscape= StringLiteral )? -> ^( TOK_TABLEROWFORMATFIELD $fldIdnt ( $fldEscape)? ) ;
  public final HiveParser.tableRowFormatFieldIdentifier_return tableRowFormatFieldIdentifier()
      throws RecognitionException {
    HiveParser.tableRowFormatFieldIdentifier_return retval = new HiveParser.tableRowFormatFieldIdentifier_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token fldIdnt = null;
    Token fldEscape = null;
    Token KW_FIELDS715 = null;
    Token KW_TERMINATED716 = null;
    Token KW_BY717 = null;
    Token KW_ESCAPED718 = null;
    Token KW_BY719 = null;

    CommonTree fldIdnt_tree = null;
    CommonTree fldEscape_tree = null;
    CommonTree KW_FIELDS715_tree = null;
    CommonTree KW_TERMINATED716_tree = null;
    CommonTree KW_BY717_tree = null;
    CommonTree KW_ESCAPED718_tree = null;
    CommonTree KW_BY719_tree = null;
    RewriteRuleTokenStream stream_KW_TERMINATED = new RewriteRuleTokenStream(adaptor, "token KW_TERMINATED");
    RewriteRuleTokenStream stream_KW_BY = new RewriteRuleTokenStream(adaptor, "token KW_BY");
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_ESCAPED = new RewriteRuleTokenStream(adaptor, "token KW_ESCAPED");
    RewriteRuleTokenStream stream_KW_FIELDS = new RewriteRuleTokenStream(adaptor, "token KW_FIELDS");

    pushMsg("table row format's field separator", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1829:5: ( KW_FIELDS KW_TERMINATED KW_BY fldIdnt= StringLiteral ( KW_ESCAPED KW_BY fldEscape= StringLiteral )? -> ^( TOK_TABLEROWFORMATFIELD $fldIdnt ( $fldEscape)? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1830:7: KW_FIELDS KW_TERMINATED KW_BY fldIdnt= StringLiteral ( KW_ESCAPED KW_BY fldEscape= StringLiteral )?
      {
        KW_FIELDS715 = (Token) match(input, KW_FIELDS, FOLLOW_KW_FIELDS_in_tableRowFormatFieldIdentifier10888);
        stream_KW_FIELDS.add(KW_FIELDS715);

        KW_TERMINATED716 =
            (Token) match(input, KW_TERMINATED, FOLLOW_KW_TERMINATED_in_tableRowFormatFieldIdentifier10890);
        stream_KW_TERMINATED.add(KW_TERMINATED716);

        KW_BY717 = (Token) match(input, KW_BY, FOLLOW_KW_BY_in_tableRowFormatFieldIdentifier10892);
        stream_KW_BY.add(KW_BY717);

        fldIdnt = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_tableRowFormatFieldIdentifier10896);
        stream_StringLiteral.add(fldIdnt);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1830:59: ( KW_ESCAPED KW_BY fldEscape= StringLiteral )?
        int alt211 = 2;
        switch (input.LA(1)) {
          case KW_ESCAPED: {
            alt211 = 1;
          }
            break;
        }

        switch (alt211) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1830:60: KW_ESCAPED KW_BY fldEscape= StringLiteral
          {
            KW_ESCAPED718 = (Token) match(input, KW_ESCAPED, FOLLOW_KW_ESCAPED_in_tableRowFormatFieldIdentifier10899);
            stream_KW_ESCAPED.add(KW_ESCAPED718);

            KW_BY719 = (Token) match(input, KW_BY, FOLLOW_KW_BY_in_tableRowFormatFieldIdentifier10901);
            stream_KW_BY.add(KW_BY719);

            fldEscape = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_tableRowFormatFieldIdentifier10905);
            stream_StringLiteral.add(fldEscape);
          }
            break;
        }

        // AST REWRITE
        // elements: fldEscape, fldIdnt
        // token labels: fldIdnt, fldEscape
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_fldIdnt = new RewriteRuleTokenStream(adaptor, "token fldIdnt", fldIdnt);
        RewriteRuleTokenStream stream_fldEscape = new RewriteRuleTokenStream(adaptor, "token fldEscape", fldEscape);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1831:5: -> ^( TOK_TABLEROWFORMATFIELD $fldIdnt ( $fldEscape)? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1831:8: ^( TOK_TABLEROWFORMATFIELD $fldIdnt ( $fldEscape)? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_TABLEROWFORMATFIELD, "TOK_TABLEROWFORMATFIELD"), root_1);

            adaptor.addChild(root_1, stream_fldIdnt.nextNode());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1831:44: ( $fldEscape)?
            if (stream_fldEscape.hasNext()) {
              adaptor.addChild(root_1, stream_fldEscape.nextNode());
            }
            stream_fldEscape.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "tableRowFormatFieldIdentifier"

  public static class tableRowFormatCollItemsIdentifier_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "tableRowFormatCollItemsIdentifier"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1834:1: tableRowFormatCollItemsIdentifier : KW_COLLECTION KW_ITEMS KW_TERMINATED KW_BY collIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATCOLLITEMS $collIdnt) ;
  public final HiveParser.tableRowFormatCollItemsIdentifier_return tableRowFormatCollItemsIdentifier()
      throws RecognitionException {
    HiveParser.tableRowFormatCollItemsIdentifier_return retval =
        new HiveParser.tableRowFormatCollItemsIdentifier_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token collIdnt = null;
    Token KW_COLLECTION720 = null;
    Token KW_ITEMS721 = null;
    Token KW_TERMINATED722 = null;
    Token KW_BY723 = null;

    CommonTree collIdnt_tree = null;
    CommonTree KW_COLLECTION720_tree = null;
    CommonTree KW_ITEMS721_tree = null;
    CommonTree KW_TERMINATED722_tree = null;
    CommonTree KW_BY723_tree = null;
    RewriteRuleTokenStream stream_KW_COLLECTION = new RewriteRuleTokenStream(adaptor, "token KW_COLLECTION");
    RewriteRuleTokenStream stream_KW_TERMINATED = new RewriteRuleTokenStream(adaptor, "token KW_TERMINATED");
    RewriteRuleTokenStream stream_KW_ITEMS = new RewriteRuleTokenStream(adaptor, "token KW_ITEMS");
    RewriteRuleTokenStream stream_KW_BY = new RewriteRuleTokenStream(adaptor, "token KW_BY");
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");

    pushMsg("table row format's column separator", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1837:5: ( KW_COLLECTION KW_ITEMS KW_TERMINATED KW_BY collIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATCOLLITEMS $collIdnt) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1838:7: KW_COLLECTION KW_ITEMS KW_TERMINATED KW_BY collIdnt= StringLiteral
      {
        KW_COLLECTION720 =
            (Token) match(input, KW_COLLECTION, FOLLOW_KW_COLLECTION_in_tableRowFormatCollItemsIdentifier10957);
        stream_KW_COLLECTION.add(KW_COLLECTION720);

        KW_ITEMS721 = (Token) match(input, KW_ITEMS, FOLLOW_KW_ITEMS_in_tableRowFormatCollItemsIdentifier10959);
        stream_KW_ITEMS.add(KW_ITEMS721);

        KW_TERMINATED722 =
            (Token) match(input, KW_TERMINATED, FOLLOW_KW_TERMINATED_in_tableRowFormatCollItemsIdentifier10961);
        stream_KW_TERMINATED.add(KW_TERMINATED722);

        KW_BY723 = (Token) match(input, KW_BY, FOLLOW_KW_BY_in_tableRowFormatCollItemsIdentifier10963);
        stream_KW_BY.add(KW_BY723);

        collIdnt = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_tableRowFormatCollItemsIdentifier10967);
        stream_StringLiteral.add(collIdnt);

        // AST REWRITE
        // elements: collIdnt
        // token labels: collIdnt
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_collIdnt = new RewriteRuleTokenStream(adaptor, "token collIdnt", collIdnt);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1839:5: -> ^( TOK_TABLEROWFORMATCOLLITEMS $collIdnt)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1839:8: ^( TOK_TABLEROWFORMATCOLLITEMS $collIdnt)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_TABLEROWFORMATCOLLITEMS, "TOK_TABLEROWFORMATCOLLITEMS"), root_1);

            adaptor.addChild(root_1, stream_collIdnt.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "tableRowFormatCollItemsIdentifier"

  public static class tableRowFormatMapKeysIdentifier_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "tableRowFormatMapKeysIdentifier"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1842:1: tableRowFormatMapKeysIdentifier : KW_MAP KW_KEYS KW_TERMINATED KW_BY mapKeysIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATMAPKEYS $mapKeysIdnt) ;
  public final HiveParser.tableRowFormatMapKeysIdentifier_return tableRowFormatMapKeysIdentifier()
      throws RecognitionException {
    HiveParser.tableRowFormatMapKeysIdentifier_return retval = new HiveParser.tableRowFormatMapKeysIdentifier_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token mapKeysIdnt = null;
    Token KW_MAP724 = null;
    Token KW_KEYS725 = null;
    Token KW_TERMINATED726 = null;
    Token KW_BY727 = null;

    CommonTree mapKeysIdnt_tree = null;
    CommonTree KW_MAP724_tree = null;
    CommonTree KW_KEYS725_tree = null;
    CommonTree KW_TERMINATED726_tree = null;
    CommonTree KW_BY727_tree = null;
    RewriteRuleTokenStream stream_KW_KEYS = new RewriteRuleTokenStream(adaptor, "token KW_KEYS");
    RewriteRuleTokenStream stream_KW_TERMINATED = new RewriteRuleTokenStream(adaptor, "token KW_TERMINATED");
    RewriteRuleTokenStream stream_KW_BY = new RewriteRuleTokenStream(adaptor, "token KW_BY");
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_MAP = new RewriteRuleTokenStream(adaptor, "token KW_MAP");

    pushMsg("table row format's map key separator", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1845:5: ( KW_MAP KW_KEYS KW_TERMINATED KW_BY mapKeysIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATMAPKEYS $mapKeysIdnt) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1846:7: KW_MAP KW_KEYS KW_TERMINATED KW_BY mapKeysIdnt= StringLiteral
      {
        KW_MAP724 = (Token) match(input, KW_MAP, FOLLOW_KW_MAP_in_tableRowFormatMapKeysIdentifier11013);
        stream_KW_MAP.add(KW_MAP724);

        KW_KEYS725 = (Token) match(input, KW_KEYS, FOLLOW_KW_KEYS_in_tableRowFormatMapKeysIdentifier11015);
        stream_KW_KEYS.add(KW_KEYS725);

        KW_TERMINATED726 =
            (Token) match(input, KW_TERMINATED, FOLLOW_KW_TERMINATED_in_tableRowFormatMapKeysIdentifier11017);
        stream_KW_TERMINATED.add(KW_TERMINATED726);

        KW_BY727 = (Token) match(input, KW_BY, FOLLOW_KW_BY_in_tableRowFormatMapKeysIdentifier11019);
        stream_KW_BY.add(KW_BY727);

        mapKeysIdnt = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_tableRowFormatMapKeysIdentifier11023);
        stream_StringLiteral.add(mapKeysIdnt);

        // AST REWRITE
        // elements: mapKeysIdnt
        // token labels: mapKeysIdnt
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_mapKeysIdnt =
            new RewriteRuleTokenStream(adaptor, "token mapKeysIdnt", mapKeysIdnt);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1847:5: -> ^( TOK_TABLEROWFORMATMAPKEYS $mapKeysIdnt)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1847:8: ^( TOK_TABLEROWFORMATMAPKEYS $mapKeysIdnt)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_TABLEROWFORMATMAPKEYS, "TOK_TABLEROWFORMATMAPKEYS"), root_1);

            adaptor.addChild(root_1, stream_mapKeysIdnt.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "tableRowFormatMapKeysIdentifier"

  public static class tableRowFormatLinesIdentifier_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "tableRowFormatLinesIdentifier"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1850:1: tableRowFormatLinesIdentifier : KW_LINES KW_TERMINATED KW_BY linesIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATLINES $linesIdnt) ;
  public final HiveParser.tableRowFormatLinesIdentifier_return tableRowFormatLinesIdentifier()
      throws RecognitionException {
    HiveParser.tableRowFormatLinesIdentifier_return retval = new HiveParser.tableRowFormatLinesIdentifier_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token linesIdnt = null;
    Token KW_LINES728 = null;
    Token KW_TERMINATED729 = null;
    Token KW_BY730 = null;

    CommonTree linesIdnt_tree = null;
    CommonTree KW_LINES728_tree = null;
    CommonTree KW_TERMINATED729_tree = null;
    CommonTree KW_BY730_tree = null;
    RewriteRuleTokenStream stream_KW_TERMINATED = new RewriteRuleTokenStream(adaptor, "token KW_TERMINATED");
    RewriteRuleTokenStream stream_KW_BY = new RewriteRuleTokenStream(adaptor, "token KW_BY");
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_LINES = new RewriteRuleTokenStream(adaptor, "token KW_LINES");

    pushMsg("table row format's line separator", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1853:5: ( KW_LINES KW_TERMINATED KW_BY linesIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATLINES $linesIdnt) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1854:7: KW_LINES KW_TERMINATED KW_BY linesIdnt= StringLiteral
      {
        KW_LINES728 = (Token) match(input, KW_LINES, FOLLOW_KW_LINES_in_tableRowFormatLinesIdentifier11069);
        stream_KW_LINES.add(KW_LINES728);

        KW_TERMINATED729 =
            (Token) match(input, KW_TERMINATED, FOLLOW_KW_TERMINATED_in_tableRowFormatLinesIdentifier11071);
        stream_KW_TERMINATED.add(KW_TERMINATED729);

        KW_BY730 = (Token) match(input, KW_BY, FOLLOW_KW_BY_in_tableRowFormatLinesIdentifier11073);
        stream_KW_BY.add(KW_BY730);

        linesIdnt = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_tableRowFormatLinesIdentifier11077);
        stream_StringLiteral.add(linesIdnt);

        // AST REWRITE
        // elements: linesIdnt
        // token labels: linesIdnt
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_linesIdnt = new RewriteRuleTokenStream(adaptor, "token linesIdnt", linesIdnt);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1855:5: -> ^( TOK_TABLEROWFORMATLINES $linesIdnt)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1855:8: ^( TOK_TABLEROWFORMATLINES $linesIdnt)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_TABLEROWFORMATLINES, "TOK_TABLEROWFORMATLINES"), root_1);

            adaptor.addChild(root_1, stream_linesIdnt.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "tableRowFormatLinesIdentifier"

  public static class tableRowNullFormat_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "tableRowNullFormat"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1858:1: tableRowNullFormat : KW_NULL KW_DEFINED KW_AS nullIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATNULL $nullIdnt) ;
  public final HiveParser.tableRowNullFormat_return tableRowNullFormat() throws RecognitionException {
    HiveParser.tableRowNullFormat_return retval = new HiveParser.tableRowNullFormat_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token nullIdnt = null;
    Token KW_NULL731 = null;
    Token KW_DEFINED732 = null;
    Token KW_AS733 = null;

    CommonTree nullIdnt_tree = null;
    CommonTree KW_NULL731_tree = null;
    CommonTree KW_DEFINED732_tree = null;
    CommonTree KW_AS733_tree = null;
    RewriteRuleTokenStream stream_KW_NULL = new RewriteRuleTokenStream(adaptor, "token KW_NULL");
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_AS = new RewriteRuleTokenStream(adaptor, "token KW_AS");
    RewriteRuleTokenStream stream_KW_DEFINED = new RewriteRuleTokenStream(adaptor, "token KW_DEFINED");

    pushMsg("table row format's null specifier", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1861:5: ( KW_NULL KW_DEFINED KW_AS nullIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATNULL $nullIdnt) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1862:7: KW_NULL KW_DEFINED KW_AS nullIdnt= StringLiteral
      {
        KW_NULL731 = (Token) match(input, KW_NULL, FOLLOW_KW_NULL_in_tableRowNullFormat11123);
        stream_KW_NULL.add(KW_NULL731);

        KW_DEFINED732 = (Token) match(input, KW_DEFINED, FOLLOW_KW_DEFINED_in_tableRowNullFormat11125);
        stream_KW_DEFINED.add(KW_DEFINED732);

        KW_AS733 = (Token) match(input, KW_AS, FOLLOW_KW_AS_in_tableRowNullFormat11127);
        stream_KW_AS.add(KW_AS733);

        nullIdnt = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_tableRowNullFormat11131);
        stream_StringLiteral.add(nullIdnt);

        // AST REWRITE
        // elements: nullIdnt
        // token labels: nullIdnt
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_nullIdnt = new RewriteRuleTokenStream(adaptor, "token nullIdnt", nullIdnt);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1863:5: -> ^( TOK_TABLEROWFORMATNULL $nullIdnt)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1863:8: ^( TOK_TABLEROWFORMATNULL $nullIdnt)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_TABLEROWFORMATNULL, "TOK_TABLEROWFORMATNULL"), root_1);

            adaptor.addChild(root_1, stream_nullIdnt.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "tableRowNullFormat"

  public static class tableFileFormat_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "tableFileFormat"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1865:1: tableFileFormat : ( KW_STORED KW_AS KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )? -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt ( $inDriver)? ( $outDriver)? ) | KW_STORED KW_BY storageHandler= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )? -> ^( TOK_STORAGEHANDLER $storageHandler ( $serdeprops)? ) | KW_STORED KW_AS genericSpec= identifier -> ^( TOK_FILEFORMAT_GENERIC $genericSpec) );
  public final HiveParser.tableFileFormat_return tableFileFormat() throws RecognitionException {
    HiveParser.tableFileFormat_return retval = new HiveParser.tableFileFormat_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token inFmt = null;
    Token outFmt = null;
    Token inDriver = null;
    Token outDriver = null;
    Token storageHandler = null;
    Token KW_STORED734 = null;
    Token KW_AS735 = null;
    Token KW_INPUTFORMAT736 = null;
    Token KW_OUTPUTFORMAT737 = null;
    Token KW_INPUTDRIVER738 = null;
    Token KW_OUTPUTDRIVER739 = null;
    Token KW_STORED740 = null;
    Token KW_BY741 = null;
    Token KW_WITH742 = null;
    Token KW_SERDEPROPERTIES743 = null;
    Token KW_STORED744 = null;
    Token KW_AS745 = null;
    HiveParser.tableProperties_return serdeprops = null;

    HiveParser_IdentifiersParser.identifier_return genericSpec = null;

    CommonTree inFmt_tree = null;
    CommonTree outFmt_tree = null;
    CommonTree inDriver_tree = null;
    CommonTree outDriver_tree = null;
    CommonTree storageHandler_tree = null;
    CommonTree KW_STORED734_tree = null;
    CommonTree KW_AS735_tree = null;
    CommonTree KW_INPUTFORMAT736_tree = null;
    CommonTree KW_OUTPUTFORMAT737_tree = null;
    CommonTree KW_INPUTDRIVER738_tree = null;
    CommonTree KW_OUTPUTDRIVER739_tree = null;
    CommonTree KW_STORED740_tree = null;
    CommonTree KW_BY741_tree = null;
    CommonTree KW_WITH742_tree = null;
    CommonTree KW_SERDEPROPERTIES743_tree = null;
    CommonTree KW_STORED744_tree = null;
    CommonTree KW_AS745_tree = null;
    RewriteRuleTokenStream stream_KW_BY = new RewriteRuleTokenStream(adaptor, "token KW_BY");
    RewriteRuleTokenStream stream_KW_INPUTFORMAT = new RewriteRuleTokenStream(adaptor, "token KW_INPUTFORMAT");
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_WITH = new RewriteRuleTokenStream(adaptor, "token KW_WITH");
    RewriteRuleTokenStream stream_KW_SERDEPROPERTIES = new RewriteRuleTokenStream(adaptor, "token KW_SERDEPROPERTIES");
    RewriteRuleTokenStream stream_KW_INPUTDRIVER = new RewriteRuleTokenStream(adaptor, "token KW_INPUTDRIVER");
    RewriteRuleTokenStream stream_KW_AS = new RewriteRuleTokenStream(adaptor, "token KW_AS");
    RewriteRuleTokenStream stream_KW_OUTPUTFORMAT = new RewriteRuleTokenStream(adaptor, "token KW_OUTPUTFORMAT");
    RewriteRuleTokenStream stream_KW_STORED = new RewriteRuleTokenStream(adaptor, "token KW_STORED");
    RewriteRuleTokenStream stream_KW_OUTPUTDRIVER = new RewriteRuleTokenStream(adaptor, "token KW_OUTPUTDRIVER");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_tableProperties = new RewriteRuleSubtreeStream(adaptor, "rule tableProperties");
    pushMsg("table file format specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1868:5: ( KW_STORED KW_AS KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )? -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt ( $inDriver)? ( $outDriver)? ) | KW_STORED KW_BY storageHandler= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )? -> ^( TOK_STORAGEHANDLER $storageHandler ( $serdeprops)? ) | KW_STORED KW_AS genericSpec= identifier -> ^( TOK_FILEFORMAT_GENERIC $genericSpec) )
      int alt214 = 3;
      switch (input.LA(1)) {
        case KW_STORED: {
          switch (input.LA(2)) {
            case KW_AS: {
              switch (input.LA(3)) {
                case KW_INPUTFORMAT: {
                  alt214 = 1;
                }
                  break;
                case Identifier:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFAULT:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_METADATA:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NONE:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITION:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH: {
                  alt214 = 3;
                }
                  break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 214, 2, input);

                  throw nvae;
              }
            }
              break;
            case KW_BY: {
              alt214 = 2;
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 214, 1, input);

              throw nvae;
          }
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 214, 0, input);

          throw nvae;
      }

      switch (alt214) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1869:7: KW_STORED KW_AS KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )?
        {
          KW_STORED734 = (Token) match(input, KW_STORED, FOLLOW_KW_STORED_in_tableFileFormat11176);
          stream_KW_STORED.add(KW_STORED734);

          KW_AS735 = (Token) match(input, KW_AS, FOLLOW_KW_AS_in_tableFileFormat11178);
          stream_KW_AS.add(KW_AS735);

          KW_INPUTFORMAT736 = (Token) match(input, KW_INPUTFORMAT, FOLLOW_KW_INPUTFORMAT_in_tableFileFormat11180);
          stream_KW_INPUTFORMAT.add(KW_INPUTFORMAT736);

          inFmt = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_tableFileFormat11184);
          stream_StringLiteral.add(inFmt);

          KW_OUTPUTFORMAT737 = (Token) match(input, KW_OUTPUTFORMAT, FOLLOW_KW_OUTPUTFORMAT_in_tableFileFormat11186);
          stream_KW_OUTPUTFORMAT.add(KW_OUTPUTFORMAT737);

          outFmt = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_tableFileFormat11190);
          stream_StringLiteral.add(outFmt);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1869:95: ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )?
          int alt212 = 2;
          switch (input.LA(1)) {
            case KW_INPUTDRIVER: {
              alt212 = 1;
            }
              break;
          }

          switch (alt212) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1869:96: KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral
            {
              KW_INPUTDRIVER738 = (Token) match(input, KW_INPUTDRIVER, FOLLOW_KW_INPUTDRIVER_in_tableFileFormat11193);
              stream_KW_INPUTDRIVER.add(KW_INPUTDRIVER738);

              inDriver = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_tableFileFormat11197);
              stream_StringLiteral.add(inDriver);

              KW_OUTPUTDRIVER739 =
                  (Token) match(input, KW_OUTPUTDRIVER, FOLLOW_KW_OUTPUTDRIVER_in_tableFileFormat11199);
              stream_KW_OUTPUTDRIVER.add(KW_OUTPUTDRIVER739);

              outDriver = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_tableFileFormat11203);
              stream_StringLiteral.add(outDriver);
            }
              break;
          }

          // AST REWRITE
          // elements: outFmt, inDriver, inFmt, outDriver
          // token labels: inFmt, inDriver, outDriver, outFmt
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleTokenStream stream_inFmt = new RewriteRuleTokenStream(adaptor, "token inFmt", inFmt);
          RewriteRuleTokenStream stream_inDriver = new RewriteRuleTokenStream(adaptor, "token inDriver", inDriver);
          RewriteRuleTokenStream stream_outDriver = new RewriteRuleTokenStream(adaptor, "token outDriver", outDriver);
          RewriteRuleTokenStream stream_outFmt = new RewriteRuleTokenStream(adaptor, "token outFmt", outFmt);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1870:7: -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt ( $inDriver)? ( $outDriver)? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1870:10: ^( TOK_TABLEFILEFORMAT $inFmt $outFmt ( $inDriver)? ( $outDriver)? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor
                  .becomeRoot((CommonTree) adaptor.create(TOK_TABLEFILEFORMAT, "TOK_TABLEFILEFORMAT"), root_1);

              adaptor.addChild(root_1, stream_inFmt.nextNode());

              adaptor.addChild(root_1, stream_outFmt.nextNode());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1870:48: ( $inDriver)?
              if (stream_inDriver.hasNext()) {
                adaptor.addChild(root_1, stream_inDriver.nextNode());
              }
              stream_inDriver.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1870:59: ( $outDriver)?
              if (stream_outDriver.hasNext()) {
                adaptor.addChild(root_1, stream_outDriver.nextNode());
              }
              stream_outDriver.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1871:9: KW_STORED KW_BY storageHandler= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )?
        {
          KW_STORED740 = (Token) match(input, KW_STORED, FOLLOW_KW_STORED_in_tableFileFormat11241);
          stream_KW_STORED.add(KW_STORED740);

          KW_BY741 = (Token) match(input, KW_BY, FOLLOW_KW_BY_in_tableFileFormat11243);
          stream_KW_BY.add(KW_BY741);

          storageHandler = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_tableFileFormat11247);
          stream_StringLiteral.add(storageHandler);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1872:10: ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )?
          int alt213 = 2;
          switch (input.LA(1)) {
            case KW_WITH: {
              alt213 = 1;
            }
              break;
          }

          switch (alt213) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1872:11: KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties
            {
              KW_WITH742 = (Token) match(input, KW_WITH, FOLLOW_KW_WITH_in_tableFileFormat11259);
              stream_KW_WITH.add(KW_WITH742);

              KW_SERDEPROPERTIES743 =
                  (Token) match(input, KW_SERDEPROPERTIES, FOLLOW_KW_SERDEPROPERTIES_in_tableFileFormat11261);
              stream_KW_SERDEPROPERTIES.add(KW_SERDEPROPERTIES743);

              pushFollow(FOLLOW_tableProperties_in_tableFileFormat11265);
              serdeprops = tableProperties();

              state._fsp--;

              stream_tableProperties.add(serdeprops.getTree());
            }
              break;
          }

          // AST REWRITE
          // elements: serdeprops, storageHandler
          // token labels: storageHandler
          // rule labels: serdeprops, retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleTokenStream stream_storageHandler =
              new RewriteRuleTokenStream(adaptor, "token storageHandler", storageHandler);
          RewriteRuleSubtreeStream stream_serdeprops =
              new RewriteRuleSubtreeStream(adaptor, "rule serdeprops", serdeprops != null ? serdeprops.tree : null);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1873:7: -> ^( TOK_STORAGEHANDLER $storageHandler ( $serdeprops)? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1873:10: ^( TOK_STORAGEHANDLER $storageHandler ( $serdeprops)? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor
                  .becomeRoot((CommonTree) adaptor.create(TOK_STORAGEHANDLER, "TOK_STORAGEHANDLER"), root_1);

              adaptor.addChild(root_1, stream_storageHandler.nextNode());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1873:48: ( $serdeprops)?
              if (stream_serdeprops.hasNext()) {
                adaptor.addChild(root_1, stream_serdeprops.nextTree());
              }
              stream_serdeprops.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 3:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1874:9: KW_STORED KW_AS genericSpec= identifier
        {
          KW_STORED744 = (Token) match(input, KW_STORED, FOLLOW_KW_STORED_in_tableFileFormat11296);
          stream_KW_STORED.add(KW_STORED744);

          KW_AS745 = (Token) match(input, KW_AS, FOLLOW_KW_AS_in_tableFileFormat11298);
          stream_KW_AS.add(KW_AS745);

          pushFollow(FOLLOW_identifier_in_tableFileFormat11302);
          genericSpec = identifier();

          state._fsp--;

          stream_identifier.add(genericSpec.getTree());

          // AST REWRITE
          // elements: genericSpec
          // token labels:
          // rule labels: genericSpec, retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_genericSpec =
              new RewriteRuleSubtreeStream(adaptor, "rule genericSpec", genericSpec != null ? genericSpec.tree : null);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1875:7: -> ^( TOK_FILEFORMAT_GENERIC $genericSpec)
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1875:10: ^( TOK_FILEFORMAT_GENERIC $genericSpec)
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor
                  .becomeRoot((CommonTree) adaptor.create(TOK_FILEFORMAT_GENERIC, "TOK_FILEFORMAT_GENERIC"), root_1);

              adaptor.addChild(root_1, stream_genericSpec.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "tableFileFormat"

  public static class columnNameTypeList_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "columnNameTypeList"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1878:1: columnNameTypeList : columnNameType ( COMMA columnNameType )* -> ^( TOK_TABCOLLIST ( columnNameType )+ ) ;
  public final HiveParser.columnNameTypeList_return columnNameTypeList() throws RecognitionException {
    HiveParser.columnNameTypeList_return retval = new HiveParser.columnNameTypeList_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token COMMA747 = null;
    HiveParser.columnNameType_return columnNameType746 = null;

    HiveParser.columnNameType_return columnNameType748 = null;

    CommonTree COMMA747_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleSubtreeStream stream_columnNameType = new RewriteRuleSubtreeStream(adaptor, "rule columnNameType");
    pushMsg("column name type list", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1881:5: ( columnNameType ( COMMA columnNameType )* -> ^( TOK_TABCOLLIST ( columnNameType )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1881:7: columnNameType ( COMMA columnNameType )*
      {
        pushFollow(FOLLOW_columnNameType_in_columnNameTypeList11344);
        columnNameType746 = columnNameType();

        state._fsp--;

        stream_columnNameType.add(columnNameType746.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1881:22: ( COMMA columnNameType )*
        loop215: do {
          int alt215 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt215 = 1;
            }
              break;
          }

          switch (alt215) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1881:23: COMMA columnNameType
            {
              COMMA747 = (Token) match(input, COMMA, FOLLOW_COMMA_in_columnNameTypeList11347);
              stream_COMMA.add(COMMA747);

              pushFollow(FOLLOW_columnNameType_in_columnNameTypeList11349);
              columnNameType748 = columnNameType();

              state._fsp--;

              stream_columnNameType.add(columnNameType748.getTree());
            }
              break;

            default:
              break loop215;
          }
        } while (true);

        // AST REWRITE
        // elements: columnNameType
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1881:46: -> ^( TOK_TABCOLLIST ( columnNameType )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1881:49: ^( TOK_TABCOLLIST ( columnNameType )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABCOLLIST, "TOK_TABCOLLIST"), root_1);

            if (!(stream_columnNameType.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_columnNameType.hasNext()) {
              adaptor.addChild(root_1, stream_columnNameType.nextTree());
            }
            stream_columnNameType.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "columnNameTypeList"

  public static class columnNameColonTypeList_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "columnNameColonTypeList"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1884:1: columnNameColonTypeList : columnNameColonType ( COMMA columnNameColonType )* -> ^( TOK_TABCOLLIST ( columnNameColonType )+ ) ;
  public final HiveParser.columnNameColonTypeList_return columnNameColonTypeList() throws RecognitionException {
    HiveParser.columnNameColonTypeList_return retval = new HiveParser.columnNameColonTypeList_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token COMMA750 = null;
    HiveParser.columnNameColonType_return columnNameColonType749 = null;

    HiveParser.columnNameColonType_return columnNameColonType751 = null;

    CommonTree COMMA750_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleSubtreeStream stream_columnNameColonType =
        new RewriteRuleSubtreeStream(adaptor, "rule columnNameColonType");
    pushMsg("column name type list", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1887:5: ( columnNameColonType ( COMMA columnNameColonType )* -> ^( TOK_TABCOLLIST ( columnNameColonType )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1887:7: columnNameColonType ( COMMA columnNameColonType )*
      {
        pushFollow(FOLLOW_columnNameColonType_in_columnNameColonTypeList11387);
        columnNameColonType749 = columnNameColonType();

        state._fsp--;

        stream_columnNameColonType.add(columnNameColonType749.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1887:27: ( COMMA columnNameColonType )*
        loop216: do {
          int alt216 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt216 = 1;
            }
              break;
          }

          switch (alt216) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1887:28: COMMA columnNameColonType
            {
              COMMA750 = (Token) match(input, COMMA, FOLLOW_COMMA_in_columnNameColonTypeList11390);
              stream_COMMA.add(COMMA750);

              pushFollow(FOLLOW_columnNameColonType_in_columnNameColonTypeList11392);
              columnNameColonType751 = columnNameColonType();

              state._fsp--;

              stream_columnNameColonType.add(columnNameColonType751.getTree());
            }
              break;

            default:
              break loop216;
          }
        } while (true);

        // AST REWRITE
        // elements: columnNameColonType
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1887:56: -> ^( TOK_TABCOLLIST ( columnNameColonType )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1887:59: ^( TOK_TABCOLLIST ( columnNameColonType )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABCOLLIST, "TOK_TABCOLLIST"), root_1);

            if (!(stream_columnNameColonType.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_columnNameColonType.hasNext()) {
              adaptor.addChild(root_1, stream_columnNameColonType.nextTree());
            }
            stream_columnNameColonType.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "columnNameColonTypeList"

  public static class columnNameList_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "columnNameList"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1890:1: columnNameList : columnName ( COMMA columnName )* -> ^( TOK_TABCOLNAME ( columnName )+ ) ;
  public final HiveParser.columnNameList_return columnNameList() throws RecognitionException {
    HiveParser.columnNameList_return retval = new HiveParser.columnNameList_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token COMMA753 = null;
    HiveParser.columnName_return columnName752 = null;

    HiveParser.columnName_return columnName754 = null;

    CommonTree COMMA753_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleSubtreeStream stream_columnName = new RewriteRuleSubtreeStream(adaptor, "rule columnName");
    pushMsg("column name list", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1893:5: ( columnName ( COMMA columnName )* -> ^( TOK_TABCOLNAME ( columnName )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1893:7: columnName ( COMMA columnName )*
      {
        pushFollow(FOLLOW_columnName_in_columnNameList11430);
        columnName752 = columnName();

        state._fsp--;

        stream_columnName.add(columnName752.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1893:18: ( COMMA columnName )*
        loop217: do {
          int alt217 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt217 = 1;
            }
              break;
          }

          switch (alt217) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1893:19: COMMA columnName
            {
              COMMA753 = (Token) match(input, COMMA, FOLLOW_COMMA_in_columnNameList11433);
              stream_COMMA.add(COMMA753);

              pushFollow(FOLLOW_columnName_in_columnNameList11435);
              columnName754 = columnName();

              state._fsp--;

              stream_columnName.add(columnName754.getTree());
            }
              break;

            default:
              break loop217;
          }
        } while (true);

        // AST REWRITE
        // elements: columnName
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1893:38: -> ^( TOK_TABCOLNAME ( columnName )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1893:41: ^( TOK_TABCOLNAME ( columnName )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_1);

            if (!(stream_columnName.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_columnName.hasNext()) {
              adaptor.addChild(root_1, stream_columnName.nextTree());
            }
            stream_columnName.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "columnNameList"

  public static class columnName_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "columnName"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1896:1: columnName : identifier ;
  public final HiveParser.columnName_return columnName() throws RecognitionException {
    HiveParser.columnName_return retval = new HiveParser.columnName_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser_IdentifiersParser.identifier_return identifier755 = null;

    pushMsg("column name", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1899:5: ( identifier )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1900:7: identifier
      {
        root_0 = (CommonTree) adaptor.nil();

        pushFollow(FOLLOW_identifier_in_columnName11479);
        identifier755 = identifier();

        state._fsp--;

        adaptor.addChild(root_0, identifier755.getTree());
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "columnName"

  public static class columnNameOrderList_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "columnNameOrderList"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1903:1: columnNameOrderList : columnNameOrder ( COMMA columnNameOrder )* -> ^( TOK_TABCOLNAME ( columnNameOrder )+ ) ;
  public final HiveParser.columnNameOrderList_return columnNameOrderList() throws RecognitionException {
    HiveParser.columnNameOrderList_return retval = new HiveParser.columnNameOrderList_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token COMMA757 = null;
    HiveParser.columnNameOrder_return columnNameOrder756 = null;

    HiveParser.columnNameOrder_return columnNameOrder758 = null;

    CommonTree COMMA757_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleSubtreeStream stream_columnNameOrder = new RewriteRuleSubtreeStream(adaptor, "rule columnNameOrder");
    pushMsg("column name order list", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1906:5: ( columnNameOrder ( COMMA columnNameOrder )* -> ^( TOK_TABCOLNAME ( columnNameOrder )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1906:7: columnNameOrder ( COMMA columnNameOrder )*
      {
        pushFollow(FOLLOW_columnNameOrder_in_columnNameOrderList11506);
        columnNameOrder756 = columnNameOrder();

        state._fsp--;

        stream_columnNameOrder.add(columnNameOrder756.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1906:23: ( COMMA columnNameOrder )*
        loop218: do {
          int alt218 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt218 = 1;
            }
              break;
          }

          switch (alt218) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1906:24: COMMA columnNameOrder
            {
              COMMA757 = (Token) match(input, COMMA, FOLLOW_COMMA_in_columnNameOrderList11509);
              stream_COMMA.add(COMMA757);

              pushFollow(FOLLOW_columnNameOrder_in_columnNameOrderList11511);
              columnNameOrder758 = columnNameOrder();

              state._fsp--;

              stream_columnNameOrder.add(columnNameOrder758.getTree());
            }
              break;

            default:
              break loop218;
          }
        } while (true);

        // AST REWRITE
        // elements: columnNameOrder
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1906:48: -> ^( TOK_TABCOLNAME ( columnNameOrder )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1906:51: ^( TOK_TABCOLNAME ( columnNameOrder )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_1);

            if (!(stream_columnNameOrder.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_columnNameOrder.hasNext()) {
              adaptor.addChild(root_1, stream_columnNameOrder.nextTree());
            }
            stream_columnNameOrder.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "columnNameOrderList"

  public static class skewedValueElement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "skewedValueElement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1909:1: skewedValueElement : ( skewedColumnValues | skewedColumnValuePairList );
  public final HiveParser.skewedValueElement_return skewedValueElement() throws RecognitionException {
    HiveParser.skewedValueElement_return retval = new HiveParser.skewedValueElement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.skewedColumnValues_return skewedColumnValues759 = null;

    HiveParser.skewedColumnValuePairList_return skewedColumnValuePairList760 = null;

    pushMsg("skewed value element", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1912:5: ( skewedColumnValues | skewedColumnValuePairList )
      int alt219 = 2;
      switch (input.LA(1)) {
        case BigintLiteral:
        case CharSetName:
        case DecimalLiteral:
        case KW_DATE:
        case KW_FALSE:
        case KW_TIMESTAMP:
        case KW_TRUE:
        case Number:
        case SmallintLiteral:
        case StringLiteral:
        case TinyintLiteral: {
          alt219 = 1;
        }
          break;
        case LPAREN: {
          alt219 = 2;
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 219, 0, input);

          throw nvae;
      }

      switch (alt219) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1913:7: skewedColumnValues
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_skewedColumnValues_in_skewedValueElement11556);
          skewedColumnValues759 = skewedColumnValues();

          state._fsp--;

          adaptor.addChild(root_0, skewedColumnValues759.getTree());
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1914:8: skewedColumnValuePairList
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_skewedColumnValuePairList_in_skewedValueElement11565);
          skewedColumnValuePairList760 = skewedColumnValuePairList();

          state._fsp--;

          adaptor.addChild(root_0, skewedColumnValuePairList760.getTree());
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "skewedValueElement"

  public static class skewedColumnValuePairList_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "skewedColumnValuePairList"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1917:1: skewedColumnValuePairList : skewedColumnValuePair ( COMMA skewedColumnValuePair )* -> ^( TOK_TABCOLVALUE_PAIR ( skewedColumnValuePair )+ ) ;
  public final HiveParser.skewedColumnValuePairList_return skewedColumnValuePairList() throws RecognitionException {
    HiveParser.skewedColumnValuePairList_return retval = new HiveParser.skewedColumnValuePairList_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token COMMA762 = null;
    HiveParser.skewedColumnValuePair_return skewedColumnValuePair761 = null;

    HiveParser.skewedColumnValuePair_return skewedColumnValuePair763 = null;

    CommonTree COMMA762_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleSubtreeStream stream_skewedColumnValuePair =
        new RewriteRuleSubtreeStream(adaptor, "rule skewedColumnValuePair");
    pushMsg("column value pair list", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1920:5: ( skewedColumnValuePair ( COMMA skewedColumnValuePair )* -> ^( TOK_TABCOLVALUE_PAIR ( skewedColumnValuePair )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1920:7: skewedColumnValuePair ( COMMA skewedColumnValuePair )*
      {
        pushFollow(FOLLOW_skewedColumnValuePair_in_skewedColumnValuePairList11592);
        skewedColumnValuePair761 = skewedColumnValuePair();

        state._fsp--;

        stream_skewedColumnValuePair.add(skewedColumnValuePair761.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1920:29: ( COMMA skewedColumnValuePair )*
        loop220: do {
          int alt220 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt220 = 1;
            }
              break;
          }

          switch (alt220) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1920:30: COMMA skewedColumnValuePair
            {
              COMMA762 = (Token) match(input, COMMA, FOLLOW_COMMA_in_skewedColumnValuePairList11595);
              stream_COMMA.add(COMMA762);

              pushFollow(FOLLOW_skewedColumnValuePair_in_skewedColumnValuePairList11597);
              skewedColumnValuePair763 = skewedColumnValuePair();

              state._fsp--;

              stream_skewedColumnValuePair.add(skewedColumnValuePair763.getTree());
            }
              break;

            default:
              break loop220;
          }
        } while (true);

        // AST REWRITE
        // elements: skewedColumnValuePair
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1920:60: -> ^( TOK_TABCOLVALUE_PAIR ( skewedColumnValuePair )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1920:63: ^( TOK_TABCOLVALUE_PAIR ( skewedColumnValuePair )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_TABCOLVALUE_PAIR, "TOK_TABCOLVALUE_PAIR"), root_1);

            if (!(stream_skewedColumnValuePair.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_skewedColumnValuePair.hasNext()) {
              adaptor.addChild(root_1, stream_skewedColumnValuePair.nextTree());
            }
            stream_skewedColumnValuePair.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "skewedColumnValuePairList"

  public static class skewedColumnValuePair_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "skewedColumnValuePair"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1923:1: skewedColumnValuePair : LPAREN colValues= skewedColumnValues RPAREN -> ^( TOK_TABCOLVALUES $colValues) ;
  public final HiveParser.skewedColumnValuePair_return skewedColumnValuePair() throws RecognitionException {
    HiveParser.skewedColumnValuePair_return retval = new HiveParser.skewedColumnValuePair_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token LPAREN764 = null;
    Token RPAREN765 = null;
    HiveParser.skewedColumnValues_return colValues = null;

    CommonTree LPAREN764_tree = null;
    CommonTree RPAREN765_tree = null;
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleSubtreeStream stream_skewedColumnValues =
        new RewriteRuleSubtreeStream(adaptor, "rule skewedColumnValues");
    pushMsg("column value pair", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1926:5: ( LPAREN colValues= skewedColumnValues RPAREN -> ^( TOK_TABCOLVALUES $colValues) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1927:7: LPAREN colValues= skewedColumnValues RPAREN
      {
        LPAREN764 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_skewedColumnValuePair11642);
        stream_LPAREN.add(LPAREN764);

        pushFollow(FOLLOW_skewedColumnValues_in_skewedColumnValuePair11646);
        colValues = skewedColumnValues();

        state._fsp--;

        stream_skewedColumnValues.add(colValues.getTree());

        RPAREN765 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_skewedColumnValuePair11648);
        stream_RPAREN.add(RPAREN765);

        // AST REWRITE
        // elements: colValues
        // token labels:
        // rule labels: colValues, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_colValues =
            new RewriteRuleSubtreeStream(adaptor, "rule colValues", colValues != null ? colValues.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1928:7: -> ^( TOK_TABCOLVALUES $colValues)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1928:10: ^( TOK_TABCOLVALUES $colValues)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABCOLVALUES, "TOK_TABCOLVALUES"),
                root_1);

            adaptor.addChild(root_1, stream_colValues.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "skewedColumnValuePair"

  public static class skewedColumnValues_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "skewedColumnValues"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1931:1: skewedColumnValues : skewedColumnValue ( COMMA skewedColumnValue )* -> ^( TOK_TABCOLVALUE ( skewedColumnValue )+ ) ;
  public final HiveParser.skewedColumnValues_return skewedColumnValues() throws RecognitionException {
    HiveParser.skewedColumnValues_return retval = new HiveParser.skewedColumnValues_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token COMMA767 = null;
    HiveParser.skewedColumnValue_return skewedColumnValue766 = null;

    HiveParser.skewedColumnValue_return skewedColumnValue768 = null;

    CommonTree COMMA767_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleSubtreeStream stream_skewedColumnValue = new RewriteRuleSubtreeStream(adaptor, "rule skewedColumnValue");
    pushMsg("column values", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1934:5: ( skewedColumnValue ( COMMA skewedColumnValue )* -> ^( TOK_TABCOLVALUE ( skewedColumnValue )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1934:7: skewedColumnValue ( COMMA skewedColumnValue )*
      {
        pushFollow(FOLLOW_skewedColumnValue_in_skewedColumnValues11691);
        skewedColumnValue766 = skewedColumnValue();

        state._fsp--;

        stream_skewedColumnValue.add(skewedColumnValue766.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1934:25: ( COMMA skewedColumnValue )*
        loop221: do {
          int alt221 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt221 = 1;
            }
              break;
          }

          switch (alt221) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1934:26: COMMA skewedColumnValue
            {
              COMMA767 = (Token) match(input, COMMA, FOLLOW_COMMA_in_skewedColumnValues11694);
              stream_COMMA.add(COMMA767);

              pushFollow(FOLLOW_skewedColumnValue_in_skewedColumnValues11696);
              skewedColumnValue768 = skewedColumnValue();

              state._fsp--;

              stream_skewedColumnValue.add(skewedColumnValue768.getTree());
            }
              break;

            default:
              break loop221;
          }
        } while (true);

        // AST REWRITE
        // elements: skewedColumnValue
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1934:52: -> ^( TOK_TABCOLVALUE ( skewedColumnValue )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1934:55: ^( TOK_TABCOLVALUE ( skewedColumnValue )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABCOLVALUE, "TOK_TABCOLVALUE"),
                root_1);

            if (!(stream_skewedColumnValue.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_skewedColumnValue.hasNext()) {
              adaptor.addChild(root_1, stream_skewedColumnValue.nextTree());
            }
            stream_skewedColumnValue.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "skewedColumnValues"

  public static class skewedColumnValue_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "skewedColumnValue"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1937:1: skewedColumnValue : constant ;
  public final HiveParser.skewedColumnValue_return skewedColumnValue() throws RecognitionException {
    HiveParser.skewedColumnValue_return retval = new HiveParser.skewedColumnValue_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser_IdentifiersParser.constant_return constant769 = null;

    pushMsg("column value", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1940:5: ( constant )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1941:7: constant
      {
        root_0 = (CommonTree) adaptor.nil();

        pushFollow(FOLLOW_constant_in_skewedColumnValue11740);
        constant769 = constant();

        state._fsp--;

        adaptor.addChild(root_0, constant769.getTree());
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "skewedColumnValue"

  public static class skewedValueLocationElement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "skewedValueLocationElement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1944:1: skewedValueLocationElement : ( skewedColumnValue | skewedColumnValuePair );
  public final HiveParser.skewedValueLocationElement_return skewedValueLocationElement() throws RecognitionException {
    HiveParser.skewedValueLocationElement_return retval = new HiveParser.skewedValueLocationElement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.skewedColumnValue_return skewedColumnValue770 = null;

    HiveParser.skewedColumnValuePair_return skewedColumnValuePair771 = null;

    pushMsg("skewed value location element", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1947:5: ( skewedColumnValue | skewedColumnValuePair )
      int alt222 = 2;
      switch (input.LA(1)) {
        case BigintLiteral:
        case CharSetName:
        case DecimalLiteral:
        case KW_DATE:
        case KW_FALSE:
        case KW_TIMESTAMP:
        case KW_TRUE:
        case Number:
        case SmallintLiteral:
        case StringLiteral:
        case TinyintLiteral: {
          alt222 = 1;
        }
          break;
        case LPAREN: {
          alt222 = 2;
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 222, 0, input);

          throw nvae;
      }

      switch (alt222) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1948:7: skewedColumnValue
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_skewedColumnValue_in_skewedValueLocationElement11774);
          skewedColumnValue770 = skewedColumnValue();

          state._fsp--;

          adaptor.addChild(root_0, skewedColumnValue770.getTree());
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1949:8: skewedColumnValuePair
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_skewedColumnValuePair_in_skewedValueLocationElement11783);
          skewedColumnValuePair771 = skewedColumnValuePair();

          state._fsp--;

          adaptor.addChild(root_0, skewedColumnValuePair771.getTree());
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "skewedValueLocationElement"

  public static class columnNameOrder_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "columnNameOrder"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1952:1: columnNameOrder : identifier (asc= KW_ASC |desc= KW_DESC )? -> {$desc == null}? ^( TOK_TABSORTCOLNAMEASC identifier ) -> ^( TOK_TABSORTCOLNAMEDESC identifier ) ;
  public final HiveParser.columnNameOrder_return columnNameOrder() throws RecognitionException {
    HiveParser.columnNameOrder_return retval = new HiveParser.columnNameOrder_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token asc = null;
    Token desc = null;
    HiveParser_IdentifiersParser.identifier_return identifier772 = null;

    CommonTree asc_tree = null;
    CommonTree desc_tree = null;
    RewriteRuleTokenStream stream_KW_DESC = new RewriteRuleTokenStream(adaptor, "token KW_DESC");
    RewriteRuleTokenStream stream_KW_ASC = new RewriteRuleTokenStream(adaptor, "token KW_ASC");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    pushMsg("column name order", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1955:5: ( identifier (asc= KW_ASC |desc= KW_DESC )? -> {$desc == null}? ^( TOK_TABSORTCOLNAMEASC identifier ) -> ^( TOK_TABSORTCOLNAMEDESC identifier ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1955:7: identifier (asc= KW_ASC |desc= KW_DESC )?
      {
        pushFollow(FOLLOW_identifier_in_columnNameOrder11814);
        identifier772 = identifier();

        state._fsp--;

        stream_identifier.add(identifier772.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1955:18: (asc= KW_ASC |desc= KW_DESC )?
        int alt223 = 3;
        switch (input.LA(1)) {
          case KW_ASC: {
            alt223 = 1;
          }
            break;
          case KW_DESC: {
            alt223 = 2;
          }
            break;
        }

        switch (alt223) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1955:19: asc= KW_ASC
          {
            asc = (Token) match(input, KW_ASC, FOLLOW_KW_ASC_in_columnNameOrder11819);
            stream_KW_ASC.add(asc);
          }
            break;
          case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1955:32: desc= KW_DESC
          {
            desc = (Token) match(input, KW_DESC, FOLLOW_KW_DESC_in_columnNameOrder11825);
            stream_KW_DESC.add(desc);
          }
            break;
        }

        // AST REWRITE
        // elements: identifier, identifier
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1956:5: -> {$desc == null}? ^( TOK_TABSORTCOLNAMEASC identifier )
        if (desc == null) {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1956:25: ^( TOK_TABSORTCOLNAMEASC identifier )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC"), root_1);

            adaptor.addChild(root_1, stream_identifier.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        } else // 1957:5: -> ^( TOK_TABSORTCOLNAMEDESC identifier )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1957:25: ^( TOK_TABSORTCOLNAMEDESC identifier )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_TABSORTCOLNAMEDESC, "TOK_TABSORTCOLNAMEDESC"), root_1);

            adaptor.addChild(root_1, stream_identifier.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "columnNameOrder"

  public static class columnNameCommentList_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "columnNameCommentList"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1960:1: columnNameCommentList : columnNameComment ( COMMA columnNameComment )* -> ^( TOK_TABCOLNAME ( columnNameComment )+ ) ;
  public final HiveParser.columnNameCommentList_return columnNameCommentList() throws RecognitionException {
    HiveParser.columnNameCommentList_return retval = new HiveParser.columnNameCommentList_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token COMMA774 = null;
    HiveParser.columnNameComment_return columnNameComment773 = null;

    HiveParser.columnNameComment_return columnNameComment775 = null;

    CommonTree COMMA774_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleSubtreeStream stream_columnNameComment = new RewriteRuleSubtreeStream(adaptor, "rule columnNameComment");
    pushMsg("column name comment list", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1963:5: ( columnNameComment ( COMMA columnNameComment )* -> ^( TOK_TABCOLNAME ( columnNameComment )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1963:7: columnNameComment ( COMMA columnNameComment )*
      {
        pushFollow(FOLLOW_columnNameComment_in_columnNameCommentList11897);
        columnNameComment773 = columnNameComment();

        state._fsp--;

        stream_columnNameComment.add(columnNameComment773.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1963:25: ( COMMA columnNameComment )*
        loop224: do {
          int alt224 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt224 = 1;
            }
              break;
          }

          switch (alt224) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1963:26: COMMA columnNameComment
            {
              COMMA774 = (Token) match(input, COMMA, FOLLOW_COMMA_in_columnNameCommentList11900);
              stream_COMMA.add(COMMA774);

              pushFollow(FOLLOW_columnNameComment_in_columnNameCommentList11902);
              columnNameComment775 = columnNameComment();

              state._fsp--;

              stream_columnNameComment.add(columnNameComment775.getTree());
            }
              break;

            default:
              break loop224;
          }
        } while (true);

        // AST REWRITE
        // elements: columnNameComment
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1963:52: -> ^( TOK_TABCOLNAME ( columnNameComment )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1963:55: ^( TOK_TABCOLNAME ( columnNameComment )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_1);

            if (!(stream_columnNameComment.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_columnNameComment.hasNext()) {
              adaptor.addChild(root_1, stream_columnNameComment.nextTree());
            }
            stream_columnNameComment.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "columnNameCommentList"

  public static class columnNameComment_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "columnNameComment"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1966:1: columnNameComment : colName= identifier ( KW_COMMENT comment= StringLiteral )? -> ^( TOK_TABCOL $colName TOK_NULL ( $comment)? ) ;
  public final HiveParser.columnNameComment_return columnNameComment() throws RecognitionException {
    HiveParser.columnNameComment_return retval = new HiveParser.columnNameComment_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token comment = null;
    Token KW_COMMENT776 = null;
    HiveParser_IdentifiersParser.identifier_return colName = null;

    CommonTree comment_tree = null;
    CommonTree KW_COMMENT776_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_COMMENT = new RewriteRuleTokenStream(adaptor, "token KW_COMMENT");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    pushMsg("column name comment", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1969:5: (colName= identifier ( KW_COMMENT comment= StringLiteral )? -> ^( TOK_TABCOL $colName TOK_NULL ( $comment)? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1969:7: colName= identifier ( KW_COMMENT comment= StringLiteral )?
      {
        pushFollow(FOLLOW_identifier_in_columnNameComment11942);
        colName = identifier();

        state._fsp--;

        stream_identifier.add(colName.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1969:26: ( KW_COMMENT comment= StringLiteral )?
        int alt225 = 2;
        switch (input.LA(1)) {
          case KW_COMMENT: {
            alt225 = 1;
          }
            break;
        }

        switch (alt225) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1969:27: KW_COMMENT comment= StringLiteral
          {
            KW_COMMENT776 = (Token) match(input, KW_COMMENT, FOLLOW_KW_COMMENT_in_columnNameComment11945);
            stream_KW_COMMENT.add(KW_COMMENT776);

            comment = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_columnNameComment11949);
            stream_StringLiteral.add(comment);
          }
            break;
        }

        // AST REWRITE
        // elements: colName, comment
        // token labels: comment
        // rule labels: colName, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_comment = new RewriteRuleTokenStream(adaptor, "token comment", comment);
        RewriteRuleSubtreeStream stream_colName =
            new RewriteRuleSubtreeStream(adaptor, "rule colName", colName != null ? colName.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1970:5: -> ^( TOK_TABCOL $colName TOK_NULL ( $comment)? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1970:8: ^( TOK_TABCOL $colName TOK_NULL ( $comment)? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABCOL, "TOK_TABCOL"), root_1);

            adaptor.addChild(root_1, stream_colName.nextTree());

            adaptor.addChild(root_1, (CommonTree) adaptor.create(TOK_NULL, "TOK_NULL"));

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1970:40: ( $comment)?
            if (stream_comment.hasNext()) {
              adaptor.addChild(root_1, stream_comment.nextNode());
            }
            stream_comment.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "columnNameComment"

  public static class columnRefOrder_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "columnRefOrder"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1973:1: columnRefOrder : expression (asc= KW_ASC |desc= KW_DESC )? -> {$desc == null}? ^( TOK_TABSORTCOLNAMEASC expression ) -> ^( TOK_TABSORTCOLNAMEDESC expression ) ;
  public final HiveParser.columnRefOrder_return columnRefOrder() throws RecognitionException {
    HiveParser.columnRefOrder_return retval = new HiveParser.columnRefOrder_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token asc = null;
    Token desc = null;
    HiveParser_IdentifiersParser.expression_return expression777 = null;

    CommonTree asc_tree = null;
    CommonTree desc_tree = null;
    RewriteRuleTokenStream stream_KW_DESC = new RewriteRuleTokenStream(adaptor, "token KW_DESC");
    RewriteRuleTokenStream stream_KW_ASC = new RewriteRuleTokenStream(adaptor, "token KW_ASC");
    RewriteRuleSubtreeStream stream_expression = new RewriteRuleSubtreeStream(adaptor, "rule expression");
    pushMsg("column order", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1976:5: ( expression (asc= KW_ASC |desc= KW_DESC )? -> {$desc == null}? ^( TOK_TABSORTCOLNAMEASC expression ) -> ^( TOK_TABSORTCOLNAMEDESC expression ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1976:7: expression (asc= KW_ASC |desc= KW_DESC )?
      {
        pushFollow(FOLLOW_expression_in_columnRefOrder11997);
        expression777 = expression();

        state._fsp--;

        stream_expression.add(expression777.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1976:18: (asc= KW_ASC |desc= KW_DESC )?
        int alt226 = 3;
        switch (input.LA(1)) {
          case KW_ASC: {
            alt226 = 1;
          }
            break;
          case KW_DESC: {
            alt226 = 2;
          }
            break;
        }

        switch (alt226) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1976:19: asc= KW_ASC
          {
            asc = (Token) match(input, KW_ASC, FOLLOW_KW_ASC_in_columnRefOrder12002);
            stream_KW_ASC.add(asc);
          }
            break;
          case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1976:32: desc= KW_DESC
          {
            desc = (Token) match(input, KW_DESC, FOLLOW_KW_DESC_in_columnRefOrder12008);
            stream_KW_DESC.add(desc);
          }
            break;
        }

        // AST REWRITE
        // elements: expression, expression
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1977:5: -> {$desc == null}? ^( TOK_TABSORTCOLNAMEASC expression )
        if (desc == null) {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1977:25: ^( TOK_TABSORTCOLNAMEASC expression )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC"), root_1);

            adaptor.addChild(root_1, stream_expression.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        } else // 1978:5: -> ^( TOK_TABSORTCOLNAMEDESC expression )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1978:25: ^( TOK_TABSORTCOLNAMEDESC expression )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_TABSORTCOLNAMEDESC, "TOK_TABSORTCOLNAMEDESC"), root_1);

            adaptor.addChild(root_1, stream_expression.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "columnRefOrder"

  public static class columnNameType_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "columnNameType"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1981:1: columnNameType : colName= identifier colType ( KW_COMMENT comment= StringLiteral )? -> {$comment == null}? ^( TOK_TABCOL $colName colType ) -> ^( TOK_TABCOL $colName colType $comment) ;
  public final HiveParser.columnNameType_return columnNameType() throws RecognitionException {
    HiveParser.columnNameType_return retval = new HiveParser.columnNameType_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token comment = null;
    Token KW_COMMENT779 = null;
    HiveParser_IdentifiersParser.identifier_return colName = null;

    HiveParser.colType_return colType778 = null;

    CommonTree comment_tree = null;
    CommonTree KW_COMMENT779_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_COMMENT = new RewriteRuleTokenStream(adaptor, "token KW_COMMENT");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_colType = new RewriteRuleSubtreeStream(adaptor, "rule colType");
    pushMsg("column specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1984:5: (colName= identifier colType ( KW_COMMENT comment= StringLiteral )? -> {$comment == null}? ^( TOK_TABCOL $colName colType ) -> ^( TOK_TABCOL $colName colType $comment) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1984:7: colName= identifier colType ( KW_COMMENT comment= StringLiteral )?
      {
        pushFollow(FOLLOW_identifier_in_columnNameType12082);
        colName = identifier();

        state._fsp--;

        stream_identifier.add(colName.getTree());

        pushFollow(FOLLOW_colType_in_columnNameType12084);
        colType778 = colType();

        state._fsp--;

        stream_colType.add(colType778.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1984:34: ( KW_COMMENT comment= StringLiteral )?
        int alt227 = 2;
        switch (input.LA(1)) {
          case KW_COMMENT: {
            alt227 = 1;
          }
            break;
        }

        switch (alt227) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1984:35: KW_COMMENT comment= StringLiteral
          {
            KW_COMMENT779 = (Token) match(input, KW_COMMENT, FOLLOW_KW_COMMENT_in_columnNameType12087);
            stream_KW_COMMENT.add(KW_COMMENT779);

            comment = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_columnNameType12091);
            stream_StringLiteral.add(comment);
          }
            break;
        }

        // AST REWRITE
        // elements: colType, comment, colName, colName, colType
        // token labels: comment
        // rule labels: colName, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_comment = new RewriteRuleTokenStream(adaptor, "token comment", comment);
        RewriteRuleSubtreeStream stream_colName =
            new RewriteRuleSubtreeStream(adaptor, "rule colName", colName != null ? colName.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1985:5: -> {$comment == null}? ^( TOK_TABCOL $colName colType )
        if (comment == null) {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1985:28: ^( TOK_TABCOL $colName colType )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABCOL, "TOK_TABCOL"), root_1);

            adaptor.addChild(root_1, stream_colName.nextTree());

            adaptor.addChild(root_1, stream_colType.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        } else // 1986:5: -> ^( TOK_TABCOL $colName colType $comment)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1986:28: ^( TOK_TABCOL $colName colType $comment)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABCOL, "TOK_TABCOL"), root_1);

            adaptor.addChild(root_1, stream_colName.nextTree());

            adaptor.addChild(root_1, stream_colType.nextTree());

            adaptor.addChild(root_1, stream_comment.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "columnNameType"

  public static class columnNameColonType_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "columnNameColonType"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1989:1: columnNameColonType : colName= identifier COLON colType ( KW_COMMENT comment= StringLiteral )? -> {$comment == null}? ^( TOK_TABCOL $colName colType ) -> ^( TOK_TABCOL $colName colType $comment) ;
  public final HiveParser.columnNameColonType_return columnNameColonType() throws RecognitionException {
    HiveParser.columnNameColonType_return retval = new HiveParser.columnNameColonType_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token comment = null;
    Token COLON780 = null;
    Token KW_COMMENT782 = null;
    HiveParser_IdentifiersParser.identifier_return colName = null;

    HiveParser.colType_return colType781 = null;

    CommonTree comment_tree = null;
    CommonTree COLON780_tree = null;
    CommonTree KW_COMMENT782_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_COLON = new RewriteRuleTokenStream(adaptor, "token COLON");
    RewriteRuleTokenStream stream_KW_COMMENT = new RewriteRuleTokenStream(adaptor, "token KW_COMMENT");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_colType = new RewriteRuleSubtreeStream(adaptor, "rule colType");
    pushMsg("column specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1992:5: (colName= identifier COLON colType ( KW_COMMENT comment= StringLiteral )? -> {$comment == null}? ^( TOK_TABCOL $colName colType ) -> ^( TOK_TABCOL $colName colType $comment) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1992:7: colName= identifier COLON colType ( KW_COMMENT comment= StringLiteral )?
      {
        pushFollow(FOLLOW_identifier_in_columnNameColonType12177);
        colName = identifier();

        state._fsp--;

        stream_identifier.add(colName.getTree());

        COLON780 = (Token) match(input, COLON, FOLLOW_COLON_in_columnNameColonType12179);
        stream_COLON.add(COLON780);

        pushFollow(FOLLOW_colType_in_columnNameColonType12181);
        colType781 = colType();

        state._fsp--;

        stream_colType.add(colType781.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1992:40: ( KW_COMMENT comment= StringLiteral )?
        int alt228 = 2;
        switch (input.LA(1)) {
          case KW_COMMENT: {
            alt228 = 1;
          }
            break;
        }

        switch (alt228) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1992:41: KW_COMMENT comment= StringLiteral
          {
            KW_COMMENT782 = (Token) match(input, KW_COMMENT, FOLLOW_KW_COMMENT_in_columnNameColonType12184);
            stream_KW_COMMENT.add(KW_COMMENT782);

            comment = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_columnNameColonType12188);
            stream_StringLiteral.add(comment);
          }
            break;
        }

        // AST REWRITE
        // elements: colType, colName, comment, colName, colType
        // token labels: comment
        // rule labels: colName, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_comment = new RewriteRuleTokenStream(adaptor, "token comment", comment);
        RewriteRuleSubtreeStream stream_colName =
            new RewriteRuleSubtreeStream(adaptor, "rule colName", colName != null ? colName.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1993:5: -> {$comment == null}? ^( TOK_TABCOL $colName colType )
        if (comment == null) {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1993:28: ^( TOK_TABCOL $colName colType )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABCOL, "TOK_TABCOL"), root_1);

            adaptor.addChild(root_1, stream_colName.nextTree());

            adaptor.addChild(root_1, stream_colType.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        } else // 1994:5: -> ^( TOK_TABCOL $colName colType $comment)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1994:28: ^( TOK_TABCOL $colName colType $comment)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABCOL, "TOK_TABCOL"), root_1);

            adaptor.addChild(root_1, stream_colName.nextTree());

            adaptor.addChild(root_1, stream_colType.nextTree());

            adaptor.addChild(root_1, stream_comment.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "columnNameColonType"

  public static class colType_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "colType"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1997:1: colType : type ;
  public final HiveParser.colType_return colType() throws RecognitionException {
    HiveParser.colType_return retval = new HiveParser.colType_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.type_return type783 = null;

    pushMsg("column type", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2000:5: ( type )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2000:7: type
      {
        root_0 = (CommonTree) adaptor.nil();

        pushFollow(FOLLOW_type_in_colType12272);
        type783 = type();

        state._fsp--;

        adaptor.addChild(root_0, type783.getTree());
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "colType"

  public static class colTypeList_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "colTypeList"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2003:1: colTypeList : colType ( COMMA colType )* -> ^( TOK_COLTYPELIST ( colType )+ ) ;
  public final HiveParser.colTypeList_return colTypeList() throws RecognitionException {
    HiveParser.colTypeList_return retval = new HiveParser.colTypeList_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token COMMA785 = null;
    HiveParser.colType_return colType784 = null;

    HiveParser.colType_return colType786 = null;

    CommonTree COMMA785_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleSubtreeStream stream_colType = new RewriteRuleSubtreeStream(adaptor, "rule colType");
    pushMsg("column type list", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2006:5: ( colType ( COMMA colType )* -> ^( TOK_COLTYPELIST ( colType )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2006:7: colType ( COMMA colType )*
      {
        pushFollow(FOLLOW_colType_in_colTypeList12299);
        colType784 = colType();

        state._fsp--;

        stream_colType.add(colType784.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2006:15: ( COMMA colType )*
        loop229: do {
          int alt229 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt229 = 1;
            }
              break;
          }

          switch (alt229) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2006:16: COMMA colType
            {
              COMMA785 = (Token) match(input, COMMA, FOLLOW_COMMA_in_colTypeList12302);
              stream_COMMA.add(COMMA785);

              pushFollow(FOLLOW_colType_in_colTypeList12304);
              colType786 = colType();

              state._fsp--;

              stream_colType.add(colType786.getTree());
            }
              break;

            default:
              break loop229;
          }
        } while (true);

        // AST REWRITE
        // elements: colType
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2006:32: -> ^( TOK_COLTYPELIST ( colType )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2006:35: ^( TOK_COLTYPELIST ( colType )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_COLTYPELIST, "TOK_COLTYPELIST"),
                root_1);

            if (!(stream_colType.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_colType.hasNext()) {
              adaptor.addChild(root_1, stream_colType.nextTree());
            }
            stream_colType.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "colTypeList"

  public static class type_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "type"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2009:1: type : ( primitiveType | listType | structType | mapType | unionType );
  public final HiveParser.type_return type() throws RecognitionException {
    HiveParser.type_return retval = new HiveParser.type_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.primitiveType_return primitiveType787 = null;

    HiveParser.listType_return listType788 = null;

    HiveParser.structType_return structType789 = null;

    HiveParser.mapType_return mapType790 = null;

    HiveParser.unionType_return unionType791 = null;

    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2010:5: ( primitiveType | listType | structType | mapType | unionType )
      int alt230 = 5;
      switch (input.LA(1)) {
        case KW_BIGINT:
        case KW_BINARY:
        case KW_BOOLEAN:
        case KW_CHAR:
        case KW_DATE:
        case KW_DATETIME:
        case KW_DECIMAL:
        case KW_DOUBLE:
        case KW_FLOAT:
        case KW_INT:
        case KW_SMALLINT:
        case KW_STRING:
        case KW_TIMESTAMP:
        case KW_TINYINT:
        case KW_VARCHAR: {
          alt230 = 1;
        }
          break;
        case KW_ARRAY: {
          alt230 = 2;
        }
          break;
        case KW_STRUCT: {
          alt230 = 3;
        }
          break;
        case KW_MAP: {
          alt230 = 4;
        }
          break;
        case KW_UNIONTYPE: {
          alt230 = 5;
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 230, 0, input);

          throw nvae;
      }

      switch (alt230) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2010:7: primitiveType
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_primitiveType_in_type12332);
          primitiveType787 = primitiveType();

          state._fsp--;

          adaptor.addChild(root_0, primitiveType787.getTree());
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2011:7: listType
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_listType_in_type12340);
          listType788 = listType();

          state._fsp--;

          adaptor.addChild(root_0, listType788.getTree());
        }
          break;
        case 3:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2012:7: structType
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_structType_in_type12348);
          structType789 = structType();

          state._fsp--;

          adaptor.addChild(root_0, structType789.getTree());
        }
          break;
        case 4:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2013:7: mapType
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_mapType_in_type12356);
          mapType790 = mapType();

          state._fsp--;

          adaptor.addChild(root_0, mapType790.getTree());
        }
          break;
        case 5:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2014:7: unionType
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_unionType_in_type12364);
          unionType791 = unionType();

          state._fsp--;

          adaptor.addChild(root_0, unionType791.getTree());
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "type"

  public static class primitiveType_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "primitiveType"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2016:1: primitiveType : ( KW_TINYINT -> TOK_TINYINT | KW_SMALLINT -> TOK_SMALLINT | KW_INT -> TOK_INT | KW_BIGINT -> TOK_BIGINT | KW_BOOLEAN -> TOK_BOOLEAN | KW_FLOAT -> TOK_FLOAT | KW_DOUBLE -> TOK_DOUBLE | KW_DATE -> TOK_DATE | KW_DATETIME -> TOK_DATETIME | KW_TIMESTAMP -> TOK_TIMESTAMP | KW_STRING -> TOK_STRING | KW_BINARY -> TOK_BINARY | KW_DECIMAL ( LPAREN prec= Number ( COMMA scale= Number )? RPAREN )? -> ^( TOK_DECIMAL ( $prec)? ( $scale)? ) | KW_VARCHAR LPAREN length= Number RPAREN -> ^( TOK_VARCHAR $length) | KW_CHAR LPAREN length= Number RPAREN -> ^( TOK_CHAR $length) );
  public final HiveParser.primitiveType_return primitiveType() throws RecognitionException {
    HiveParser.primitiveType_return retval = new HiveParser.primitiveType_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token prec = null;
    Token scale = null;
    Token length = null;
    Token KW_TINYINT792 = null;
    Token KW_SMALLINT793 = null;
    Token KW_INT794 = null;
    Token KW_BIGINT795 = null;
    Token KW_BOOLEAN796 = null;
    Token KW_FLOAT797 = null;
    Token KW_DOUBLE798 = null;
    Token KW_DATE799 = null;
    Token KW_DATETIME800 = null;
    Token KW_TIMESTAMP801 = null;
    Token KW_STRING802 = null;
    Token KW_BINARY803 = null;
    Token KW_DECIMAL804 = null;
    Token LPAREN805 = null;
    Token COMMA806 = null;
    Token RPAREN807 = null;
    Token KW_VARCHAR808 = null;
    Token LPAREN809 = null;
    Token RPAREN810 = null;
    Token KW_CHAR811 = null;
    Token LPAREN812 = null;
    Token RPAREN813 = null;

    CommonTree prec_tree = null;
    CommonTree scale_tree = null;
    CommonTree length_tree = null;
    CommonTree KW_TINYINT792_tree = null;
    CommonTree KW_SMALLINT793_tree = null;
    CommonTree KW_INT794_tree = null;
    CommonTree KW_BIGINT795_tree = null;
    CommonTree KW_BOOLEAN796_tree = null;
    CommonTree KW_FLOAT797_tree = null;
    CommonTree KW_DOUBLE798_tree = null;
    CommonTree KW_DATE799_tree = null;
    CommonTree KW_DATETIME800_tree = null;
    CommonTree KW_TIMESTAMP801_tree = null;
    CommonTree KW_STRING802_tree = null;
    CommonTree KW_BINARY803_tree = null;
    CommonTree KW_DECIMAL804_tree = null;
    CommonTree LPAREN805_tree = null;
    CommonTree COMMA806_tree = null;
    CommonTree RPAREN807_tree = null;
    CommonTree KW_VARCHAR808_tree = null;
    CommonTree LPAREN809_tree = null;
    CommonTree RPAREN810_tree = null;
    CommonTree KW_CHAR811_tree = null;
    CommonTree LPAREN812_tree = null;
    CommonTree RPAREN813_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleTokenStream stream_KW_SMALLINT = new RewriteRuleTokenStream(adaptor, "token KW_SMALLINT");
    RewriteRuleTokenStream stream_KW_DATE = new RewriteRuleTokenStream(adaptor, "token KW_DATE");
    RewriteRuleTokenStream stream_KW_DATETIME = new RewriteRuleTokenStream(adaptor, "token KW_DATETIME");
    RewriteRuleTokenStream stream_KW_TIMESTAMP = new RewriteRuleTokenStream(adaptor, "token KW_TIMESTAMP");
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_KW_BOOLEAN = new RewriteRuleTokenStream(adaptor, "token KW_BOOLEAN");
    RewriteRuleTokenStream stream_KW_DOUBLE = new RewriteRuleTokenStream(adaptor, "token KW_DOUBLE");
    RewriteRuleTokenStream stream_KW_BIGINT = new RewriteRuleTokenStream(adaptor, "token KW_BIGINT");
    RewriteRuleTokenStream stream_KW_CHAR = new RewriteRuleTokenStream(adaptor, "token KW_CHAR");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleTokenStream stream_KW_INT = new RewriteRuleTokenStream(adaptor, "token KW_INT");
    RewriteRuleTokenStream stream_KW_STRING = new RewriteRuleTokenStream(adaptor, "token KW_STRING");
    RewriteRuleTokenStream stream_KW_DECIMAL = new RewriteRuleTokenStream(adaptor, "token KW_DECIMAL");
    RewriteRuleTokenStream stream_KW_VARCHAR = new RewriteRuleTokenStream(adaptor, "token KW_VARCHAR");
    RewriteRuleTokenStream stream_Number = new RewriteRuleTokenStream(adaptor, "token Number");
    RewriteRuleTokenStream stream_KW_FLOAT = new RewriteRuleTokenStream(adaptor, "token KW_FLOAT");
    RewriteRuleTokenStream stream_KW_TINYINT = new RewriteRuleTokenStream(adaptor, "token KW_TINYINT");
    RewriteRuleTokenStream stream_KW_BINARY = new RewriteRuleTokenStream(adaptor, "token KW_BINARY");

    pushMsg("primitive type specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2019:5: ( KW_TINYINT -> TOK_TINYINT | KW_SMALLINT -> TOK_SMALLINT | KW_INT -> TOK_INT | KW_BIGINT -> TOK_BIGINT | KW_BOOLEAN -> TOK_BOOLEAN | KW_FLOAT -> TOK_FLOAT | KW_DOUBLE -> TOK_DOUBLE | KW_DATE -> TOK_DATE | KW_DATETIME -> TOK_DATETIME | KW_TIMESTAMP -> TOK_TIMESTAMP | KW_STRING -> TOK_STRING | KW_BINARY -> TOK_BINARY | KW_DECIMAL ( LPAREN prec= Number ( COMMA scale= Number )? RPAREN )? -> ^( TOK_DECIMAL ( $prec)? ( $scale)? ) | KW_VARCHAR LPAREN length= Number RPAREN -> ^( TOK_VARCHAR $length) | KW_CHAR LPAREN length= Number RPAREN -> ^( TOK_CHAR $length) )
      int alt233 = 15;
      switch (input.LA(1)) {
        case KW_TINYINT: {
          alt233 = 1;
        }
          break;
        case KW_SMALLINT: {
          alt233 = 2;
        }
          break;
        case KW_INT: {
          alt233 = 3;
        }
          break;
        case KW_BIGINT: {
          alt233 = 4;
        }
          break;
        case KW_BOOLEAN: {
          alt233 = 5;
        }
          break;
        case KW_FLOAT: {
          alt233 = 6;
        }
          break;
        case KW_DOUBLE: {
          alt233 = 7;
        }
          break;
        case KW_DATE: {
          alt233 = 8;
        }
          break;
        case KW_DATETIME: {
          alt233 = 9;
        }
          break;
        case KW_TIMESTAMP: {
          alt233 = 10;
        }
          break;
        case KW_STRING: {
          alt233 = 11;
        }
          break;
        case KW_BINARY: {
          alt233 = 12;
        }
          break;
        case KW_DECIMAL: {
          alt233 = 13;
        }
          break;
        case KW_VARCHAR: {
          alt233 = 14;
        }
          break;
        case KW_CHAR: {
          alt233 = 15;
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 233, 0, input);

          throw nvae;
      }

      switch (alt233) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2019:7: KW_TINYINT
        {
          KW_TINYINT792 = (Token) match(input, KW_TINYINT, FOLLOW_KW_TINYINT_in_primitiveType12386);
          stream_KW_TINYINT.add(KW_TINYINT792);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2019:24: -> TOK_TINYINT
          {
            adaptor.addChild(root_0, (CommonTree) adaptor.create(TOK_TINYINT, "TOK_TINYINT"));
          }

          retval.tree = root_0;
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2020:7: KW_SMALLINT
        {
          KW_SMALLINT793 = (Token) match(input, KW_SMALLINT, FOLLOW_KW_SMALLINT_in_primitiveType12407);
          stream_KW_SMALLINT.add(KW_SMALLINT793);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2020:24: -> TOK_SMALLINT
          {
            adaptor.addChild(root_0, (CommonTree) adaptor.create(TOK_SMALLINT, "TOK_SMALLINT"));
          }

          retval.tree = root_0;
        }
          break;
        case 3:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2021:7: KW_INT
        {
          KW_INT794 = (Token) match(input, KW_INT, FOLLOW_KW_INT_in_primitiveType12427);
          stream_KW_INT.add(KW_INT794);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2021:24: -> TOK_INT
          {
            adaptor.addChild(root_0, (CommonTree) adaptor.create(TOK_INT, "TOK_INT"));
          }

          retval.tree = root_0;
        }
          break;
        case 4:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2022:7: KW_BIGINT
        {
          KW_BIGINT795 = (Token) match(input, KW_BIGINT, FOLLOW_KW_BIGINT_in_primitiveType12452);
          stream_KW_BIGINT.add(KW_BIGINT795);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2022:24: -> TOK_BIGINT
          {
            adaptor.addChild(root_0, (CommonTree) adaptor.create(TOK_BIGINT, "TOK_BIGINT"));
          }

          retval.tree = root_0;
        }
          break;
        case 5:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2023:7: KW_BOOLEAN
        {
          KW_BOOLEAN796 = (Token) match(input, KW_BOOLEAN, FOLLOW_KW_BOOLEAN_in_primitiveType12474);
          stream_KW_BOOLEAN.add(KW_BOOLEAN796);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2023:24: -> TOK_BOOLEAN
          {
            adaptor.addChild(root_0, (CommonTree) adaptor.create(TOK_BOOLEAN, "TOK_BOOLEAN"));
          }

          retval.tree = root_0;
        }
          break;
        case 6:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2024:7: KW_FLOAT
        {
          KW_FLOAT797 = (Token) match(input, KW_FLOAT, FOLLOW_KW_FLOAT_in_primitiveType12495);
          stream_KW_FLOAT.add(KW_FLOAT797);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2024:24: -> TOK_FLOAT
          {
            adaptor.addChild(root_0, (CommonTree) adaptor.create(TOK_FLOAT, "TOK_FLOAT"));
          }

          retval.tree = root_0;
        }
          break;
        case 7:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2025:7: KW_DOUBLE
        {
          KW_DOUBLE798 = (Token) match(input, KW_DOUBLE, FOLLOW_KW_DOUBLE_in_primitiveType12518);
          stream_KW_DOUBLE.add(KW_DOUBLE798);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2025:24: -> TOK_DOUBLE
          {
            adaptor.addChild(root_0, (CommonTree) adaptor.create(TOK_DOUBLE, "TOK_DOUBLE"));
          }

          retval.tree = root_0;
        }
          break;
        case 8:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2026:7: KW_DATE
        {
          KW_DATE799 = (Token) match(input, KW_DATE, FOLLOW_KW_DATE_in_primitiveType12540);
          stream_KW_DATE.add(KW_DATE799);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2026:24: -> TOK_DATE
          {
            adaptor.addChild(root_0, (CommonTree) adaptor.create(TOK_DATE, "TOK_DATE"));
          }

          retval.tree = root_0;
        }
          break;
        case 9:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2027:7: KW_DATETIME
        {
          KW_DATETIME800 = (Token) match(input, KW_DATETIME, FOLLOW_KW_DATETIME_in_primitiveType12564);
          stream_KW_DATETIME.add(KW_DATETIME800);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2027:24: -> TOK_DATETIME
          {
            adaptor.addChild(root_0, (CommonTree) adaptor.create(TOK_DATETIME, "TOK_DATETIME"));
          }

          retval.tree = root_0;
        }
          break;
        case 10:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2028:7: KW_TIMESTAMP
        {
          KW_TIMESTAMP801 = (Token) match(input, KW_TIMESTAMP, FOLLOW_KW_TIMESTAMP_in_primitiveType12584);
          stream_KW_TIMESTAMP.add(KW_TIMESTAMP801);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2028:24: -> TOK_TIMESTAMP
          {
            adaptor.addChild(root_0, (CommonTree) adaptor.create(TOK_TIMESTAMP, "TOK_TIMESTAMP"));
          }

          retval.tree = root_0;
        }
          break;
        case 11:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2029:7: KW_STRING
        {
          KW_STRING802 = (Token) match(input, KW_STRING, FOLLOW_KW_STRING_in_primitiveType12603);
          stream_KW_STRING.add(KW_STRING802);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2029:24: -> TOK_STRING
          {
            adaptor.addChild(root_0, (CommonTree) adaptor.create(TOK_STRING, "TOK_STRING"));
          }

          retval.tree = root_0;
        }
          break;
        case 12:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2030:7: KW_BINARY
        {
          KW_BINARY803 = (Token) match(input, KW_BINARY, FOLLOW_KW_BINARY_in_primitiveType12625);
          stream_KW_BINARY.add(KW_BINARY803);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2030:24: -> TOK_BINARY
          {
            adaptor.addChild(root_0, (CommonTree) adaptor.create(TOK_BINARY, "TOK_BINARY"));
          }

          retval.tree = root_0;
        }
          break;
        case 13:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2031:7: KW_DECIMAL ( LPAREN prec= Number ( COMMA scale= Number )? RPAREN )?
        {
          KW_DECIMAL804 = (Token) match(input, KW_DECIMAL, FOLLOW_KW_DECIMAL_in_primitiveType12647);
          stream_KW_DECIMAL.add(KW_DECIMAL804);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2031:18: ( LPAREN prec= Number ( COMMA scale= Number )? RPAREN )?
          int alt232 = 2;
          switch (input.LA(1)) {
            case LPAREN: {
              alt232 = 1;
            }
              break;
          }

          switch (alt232) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2031:19: LPAREN prec= Number ( COMMA scale= Number )? RPAREN
            {
              LPAREN805 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_primitiveType12650);
              stream_LPAREN.add(LPAREN805);

              prec = (Token) match(input, Number, FOLLOW_Number_in_primitiveType12654);
              stream_Number.add(prec);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2031:38: ( COMMA scale= Number )?
              int alt231 = 2;
              switch (input.LA(1)) {
                case COMMA: {
                  alt231 = 1;
                }
                  break;
              }

              switch (alt231) {
                case 1:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2031:39: COMMA scale= Number
                {
                  COMMA806 = (Token) match(input, COMMA, FOLLOW_COMMA_in_primitiveType12657);
                  stream_COMMA.add(COMMA806);

                  scale = (Token) match(input, Number, FOLLOW_Number_in_primitiveType12661);
                  stream_Number.add(scale);
                }
                  break;
              }

              RPAREN807 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_primitiveType12665);
              stream_RPAREN.add(RPAREN807);
            }
              break;
          }

          // AST REWRITE
          // elements: prec, scale
          // token labels: prec, scale
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleTokenStream stream_prec = new RewriteRuleTokenStream(adaptor, "token prec", prec);
          RewriteRuleTokenStream stream_scale = new RewriteRuleTokenStream(adaptor, "token scale", scale);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2031:69: -> ^( TOK_DECIMAL ( $prec)? ( $scale)? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2031:72: ^( TOK_DECIMAL ( $prec)? ( $scale)? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DECIMAL, "TOK_DECIMAL"), root_1);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2031:87: ( $prec)?
              if (stream_prec.hasNext()) {
                adaptor.addChild(root_1, stream_prec.nextNode());
              }
              stream_prec.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2031:94: ( $scale)?
              if (stream_scale.hasNext()) {
                adaptor.addChild(root_1, stream_scale.nextNode());
              }
              stream_scale.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 14:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2032:7: KW_VARCHAR LPAREN length= Number RPAREN
        {
          KW_VARCHAR808 = (Token) match(input, KW_VARCHAR, FOLLOW_KW_VARCHAR_in_primitiveType12689);
          stream_KW_VARCHAR.add(KW_VARCHAR808);

          LPAREN809 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_primitiveType12691);
          stream_LPAREN.add(LPAREN809);

          length = (Token) match(input, Number, FOLLOW_Number_in_primitiveType12695);
          stream_Number.add(length);

          RPAREN810 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_primitiveType12697);
          stream_RPAREN.add(RPAREN810);

          // AST REWRITE
          // elements: length
          // token labels: length
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleTokenStream stream_length = new RewriteRuleTokenStream(adaptor, "token length", length);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2032:51: -> ^( TOK_VARCHAR $length)
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2032:57: ^( TOK_VARCHAR $length)
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_VARCHAR, "TOK_VARCHAR"), root_1);

              adaptor.addChild(root_1, stream_length.nextNode());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 15:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2033:7: KW_CHAR LPAREN length= Number RPAREN
        {
          KW_CHAR811 = (Token) match(input, KW_CHAR, FOLLOW_KW_CHAR_in_primitiveType12722);
          stream_KW_CHAR.add(KW_CHAR811);

          LPAREN812 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_primitiveType12724);
          stream_LPAREN.add(LPAREN812);

          length = (Token) match(input, Number, FOLLOW_Number_in_primitiveType12728);
          stream_Number.add(length);

          RPAREN813 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_primitiveType12730);
          stream_RPAREN.add(RPAREN813);

          // AST REWRITE
          // elements: length
          // token labels: length
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleTokenStream stream_length = new RewriteRuleTokenStream(adaptor, "token length", length);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2033:48: -> ^( TOK_CHAR $length)
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2033:54: ^( TOK_CHAR $length)
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_CHAR, "TOK_CHAR"), root_1);

              adaptor.addChild(root_1, stream_length.nextNode());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "primitiveType"

  public static class listType_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "listType"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2036:1: listType : KW_ARRAY LESSTHAN type GREATERTHAN -> ^( TOK_LIST type ) ;
  public final HiveParser.listType_return listType() throws RecognitionException {
    HiveParser.listType_return retval = new HiveParser.listType_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_ARRAY814 = null;
    Token LESSTHAN815 = null;
    Token GREATERTHAN817 = null;
    HiveParser.type_return type816 = null;

    CommonTree KW_ARRAY814_tree = null;
    CommonTree LESSTHAN815_tree = null;
    CommonTree GREATERTHAN817_tree = null;
    RewriteRuleTokenStream stream_LESSTHAN = new RewriteRuleTokenStream(adaptor, "token LESSTHAN");
    RewriteRuleTokenStream stream_KW_ARRAY = new RewriteRuleTokenStream(adaptor, "token KW_ARRAY");
    RewriteRuleTokenStream stream_GREATERTHAN = new RewriteRuleTokenStream(adaptor, "token GREATERTHAN");
    RewriteRuleSubtreeStream stream_type = new RewriteRuleSubtreeStream(adaptor, "rule type");
    pushMsg("list type", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2039:5: ( KW_ARRAY LESSTHAN type GREATERTHAN -> ^( TOK_LIST type ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2039:7: KW_ARRAY LESSTHAN type GREATERTHAN
      {
        KW_ARRAY814 = (Token) match(input, KW_ARRAY, FOLLOW_KW_ARRAY_in_listType12774);
        stream_KW_ARRAY.add(KW_ARRAY814);

        LESSTHAN815 = (Token) match(input, LESSTHAN, FOLLOW_LESSTHAN_in_listType12776);
        stream_LESSTHAN.add(LESSTHAN815);

        pushFollow(FOLLOW_type_in_listType12778);
        type816 = type();

        state._fsp--;

        stream_type.add(type816.getTree());

        GREATERTHAN817 = (Token) match(input, GREATERTHAN, FOLLOW_GREATERTHAN_in_listType12780);
        stream_GREATERTHAN.add(GREATERTHAN817);

        // AST REWRITE
        // elements: type
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2039:44: -> ^( TOK_LIST type )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2039:47: ^( TOK_LIST type )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_LIST, "TOK_LIST"), root_1);

            adaptor.addChild(root_1, stream_type.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "listType"

  public static class structType_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "structType"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2042:1: structType : KW_STRUCT LESSTHAN columnNameColonTypeList GREATERTHAN -> ^( TOK_STRUCT columnNameColonTypeList ) ;
  public final HiveParser.structType_return structType() throws RecognitionException {
    HiveParser.structType_return retval = new HiveParser.structType_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_STRUCT818 = null;
    Token LESSTHAN819 = null;
    Token GREATERTHAN821 = null;
    HiveParser.columnNameColonTypeList_return columnNameColonTypeList820 = null;

    CommonTree KW_STRUCT818_tree = null;
    CommonTree LESSTHAN819_tree = null;
    CommonTree GREATERTHAN821_tree = null;
    RewriteRuleTokenStream stream_KW_STRUCT = new RewriteRuleTokenStream(adaptor, "token KW_STRUCT");
    RewriteRuleTokenStream stream_LESSTHAN = new RewriteRuleTokenStream(adaptor, "token LESSTHAN");
    RewriteRuleTokenStream stream_GREATERTHAN = new RewriteRuleTokenStream(adaptor, "token GREATERTHAN");
    RewriteRuleSubtreeStream stream_columnNameColonTypeList =
        new RewriteRuleSubtreeStream(adaptor, "rule columnNameColonTypeList");
    pushMsg("struct type", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2045:5: ( KW_STRUCT LESSTHAN columnNameColonTypeList GREATERTHAN -> ^( TOK_STRUCT columnNameColonTypeList ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2045:7: KW_STRUCT LESSTHAN columnNameColonTypeList GREATERTHAN
      {
        KW_STRUCT818 = (Token) match(input, KW_STRUCT, FOLLOW_KW_STRUCT_in_structType12817);
        stream_KW_STRUCT.add(KW_STRUCT818);

        LESSTHAN819 = (Token) match(input, LESSTHAN, FOLLOW_LESSTHAN_in_structType12819);
        stream_LESSTHAN.add(LESSTHAN819);

        pushFollow(FOLLOW_columnNameColonTypeList_in_structType12821);
        columnNameColonTypeList820 = columnNameColonTypeList();

        state._fsp--;

        stream_columnNameColonTypeList.add(columnNameColonTypeList820.getTree());

        GREATERTHAN821 = (Token) match(input, GREATERTHAN, FOLLOW_GREATERTHAN_in_structType12823);
        stream_GREATERTHAN.add(GREATERTHAN821);

        // AST REWRITE
        // elements: columnNameColonTypeList
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2045:62: -> ^( TOK_STRUCT columnNameColonTypeList )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2045:65: ^( TOK_STRUCT columnNameColonTypeList )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_STRUCT, "TOK_STRUCT"), root_1);

            adaptor.addChild(root_1, stream_columnNameColonTypeList.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "structType"

  public static class mapType_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "mapType"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2048:1: mapType : KW_MAP LESSTHAN left= primitiveType COMMA right= type GREATERTHAN -> ^( TOK_MAP $left $right) ;
  public final HiveParser.mapType_return mapType() throws RecognitionException {
    HiveParser.mapType_return retval = new HiveParser.mapType_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_MAP822 = null;
    Token LESSTHAN823 = null;
    Token COMMA824 = null;
    Token GREATERTHAN825 = null;
    HiveParser.primitiveType_return left = null;

    HiveParser.type_return right = null;

    CommonTree KW_MAP822_tree = null;
    CommonTree LESSTHAN823_tree = null;
    CommonTree COMMA824_tree = null;
    CommonTree GREATERTHAN825_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleTokenStream stream_KW_MAP = new RewriteRuleTokenStream(adaptor, "token KW_MAP");
    RewriteRuleTokenStream stream_LESSTHAN = new RewriteRuleTokenStream(adaptor, "token LESSTHAN");
    RewriteRuleTokenStream stream_GREATERTHAN = new RewriteRuleTokenStream(adaptor, "token GREATERTHAN");
    RewriteRuleSubtreeStream stream_type = new RewriteRuleSubtreeStream(adaptor, "rule type");
    RewriteRuleSubtreeStream stream_primitiveType = new RewriteRuleSubtreeStream(adaptor, "rule primitiveType");
    pushMsg("map type", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2051:5: ( KW_MAP LESSTHAN left= primitiveType COMMA right= type GREATERTHAN -> ^( TOK_MAP $left $right) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2051:7: KW_MAP LESSTHAN left= primitiveType COMMA right= type GREATERTHAN
      {
        KW_MAP822 = (Token) match(input, KW_MAP, FOLLOW_KW_MAP_in_mapType12858);
        stream_KW_MAP.add(KW_MAP822);

        LESSTHAN823 = (Token) match(input, LESSTHAN, FOLLOW_LESSTHAN_in_mapType12860);
        stream_LESSTHAN.add(LESSTHAN823);

        pushFollow(FOLLOW_primitiveType_in_mapType12864);
        left = primitiveType();

        state._fsp--;

        stream_primitiveType.add(left.getTree());

        COMMA824 = (Token) match(input, COMMA, FOLLOW_COMMA_in_mapType12866);
        stream_COMMA.add(COMMA824);

        pushFollow(FOLLOW_type_in_mapType12870);
        right = type();

        state._fsp--;

        stream_type.add(right.getTree());

        GREATERTHAN825 = (Token) match(input, GREATERTHAN, FOLLOW_GREATERTHAN_in_mapType12872);
        stream_GREATERTHAN.add(GREATERTHAN825);

        // AST REWRITE
        // elements: left, right
        // token labels:
        // rule labels: left, right, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_left =
            new RewriteRuleSubtreeStream(adaptor, "rule left", left != null ? left.tree : null);
        RewriteRuleSubtreeStream stream_right =
            new RewriteRuleSubtreeStream(adaptor, "rule right", right != null ? right.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2052:5: -> ^( TOK_MAP $left $right)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2052:8: ^( TOK_MAP $left $right)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_MAP, "TOK_MAP"), root_1);

            adaptor.addChild(root_1, stream_left.nextTree());

            adaptor.addChild(root_1, stream_right.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "mapType"

  public static class unionType_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "unionType"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2055:1: unionType : KW_UNIONTYPE LESSTHAN colTypeList GREATERTHAN -> ^( TOK_UNIONTYPE colTypeList ) ;
  public final HiveParser.unionType_return unionType() throws RecognitionException {
    HiveParser.unionType_return retval = new HiveParser.unionType_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_UNIONTYPE826 = null;
    Token LESSTHAN827 = null;
    Token GREATERTHAN829 = null;
    HiveParser.colTypeList_return colTypeList828 = null;

    CommonTree KW_UNIONTYPE826_tree = null;
    CommonTree LESSTHAN827_tree = null;
    CommonTree GREATERTHAN829_tree = null;
    RewriteRuleTokenStream stream_KW_UNIONTYPE = new RewriteRuleTokenStream(adaptor, "token KW_UNIONTYPE");
    RewriteRuleTokenStream stream_LESSTHAN = new RewriteRuleTokenStream(adaptor, "token LESSTHAN");
    RewriteRuleTokenStream stream_GREATERTHAN = new RewriteRuleTokenStream(adaptor, "token GREATERTHAN");
    RewriteRuleSubtreeStream stream_colTypeList = new RewriteRuleSubtreeStream(adaptor, "rule colTypeList");
    pushMsg("uniontype type", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2058:5: ( KW_UNIONTYPE LESSTHAN colTypeList GREATERTHAN -> ^( TOK_UNIONTYPE colTypeList ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2058:7: KW_UNIONTYPE LESSTHAN colTypeList GREATERTHAN
      {
        KW_UNIONTYPE826 = (Token) match(input, KW_UNIONTYPE, FOLLOW_KW_UNIONTYPE_in_unionType12915);
        stream_KW_UNIONTYPE.add(KW_UNIONTYPE826);

        LESSTHAN827 = (Token) match(input, LESSTHAN, FOLLOW_LESSTHAN_in_unionType12917);
        stream_LESSTHAN.add(LESSTHAN827);

        pushFollow(FOLLOW_colTypeList_in_unionType12919);
        colTypeList828 = colTypeList();

        state._fsp--;

        stream_colTypeList.add(colTypeList828.getTree());

        GREATERTHAN829 = (Token) match(input, GREATERTHAN, FOLLOW_GREATERTHAN_in_unionType12921);
        stream_GREATERTHAN.add(GREATERTHAN829);

        // AST REWRITE
        // elements: colTypeList
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2058:53: -> ^( TOK_UNIONTYPE colTypeList )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2058:56: ^( TOK_UNIONTYPE colTypeList )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_UNIONTYPE, "TOK_UNIONTYPE"), root_1);

            adaptor.addChild(root_1, stream_colTypeList.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "unionType"

  public static class setOperator_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "setOperator"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2061:1: setOperator : KW_UNION KW_ALL -> ^( TOK_UNION ) ;
  public final HiveParser.setOperator_return setOperator() throws RecognitionException {
    HiveParser.setOperator_return retval = new HiveParser.setOperator_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_UNION830 = null;
    Token KW_ALL831 = null;

    CommonTree KW_UNION830_tree = null;
    CommonTree KW_ALL831_tree = null;
    RewriteRuleTokenStream stream_KW_UNION = new RewriteRuleTokenStream(adaptor, "token KW_UNION");
    RewriteRuleTokenStream stream_KW_ALL = new RewriteRuleTokenStream(adaptor, "token KW_ALL");

    pushMsg("set operator", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2064:5: ( KW_UNION KW_ALL -> ^( TOK_UNION ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2064:7: KW_UNION KW_ALL
      {
        KW_UNION830 = (Token) match(input, KW_UNION, FOLLOW_KW_UNION_in_setOperator12956);
        stream_KW_UNION.add(KW_UNION830);

        KW_ALL831 = (Token) match(input, KW_ALL, FOLLOW_KW_ALL_in_setOperator12958);
        stream_KW_ALL.add(KW_ALL831);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2064:23: -> ^( TOK_UNION )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2064:26: ^( TOK_UNION )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_UNION, "TOK_UNION"), root_1);

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "setOperator"

  public static class queryStatementExpression_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "queryStatementExpression"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2067:1: queryStatementExpression[boolean topLevel] : (w= withClause {...}?)? queryStatementExpressionBody[topLevel] -> queryStatementExpressionBody ;
  public final HiveParser.queryStatementExpression_return queryStatementExpression(boolean topLevel)
      throws RecognitionException {
    HiveParser.queryStatementExpression_return retval = new HiveParser.queryStatementExpression_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.withClause_return w = null;

    HiveParser.queryStatementExpressionBody_return queryStatementExpressionBody832 = null;

    RewriteRuleSubtreeStream stream_withClause = new RewriteRuleSubtreeStream(adaptor, "rule withClause");
    RewriteRuleSubtreeStream stream_queryStatementExpressionBody =
        new RewriteRuleSubtreeStream(adaptor, "rule queryStatementExpressionBody");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2068:5: ( (w= withClause {...}?)? queryStatementExpressionBody[topLevel] -> queryStatementExpressionBody )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2073:5: (w= withClause {...}?)? queryStatementExpressionBody[topLevel]
      {
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2073:5: (w= withClause {...}?)?
        int alt234 = 2;
        switch (input.LA(1)) {
          case KW_WITH: {
            alt234 = 1;
          }
            break;
        }

        switch (alt234) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2073:6: w= withClause {...}?
          {
            pushFollow(FOLLOW_withClause_in_queryStatementExpression12995);
            w = withClause();

            state._fsp--;

            stream_withClause.add(w.getTree());

            if (!((topLevel))) {
              throw new FailedPredicateException(input, "queryStatementExpression", "topLevel");
            }
          }
            break;
        }

        pushFollow(FOLLOW_queryStatementExpressionBody_in_queryStatementExpression13005);
        queryStatementExpressionBody832 = queryStatementExpressionBody(topLevel);

        state._fsp--;

        stream_queryStatementExpressionBody.add(queryStatementExpressionBody832.getTree());

        if ((w != null ? ((CommonTree) w.tree) : null) != null) {
          (queryStatementExpressionBody832 != null ? ((CommonTree) queryStatementExpressionBody832.tree) : null)
              .insertChild(0, (w != null ? ((CommonTree) w.tree) : null));
        }

        // AST REWRITE
        // elements: queryStatementExpressionBody
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2079:5: -> queryStatementExpressionBody
        {
          adaptor.addChild(root_0, stream_queryStatementExpressionBody.nextTree());
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "queryStatementExpression"

  public static class queryStatementExpressionBody_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "queryStatementExpressionBody"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2082:1: queryStatementExpressionBody[boolean topLevel] : ( fromStatement[topLevel] | regularBody[topLevel] );
  public final HiveParser.queryStatementExpressionBody_return queryStatementExpressionBody(boolean topLevel)
      throws RecognitionException {
    HiveParser.queryStatementExpressionBody_return retval = new HiveParser.queryStatementExpressionBody_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.fromStatement_return fromStatement833 = null;

    HiveParser.regularBody_return regularBody834 = null;

    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2083:5: ( fromStatement[topLevel] | regularBody[topLevel] )
      int alt235 = 2;
      switch (input.LA(1)) {
        case KW_FROM: {
          alt235 = 1;
        }
          break;
        case KW_INSERT:
        case KW_MAP:
        case KW_REDUCE:
        case KW_SELECT: {
          alt235 = 2;
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 235, 0, input);

          throw nvae;
      }

      switch (alt235) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2084:5: fromStatement[topLevel]
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_fromStatement_in_queryStatementExpressionBody13039);
          fromStatement833 = fromStatement(topLevel);

          state._fsp--;

          adaptor.addChild(root_0, fromStatement833.getTree());
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2085:7: regularBody[topLevel]
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_regularBody_in_queryStatementExpressionBody13048);
          regularBody834 = regularBody(topLevel);

          state._fsp--;

          adaptor.addChild(root_0, regularBody834.getTree());
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "queryStatementExpressionBody"

  public static class withClause_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "withClause"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2088:1: withClause : KW_WITH cteStatement ( COMMA cteStatement )* -> ^( TOK_CTE ( cteStatement )+ ) ;
  public final HiveParser.withClause_return withClause() throws RecognitionException {
    HiveParser.withClause_return retval = new HiveParser.withClause_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_WITH835 = null;
    Token COMMA837 = null;
    HiveParser.cteStatement_return cteStatement836 = null;

    HiveParser.cteStatement_return cteStatement838 = null;

    CommonTree KW_WITH835_tree = null;
    CommonTree COMMA837_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleTokenStream stream_KW_WITH = new RewriteRuleTokenStream(adaptor, "token KW_WITH");
    RewriteRuleSubtreeStream stream_cteStatement = new RewriteRuleSubtreeStream(adaptor, "rule cteStatement");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2089:3: ( KW_WITH cteStatement ( COMMA cteStatement )* -> ^( TOK_CTE ( cteStatement )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2090:3: KW_WITH cteStatement ( COMMA cteStatement )*
      {
        KW_WITH835 = (Token) match(input, KW_WITH, FOLLOW_KW_WITH_in_withClause13066);
        stream_KW_WITH.add(KW_WITH835);

        pushFollow(FOLLOW_cteStatement_in_withClause13068);
        cteStatement836 = cteStatement();

        state._fsp--;

        stream_cteStatement.add(cteStatement836.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2090:24: ( COMMA cteStatement )*
        loop236: do {
          int alt236 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt236 = 1;
            }
              break;
          }

          switch (alt236) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2090:25: COMMA cteStatement
            {
              COMMA837 = (Token) match(input, COMMA, FOLLOW_COMMA_in_withClause13071);
              stream_COMMA.add(COMMA837);

              pushFollow(FOLLOW_cteStatement_in_withClause13073);
              cteStatement838 = cteStatement();

              state._fsp--;

              stream_cteStatement.add(cteStatement838.getTree());
            }
              break;

            default:
              break loop236;
          }
        } while (true);

        // AST REWRITE
        // elements: cteStatement
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2090:46: -> ^( TOK_CTE ( cteStatement )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2090:49: ^( TOK_CTE ( cteStatement )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_CTE, "TOK_CTE"), root_1);

            if (!(stream_cteStatement.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_cteStatement.hasNext()) {
              adaptor.addChild(root_1, stream_cteStatement.nextTree());
            }
            stream_cteStatement.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "withClause"

  public static class cteStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "cteStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2093:1: cteStatement : identifier KW_AS LPAREN queryStatementExpression[false] RPAREN -> ^( TOK_SUBQUERY queryStatementExpression identifier ) ;
  public final HiveParser.cteStatement_return cteStatement() throws RecognitionException {
    HiveParser.cteStatement_return retval = new HiveParser.cteStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_AS840 = null;
    Token LPAREN841 = null;
    Token RPAREN843 = null;
    HiveParser_IdentifiersParser.identifier_return identifier839 = null;

    HiveParser.queryStatementExpression_return queryStatementExpression842 = null;

    CommonTree KW_AS840_tree = null;
    CommonTree LPAREN841_tree = null;
    CommonTree RPAREN843_tree = null;
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleTokenStream stream_KW_AS = new RewriteRuleTokenStream(adaptor, "token KW_AS");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_queryStatementExpression =
        new RewriteRuleSubtreeStream(adaptor, "rule queryStatementExpression");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2094:4: ( identifier KW_AS LPAREN queryStatementExpression[false] RPAREN -> ^( TOK_SUBQUERY queryStatementExpression identifier ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2095:4: identifier KW_AS LPAREN queryStatementExpression[false] RPAREN
      {
        pushFollow(FOLLOW_identifier_in_cteStatement13099);
        identifier839 = identifier();

        state._fsp--;

        stream_identifier.add(identifier839.getTree());

        KW_AS840 = (Token) match(input, KW_AS, FOLLOW_KW_AS_in_cteStatement13101);
        stream_KW_AS.add(KW_AS840);

        LPAREN841 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_cteStatement13103);
        stream_LPAREN.add(LPAREN841);

        pushFollow(FOLLOW_queryStatementExpression_in_cteStatement13105);
        queryStatementExpression842 = queryStatementExpression(false);

        state._fsp--;

        stream_queryStatementExpression.add(queryStatementExpression842.getTree());

        RPAREN843 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_cteStatement13108);
        stream_RPAREN.add(RPAREN843);

        // AST REWRITE
        // elements: identifier, queryStatementExpression
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2096:4: -> ^( TOK_SUBQUERY queryStatementExpression identifier )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2096:7: ^( TOK_SUBQUERY queryStatementExpression identifier )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SUBQUERY, "TOK_SUBQUERY"), root_1);

            adaptor.addChild(root_1, stream_queryStatementExpression.nextTree());

            adaptor.addChild(root_1, stream_identifier.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "cteStatement"

  public static class fromStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "fromStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2099:1: fromStatement[boolean topLevel] : ( singleFromStatement -> singleFromStatement ) (u= setOperator r= singleFromStatement -> ^( $u $r) )* -> {u != null && topLevel}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) ) ->;
  public final HiveParser.fromStatement_return fromStatement(boolean topLevel) throws RecognitionException {
    HiveParser.fromStatement_return retval = new HiveParser.fromStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.setOperator_return u = null;

    HiveParser.singleFromStatement_return r = null;

    HiveParser.singleFromStatement_return singleFromStatement844 = null;

    RewriteRuleSubtreeStream stream_setOperator = new RewriteRuleSubtreeStream(adaptor, "rule setOperator");
    RewriteRuleSubtreeStream stream_singleFromStatement =
        new RewriteRuleSubtreeStream(adaptor, "rule singleFromStatement");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2100:3: ( ( singleFromStatement -> singleFromStatement ) (u= setOperator r= singleFromStatement -> ^( $u $r) )* -> {u != null && topLevel}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) ) ->)
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2100:3: ( singleFromStatement -> singleFromStatement ) (u= setOperator r= singleFromStatement -> ^( $u $r) )*
      {
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2100:3: ( singleFromStatement -> singleFromStatement )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2100:4: singleFromStatement
        {
          pushFollow(FOLLOW_singleFromStatement_in_fromStatement13132);
          singleFromStatement844 = singleFromStatement();

          state._fsp--;

          stream_singleFromStatement.add(singleFromStatement844.getTree());

          // AST REWRITE
          // elements: singleFromStatement
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2100:25: -> singleFromStatement
          {
            adaptor.addChild(root_0, stream_singleFromStatement.nextTree());
          }

          retval.tree = root_0;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2101:2: (u= setOperator r= singleFromStatement -> ^( $u $r) )*
        loop237: do {
          int alt237 = 2;
          switch (input.LA(1)) {
            case KW_UNION: {
              alt237 = 1;
            }
              break;
          }

          switch (alt237) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2101:3: u= setOperator r= singleFromStatement
            {
              pushFollow(FOLLOW_setOperator_in_fromStatement13144);
              u = setOperator();

              state._fsp--;

              stream_setOperator.add(u.getTree());

              pushFollow(FOLLOW_singleFromStatement_in_fromStatement13148);
              r = singleFromStatement();

              state._fsp--;

              stream_singleFromStatement.add(r.getTree());

              // AST REWRITE
              // elements: u, r
              // token labels:
              // rule labels: r, u, retval
              // token list labels:
              // rule list labels:
              // wildcard labels:
              retval.tree = root_0;
              RewriteRuleSubtreeStream stream_r =
                  new RewriteRuleSubtreeStream(adaptor, "rule r", r != null ? r.tree : null);
              RewriteRuleSubtreeStream stream_u =
                  new RewriteRuleSubtreeStream(adaptor, "rule u", u != null ? u.tree : null);
              RewriteRuleSubtreeStream stream_retval =
                  new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

              root_0 = (CommonTree) adaptor.nil();
              // 2102:4: -> ^( $u $r)
              {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2102:7: ^( $u $r)
                {
                  CommonTree root_1 = (CommonTree) adaptor.nil();
                  root_1 = (CommonTree) adaptor.becomeRoot(stream_u.nextNode(), root_1);

                  adaptor.addChild(root_1, ((CommonTree) retval.tree));

                  adaptor.addChild(root_1, stream_r.nextTree());

                  adaptor.addChild(root_0, root_1);
                }
              }

              retval.tree = root_0;
            }
              break;

            default:
              break loop237;
          }
        } while (true);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2104:3: -> {u != null && topLevel}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) )
        if (u != null && topLevel) {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2104:31: ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2105:9: ^( TOK_FROM ^( TOK_SUBQUERY ) )
            {
              CommonTree root_2 = (CommonTree) adaptor.nil();
              root_2 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_FROM, "TOK_FROM"), root_2);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2106:11: ^( TOK_SUBQUERY )
              {
                CommonTree root_3 = (CommonTree) adaptor.nil();
                root_3 =
                    (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SUBQUERY, "TOK_SUBQUERY"), root_3);

                adaptor.addChild(root_3, ((CommonTree) retval.tree));

                adaptor.addChild(root_3, adaptor.create(Identifier, generateUnionAlias()));

                adaptor.addChild(root_2, root_3);
              }

              adaptor.addChild(root_1, root_2);
            }

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2111:9: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) )
            {
              CommonTree root_2 = (CommonTree) adaptor.nil();
              root_2 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_INSERT, "TOK_INSERT"), root_2);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2112:12: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
              {
                CommonTree root_3 = (CommonTree) adaptor.nil();
                root_3 = (CommonTree) adaptor
                    .becomeRoot((CommonTree) adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"), root_3);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2112:30: ^( TOK_DIR TOK_TMP_FILE )
                {
                  CommonTree root_4 = (CommonTree) adaptor.nil();
                  root_4 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DIR, "TOK_DIR"), root_4);

                  adaptor.addChild(root_4, (CommonTree) adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE"));

                  adaptor.addChild(root_3, root_4);
                }

                adaptor.addChild(root_2, root_3);
              }

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2113:12: ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) )
              {
                CommonTree root_3 = (CommonTree) adaptor.nil();
                root_3 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SELECT, "TOK_SELECT"), root_3);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2113:25: ^( TOK_SELEXPR TOK_ALLCOLREF )
                {
                  CommonTree root_4 = (CommonTree) adaptor.nil();
                  root_4 =
                      (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SELEXPR, "TOK_SELEXPR"), root_4);

                  adaptor.addChild(root_4, (CommonTree) adaptor.create(TOK_ALLCOLREF, "TOK_ALLCOLREF"));

                  adaptor.addChild(root_3, root_4);
                }

                adaptor.addChild(root_2, root_3);
              }

              adaptor.addChild(root_1, root_2);
            }

            adaptor.addChild(root_0, root_1);
          }
        } else // 2116:5: ->
        {
          adaptor.addChild(root_0, ((CommonTree) retval.tree));
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "fromStatement"

  public static class singleFromStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "singleFromStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2120:1: singleFromStatement : fromClause (b+= body )+ -> ^( TOK_QUERY fromClause ( body )+ ) ;
  public final HiveParser.singleFromStatement_return singleFromStatement() throws RecognitionException {
    HiveParser.singleFromStatement_return retval = new HiveParser.singleFromStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    List list_b = null;
    HiveParser_FromClauseParser.fromClause_return fromClause845 = null;

    RuleReturnScope b = null;
    RewriteRuleSubtreeStream stream_fromClause = new RewriteRuleSubtreeStream(adaptor, "rule fromClause");
    RewriteRuleSubtreeStream stream_body = new RewriteRuleSubtreeStream(adaptor, "rule body");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2121:5: ( fromClause (b+= body )+ -> ^( TOK_QUERY fromClause ( body )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2122:5: fromClause (b+= body )+
      {
        pushFollow(FOLLOW_fromClause_in_singleFromStatement13355);
        fromClause845 = fromClause();

        state._fsp--;

        stream_fromClause.add(fromClause845.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2123:5: (b+= body )+
        int cnt238 = 0;
        loop238: do {
          int alt238 = 2;
          switch (input.LA(1)) {
            case KW_INSERT:
            case KW_MAP:
            case KW_REDUCE:
            case KW_SELECT: {
              alt238 = 1;
            }
              break;
          }

          switch (alt238) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2123:7: b+= body
            {
              pushFollow(FOLLOW_body_in_singleFromStatement13365);
              b = body();

              state._fsp--;

              stream_body.add(b.getTree());
              if (list_b == null) {
                list_b = new ArrayList();
              }
              list_b.add(b.getTree());
            }
              break;

            default:
              if (cnt238 >= 1) {
                break loop238;
              }
              EarlyExitException eee = new EarlyExitException(238, input);
              throw eee;
          }
          cnt238++;
        } while (true);

        // AST REWRITE
        // elements: body, fromClause
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2123:18: -> ^( TOK_QUERY fromClause ( body )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2123:21: ^( TOK_QUERY fromClause ( body )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);

            adaptor.addChild(root_1, stream_fromClause.nextTree());

            if (!(stream_body.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_body.hasNext()) {
              adaptor.addChild(root_1, stream_body.nextTree());
            }
            stream_body.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "singleFromStatement"

  public static class regularBody_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "regularBody"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2133:1: regularBody[boolean topLevel] : (i= insertClause (s= selectStatement[topLevel] ->| valuesClause -> ^( TOK_QUERY ^( TOK_FROM ^( TOK_VIRTUAL_TABLE ^( TOK_VIRTUAL_TABREF ^( TOK_ANONYMOUS ) ) valuesClause ) ) ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) ) ) | selectStatement[topLevel] );
  public final HiveParser.regularBody_return regularBody(boolean topLevel) throws RecognitionException {
    HiveParser.regularBody_return retval = new HiveParser.regularBody_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.insertClause_return i = null;

    HiveParser.selectStatement_return s = null;

    HiveParser_FromClauseParser.valuesClause_return valuesClause846 = null;

    HiveParser.selectStatement_return selectStatement847 = null;

    RewriteRuleSubtreeStream stream_insertClause = new RewriteRuleSubtreeStream(adaptor, "rule insertClause");
    RewriteRuleSubtreeStream stream_valuesClause = new RewriteRuleSubtreeStream(adaptor, "rule valuesClause");
    RewriteRuleSubtreeStream stream_selectStatement = new RewriteRuleSubtreeStream(adaptor, "rule selectStatement");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2134:4: (i= insertClause (s= selectStatement[topLevel] ->| valuesClause -> ^( TOK_QUERY ^( TOK_FROM ^( TOK_VIRTUAL_TABLE ^( TOK_VIRTUAL_TABREF ^( TOK_ANONYMOUS ) ) valuesClause ) ) ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) ) ) | selectStatement[topLevel] )
      int alt240 = 2;
      switch (input.LA(1)) {
        case KW_INSERT: {
          alt240 = 1;
        }
          break;
        case KW_MAP:
        case KW_REDUCE:
        case KW_SELECT: {
          alt240 = 2;
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 240, 0, input);

          throw nvae;
      }

      switch (alt240) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2135:4: i= insertClause (s= selectStatement[topLevel] ->| valuesClause -> ^( TOK_QUERY ^( TOK_FROM ^( TOK_VIRTUAL_TABLE ^( TOK_VIRTUAL_TABREF ^( TOK_ANONYMOUS ) ) valuesClause ) ) ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) ) )
        {
          pushFollow(FOLLOW_insertClause_in_regularBody13403);
          i = insertClause();

          state._fsp--;

          stream_insertClause.add(i.getTree());

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2136:4: (s= selectStatement[topLevel] ->| valuesClause -> ^( TOK_QUERY ^( TOK_FROM ^( TOK_VIRTUAL_TABLE ^( TOK_VIRTUAL_TABREF ^( TOK_ANONYMOUS ) ) valuesClause ) ) ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) ) )
          int alt239 = 2;
          switch (input.LA(1)) {
            case KW_MAP:
            case KW_REDUCE:
            case KW_SELECT: {
              alt239 = 1;
            }
              break;
            case KW_VALUES: {
              alt239 = 2;
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 239, 0, input);

              throw nvae;
          }

          switch (alt239) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2137:4: s= selectStatement[topLevel]
            {
              pushFollow(FOLLOW_selectStatement_in_regularBody13415);
              s = selectStatement(topLevel);

              state._fsp--;

              stream_selectStatement.add(s.getTree());

              (s != null ? ((CommonTree) s.tree) : null).getFirstChildWithType(TOK_INSERT).replaceChildren(0, 0,
                  (i != null ? ((CommonTree) i.tree) : null));

              // AST REWRITE
              // elements:
              // token labels:
              // rule labels: retval
              // token list labels:
              // rule list labels:
              // wildcard labels:
              retval.tree = root_0;
              RewriteRuleSubtreeStream stream_retval =
                  new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

              root_0 = (CommonTree) adaptor.nil();
              // 2138:82: ->
              {
                adaptor.addChild(root_0, (s != null ? ((CommonTree) s.tree) : null));
              }

              retval.tree = root_0;
            }
              break;
            case 2:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2140:6: valuesClause
            {
              pushFollow(FOLLOW_valuesClause_in_regularBody13441);
              valuesClause846 = valuesClause();

              state._fsp--;

              stream_valuesClause.add(valuesClause846.getTree());

              // AST REWRITE
              // elements: valuesClause
              // token labels:
              // rule labels: retval
              // token list labels:
              // rule list labels:
              // wildcard labels:
              retval.tree = root_0;
              RewriteRuleSubtreeStream stream_retval =
                  new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

              root_0 = (CommonTree) adaptor.nil();
              // 2141:7: -> ^( TOK_QUERY ^( TOK_FROM ^( TOK_VIRTUAL_TABLE ^( TOK_VIRTUAL_TABREF ^( TOK_ANONYMOUS ) ) valuesClause ) ) ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) )
              {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2141:10: ^( TOK_QUERY ^( TOK_FROM ^( TOK_VIRTUAL_TABLE ^( TOK_VIRTUAL_TABREF ^( TOK_ANONYMOUS ) ) valuesClause ) ) ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) )
                {
                  CommonTree root_1 = (CommonTree) adaptor.nil();
                  root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);

                  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2142:13: ^( TOK_FROM ^( TOK_VIRTUAL_TABLE ^( TOK_VIRTUAL_TABREF ^( TOK_ANONYMOUS ) ) valuesClause ) )
                  {
                    CommonTree root_2 = (CommonTree) adaptor.nil();
                    root_2 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_FROM, "TOK_FROM"), root_2);

                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2143:15: ^( TOK_VIRTUAL_TABLE ^( TOK_VIRTUAL_TABREF ^( TOK_ANONYMOUS ) ) valuesClause )
                    {
                      CommonTree root_3 = (CommonTree) adaptor.nil();
                      root_3 = (CommonTree) adaptor
                          .becomeRoot((CommonTree) adaptor.create(TOK_VIRTUAL_TABLE, "TOK_VIRTUAL_TABLE"), root_3);

                      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2143:35: ^( TOK_VIRTUAL_TABREF ^( TOK_ANONYMOUS ) )
                      {
                        CommonTree root_4 = (CommonTree) adaptor.nil();
                        root_4 = (CommonTree) adaptor
                            .becomeRoot((CommonTree) adaptor.create(TOK_VIRTUAL_TABREF, "TOK_VIRTUAL_TABREF"), root_4);

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2143:56: ^( TOK_ANONYMOUS )
                        {
                          CommonTree root_5 = (CommonTree) adaptor.nil();
                          root_5 = (CommonTree) adaptor
                              .becomeRoot((CommonTree) adaptor.create(TOK_ANONYMOUS, "TOK_ANONYMOUS"), root_5);

                          adaptor.addChild(root_4, root_5);
                        }

                        adaptor.addChild(root_3, root_4);
                      }

                      adaptor.addChild(root_3, stream_valuesClause.nextTree());

                      adaptor.addChild(root_2, root_3);
                    }

                    adaptor.addChild(root_1, root_2);
                  }

                  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2145:13: ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) )
                  {
                    CommonTree root_2 = (CommonTree) adaptor.nil();
                    root_2 =
                        (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_INSERT, "TOK_INSERT"), root_2);

                    adaptor.addChild(root_2, (i != null ? ((CommonTree) i.tree) : null));

                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2145:36: ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) )
                    {
                      CommonTree root_3 = (CommonTree) adaptor.nil();
                      root_3 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SELECT, "TOK_SELECT"),
                          root_3);

                      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2145:49: ^( TOK_SELEXPR TOK_ALLCOLREF )
                      {
                        CommonTree root_4 = (CommonTree) adaptor.nil();
                        root_4 = (CommonTree) adaptor
                            .becomeRoot((CommonTree) adaptor.create(TOK_SELEXPR, "TOK_SELEXPR"), root_4);

                        adaptor.addChild(root_4, (CommonTree) adaptor.create(TOK_ALLCOLREF, "TOK_ALLCOLREF"));

                        adaptor.addChild(root_3, root_4);
                      }

                      adaptor.addChild(root_2, root_3);
                    }

                    adaptor.addChild(root_1, root_2);
                  }

                  adaptor.addChild(root_0, root_1);
                }
              }

              retval.tree = root_0;
            }
              break;
          }
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2149:4: selectStatement[topLevel]
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_selectStatement_in_regularBody13565);
          selectStatement847 = selectStatement(topLevel);

          state._fsp--;

          adaptor.addChild(root_0, selectStatement847.getTree());
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "regularBody"

  public static class selectStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "selectStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2152:2: selectStatement[boolean topLevel] : ( singleSelectStatement -> singleSelectStatement ) (u= setOperator b= singleSelectStatement -> ^( $u $b) )* -> {u != null && topLevel}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) ) ->;
  public final HiveParser.selectStatement_return selectStatement(boolean topLevel) throws RecognitionException {
    HiveParser.selectStatement_return retval = new HiveParser.selectStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.setOperator_return u = null;

    HiveParser.singleSelectStatement_return b = null;

    HiveParser.singleSelectStatement_return singleSelectStatement848 = null;

    RewriteRuleSubtreeStream stream_singleSelectStatement =
        new RewriteRuleSubtreeStream(adaptor, "rule singleSelectStatement");
    RewriteRuleSubtreeStream stream_setOperator = new RewriteRuleSubtreeStream(adaptor, "rule setOperator");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2153:2: ( ( singleSelectStatement -> singleSelectStatement ) (u= setOperator b= singleSelectStatement -> ^( $u $b) )* -> {u != null && topLevel}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) ) ->)
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2153:4: ( singleSelectStatement -> singleSelectStatement ) (u= setOperator b= singleSelectStatement -> ^( $u $b) )*
      {
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2153:4: ( singleSelectStatement -> singleSelectStatement )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2153:5: singleSelectStatement
        {
          pushFollow(FOLLOW_singleSelectStatement_in_selectStatement13582);
          singleSelectStatement848 = singleSelectStatement();

          state._fsp--;

          stream_singleSelectStatement.add(singleSelectStatement848.getTree());

          // AST REWRITE
          // elements: singleSelectStatement
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2153:27: -> singleSelectStatement
          {
            adaptor.addChild(root_0, stream_singleSelectStatement.nextTree());
          }

          retval.tree = root_0;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2154:4: (u= setOperator b= singleSelectStatement -> ^( $u $b) )*
        loop241: do {
          int alt241 = 2;
          switch (input.LA(1)) {
            case KW_UNION: {
              alt241 = 1;
            }
              break;
          }

          switch (alt241) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2154:5: u= setOperator b= singleSelectStatement
            {
              pushFollow(FOLLOW_setOperator_in_selectStatement13595);
              u = setOperator();

              state._fsp--;

              stream_setOperator.add(u.getTree());

              pushFollow(FOLLOW_singleSelectStatement_in_selectStatement13599);
              b = singleSelectStatement();

              state._fsp--;

              stream_singleSelectStatement.add(b.getTree());

              // AST REWRITE
              // elements: u, b
              // token labels:
              // rule labels: b, u, retval
              // token list labels:
              // rule list labels:
              // wildcard labels:
              retval.tree = root_0;
              RewriteRuleSubtreeStream stream_b =
                  new RewriteRuleSubtreeStream(adaptor, "rule b", b != null ? b.tree : null);
              RewriteRuleSubtreeStream stream_u =
                  new RewriteRuleSubtreeStream(adaptor, "rule u", u != null ? u.tree : null);
              RewriteRuleSubtreeStream stream_retval =
                  new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

              root_0 = (CommonTree) adaptor.nil();
              // 2155:8: -> ^( $u $b)
              {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2155:11: ^( $u $b)
                {
                  CommonTree root_1 = (CommonTree) adaptor.nil();
                  root_1 = (CommonTree) adaptor.becomeRoot(stream_u.nextNode(), root_1);

                  adaptor.addChild(root_1, ((CommonTree) retval.tree));

                  adaptor.addChild(root_1, stream_b.nextTree());

                  adaptor.addChild(root_0, root_1);
                }
              }

              retval.tree = root_0;
            }
              break;

            default:
              break loop241;
          }
        } while (true);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2157:4: -> {u != null && topLevel}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) )
        if (u != null && topLevel) {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2157:32: ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2158:10: ^( TOK_FROM ^( TOK_SUBQUERY ) )
            {
              CommonTree root_2 = (CommonTree) adaptor.nil();
              root_2 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_FROM, "TOK_FROM"), root_2);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2159:12: ^( TOK_SUBQUERY )
              {
                CommonTree root_3 = (CommonTree) adaptor.nil();
                root_3 =
                    (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SUBQUERY, "TOK_SUBQUERY"), root_3);

                adaptor.addChild(root_3, ((CommonTree) retval.tree));

                adaptor.addChild(root_3, adaptor.create(Identifier, generateUnionAlias()));

                adaptor.addChild(root_2, root_3);
              }

              adaptor.addChild(root_1, root_2);
            }

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2164:10: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) )
            {
              CommonTree root_2 = (CommonTree) adaptor.nil();
              root_2 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_INSERT, "TOK_INSERT"), root_2);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2165:13: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
              {
                CommonTree root_3 = (CommonTree) adaptor.nil();
                root_3 = (CommonTree) adaptor
                    .becomeRoot((CommonTree) adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"), root_3);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2165:31: ^( TOK_DIR TOK_TMP_FILE )
                {
                  CommonTree root_4 = (CommonTree) adaptor.nil();
                  root_4 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DIR, "TOK_DIR"), root_4);

                  adaptor.addChild(root_4, (CommonTree) adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE"));

                  adaptor.addChild(root_3, root_4);
                }

                adaptor.addChild(root_2, root_3);
              }

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2166:13: ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) )
              {
                CommonTree root_3 = (CommonTree) adaptor.nil();
                root_3 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SELECT, "TOK_SELECT"), root_3);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2166:26: ^( TOK_SELEXPR TOK_ALLCOLREF )
                {
                  CommonTree root_4 = (CommonTree) adaptor.nil();
                  root_4 =
                      (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SELEXPR, "TOK_SELEXPR"), root_4);

                  adaptor.addChild(root_4, (CommonTree) adaptor.create(TOK_ALLCOLREF, "TOK_ALLCOLREF"));

                  adaptor.addChild(root_3, root_4);
                }

                adaptor.addChild(root_2, root_3);
              }

              adaptor.addChild(root_1, root_2);
            }

            adaptor.addChild(root_0, root_1);
          }
        } else // 2169:5: ->
        {
          adaptor.addChild(root_0, ((CommonTree) retval.tree));
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "selectStatement"

  public static class singleSelectStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "singleSelectStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2172:1: singleSelectStatement : selectClause ( fromClause )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? -> ^( TOK_QUERY ( fromClause )? ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) ) ;
  public final HiveParser.singleSelectStatement_return singleSelectStatement() throws RecognitionException {
    HiveParser.singleSelectStatement_return retval = new HiveParser.singleSelectStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser_SelectClauseParser.selectClause_return selectClause849 = null;

    HiveParser_FromClauseParser.fromClause_return fromClause850 = null;

    HiveParser_FromClauseParser.whereClause_return whereClause851 = null;

    HiveParser_IdentifiersParser.groupByClause_return groupByClause852 = null;

    HiveParser_IdentifiersParser.havingClause_return havingClause853 = null;

    HiveParser_IdentifiersParser.orderByClause_return orderByClause854 = null;

    HiveParser_IdentifiersParser.clusterByClause_return clusterByClause855 = null;

    HiveParser_IdentifiersParser.distributeByClause_return distributeByClause856 = null;

    HiveParser_IdentifiersParser.sortByClause_return sortByClause857 = null;

    HiveParser_SelectClauseParser.window_clause_return window_clause858 = null;

    HiveParser.limitClause_return limitClause859 = null;

    RewriteRuleSubtreeStream stream_whereClause = new RewriteRuleSubtreeStream(adaptor, "rule whereClause");
    RewriteRuleSubtreeStream stream_havingClause = new RewriteRuleSubtreeStream(adaptor, "rule havingClause");
    RewriteRuleSubtreeStream stream_clusterByClause = new RewriteRuleSubtreeStream(adaptor, "rule clusterByClause");
    RewriteRuleSubtreeStream stream_fromClause = new RewriteRuleSubtreeStream(adaptor, "rule fromClause");
    RewriteRuleSubtreeStream stream_selectClause = new RewriteRuleSubtreeStream(adaptor, "rule selectClause");
    RewriteRuleSubtreeStream stream_sortByClause = new RewriteRuleSubtreeStream(adaptor, "rule sortByClause");
    RewriteRuleSubtreeStream stream_groupByClause = new RewriteRuleSubtreeStream(adaptor, "rule groupByClause");
    RewriteRuleSubtreeStream stream_distributeByClause =
        new RewriteRuleSubtreeStream(adaptor, "rule distributeByClause");
    RewriteRuleSubtreeStream stream_limitClause = new RewriteRuleSubtreeStream(adaptor, "rule limitClause");
    RewriteRuleSubtreeStream stream_orderByClause = new RewriteRuleSubtreeStream(adaptor, "rule orderByClause");
    RewriteRuleSubtreeStream stream_window_clause = new RewriteRuleSubtreeStream(adaptor, "rule window_clause");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2173:4: ( selectClause ( fromClause )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? -> ^( TOK_QUERY ( fromClause )? ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2174:4: selectClause ( fromClause )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )?
      {
        pushFollow(FOLLOW_selectClause_in_singleSelectStatement13821);
        selectClause849 = selectClause();

        state._fsp--;

        stream_selectClause.add(selectClause849.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2175:4: ( fromClause )?
        int alt242 = 2;
        switch (input.LA(1)) {
          case KW_FROM: {
            alt242 = 1;
          }
            break;
        }

        switch (alt242) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2175:4: fromClause
          {
            pushFollow(FOLLOW_fromClause_in_singleSelectStatement13826);
            fromClause850 = fromClause();

            state._fsp--;

            stream_fromClause.add(fromClause850.getTree());
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2176:4: ( whereClause )?
        int alt243 = 2;
        switch (input.LA(1)) {
          case KW_WHERE: {
            alt243 = 1;
          }
            break;
        }

        switch (alt243) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2176:4: whereClause
          {
            pushFollow(FOLLOW_whereClause_in_singleSelectStatement13832);
            whereClause851 = whereClause();

            state._fsp--;

            stream_whereClause.add(whereClause851.getTree());
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2177:4: ( groupByClause )?
        int alt244 = 2;
        switch (input.LA(1)) {
          case KW_GROUP: {
            alt244 = 1;
          }
            break;
        }

        switch (alt244) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2177:4: groupByClause
          {
            pushFollow(FOLLOW_groupByClause_in_singleSelectStatement13838);
            groupByClause852 = groupByClause();

            state._fsp--;

            stream_groupByClause.add(groupByClause852.getTree());
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2178:4: ( havingClause )?
        int alt245 = 2;
        switch (input.LA(1)) {
          case KW_HAVING: {
            alt245 = 1;
          }
            break;
        }

        switch (alt245) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2178:4: havingClause
          {
            pushFollow(FOLLOW_havingClause_in_singleSelectStatement13844);
            havingClause853 = havingClause();

            state._fsp--;

            stream_havingClause.add(havingClause853.getTree());
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2179:4: ( orderByClause )?
        int alt246 = 2;
        switch (input.LA(1)) {
          case KW_ORDER: {
            alt246 = 1;
          }
            break;
        }

        switch (alt246) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2179:4: orderByClause
          {
            pushFollow(FOLLOW_orderByClause_in_singleSelectStatement13850);
            orderByClause854 = orderByClause();

            state._fsp--;

            stream_orderByClause.add(orderByClause854.getTree());
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2180:4: ( clusterByClause )?
        int alt247 = 2;
        switch (input.LA(1)) {
          case KW_CLUSTER: {
            alt247 = 1;
          }
            break;
        }

        switch (alt247) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2180:4: clusterByClause
          {
            pushFollow(FOLLOW_clusterByClause_in_singleSelectStatement13856);
            clusterByClause855 = clusterByClause();

            state._fsp--;

            stream_clusterByClause.add(clusterByClause855.getTree());
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2181:4: ( distributeByClause )?
        int alt248 = 2;
        switch (input.LA(1)) {
          case KW_DISTRIBUTE: {
            alt248 = 1;
          }
            break;
        }

        switch (alt248) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2181:4: distributeByClause
          {
            pushFollow(FOLLOW_distributeByClause_in_singleSelectStatement13862);
            distributeByClause856 = distributeByClause();

            state._fsp--;

            stream_distributeByClause.add(distributeByClause856.getTree());
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2182:4: ( sortByClause )?
        int alt249 = 2;
        switch (input.LA(1)) {
          case KW_SORT: {
            alt249 = 1;
          }
            break;
        }

        switch (alt249) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2182:4: sortByClause
          {
            pushFollow(FOLLOW_sortByClause_in_singleSelectStatement13868);
            sortByClause857 = sortByClause();

            state._fsp--;

            stream_sortByClause.add(sortByClause857.getTree());
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2183:4: ( window_clause )?
        int alt250 = 2;
        switch (input.LA(1)) {
          case KW_WINDOW: {
            alt250 = 1;
          }
            break;
        }

        switch (alt250) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2183:4: window_clause
          {
            pushFollow(FOLLOW_window_clause_in_singleSelectStatement13874);
            window_clause858 = window_clause();

            state._fsp--;

            stream_window_clause.add(window_clause858.getTree());
          }
            break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2184:4: ( limitClause )?
        int alt251 = 2;
        switch (input.LA(1)) {
          case KW_LIMIT: {
            alt251 = 1;
          }
            break;
        }

        switch (alt251) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2184:4: limitClause
          {
            pushFollow(FOLLOW_limitClause_in_singleSelectStatement13880);
            limitClause859 = limitClause();

            state._fsp--;

            stream_limitClause.add(limitClause859.getTree());
          }
            break;
        }

        // AST REWRITE
        // elements: whereClause, window_clause, clusterByClause, selectClause, distributeByClause, havingClause, groupByClause, fromClause, orderByClause, sortByClause, limitClause
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2184:17: -> ^( TOK_QUERY ( fromClause )? ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2184:20: ^( TOK_QUERY ( fromClause )? ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2184:32: ( fromClause )?
            if (stream_fromClause.hasNext()) {
              adaptor.addChild(root_1, stream_fromClause.nextTree());
            }
            stream_fromClause.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2184:44: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? )
            {
              CommonTree root_2 = (CommonTree) adaptor.nil();
              root_2 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_INSERT, "TOK_INSERT"), root_2);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2184:57: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
              {
                CommonTree root_3 = (CommonTree) adaptor.nil();
                root_3 = (CommonTree) adaptor
                    .becomeRoot((CommonTree) adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"), root_3);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2184:75: ^( TOK_DIR TOK_TMP_FILE )
                {
                  CommonTree root_4 = (CommonTree) adaptor.nil();
                  root_4 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DIR, "TOK_DIR"), root_4);

                  adaptor.addChild(root_4, (CommonTree) adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE"));

                  adaptor.addChild(root_3, root_4);
                }

                adaptor.addChild(root_2, root_3);
              }

              adaptor.addChild(root_2, stream_selectClause.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2185:35: ( whereClause )?
              if (stream_whereClause.hasNext()) {
                adaptor.addChild(root_2, stream_whereClause.nextTree());
              }
              stream_whereClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2185:48: ( groupByClause )?
              if (stream_groupByClause.hasNext()) {
                adaptor.addChild(root_2, stream_groupByClause.nextTree());
              }
              stream_groupByClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2185:63: ( havingClause )?
              if (stream_havingClause.hasNext()) {
                adaptor.addChild(root_2, stream_havingClause.nextTree());
              }
              stream_havingClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2185:77: ( orderByClause )?
              if (stream_orderByClause.hasNext()) {
                adaptor.addChild(root_2, stream_orderByClause.nextTree());
              }
              stream_orderByClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2185:92: ( clusterByClause )?
              if (stream_clusterByClause.hasNext()) {
                adaptor.addChild(root_2, stream_clusterByClause.nextTree());
              }
              stream_clusterByClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2186:22: ( distributeByClause )?
              if (stream_distributeByClause.hasNext()) {
                adaptor.addChild(root_2, stream_distributeByClause.nextTree());
              }
              stream_distributeByClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2186:42: ( sortByClause )?
              if (stream_sortByClause.hasNext()) {
                adaptor.addChild(root_2, stream_sortByClause.nextTree());
              }
              stream_sortByClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2186:56: ( window_clause )?
              if (stream_window_clause.hasNext()) {
                adaptor.addChild(root_2, stream_window_clause.nextTree());
              }
              stream_window_clause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2186:71: ( limitClause )?
              if (stream_limitClause.hasNext()) {
                adaptor.addChild(root_2, stream_limitClause.nextTree());
              }
              stream_limitClause.reset();

              adaptor.addChild(root_1, root_2);
            }

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "singleSelectStatement"

  public static class selectStatementWithCTE_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "selectStatementWithCTE"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2189:1: selectStatementWithCTE : (w= withClause )? selectStatement[true] -> selectStatement ;
  public final HiveParser.selectStatementWithCTE_return selectStatementWithCTE() throws RecognitionException {
    HiveParser.selectStatementWithCTE_return retval = new HiveParser.selectStatementWithCTE_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.withClause_return w = null;

    HiveParser.selectStatement_return selectStatement860 = null;

    RewriteRuleSubtreeStream stream_withClause = new RewriteRuleSubtreeStream(adaptor, "rule withClause");
    RewriteRuleSubtreeStream stream_selectStatement = new RewriteRuleSubtreeStream(adaptor, "rule selectStatement");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2190:5: ( (w= withClause )? selectStatement[true] -> selectStatement )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2191:5: (w= withClause )? selectStatement[true]
      {
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2191:5: (w= withClause )?
        int alt252 = 2;
        switch (input.LA(1)) {
          case KW_WITH: {
            alt252 = 1;
          }
            break;
        }

        switch (alt252) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2191:6: w= withClause
          {
            pushFollow(FOLLOW_withClause_in_selectStatementWithCTE13998);
            w = withClause();

            state._fsp--;

            stream_withClause.add(w.getTree());
          }
            break;
        }

        pushFollow(FOLLOW_selectStatement_in_selectStatementWithCTE14006);
        selectStatement860 = selectStatement(true);

        state._fsp--;

        stream_selectStatement.add(selectStatement860.getTree());

        if ((w != null ? ((CommonTree) w.tree) : null) != null) {
          (selectStatement860 != null ? ((CommonTree) selectStatement860.tree) : null).insertChild(0,
              (w != null ? ((CommonTree) w.tree) : null));
        }

        // AST REWRITE
        // elements: selectStatement
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2197:5: -> selectStatement
        {
          adaptor.addChild(root_0, stream_selectStatement.nextTree());
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "selectStatementWithCTE"

  public static class body_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "body"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2200:1: body : ( insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? -> ^( TOK_INSERT insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) | selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? -> ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) );
  public final HiveParser.body_return body() throws RecognitionException {
    HiveParser.body_return retval = new HiveParser.body_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.insertClause_return insertClause861 = null;

    HiveParser_SelectClauseParser.selectClause_return selectClause862 = null;

    HiveParser_FromClauseParser.lateralView_return lateralView863 = null;

    HiveParser_FromClauseParser.whereClause_return whereClause864 = null;

    HiveParser_IdentifiersParser.groupByClause_return groupByClause865 = null;

    HiveParser_IdentifiersParser.havingClause_return havingClause866 = null;

    HiveParser_IdentifiersParser.orderByClause_return orderByClause867 = null;

    HiveParser_IdentifiersParser.clusterByClause_return clusterByClause868 = null;

    HiveParser_IdentifiersParser.distributeByClause_return distributeByClause869 = null;

    HiveParser_IdentifiersParser.sortByClause_return sortByClause870 = null;

    HiveParser_SelectClauseParser.window_clause_return window_clause871 = null;

    HiveParser.limitClause_return limitClause872 = null;

    HiveParser_SelectClauseParser.selectClause_return selectClause873 = null;

    HiveParser_FromClauseParser.lateralView_return lateralView874 = null;

    HiveParser_FromClauseParser.whereClause_return whereClause875 = null;

    HiveParser_IdentifiersParser.groupByClause_return groupByClause876 = null;

    HiveParser_IdentifiersParser.havingClause_return havingClause877 = null;

    HiveParser_IdentifiersParser.orderByClause_return orderByClause878 = null;

    HiveParser_IdentifiersParser.clusterByClause_return clusterByClause879 = null;

    HiveParser_IdentifiersParser.distributeByClause_return distributeByClause880 = null;

    HiveParser_IdentifiersParser.sortByClause_return sortByClause881 = null;

    HiveParser_SelectClauseParser.window_clause_return window_clause882 = null;

    HiveParser.limitClause_return limitClause883 = null;

    RewriteRuleSubtreeStream stream_whereClause = new RewriteRuleSubtreeStream(adaptor, "rule whereClause");
    RewriteRuleSubtreeStream stream_havingClause = new RewriteRuleSubtreeStream(adaptor, "rule havingClause");
    RewriteRuleSubtreeStream stream_clusterByClause = new RewriteRuleSubtreeStream(adaptor, "rule clusterByClause");
    RewriteRuleSubtreeStream stream_lateralView = new RewriteRuleSubtreeStream(adaptor, "rule lateralView");
    RewriteRuleSubtreeStream stream_insertClause = new RewriteRuleSubtreeStream(adaptor, "rule insertClause");
    RewriteRuleSubtreeStream stream_selectClause = new RewriteRuleSubtreeStream(adaptor, "rule selectClause");
    RewriteRuleSubtreeStream stream_sortByClause = new RewriteRuleSubtreeStream(adaptor, "rule sortByClause");
    RewriteRuleSubtreeStream stream_groupByClause = new RewriteRuleSubtreeStream(adaptor, "rule groupByClause");
    RewriteRuleSubtreeStream stream_distributeByClause =
        new RewriteRuleSubtreeStream(adaptor, "rule distributeByClause");
    RewriteRuleSubtreeStream stream_limitClause = new RewriteRuleSubtreeStream(adaptor, "rule limitClause");
    RewriteRuleSubtreeStream stream_orderByClause = new RewriteRuleSubtreeStream(adaptor, "rule orderByClause");
    RewriteRuleSubtreeStream stream_window_clause = new RewriteRuleSubtreeStream(adaptor, "rule window_clause");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2201:4: ( insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? -> ^( TOK_INSERT insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) | selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? -> ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) )
      int alt273 = 2;
      switch (input.LA(1)) {
        case KW_INSERT: {
          alt273 = 1;
        }
          break;
        case KW_MAP:
        case KW_REDUCE:
        case KW_SELECT: {
          alt273 = 2;
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 273, 0, input);

          throw nvae;
      }

      switch (alt273) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2202:4: insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )?
        {
          pushFollow(FOLLOW_insertClause_in_body14037);
          insertClause861 = insertClause();

          state._fsp--;

          stream_insertClause.add(insertClause861.getTree());

          pushFollow(FOLLOW_selectClause_in_body14042);
          selectClause862 = selectClause();

          state._fsp--;

          stream_selectClause.add(selectClause862.getTree());

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2204:4: ( lateralView )?
          int alt253 = 2;
          switch (input.LA(1)) {
            case KW_LATERAL: {
              alt253 = 1;
            }
              break;
          }

          switch (alt253) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2204:4: lateralView
            {
              pushFollow(FOLLOW_lateralView_in_body14047);
              lateralView863 = lateralView();

              state._fsp--;

              stream_lateralView.add(lateralView863.getTree());
            }
              break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2205:4: ( whereClause )?
          int alt254 = 2;
          switch (input.LA(1)) {
            case KW_WHERE: {
              alt254 = 1;
            }
              break;
          }

          switch (alt254) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2205:4: whereClause
            {
              pushFollow(FOLLOW_whereClause_in_body14053);
              whereClause864 = whereClause();

              state._fsp--;

              stream_whereClause.add(whereClause864.getTree());
            }
              break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2206:4: ( groupByClause )?
          int alt255 = 2;
          switch (input.LA(1)) {
            case KW_GROUP: {
              alt255 = 1;
            }
              break;
          }

          switch (alt255) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2206:4: groupByClause
            {
              pushFollow(FOLLOW_groupByClause_in_body14059);
              groupByClause865 = groupByClause();

              state._fsp--;

              stream_groupByClause.add(groupByClause865.getTree());
            }
              break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2207:4: ( havingClause )?
          int alt256 = 2;
          switch (input.LA(1)) {
            case KW_HAVING: {
              alt256 = 1;
            }
              break;
          }

          switch (alt256) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2207:4: havingClause
            {
              pushFollow(FOLLOW_havingClause_in_body14065);
              havingClause866 = havingClause();

              state._fsp--;

              stream_havingClause.add(havingClause866.getTree());
            }
              break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2208:4: ( orderByClause )?
          int alt257 = 2;
          switch (input.LA(1)) {
            case KW_ORDER: {
              alt257 = 1;
            }
              break;
          }

          switch (alt257) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2208:4: orderByClause
            {
              pushFollow(FOLLOW_orderByClause_in_body14071);
              orderByClause867 = orderByClause();

              state._fsp--;

              stream_orderByClause.add(orderByClause867.getTree());
            }
              break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2209:4: ( clusterByClause )?
          int alt258 = 2;
          switch (input.LA(1)) {
            case KW_CLUSTER: {
              alt258 = 1;
            }
              break;
          }

          switch (alt258) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2209:4: clusterByClause
            {
              pushFollow(FOLLOW_clusterByClause_in_body14077);
              clusterByClause868 = clusterByClause();

              state._fsp--;

              stream_clusterByClause.add(clusterByClause868.getTree());
            }
              break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2210:4: ( distributeByClause )?
          int alt259 = 2;
          switch (input.LA(1)) {
            case KW_DISTRIBUTE: {
              alt259 = 1;
            }
              break;
          }

          switch (alt259) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2210:4: distributeByClause
            {
              pushFollow(FOLLOW_distributeByClause_in_body14083);
              distributeByClause869 = distributeByClause();

              state._fsp--;

              stream_distributeByClause.add(distributeByClause869.getTree());
            }
              break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2211:4: ( sortByClause )?
          int alt260 = 2;
          switch (input.LA(1)) {
            case KW_SORT: {
              alt260 = 1;
            }
              break;
          }

          switch (alt260) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2211:4: sortByClause
            {
              pushFollow(FOLLOW_sortByClause_in_body14089);
              sortByClause870 = sortByClause();

              state._fsp--;

              stream_sortByClause.add(sortByClause870.getTree());
            }
              break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2212:4: ( window_clause )?
          int alt261 = 2;
          switch (input.LA(1)) {
            case KW_WINDOW: {
              alt261 = 1;
            }
              break;
          }

          switch (alt261) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2212:4: window_clause
            {
              pushFollow(FOLLOW_window_clause_in_body14095);
              window_clause871 = window_clause();

              state._fsp--;

              stream_window_clause.add(window_clause871.getTree());
            }
              break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2213:4: ( limitClause )?
          int alt262 = 2;
          switch (input.LA(1)) {
            case KW_LIMIT: {
              alt262 = 1;
            }
              break;
          }

          switch (alt262) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2213:4: limitClause
            {
              pushFollow(FOLLOW_limitClause_in_body14101);
              limitClause872 = limitClause();

              state._fsp--;

              stream_limitClause.add(limitClause872.getTree());
            }
              break;
          }

          // AST REWRITE
          // elements: havingClause, lateralView, selectClause, groupByClause, clusterByClause, limitClause, insertClause, orderByClause, whereClause, distributeByClause, window_clause, sortByClause
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2213:17: -> ^( TOK_INSERT insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2213:20: ^( TOK_INSERT insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_INSERT, "TOK_INSERT"), root_1);

              adaptor.addChild(root_1, stream_insertClause.nextTree());

              adaptor.addChild(root_1, stream_selectClause.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2214:35: ( lateralView )?
              if (stream_lateralView.hasNext()) {
                adaptor.addChild(root_1, stream_lateralView.nextTree());
              }
              stream_lateralView.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2214:48: ( whereClause )?
              if (stream_whereClause.hasNext()) {
                adaptor.addChild(root_1, stream_whereClause.nextTree());
              }
              stream_whereClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2214:61: ( groupByClause )?
              if (stream_groupByClause.hasNext()) {
                adaptor.addChild(root_1, stream_groupByClause.nextTree());
              }
              stream_groupByClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2214:76: ( havingClause )?
              if (stream_havingClause.hasNext()) {
                adaptor.addChild(root_1, stream_havingClause.nextTree());
              }
              stream_havingClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2214:90: ( orderByClause )?
              if (stream_orderByClause.hasNext()) {
                adaptor.addChild(root_1, stream_orderByClause.nextTree());
              }
              stream_orderByClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2214:105: ( clusterByClause )?
              if (stream_clusterByClause.hasNext()) {
                adaptor.addChild(root_1, stream_clusterByClause.nextTree());
              }
              stream_clusterByClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2215:22: ( distributeByClause )?
              if (stream_distributeByClause.hasNext()) {
                adaptor.addChild(root_1, stream_distributeByClause.nextTree());
              }
              stream_distributeByClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2215:42: ( sortByClause )?
              if (stream_sortByClause.hasNext()) {
                adaptor.addChild(root_1, stream_sortByClause.nextTree());
              }
              stream_sortByClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2215:56: ( window_clause )?
              if (stream_window_clause.hasNext()) {
                adaptor.addChild(root_1, stream_window_clause.nextTree());
              }
              stream_window_clause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2215:71: ( limitClause )?
              if (stream_limitClause.hasNext()) {
                adaptor.addChild(root_1, stream_limitClause.nextTree());
              }
              stream_limitClause.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2217:4: selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )?
        {
          pushFollow(FOLLOW_selectClause_in_body14194);
          selectClause873 = selectClause();

          state._fsp--;

          stream_selectClause.add(selectClause873.getTree());

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2218:4: ( lateralView )?
          int alt263 = 2;
          switch (input.LA(1)) {
            case KW_LATERAL: {
              alt263 = 1;
            }
              break;
          }

          switch (alt263) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2218:4: lateralView
            {
              pushFollow(FOLLOW_lateralView_in_body14199);
              lateralView874 = lateralView();

              state._fsp--;

              stream_lateralView.add(lateralView874.getTree());
            }
              break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2219:4: ( whereClause )?
          int alt264 = 2;
          switch (input.LA(1)) {
            case KW_WHERE: {
              alt264 = 1;
            }
              break;
          }

          switch (alt264) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2219:4: whereClause
            {
              pushFollow(FOLLOW_whereClause_in_body14205);
              whereClause875 = whereClause();

              state._fsp--;

              stream_whereClause.add(whereClause875.getTree());
            }
              break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2220:4: ( groupByClause )?
          int alt265 = 2;
          switch (input.LA(1)) {
            case KW_GROUP: {
              alt265 = 1;
            }
              break;
          }

          switch (alt265) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2220:4: groupByClause
            {
              pushFollow(FOLLOW_groupByClause_in_body14211);
              groupByClause876 = groupByClause();

              state._fsp--;

              stream_groupByClause.add(groupByClause876.getTree());
            }
              break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2221:4: ( havingClause )?
          int alt266 = 2;
          switch (input.LA(1)) {
            case KW_HAVING: {
              alt266 = 1;
            }
              break;
          }

          switch (alt266) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2221:4: havingClause
            {
              pushFollow(FOLLOW_havingClause_in_body14217);
              havingClause877 = havingClause();

              state._fsp--;

              stream_havingClause.add(havingClause877.getTree());
            }
              break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2222:4: ( orderByClause )?
          int alt267 = 2;
          switch (input.LA(1)) {
            case KW_ORDER: {
              alt267 = 1;
            }
              break;
          }

          switch (alt267) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2222:4: orderByClause
            {
              pushFollow(FOLLOW_orderByClause_in_body14223);
              orderByClause878 = orderByClause();

              state._fsp--;

              stream_orderByClause.add(orderByClause878.getTree());
            }
              break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2223:4: ( clusterByClause )?
          int alt268 = 2;
          switch (input.LA(1)) {
            case KW_CLUSTER: {
              alt268 = 1;
            }
              break;
          }

          switch (alt268) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2223:4: clusterByClause
            {
              pushFollow(FOLLOW_clusterByClause_in_body14229);
              clusterByClause879 = clusterByClause();

              state._fsp--;

              stream_clusterByClause.add(clusterByClause879.getTree());
            }
              break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2224:4: ( distributeByClause )?
          int alt269 = 2;
          switch (input.LA(1)) {
            case KW_DISTRIBUTE: {
              alt269 = 1;
            }
              break;
          }

          switch (alt269) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2224:4: distributeByClause
            {
              pushFollow(FOLLOW_distributeByClause_in_body14235);
              distributeByClause880 = distributeByClause();

              state._fsp--;

              stream_distributeByClause.add(distributeByClause880.getTree());
            }
              break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2225:4: ( sortByClause )?
          int alt270 = 2;
          switch (input.LA(1)) {
            case KW_SORT: {
              alt270 = 1;
            }
              break;
          }

          switch (alt270) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2225:4: sortByClause
            {
              pushFollow(FOLLOW_sortByClause_in_body14241);
              sortByClause881 = sortByClause();

              state._fsp--;

              stream_sortByClause.add(sortByClause881.getTree());
            }
              break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2226:4: ( window_clause )?
          int alt271 = 2;
          switch (input.LA(1)) {
            case KW_WINDOW: {
              alt271 = 1;
            }
              break;
          }

          switch (alt271) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2226:4: window_clause
            {
              pushFollow(FOLLOW_window_clause_in_body14247);
              window_clause882 = window_clause();

              state._fsp--;

              stream_window_clause.add(window_clause882.getTree());
            }
              break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2227:4: ( limitClause )?
          int alt272 = 2;
          switch (input.LA(1)) {
            case KW_LIMIT: {
              alt272 = 1;
            }
              break;
          }

          switch (alt272) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2227:4: limitClause
            {
              pushFollow(FOLLOW_limitClause_in_body14253);
              limitClause883 = limitClause();

              state._fsp--;

              stream_limitClause.add(limitClause883.getTree());
            }
              break;
          }

          // AST REWRITE
          // elements: sortByClause, groupByClause, orderByClause, whereClause, lateralView, window_clause, limitClause, havingClause, clusterByClause, distributeByClause, selectClause
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2227:17: -> ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2227:20: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_INSERT, "TOK_INSERT"), root_1);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2227:33: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
              {
                CommonTree root_2 = (CommonTree) adaptor.nil();
                root_2 = (CommonTree) adaptor
                    .becomeRoot((CommonTree) adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"), root_2);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2227:51: ^( TOK_DIR TOK_TMP_FILE )
                {
                  CommonTree root_3 = (CommonTree) adaptor.nil();
                  root_3 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DIR, "TOK_DIR"), root_3);

                  adaptor.addChild(root_3, (CommonTree) adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE"));

                  adaptor.addChild(root_2, root_3);
                }

                adaptor.addChild(root_1, root_2);
              }

              adaptor.addChild(root_1, stream_selectClause.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2228:35: ( lateralView )?
              if (stream_lateralView.hasNext()) {
                adaptor.addChild(root_1, stream_lateralView.nextTree());
              }
              stream_lateralView.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2228:48: ( whereClause )?
              if (stream_whereClause.hasNext()) {
                adaptor.addChild(root_1, stream_whereClause.nextTree());
              }
              stream_whereClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2228:61: ( groupByClause )?
              if (stream_groupByClause.hasNext()) {
                adaptor.addChild(root_1, stream_groupByClause.nextTree());
              }
              stream_groupByClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2228:76: ( havingClause )?
              if (stream_havingClause.hasNext()) {
                adaptor.addChild(root_1, stream_havingClause.nextTree());
              }
              stream_havingClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2228:90: ( orderByClause )?
              if (stream_orderByClause.hasNext()) {
                adaptor.addChild(root_1, stream_orderByClause.nextTree());
              }
              stream_orderByClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2228:105: ( clusterByClause )?
              if (stream_clusterByClause.hasNext()) {
                adaptor.addChild(root_1, stream_clusterByClause.nextTree());
              }
              stream_clusterByClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2229:22: ( distributeByClause )?
              if (stream_distributeByClause.hasNext()) {
                adaptor.addChild(root_1, stream_distributeByClause.nextTree());
              }
              stream_distributeByClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2229:42: ( sortByClause )?
              if (stream_sortByClause.hasNext()) {
                adaptor.addChild(root_1, stream_sortByClause.nextTree());
              }
              stream_sortByClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2229:56: ( window_clause )?
              if (stream_window_clause.hasNext()) {
                adaptor.addChild(root_1, stream_window_clause.nextTree());
              }
              stream_window_clause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2229:71: ( limitClause )?
              if (stream_limitClause.hasNext()) {
                adaptor.addChild(root_1, stream_limitClause.nextTree());
              }
              stream_limitClause.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "body"

  public static class insertClause_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "insertClause"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2232:1: insertClause : ( KW_INSERT KW_OVERWRITE destination ( ifNotExists )? -> ^( TOK_DESTINATION destination ( ifNotExists )? ) | KW_INSERT KW_INTO ( KW_TABLE )? tableOrPartition -> ^( TOK_INSERT_INTO tableOrPartition ) );
  public final HiveParser.insertClause_return insertClause() throws RecognitionException {
    HiveParser.insertClause_return retval = new HiveParser.insertClause_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_INSERT884 = null;
    Token KW_OVERWRITE885 = null;
    Token KW_INSERT888 = null;
    Token KW_INTO889 = null;
    Token KW_TABLE890 = null;
    HiveParser.destination_return destination886 = null;

    HiveParser.ifNotExists_return ifNotExists887 = null;

    HiveParser_IdentifiersParser.tableOrPartition_return tableOrPartition891 = null;

    CommonTree KW_INSERT884_tree = null;
    CommonTree KW_OVERWRITE885_tree = null;
    CommonTree KW_INSERT888_tree = null;
    CommonTree KW_INTO889_tree = null;
    CommonTree KW_TABLE890_tree = null;
    RewriteRuleTokenStream stream_KW_INTO = new RewriteRuleTokenStream(adaptor, "token KW_INTO");
    RewriteRuleTokenStream stream_KW_INSERT = new RewriteRuleTokenStream(adaptor, "token KW_INSERT");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleTokenStream stream_KW_OVERWRITE = new RewriteRuleTokenStream(adaptor, "token KW_OVERWRITE");
    RewriteRuleSubtreeStream stream_destination = new RewriteRuleSubtreeStream(adaptor, "rule destination");
    RewriteRuleSubtreeStream stream_ifNotExists = new RewriteRuleSubtreeStream(adaptor, "rule ifNotExists");
    RewriteRuleSubtreeStream stream_tableOrPartition = new RewriteRuleSubtreeStream(adaptor, "rule tableOrPartition");
    pushMsg("insert clause", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2235:4: ( KW_INSERT KW_OVERWRITE destination ( ifNotExists )? -> ^( TOK_DESTINATION destination ( ifNotExists )? ) | KW_INSERT KW_INTO ( KW_TABLE )? tableOrPartition -> ^( TOK_INSERT_INTO tableOrPartition ) )
      int alt276 = 2;
      switch (input.LA(1)) {
        case KW_INSERT: {
          switch (input.LA(2)) {
            case KW_OVERWRITE: {
              alt276 = 1;
            }
              break;
            case KW_INTO: {
              alt276 = 2;
            }
              break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 276, 1, input);

              throw nvae;
          }
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 276, 0, input);

          throw nvae;
      }

      switch (alt276) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2236:6: KW_INSERT KW_OVERWRITE destination ( ifNotExists )?
        {
          KW_INSERT884 = (Token) match(input, KW_INSERT, FOLLOW_KW_INSERT_in_insertClause14374);
          stream_KW_INSERT.add(KW_INSERT884);

          KW_OVERWRITE885 = (Token) match(input, KW_OVERWRITE, FOLLOW_KW_OVERWRITE_in_insertClause14376);
          stream_KW_OVERWRITE.add(KW_OVERWRITE885);

          pushFollow(FOLLOW_destination_in_insertClause14378);
          destination886 = destination();

          state._fsp--;

          stream_destination.add(destination886.getTree());

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2236:41: ( ifNotExists )?
          int alt274 = 2;
          switch (input.LA(1)) {
            case KW_IF: {
              alt274 = 1;
            }
              break;
          }

          switch (alt274) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2236:41: ifNotExists
            {
              pushFollow(FOLLOW_ifNotExists_in_insertClause14380);
              ifNotExists887 = ifNotExists();

              state._fsp--;

              stream_ifNotExists.add(ifNotExists887.getTree());
            }
              break;
          }

          // AST REWRITE
          // elements: destination, ifNotExists
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2236:54: -> ^( TOK_DESTINATION destination ( ifNotExists )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2236:57: ^( TOK_DESTINATION destination ( ifNotExists )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"),
                  root_1);

              adaptor.addChild(root_1, stream_destination.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2236:87: ( ifNotExists )?
              if (stream_ifNotExists.hasNext()) {
                adaptor.addChild(root_1, stream_ifNotExists.nextTree());
              }
              stream_ifNotExists.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2237:6: KW_INSERT KW_INTO ( KW_TABLE )? tableOrPartition
        {
          KW_INSERT888 = (Token) match(input, KW_INSERT, FOLLOW_KW_INSERT_in_insertClause14399);
          stream_KW_INSERT.add(KW_INSERT888);

          KW_INTO889 = (Token) match(input, KW_INTO, FOLLOW_KW_INTO_in_insertClause14401);
          stream_KW_INTO.add(KW_INTO889);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2237:24: ( KW_TABLE )?
          int alt275 = 2;
          switch (input.LA(1)) {
            case KW_TABLE: {
              switch (input.LA(2)) {
                case Identifier:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFAULT:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_METADATA:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NONE:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH: {
                  alt275 = 1;
                }
                  break;
                case KW_PARTITION: {
                  switch (input.LA(3)) {
                    case DOT:
                    case KW_MAP:
                    case KW_PARTITION:
                    case KW_REDUCE:
                    case KW_SELECT:
                    case KW_VALUES: {
                      alt275 = 1;
                    }
                      break;
                  }
                }
                  break;
                case KW_VALUES: {
                  switch (input.LA(3)) {
                    case DOT:
                    case KW_MAP:
                    case KW_PARTITION:
                    case KW_REDUCE:
                    case KW_SELECT:
                    case KW_VALUES: {
                      alt275 = 1;
                    }
                      break;
                  }
                }
                  break;
              }
            }
              break;
          }

          switch (alt275) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2237:24: KW_TABLE
            {
              KW_TABLE890 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_insertClause14403);
              stream_KW_TABLE.add(KW_TABLE890);
            }
              break;
          }

          pushFollow(FOLLOW_tableOrPartition_in_insertClause14406);
          tableOrPartition891 = tableOrPartition();

          state._fsp--;

          stream_tableOrPartition.add(tableOrPartition891.getTree());

          // AST REWRITE
          // elements: tableOrPartition
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2238:8: -> ^( TOK_INSERT_INTO tableOrPartition )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2238:11: ^( TOK_INSERT_INTO tableOrPartition )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_INSERT_INTO, "TOK_INSERT_INTO"),
                  root_1);

              adaptor.addChild(root_1, stream_tableOrPartition.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "insertClause"

  public static class destination_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "destination"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2241:1: destination : ( (local= KW_LOCAL )? KW_DIRECTORY StringLiteral ( tableRowFormat )? ( tableFileFormat )? -> ^( TOK_DIR StringLiteral ( $local)? ( tableRowFormat )? ( tableFileFormat )? ) | KW_TABLE tableOrPartition -> tableOrPartition );
  public final HiveParser.destination_return destination() throws RecognitionException {
    HiveParser.destination_return retval = new HiveParser.destination_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token local = null;
    Token KW_DIRECTORY892 = null;
    Token StringLiteral893 = null;
    Token KW_TABLE896 = null;
    HiveParser.tableRowFormat_return tableRowFormat894 = null;

    HiveParser.tableFileFormat_return tableFileFormat895 = null;

    HiveParser_IdentifiersParser.tableOrPartition_return tableOrPartition897 = null;

    CommonTree local_tree = null;
    CommonTree KW_DIRECTORY892_tree = null;
    CommonTree StringLiteral893_tree = null;
    CommonTree KW_TABLE896_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_DIRECTORY = new RewriteRuleTokenStream(adaptor, "token KW_DIRECTORY");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleTokenStream stream_KW_LOCAL = new RewriteRuleTokenStream(adaptor, "token KW_LOCAL");
    RewriteRuleSubtreeStream stream_tableRowFormat = new RewriteRuleSubtreeStream(adaptor, "rule tableRowFormat");
    RewriteRuleSubtreeStream stream_tableFileFormat = new RewriteRuleSubtreeStream(adaptor, "rule tableFileFormat");
    RewriteRuleSubtreeStream stream_tableOrPartition = new RewriteRuleSubtreeStream(adaptor, "rule tableOrPartition");
    pushMsg("destination specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2244:4: ( (local= KW_LOCAL )? KW_DIRECTORY StringLiteral ( tableRowFormat )? ( tableFileFormat )? -> ^( TOK_DIR StringLiteral ( $local)? ( tableRowFormat )? ( tableFileFormat )? ) | KW_TABLE tableOrPartition -> tableOrPartition )
      int alt280 = 2;
      switch (input.LA(1)) {
        case KW_DIRECTORY:
        case KW_LOCAL: {
          alt280 = 1;
        }
          break;
        case KW_TABLE: {
          alt280 = 2;
        }
          break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 280, 0, input);

          throw nvae;
      }

      switch (alt280) {
        case 1:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2245:6: (local= KW_LOCAL )? KW_DIRECTORY StringLiteral ( tableRowFormat )? ( tableFileFormat )?
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2245:6: (local= KW_LOCAL )?
          int alt277 = 2;
          switch (input.LA(1)) {
            case KW_LOCAL: {
              alt277 = 1;
            }
              break;
          }

          switch (alt277) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2245:7: local= KW_LOCAL
            {
              local = (Token) match(input, KW_LOCAL, FOLLOW_KW_LOCAL_in_destination14456);
              stream_KW_LOCAL.add(local);
            }
              break;
          }

          KW_DIRECTORY892 = (Token) match(input, KW_DIRECTORY, FOLLOW_KW_DIRECTORY_in_destination14460);
          stream_KW_DIRECTORY.add(KW_DIRECTORY892);

          StringLiteral893 = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_destination14462);
          stream_StringLiteral.add(StringLiteral893);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2245:53: ( tableRowFormat )?
          int alt278 = 2;
          switch (input.LA(1)) {
            case KW_ROW: {
              alt278 = 1;
            }
              break;
          }

          switch (alt278) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2245:53: tableRowFormat
            {
              pushFollow(FOLLOW_tableRowFormat_in_destination14464);
              tableRowFormat894 = tableRowFormat();

              state._fsp--;

              stream_tableRowFormat.add(tableRowFormat894.getTree());
            }
              break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2245:69: ( tableFileFormat )?
          int alt279 = 2;
          switch (input.LA(1)) {
            case KW_STORED: {
              alt279 = 1;
            }
              break;
          }

          switch (alt279) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2245:69: tableFileFormat
            {
              pushFollow(FOLLOW_tableFileFormat_in_destination14467);
              tableFileFormat895 = tableFileFormat();

              state._fsp--;

              stream_tableFileFormat.add(tableFileFormat895.getTree());
            }
              break;
          }

          // AST REWRITE
          // elements: tableFileFormat, local, tableRowFormat, StringLiteral
          // token labels: local
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleTokenStream stream_local = new RewriteRuleTokenStream(adaptor, "token local", local);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2246:8: -> ^( TOK_DIR StringLiteral ( $local)? ( tableRowFormat )? ( tableFileFormat )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2246:11: ^( TOK_DIR StringLiteral ( $local)? ( tableRowFormat )? ( tableFileFormat )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DIR, "TOK_DIR"), root_1);

              adaptor.addChild(root_1, stream_StringLiteral.nextNode());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2246:36: ( $local)?
              if (stream_local.hasNext()) {
                adaptor.addChild(root_1, stream_local.nextNode());
              }
              stream_local.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2246:43: ( tableRowFormat )?
              if (stream_tableRowFormat.hasNext()) {
                adaptor.addChild(root_1, stream_tableRowFormat.nextTree());
              }
              stream_tableRowFormat.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2246:59: ( tableFileFormat )?
              if (stream_tableFileFormat.hasNext()) {
                adaptor.addChild(root_1, stream_tableFileFormat.nextTree());
              }
              stream_tableFileFormat.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
          break;
        case 2:
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2247:6: KW_TABLE tableOrPartition
        {
          KW_TABLE896 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_destination14500);
          stream_KW_TABLE.add(KW_TABLE896);

          pushFollow(FOLLOW_tableOrPartition_in_destination14502);
          tableOrPartition897 = tableOrPartition();

          state._fsp--;

          stream_tableOrPartition.add(tableOrPartition897.getTree());

          // AST REWRITE
          // elements: tableOrPartition
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2247:32: -> tableOrPartition
          {
            adaptor.addChild(root_0, stream_tableOrPartition.nextTree());
          }

          retval.tree = root_0;
        }
          break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "destination"

  public static class limitClause_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "limitClause"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2250:1: limitClause : KW_LIMIT num= Number -> ^( TOK_LIMIT $num) ;
  public final HiveParser.limitClause_return limitClause() throws RecognitionException {
    HiveParser.limitClause_return retval = new HiveParser.limitClause_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token num = null;
    Token KW_LIMIT898 = null;

    CommonTree num_tree = null;
    CommonTree KW_LIMIT898_tree = null;
    RewriteRuleTokenStream stream_Number = new RewriteRuleTokenStream(adaptor, "token Number");
    RewriteRuleTokenStream stream_KW_LIMIT = new RewriteRuleTokenStream(adaptor, "token KW_LIMIT");

    pushMsg("limit clause", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2253:4: ( KW_LIMIT num= Number -> ^( TOK_LIMIT $num) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2254:4: KW_LIMIT num= Number
      {
        KW_LIMIT898 = (Token) match(input, KW_LIMIT, FOLLOW_KW_LIMIT_in_limitClause14534);
        stream_KW_LIMIT.add(KW_LIMIT898);

        num = (Token) match(input, Number, FOLLOW_Number_in_limitClause14538);
        stream_Number.add(num);

        // AST REWRITE
        // elements: num
        // token labels: num
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_num = new RewriteRuleTokenStream(adaptor, "token num", num);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2254:24: -> ^( TOK_LIMIT $num)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2254:27: ^( TOK_LIMIT $num)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_LIMIT, "TOK_LIMIT"), root_1);

            adaptor.addChild(root_1, stream_num.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "limitClause"

  public static class deleteStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "deleteStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2258:1: deleteStatement : KW_DELETE KW_FROM tableName ( whereClause )? -> ^( TOK_DELETE_FROM tableName ( whereClause )? ) ;
  public final HiveParser.deleteStatement_return deleteStatement() throws RecognitionException {
    HiveParser.deleteStatement_return retval = new HiveParser.deleteStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_DELETE899 = null;
    Token KW_FROM900 = null;
    HiveParser_FromClauseParser.tableName_return tableName901 = null;

    HiveParser_FromClauseParser.whereClause_return whereClause902 = null;

    CommonTree KW_DELETE899_tree = null;
    CommonTree KW_FROM900_tree = null;
    RewriteRuleTokenStream stream_KW_DELETE = new RewriteRuleTokenStream(adaptor, "token KW_DELETE");
    RewriteRuleTokenStream stream_KW_FROM = new RewriteRuleTokenStream(adaptor, "token KW_FROM");
    RewriteRuleSubtreeStream stream_whereClause = new RewriteRuleSubtreeStream(adaptor, "rule whereClause");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    pushMsg("delete statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2261:4: ( KW_DELETE KW_FROM tableName ( whereClause )? -> ^( TOK_DELETE_FROM tableName ( whereClause )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2262:4: KW_DELETE KW_FROM tableName ( whereClause )?
      {
        KW_DELETE899 = (Token) match(input, KW_DELETE, FOLLOW_KW_DELETE_in_deleteStatement14576);
        stream_KW_DELETE.add(KW_DELETE899);

        KW_FROM900 = (Token) match(input, KW_FROM, FOLLOW_KW_FROM_in_deleteStatement14578);
        stream_KW_FROM.add(KW_FROM900);

        pushFollow(FOLLOW_tableName_in_deleteStatement14580);
        tableName901 = tableName();

        state._fsp--;

        stream_tableName.add(tableName901.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2262:32: ( whereClause )?
        int alt281 = 2;
        switch (input.LA(1)) {
          case KW_WHERE: {
            alt281 = 1;
          }
            break;
        }

        switch (alt281) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2262:33: whereClause
          {
            pushFollow(FOLLOW_whereClause_in_deleteStatement14583);
            whereClause902 = whereClause();

            state._fsp--;

            stream_whereClause.add(whereClause902.getTree());
          }
            break;
        }

        // AST REWRITE
        // elements: whereClause, tableName
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2262:47: -> ^( TOK_DELETE_FROM tableName ( whereClause )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2262:50: ^( TOK_DELETE_FROM tableName ( whereClause )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DELETE_FROM, "TOK_DELETE_FROM"),
                root_1);

            adaptor.addChild(root_1, stream_tableName.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2262:78: ( whereClause )?
            if (stream_whereClause.hasNext()) {
              adaptor.addChild(root_1, stream_whereClause.nextTree());
            }
            stream_whereClause.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "deleteStatement"

  public static class columnAssignmentClause_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "columnAssignmentClause"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2266:1: columnAssignmentClause : tableOrColumn EQUAL ^ precedencePlusExpression ;
  public final HiveParser.columnAssignmentClause_return columnAssignmentClause() throws RecognitionException {
    HiveParser.columnAssignmentClause_return retval = new HiveParser.columnAssignmentClause_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token EQUAL904 = null;
    HiveParser_FromClauseParser.tableOrColumn_return tableOrColumn903 = null;

    HiveParser_IdentifiersParser.precedencePlusExpression_return precedencePlusExpression905 = null;

    CommonTree EQUAL904_tree = null;

    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2267:4: ( tableOrColumn EQUAL ^ precedencePlusExpression )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2268:4: tableOrColumn EQUAL ^ precedencePlusExpression
      {
        root_0 = (CommonTree) adaptor.nil();

        pushFollow(FOLLOW_tableOrColumn_in_columnAssignmentClause14616);
        tableOrColumn903 = tableOrColumn();

        state._fsp--;

        adaptor.addChild(root_0, tableOrColumn903.getTree());

        EQUAL904 = (Token) match(input, EQUAL, FOLLOW_EQUAL_in_columnAssignmentClause14618);
        EQUAL904_tree = (CommonTree) adaptor.create(EQUAL904);
        root_0 = (CommonTree) adaptor.becomeRoot(EQUAL904_tree, root_0);

        pushFollow(FOLLOW_precedencePlusExpression_in_columnAssignmentClause14621);
        precedencePlusExpression905 = precedencePlusExpression();

        state._fsp--;

        adaptor.addChild(root_0, precedencePlusExpression905.getTree());
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "columnAssignmentClause"

  public static class setColumnsClause_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "setColumnsClause"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2272:1: setColumnsClause : KW_SET columnAssignmentClause ( COMMA columnAssignmentClause )* -> ^( TOK_SET_COLUMNS_CLAUSE ( columnAssignmentClause )* ) ;
  public final HiveParser.setColumnsClause_return setColumnsClause() throws RecognitionException {
    HiveParser.setColumnsClause_return retval = new HiveParser.setColumnsClause_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_SET906 = null;
    Token COMMA908 = null;
    HiveParser.columnAssignmentClause_return columnAssignmentClause907 = null;

    HiveParser.columnAssignmentClause_return columnAssignmentClause909 = null;

    CommonTree KW_SET906_tree = null;
    CommonTree COMMA908_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleTokenStream stream_KW_SET = new RewriteRuleTokenStream(adaptor, "token KW_SET");
    RewriteRuleSubtreeStream stream_columnAssignmentClause =
        new RewriteRuleSubtreeStream(adaptor, "rule columnAssignmentClause");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2273:4: ( KW_SET columnAssignmentClause ( COMMA columnAssignmentClause )* -> ^( TOK_SET_COLUMNS_CLAUSE ( columnAssignmentClause )* ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2274:4: KW_SET columnAssignmentClause ( COMMA columnAssignmentClause )*
      {
        KW_SET906 = (Token) match(input, KW_SET, FOLLOW_KW_SET_in_setColumnsClause14641);
        stream_KW_SET.add(KW_SET906);

        pushFollow(FOLLOW_columnAssignmentClause_in_setColumnsClause14643);
        columnAssignmentClause907 = columnAssignmentClause();

        state._fsp--;

        stream_columnAssignmentClause.add(columnAssignmentClause907.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2274:34: ( COMMA columnAssignmentClause )*
        loop282: do {
          int alt282 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt282 = 1;
            }
              break;
          }

          switch (alt282) {
            case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2274:35: COMMA columnAssignmentClause
            {
              COMMA908 = (Token) match(input, COMMA, FOLLOW_COMMA_in_setColumnsClause14646);
              stream_COMMA.add(COMMA908);

              pushFollow(FOLLOW_columnAssignmentClause_in_setColumnsClause14648);
              columnAssignmentClause909 = columnAssignmentClause();

              state._fsp--;

              stream_columnAssignmentClause.add(columnAssignmentClause909.getTree());
            }
              break;

            default:
              break loop282;
          }
        } while (true);

        // AST REWRITE
        // elements: columnAssignmentClause
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2274:66: -> ^( TOK_SET_COLUMNS_CLAUSE ( columnAssignmentClause )* )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2274:69: ^( TOK_SET_COLUMNS_CLAUSE ( columnAssignmentClause )* )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor
                .becomeRoot((CommonTree) adaptor.create(TOK_SET_COLUMNS_CLAUSE, "TOK_SET_COLUMNS_CLAUSE"), root_1);

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2274:94: ( columnAssignmentClause )*
            while (stream_columnAssignmentClause.hasNext()) {
              adaptor.addChild(root_1, stream_columnAssignmentClause.nextTree());
            }
            stream_columnAssignmentClause.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "setColumnsClause"

  public static class updateStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "updateStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2281:1: updateStatement : KW_UPDATE tableName setColumnsClause ( whereClause )? -> ^( TOK_UPDATE_TABLE tableName setColumnsClause ( whereClause )? ) ;
  public final HiveParser.updateStatement_return updateStatement() throws RecognitionException {
    HiveParser.updateStatement_return retval = new HiveParser.updateStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_UPDATE910 = null;
    HiveParser_FromClauseParser.tableName_return tableName911 = null;

    HiveParser.setColumnsClause_return setColumnsClause912 = null;

    HiveParser_FromClauseParser.whereClause_return whereClause913 = null;

    CommonTree KW_UPDATE910_tree = null;
    RewriteRuleTokenStream stream_KW_UPDATE = new RewriteRuleTokenStream(adaptor, "token KW_UPDATE");
    RewriteRuleSubtreeStream stream_setColumnsClause = new RewriteRuleSubtreeStream(adaptor, "rule setColumnsClause");
    RewriteRuleSubtreeStream stream_whereClause = new RewriteRuleSubtreeStream(adaptor, "rule whereClause");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    pushMsg("update statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2284:4: ( KW_UPDATE tableName setColumnsClause ( whereClause )? -> ^( TOK_UPDATE_TABLE tableName setColumnsClause ( whereClause )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2285:4: KW_UPDATE tableName setColumnsClause ( whereClause )?
      {
        KW_UPDATE910 = (Token) match(input, KW_UPDATE, FOLLOW_KW_UPDATE_in_updateStatement14690);
        stream_KW_UPDATE.add(KW_UPDATE910);

        pushFollow(FOLLOW_tableName_in_updateStatement14692);
        tableName911 = tableName();

        state._fsp--;

        stream_tableName.add(tableName911.getTree());

        pushFollow(FOLLOW_setColumnsClause_in_updateStatement14694);
        setColumnsClause912 = setColumnsClause();

        state._fsp--;

        stream_setColumnsClause.add(setColumnsClause912.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2285:41: ( whereClause )?
        int alt283 = 2;
        switch (input.LA(1)) {
          case KW_WHERE: {
            alt283 = 1;
          }
            break;
        }

        switch (alt283) {
          case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2285:41: whereClause
          {
            pushFollow(FOLLOW_whereClause_in_updateStatement14696);
            whereClause913 = whereClause();

            state._fsp--;

            stream_whereClause.add(whereClause913.getTree());
          }
            break;
        }

        // AST REWRITE
        // elements: tableName, whereClause, setColumnsClause
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2285:54: -> ^( TOK_UPDATE_TABLE tableName setColumnsClause ( whereClause )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2285:57: ^( TOK_UPDATE_TABLE tableName setColumnsClause ( whereClause )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_UPDATE_TABLE, "TOK_UPDATE_TABLE"),
                root_1);

            adaptor.addChild(root_1, stream_tableName.nextTree());

            adaptor.addChild(root_1, stream_setColumnsClause.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2285:103: ( whereClause )?
            if (stream_whereClause.hasNext()) {
              adaptor.addChild(root_1, stream_whereClause.nextTree());
            }
            stream_whereClause.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "updateStatement"

  // Delegated rules
  public HiveParser_IdentifiersParser.precedenceEqualExpression_return precedenceEqualExpression()
      throws RecognitionException {
    return gIdentifiersParser.precedenceEqualExpression();
  }

  public HiveParser_IdentifiersParser.sortByClause_return sortByClause() throws RecognitionException {
    return gIdentifiersParser.sortByClause();
  }

  public HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression_return precedenceUnaryPrefixExpression()
      throws RecognitionException {
    return gIdentifiersParser.precedenceUnaryPrefixExpression();
  }

  public HiveParser_IdentifiersParser.precedenceAndOperator_return precedenceAndOperator() throws RecognitionException {
    return gIdentifiersParser.precedenceAndOperator();
  }

  public HiveParser_FromClauseParser.subQuerySource_return subQuerySource() throws RecognitionException {
    return gFromClauseParser.subQuerySource();
  }

  public HiveParser_IdentifiersParser.descFuncNames_return descFuncNames() throws RecognitionException {
    return gIdentifiersParser.descFuncNames();
  }

  public HiveParser_IdentifiersParser.sysFuncNames_return sysFuncNames() throws RecognitionException {
    return gIdentifiersParser.sysFuncNames();
  }

  public HiveParser_FromClauseParser.tableBucketSample_return tableBucketSample() throws RecognitionException {
    return gFromClauseParser.tableBucketSample();
  }

  public HiveParser_IdentifiersParser.dropPartitionVal_return dropPartitionVal() throws RecognitionException {
    return gIdentifiersParser.dropPartitionVal();
  }

  public HiveParser_FromClauseParser.valuesTableConstructor_return valuesTableConstructor()
      throws RecognitionException {
    return gFromClauseParser.valuesTableConstructor();
  }

  public HiveParser_FromClauseParser.fromClause_return fromClause() throws RecognitionException {
    return gFromClauseParser.fromClause();
  }

  public HiveParser_IdentifiersParser.booleanValue_return booleanValue() throws RecognitionException {
    return gIdentifiersParser.booleanValue();
  }

  public HiveParser_SelectClauseParser.hintList_return hintList() throws RecognitionException {
    return gSelectClauseParser.hintList();
  }

  public HiveParser_IdentifiersParser.dropPartitionOperator_return dropPartitionOperator() throws RecognitionException {
    return gIdentifiersParser.dropPartitionOperator();
  }

  public HiveParser_FromClauseParser.tableAlias_return tableAlias() throws RecognitionException {
    return gFromClauseParser.tableAlias();
  }

  public HiveParser_FromClauseParser.tableSource_return tableSource() throws RecognitionException {
    return gFromClauseParser.tableSource();
  }

  public HiveParser_IdentifiersParser.precedenceAmpersandOperator_return precedenceAmpersandOperator()
      throws RecognitionException {
    return gIdentifiersParser.precedenceAmpersandOperator();
  }

  public HiveParser_FromClauseParser.partitionedTableFunction_return partitionedTableFunction()
      throws RecognitionException {
    return gFromClauseParser.partitionedTableFunction();
  }

  public HiveParser_FromClauseParser.virtualTableSource_return virtualTableSource() throws RecognitionException {
    return gFromClauseParser.virtualTableSource();
  }

  public HiveParser_IdentifiersParser.precedenceAndExpression_return precedenceAndExpression()
      throws RecognitionException {
    return gIdentifiersParser.precedenceAndExpression();
  }

  public HiveParser_SelectClauseParser.window_value_expression_return window_value_expression()
      throws RecognitionException {
    return gSelectClauseParser.window_value_expression();
  }

  public HiveParser_IdentifiersParser.charSetStringLiteral_return charSetStringLiteral() throws RecognitionException {
    return gIdentifiersParser.charSetStringLiteral();
  }

  public HiveParser_IdentifiersParser.functionIdentifier_return functionIdentifier() throws RecognitionException {
    return gIdentifiersParser.functionIdentifier();
  }

  public HiveParser_IdentifiersParser.precedenceBitwiseOrExpression_return precedenceBitwiseOrExpression()
      throws RecognitionException {
    return gIdentifiersParser.precedenceBitwiseOrExpression();
  }

  public HiveParser_SelectClauseParser.window_range_expression_return window_range_expression()
      throws RecognitionException {
    return gSelectClauseParser.window_range_expression();
  }

  public HiveParser_IdentifiersParser.partitionVal_return partitionVal() throws RecognitionException {
    return gIdentifiersParser.partitionVal();
  }

  public HiveParser_SelectClauseParser.trfmClause_return trfmClause() throws RecognitionException {
    return gSelectClauseParser.trfmClause();
  }

  public HiveParser_IdentifiersParser.stringLiteralSequence_return stringLiteralSequence() throws RecognitionException {
    return gIdentifiersParser.stringLiteralSequence();
  }

  public HiveParser_FromClauseParser.viewName_return viewName() throws RecognitionException {
    return gFromClauseParser.viewName();
  }

  public HiveParser_FromClauseParser.lateralView_return lateralView() throws RecognitionException {
    return gFromClauseParser.lateralView();
  }

  public HiveParser_SelectClauseParser.selectClause_return selectClause() throws RecognitionException {
    return gSelectClauseParser.selectClause();
  }

  public HiveParser_IdentifiersParser.timestampLiteral_return timestampLiteral() throws RecognitionException {
    return gIdentifiersParser.timestampLiteral();
  }

  public HiveParser_IdentifiersParser.groupByClause_return groupByClause() throws RecognitionException {
    return gIdentifiersParser.groupByClause();
  }

  public HiveParser_IdentifiersParser.identifier_return identifier() throws RecognitionException {
    return gIdentifiersParser.identifier();
  }

  public HiveParser_IdentifiersParser.precedenceStarOperator_return precedenceStarOperator()
      throws RecognitionException {
    return gIdentifiersParser.precedenceStarOperator();
  }

  public HiveParser_IdentifiersParser.dropPartitionSpec_return dropPartitionSpec() throws RecognitionException {
    return gIdentifiersParser.dropPartitionSpec();
  }

  public HiveParser_FromClauseParser.tableSample_return tableSample() throws RecognitionException {
    return gFromClauseParser.tableSample();
  }

  public HiveParser_SelectClauseParser.window_specification_return window_specification() throws RecognitionException {
    return gSelectClauseParser.window_specification();
  }

  public HiveParser_IdentifiersParser.precedencePlusExpression_return precedencePlusExpression()
      throws RecognitionException {
    return gIdentifiersParser.precedencePlusExpression();
  }

  public HiveParser_SelectClauseParser.window_frame_return window_frame() throws RecognitionException {
    return gSelectClauseParser.window_frame();
  }

  public HiveParser_IdentifiersParser.precedenceFieldExpression_return precedenceFieldExpression()
      throws RecognitionException {
    return gIdentifiersParser.precedenceFieldExpression();
  }

  public HiveParser_IdentifiersParser.nonParenthesizedFunctionName_return nonParenthesizedFunctionName()
      throws RecognitionException {
    return gIdentifiersParser.nonParenthesizedFunctionName();
  }

  public HiveParser_FromClauseParser.tableAllColumns_return tableAllColumns() throws RecognitionException {
    return gFromClauseParser.tableAllColumns();
  }

  public HiveParser_SelectClauseParser.hintArgName_return hintArgName() throws RecognitionException {
    return gSelectClauseParser.hintArgName();
  }

  public HiveParser_IdentifiersParser.groupByExpression_return groupByExpression() throws RecognitionException {
    return gIdentifiersParser.groupByExpression();
  }

  public HiveParser_IdentifiersParser.precedenceEqualOperator_return precedenceEqualOperator()
      throws RecognitionException {
    return gIdentifiersParser.precedenceEqualOperator();
  }

  public HiveParser_FromClauseParser.tableName_return tableName() throws RecognitionException {
    return gFromClauseParser.tableName();
  }

  public HiveParser_IdentifiersParser.principalIdentifier_return principalIdentifier() throws RecognitionException {
    return gIdentifiersParser.principalIdentifier();
  }

  public HiveParser_IdentifiersParser.partitionSpec_return partitionSpec() throws RecognitionException {
    return gIdentifiersParser.partitionSpec();
  }

  public HiveParser_SelectClauseParser.selectTrfmClause_return selectTrfmClause() throws RecognitionException {
    return gSelectClauseParser.selectTrfmClause();
  }

  public HiveParser_IdentifiersParser.partitionByClause_return partitionByClause() throws RecognitionException {
    return gIdentifiersParser.partitionByClause();
  }

  public HiveParser_IdentifiersParser.function_return function() throws RecognitionException {
    return gIdentifiersParser.function();
  }

  public HiveParser_IdentifiersParser.havingCondition_return havingCondition() throws RecognitionException {
    return gIdentifiersParser.havingCondition();
  }

  public HiveParser_IdentifiersParser.constant_return constant() throws RecognitionException {
    return gIdentifiersParser.constant();
  }

  public HiveParser_IdentifiersParser.precedenceOrOperator_return precedenceOrOperator() throws RecognitionException {
    return gIdentifiersParser.precedenceOrOperator();
  }

  public HiveParser_IdentifiersParser.dateLiteral_return dateLiteral() throws RecognitionException {
    return gIdentifiersParser.dateLiteral();
  }

  public HiveParser_IdentifiersParser.subQueryExpression_return subQueryExpression() throws RecognitionException {
    return gIdentifiersParser.subQueryExpression();
  }

  public HiveParser_IdentifiersParser.castExpression_return castExpression() throws RecognitionException {
    return gIdentifiersParser.castExpression();
  }

  public HiveParser_SelectClauseParser.hintArgs_return hintArgs() throws RecognitionException {
    return gSelectClauseParser.hintArgs();
  }

  public HiveParser_FromClauseParser.uniqueJoinToken_return uniqueJoinToken() throws RecognitionException {
    return gFromClauseParser.uniqueJoinToken();
  }

  public HiveParser_FromClauseParser.uniqueJoinSource_return uniqueJoinSource() throws RecognitionException {
    return gFromClauseParser.uniqueJoinSource();
  }

  public HiveParser_SelectClauseParser.hintName_return hintName() throws RecognitionException {
    return gSelectClauseParser.hintName();
  }

  public HiveParser_IdentifiersParser.clusterByClause_return clusterByClause() throws RecognitionException {
    return gIdentifiersParser.clusterByClause();
  }

  public HiveParser_IdentifiersParser.groupingSetExpression_return groupingSetExpression() throws RecognitionException {
    return gIdentifiersParser.groupingSetExpression();
  }

  public HiveParser_IdentifiersParser.functionName_return functionName() throws RecognitionException {
    return gIdentifiersParser.functionName();
  }

  public HiveParser_IdentifiersParser.precedenceBitwiseXorOperator_return precedenceBitwiseXorOperator()
      throws RecognitionException {
    return gIdentifiersParser.precedenceBitwiseXorOperator();
  }

  public HiveParser_SelectClauseParser.window_frame_boundary_return window_frame_boundary()
      throws RecognitionException {
    return gSelectClauseParser.window_frame_boundary();
  }

  public HiveParser_IdentifiersParser.distributeByClause_return distributeByClause() throws RecognitionException {
    return gIdentifiersParser.distributeByClause();
  }

  public HiveParser_IdentifiersParser.whenExpression_return whenExpression() throws RecognitionException {
    return gIdentifiersParser.whenExpression();
  }

  public HiveParser_IdentifiersParser.precedencePlusOperator_return precedencePlusOperator()
      throws RecognitionException {
    return gIdentifiersParser.precedencePlusOperator();
  }

  public HiveParser_FromClauseParser.valuesClause_return valuesClause() throws RecognitionException {
    return gFromClauseParser.valuesClause();
  }

  public HiveParser_IdentifiersParser.precedenceUnaryOperator_return precedenceUnaryOperator()
      throws RecognitionException {
    return gIdentifiersParser.precedenceUnaryOperator();
  }

  public HiveParser_IdentifiersParser.precedenceEqualNegatableOperator_return precedenceEqualNegatableOperator()
      throws RecognitionException {
    return gIdentifiersParser.precedenceEqualNegatableOperator();
  }

  public HiveParser_SelectClauseParser.window_defn_return window_defn() throws RecognitionException {
    return gSelectClauseParser.window_defn();
  }

  public HiveParser_SelectClauseParser.selectList_return selectList() throws RecognitionException {
    return gSelectClauseParser.selectList();
  }

  public HiveParser_FromClauseParser.partitionTableFunctionSource_return partitionTableFunctionSource()
      throws RecognitionException {
    return gFromClauseParser.partitionTableFunctionSource();
  }

  public HiveParser_IdentifiersParser.precedenceBitwiseXorExpression_return precedenceBitwiseXorExpression()
      throws RecognitionException {
    return gIdentifiersParser.precedenceBitwiseXorExpression();
  }

  public HiveParser_SelectClauseParser.selectItem_return selectItem() throws RecognitionException {
    return gSelectClauseParser.selectItem();
  }

  public HiveParser_IdentifiersParser.precedenceNotExpression_return precedenceNotExpression()
      throws RecognitionException {
    return gIdentifiersParser.precedenceNotExpression();
  }

  public HiveParser_IdentifiersParser.expression_return expression() throws RecognitionException {
    return gIdentifiersParser.expression();
  }

  public HiveParser_IdentifiersParser.precedenceBitwiseOrOperator_return precedenceBitwiseOrOperator()
      throws RecognitionException {
    return gIdentifiersParser.precedenceBitwiseOrOperator();
  }

  public HiveParser_IdentifiersParser.nonReserved_return nonReserved() throws RecognitionException {
    return gIdentifiersParser.nonReserved();
  }

  public HiveParser_FromClauseParser.aliasList_return aliasList() throws RecognitionException {
    return gFromClauseParser.aliasList();
  }

  public HiveParser_IdentifiersParser.nonParenthesizedFunction_return nonParenthesizedFunction()
      throws RecognitionException {
    return gIdentifiersParser.nonParenthesizedFunction();
  }

  public HiveParser_IdentifiersParser.precedenceAmpersandExpression_return precedenceAmpersandExpression()
      throws RecognitionException {
    return gIdentifiersParser.precedenceAmpersandExpression();
  }

  public HiveParser_FromClauseParser.whereClause_return whereClause() throws RecognitionException {
    return gFromClauseParser.whereClause();
  }

  public HiveParser_FromClauseParser.tableOrColumn_return tableOrColumn() throws RecognitionException {
    return gFromClauseParser.tableOrColumn();
  }

  public HiveParser_IdentifiersParser.atomExpression_return atomExpression() throws RecognitionException {
    return gIdentifiersParser.atomExpression();
  }

  public HiveParser_FromClauseParser.expressionList_return expressionList() throws RecognitionException {
    return gFromClauseParser.expressionList();
  }

  public HiveParser_FromClauseParser.uniqueJoinExpr_return uniqueJoinExpr() throws RecognitionException {
    return gFromClauseParser.uniqueJoinExpr();
  }

  public HiveParser_SelectClauseParser.window_clause_return window_clause() throws RecognitionException {
    return gSelectClauseParser.window_clause();
  }

  public HiveParser_SelectClauseParser.hintClause_return hintClause() throws RecognitionException {
    return gSelectClauseParser.hintClause();
  }

  public HiveParser_IdentifiersParser.precedenceOrExpression_return precedenceOrExpression()
      throws RecognitionException {
    return gIdentifiersParser.precedenceOrExpression();
  }

  public HiveParser_FromClauseParser.joinSource_return joinSource() throws RecognitionException {
    return gFromClauseParser.joinSource();
  }

  public HiveParser_SelectClauseParser.hintItem_return hintItem() throws RecognitionException {
    return gSelectClauseParser.hintItem();
  }

  public HiveParser_SelectClauseParser.selectExpressionList_return selectExpressionList() throws RecognitionException {
    return gSelectClauseParser.selectExpressionList();
  }

  public HiveParser_IdentifiersParser.caseExpression_return caseExpression() throws RecognitionException {
    return gIdentifiersParser.caseExpression();
  }

  public HiveParser_SelectClauseParser.window_frame_start_boundary_return window_frame_start_boundary()
      throws RecognitionException {
    return gSelectClauseParser.window_frame_start_boundary();
  }

  public HiveParser_IdentifiersParser.precedenceNotOperator_return precedenceNotOperator() throws RecognitionException {
    return gIdentifiersParser.precedenceNotOperator();
  }

  public HiveParser_FromClauseParser.joinToken_return joinToken() throws RecognitionException {
    return gFromClauseParser.joinToken();
  }

  public HiveParser_FromClauseParser.searchCondition_return searchCondition() throws RecognitionException {
    return gFromClauseParser.searchCondition();
  }

  public HiveParser_FromClauseParser.valueRowConstructor_return valueRowConstructor() throws RecognitionException {
    return gFromClauseParser.valueRowConstructor();
  }

  public HiveParser_IdentifiersParser.precedenceStarExpression_return precedenceStarExpression()
      throws RecognitionException {
    return gIdentifiersParser.precedenceStarExpression();
  }

  public HiveParser_FromClauseParser.partitioningSpec_return partitioningSpec() throws RecognitionException {
    return gFromClauseParser.partitioningSpec();
  }

  public HiveParser_IdentifiersParser.havingClause_return havingClause() throws RecognitionException {
    return gIdentifiersParser.havingClause();
  }

  public HiveParser_FromClauseParser.fromSource_return fromSource() throws RecognitionException {
    return gFromClauseParser.fromSource();
  }

  public HiveParser_IdentifiersParser.orderByClause_return orderByClause() throws RecognitionException {
    return gIdentifiersParser.orderByClause();
  }

  public HiveParser_IdentifiersParser.precedenceUnarySuffixExpression_return precedenceUnarySuffixExpression()
      throws RecognitionException {
    return gIdentifiersParser.precedenceUnarySuffixExpression();
  }

  public HiveParser_SelectClauseParser.selectExpression_return selectExpression() throws RecognitionException {
    return gSelectClauseParser.selectExpression();
  }

  public HiveParser_IdentifiersParser.expressions_return expressions() throws RecognitionException {
    return gIdentifiersParser.expressions();
  }

  public HiveParser_IdentifiersParser.nullCondition_return nullCondition() throws RecognitionException {
    return gIdentifiersParser.nullCondition();
  }

  public HiveParser_IdentifiersParser.tableOrPartition_return tableOrPartition() throws RecognitionException {
    return gIdentifiersParser.tableOrPartition();
  }

  public HiveParser_FromClauseParser.splitSample_return splitSample() throws RecognitionException {
    return gFromClauseParser.splitSample();
  }

  public HiveParser_FromClauseParser.tableNameColList_return tableNameColList() throws RecognitionException {
    return gFromClauseParser.tableNameColList();
  }

  protected DFA12 dfa12 = new DFA12(this);
  protected DFA204 dfa204 = new DFA204(this);
  static final String DFA12_eotS = "\u00b5\uffff";
  static final String DFA12_eofS = "\u00b5\uffff";
  static final String DFA12_minS = "\1\37\1\112\1\uffff\1\112\4\uffff\1\72\3\uffff\2\112\2\32\1\uffff"
      + "\1\152\14\uffff\1\170\37\uffff\7\12\1\uffff\3\12\3\uffff\10\12\1" + "\uffff\3\12\135\uffff";
  static final String DFA12_maxS = "\1\u0111\1\u0119\1\uffff\1\u0119\4\uffff\1\u0101\3\uffff\2\u00f6"
      + "\2\u011e\1\uffff\1\u00f6\14\uffff\1\u00a1\37\uffff\7\u0122\1\uffff"
      + "\3\u0122\3\uffff\1\u00b1\7\u0122\1\uffff\3\u0122\135\uffff";
  static final String DFA12_acceptS = "\2\uffff\1\2\1\uffff\1\6\1\7\1\10\2\uffff\1\12\1\22\1\24\4\uffff"
      + "\1\43\1\uffff\1\17\1\31\1\1\1\uffff\1\4\1\uffff\1\13\1\uffff\1\15"
      + "\1\5\1\14\1\20\1\uffff\1\32\1\3\1\uffff\1\21\1\11\12\uffff\1\35"
      + "\1\36\1\37\1\40\1\44\5\uffff\1\25\1\27\1\uffff\1\26\1\30\10\uffff"
      + "\1\33\3\uffff\1\41\12\uffff\1\34\3\uffff\1\42\3\uffff\1\16\3\uffff"
      + "\1\23\2\uffff\1\33\1\uffff\1\33\1\uffff\1\33\1\uffff\1\33\1\uffff"
      + "\1\33\1\uffff\1\33\1\uffff\1\33\1\uffff\1\33\1\uffff\1\33\1\uffff"
      + "\1\33\1\uffff\1\33\1\uffff\1\33\1\uffff\1\33\1\uffff\1\33\1\uffff"
      + "\1\33\1\uffff\1\33\1\uffff\1\33\1\uffff\1\33\1\uffff\1\33\1\uffff"
      + "\1\33\4\uffff\1\34\1\uffff\1\34\1\uffff\1\34\1\uffff\1\34\1\uffff"
      + "\1\34\1\uffff\1\34\1\uffff\1\34\1\uffff\1\34\1\uffff\1\34\1\uffff"
      + "\1\34\1\uffff\1\34\1\uffff\1\34\1\uffff\1\34\1\uffff\1\34\1\uffff"
      + "\1\34\1\uffff\1\34\1\uffff\1\34\1\uffff\1\34\1\uffff\1\34\1\uffff" + "\1\34";
  static final String DFA12_specialS = "\u00b5\uffff}>";
  static final String[] DFA12_transitionS = { "\1\5\1\13\41\uffff\1\1\23\uffff\2\6\6\uffff\1\3\33\uffff\1\16"
      + "\42\uffff\1\14\12\uffff\1\11\50\uffff\1\12\5\uffff\1\17\17\uffff"
      + "\1\20\2\uffff\1\10\32\uffff\1\4\6\uffff\1\15\4\uffff\1\2", "\1\24\37\uffff\1\26\15\uffff\1\32\13\uffff\1\22\55\uffff\1"
          + "\30\50\uffff\1\23\4\uffff\1\24\25\uffff\1\26\3\uffff\1\21\36"
          + "\uffff\1\30", "", "\1\40\55\uffff\1\42\13\uffff\1\35\126\uffff\1\37\4\uffff\1"
              + "\40\25\uffff\1\33\3\uffff\1\36\36\uffff\1\34", "", "", "", "", "\1\43\2\uffff\1\43\2\uffff\1\43\1\uffff\1\43\2\uffff\1\62\5"
                  + "\uffff\1\43\51\uffff\1\43\3\uffff\1\43\1\56\11\uffff\2\43\30"
                  + "\uffff\1\43\37\uffff\1\43\5\uffff\1\60\26\uffff\1\57\1\61\4"
                  + "\uffff\1\43\24\uffff\2\43\1\uffff\1\43\7\uffff\1\43", "", "", "", "\1\71\u0095\uffff\1\71\25\uffff\1\70", "\1\74\u0095\uffff\1\74\25\uffff\1\73", "\4\111\1\76\1\77\1\111\1\uffff\17\111\2\uffff\1\111\1\uffff"
                      + "\4\111\1\uffff\6\111\1\uffff\1\111\1\101\1\uffff\1\111\3\uffff"
                      + "\2\111\1\uffff\10\111\1\110\7\111\1\uffff\2\111\1\102\1\111"
                      + "\1\uffff\1\111\1\uffff\1\111\1\uffff\4\111\1\uffff\10\111\1"
                      + "\uffff\3\111\1\uffff\1\111\1\uffff\4\111\1\uffff\2\111\1\uffff"
                      + "\3\111\1\103\5\111\1\107\6\111\1\uffff\4\111\1\uffff\6\111\1"
                      + "\104\3\111\2\uffff\4\111\1\uffff\3\111\1\uffff\4\111\1\uffff"
                      + "\1\111\1\uffff\5\111\1\uffff\2\111\1\uffff\5\111\2\uffff\14"
                      + "\111\1\uffff\22\111\1\105\10\111\1\106\14\111\1\uffff\3\111"
                      + "\1\uffff\5\111\1\uffff\4\111\1\uffff\3\111\1\uffff\3\111\1\100"
                      + "\10\111\1\uffff\1\111\2\uffff\1\111\1\uffff\1\111", "\4\130\1\115\1\116\1\130\1\uffff\17\130\2\uffff\1\130\1\uffff"
                          + "\4\130\1\uffff\6\130\1\uffff\1\130\1\120\1\uffff\1\130\3\uffff"
                          + "\2\130\1\uffff\10\130\1\127\7\130\1\uffff\2\130\1\121\1\130"
                          + "\1\uffff\1\130\1\uffff\1\130\1\uffff\4\130\1\uffff\10\130\1"
                          + "\uffff\3\130\1\uffff\1\130\1\uffff\1\130\1\114\2\130\1\uffff"
                          + "\2\130\1\uffff\3\130\1\122\5\130\1\126\6\130\1\uffff\4\130\1"
                          + "\uffff\6\130\1\123\3\130\2\uffff\4\130\1\uffff\3\130\1\uffff"
                          + "\4\130\1\uffff\1\130\1\uffff\5\130\1\uffff\2\130\1\uffff\5\130"
                          + "\2\uffff\14\130\1\uffff\22\130\1\124\10\130\1\125\14\130\1\uffff"
                          + "\3\130\1\uffff\5\130\1\uffff\4\130\1\uffff\3\130\1\uffff\3\130"
                          + "\1\117\10\130\1\uffff\1\130\2\uffff\1\130\1\uffff\1\130", "", "\1\26\15\uffff\1\32\50\uffff\1\134\124\uffff\1\26", "", "", "", "", "", "", "", "", "", "", "", "", "\1\42\50\uffff\1\140", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "\1\143\u00a5\uffff\1\105\116\uffff\1\145\42\uffff\1\105", "\1\147\u00a5\uffff\1\105\116\uffff\1\151\42\uffff\1\105", "\1\153\u00a5\uffff\1\105\116\uffff\1\155\42\uffff\1\105", "\1\157\u00a5\uffff\1\105\116\uffff\1\161\42\uffff\1\105", "\1\163\u00a5\uffff\1\105\116\uffff\1\165\42\uffff\1\105", "\1\167\u00a5\uffff\1\105\116\uffff\1\171\42\uffff\1\105", "\1\173\u00a5\uffff\1\105\116\uffff\1\175\42\uffff\1\105", "", "\1\177\u00a5\uffff\1\105\116\uffff\1\u0081\42\uffff\1\105", "\1\u0083\u00a5\uffff\1\105\116\uffff\1\u0085\42\uffff\1\105", "\1\u0087\u00a5\uffff\1\105\116\uffff\1\u0089\42\uffff\1\105", "", "", "", "\1\130\153\uffff\1\130\72\uffff\1\124", "\1\u008e\153\uffff\1\u0090\71\uffff\1\124\161\uffff\1\124", "\1\u0092\153\uffff\1\u0094\71\uffff\1\124\161\uffff\1\124", "\1\u0096\153\uffff\1\u0098\71\uffff\1\124\161\uffff\1\124", "\1\u009a\153\uffff\1\u009c\71\uffff\1\124\161\uffff\1\124", "\1\u009e\153\uffff\1\u00a0\71\uffff\1\124\161\uffff\1\124", "\1\u00a2\153\uffff\1\u00a4\71\uffff\1\124\161\uffff\1\124", "\1\u00a6\153\uffff\1\u00a8\71\uffff\1\124\161\uffff\1\124", "", "\1\u00aa\153\uffff\1\u00ac\71\uffff\1\124\161\uffff\1\124", "\1\u00ae\153\uffff\1\u00b0\71\uffff\1\124\161\uffff\1\124", "\1\u00b2\153\uffff\1\u00b4\71\uffff\1\124\161\uffff\1\124", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "" };

  static final short[] DFA12_eot = DFA.unpackEncodedString(DFA12_eotS);
  static final short[] DFA12_eof = DFA.unpackEncodedString(DFA12_eofS);
  static final char[] DFA12_min = DFA.unpackEncodedStringToUnsignedChars(DFA12_minS);
  static final char[] DFA12_max = DFA.unpackEncodedStringToUnsignedChars(DFA12_maxS);
  static final short[] DFA12_accept = DFA.unpackEncodedString(DFA12_acceptS);
  static final short[] DFA12_special = DFA.unpackEncodedString(DFA12_specialS);
  static final short[][] DFA12_transition;

  static {
    int numStates = DFA12_transitionS.length;
    DFA12_transition = new short[numStates][];
    for (int i = 0; i < numStates; i++) {
      DFA12_transition[i] = DFA.unpackEncodedString(DFA12_transitionS[i]);
    }
  }

  class DFA12 extends DFA {

    public DFA12(BaseRecognizer recognizer) {
      this.recognizer = recognizer;
      this.decisionNumber = 12;
      this.eot = DFA12_eot;
      this.eof = DFA12_eof;
      this.min = DFA12_min;
      this.max = DFA12_max;
      this.accept = DFA12_accept;
      this.special = DFA12_special;
      this.transition = DFA12_transition;
    }

    public String getDescription() {
      return "696:1: ddlStatement : ( createDatabaseStatement | switchDatabaseStatement | dropDatabaseStatement | createTableStatement | dropTableStatement | truncateTableStatement | alterStatement | descStatement | showStatement | metastoreCheck | createViewStatement | dropViewStatement | createFunctionStatement | createMacroStatement | createIndexStatement | dropIndexStatement | dropFunctionStatement | reloadFunctionStatement | dropMacroStatement | analyzeStatement | lockStatement | unlockStatement | lockDatabase | unlockDatabase | createRoleStatement | dropRoleStatement | grantPrivileges | revokePrivileges | showGrants | showRoleGrants | showRolePrincipals | showRoles | grantRole | revokeRole | setRole | showCurrentRole );";
    }
  }

  static final String DFA204_eotS = "\127\uffff";
  static final String DFA204_eofS = "\1\2\126\uffff";
  static final String DFA204_minS = "\1\44\1\7\35\uffff\1\4\67\uffff";
  static final String DFA204_maxS = "\1\u012d\1\u0135\35\uffff\1\u0131\67\uffff";
  static final String DFA204_acceptS = "\2\uffff\1\2\70\uffff\1\1\33\uffff";
  static final String DFA204_specialS = "\127\uffff}>";
  static final String[] DFA204_transitionS = { "\1\2\20\uffff\1\2\5\uffff\1\2\40\uffff\1\2\31\uffff\1\2\4\uffff"
      + "\1\2\1\uffff\1\2\2\uffff\1\2\11\uffff\1\2\11\uffff\1\2\3\uffff"
      + "\2\2\2\uffff\1\2\5\uffff\1\1\12\uffff\1\2\5\uffff\1\2\31\uffff"
      + "\3\2\22\uffff\1\2\13\uffff\1\2\3\uffff\1\2\6\uffff\1\2\17\uffff"
      + "\1\2\11\uffff\1\2\2\uffff\1\2\4\uffff\1\2\1\uffff\1\2\17\uffff"
      + "\1\2", "\1\2\5\uffff\1\2\4\uffff\1\2\7\uffff\7\2\1\uffff\22\2\1\uffff"
          + "\4\2\1\uffff\6\2\1\uffff\2\2\1\uffff\1\2\1\uffff\4\2\1\uffff"
          + "\20\2\1\uffff\4\2\1\uffff\1\2\1\uffff\1\2\1\uffff\4\2\1\uffff"
          + "\10\2\1\uffff\3\2\1\uffff\1\2\1\uffff\4\2\1\uffff\23\2\1\uffff"
          + "\1\37\3\2\1\uffff\12\2\1\uffff\5\2\1\uffff\10\2\1\uffff\1\2"
          + "\1\uffff\5\2\1\uffff\2\2\1\uffff\5\2\2\uffff\14\2\1\uffff\22"
          + "\2\1\uffff\25\2\1\uffff\3\2\1\uffff\5\2\1\uffff\4\2\1\uffff"
          + "\3\2\1\uffff\14\2\1\uffff\1\2\2\uffff\1\2\1\uffff\1\2\3\uffff"
          + "\1\2\2\uffff\1\2\2\uffff\2\2\7\uffff\5\2", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "\3\2\3\uffff\1\2\3\uffff\2\2\1\uffff\1\2\2\uffff\2\2\1\uffff"
              + "\2\2\10\uffff\1\2\6\uffff\1\2\132\uffff\1\2\12\uffff\1\2\10"
              + "\uffff\1\2\23\uffff\1\2\6\uffff\1\2\33\uffff\1\2\1\uffff\1\2"
              + "\11\uffff\1\2\3\uffff\1\2\34\uffff\1\73\27\uffff\1\2\14\uffff"
              + "\4\2\1\uffff\3\2\1\uffff\1\2\7\uffff\1\2", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "" };

  static final short[] DFA204_eot = DFA.unpackEncodedString(DFA204_eotS);
  static final short[] DFA204_eof = DFA.unpackEncodedString(DFA204_eofS);
  static final char[] DFA204_min = DFA.unpackEncodedStringToUnsignedChars(DFA204_minS);
  static final char[] DFA204_max = DFA.unpackEncodedStringToUnsignedChars(DFA204_maxS);
  static final short[] DFA204_accept = DFA.unpackEncodedString(DFA204_acceptS);
  static final short[] DFA204_special = DFA.unpackEncodedString(DFA204_specialS);
  static final short[][] DFA204_transition;

  static {
    int numStates = DFA204_transitionS.length;
    DFA204_transition = new short[numStates][];
    for (int i = 0; i < numStates; i++) {
      DFA204_transition[i] = DFA.unpackEncodedString(DFA204_transitionS[i]);
    }
  }

  class DFA204 extends DFA {

    public DFA204(BaseRecognizer recognizer) {
      this.recognizer = recognizer;
      this.decisionNumber = 204;
      this.eot = DFA204_eot;
      this.eof = DFA204_eof;
      this.min = DFA204_min;
      this.max = DFA204_max;
      this.accept = DFA204_accept;
      this.special = DFA204_special;
      this.transition = DFA204_transition;
    }

    public String getDescription() {
      return "1775:103: ( tableRowFormatMapKeysIdentifier )?";
    }
  }

  public static final BitSet FOLLOW_explainStatement_in_statement1034 = new BitSet(new long[] { 0x0000000000000000L });
  public static final BitSet FOLLOW_EOF_in_statement1036 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_execStatement_in_statement1041 = new BitSet(new long[] { 0x0000000000000000L });
  public static final BitSet FOLLOW_EOF_in_statement1043 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_EXPLAIN_in_explainStatement1064 = new BitSet(
      new long[] { 0x0000004180000000L, 0x0460030040E80004L, 0x00000104A4000404L, 0x0000048401828000L, 0x0000000040029020L });
  public static final BitSet FOLLOW_explainOption_in_explainStatement1073 = new BitSet(
      new long[] { 0x0000004180000000L, 0x0460030040E80004L, 0x00000104A4000404L, 0x0000048400828000L, 0x0000000040029020L });
  public static final BitSet FOLLOW_execStatement_in_explainStatement1076 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_REWRITE_in_explainStatement1107 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0040000000000000L, 0x0000000400000400L, 0x0000000400008000L, 0x0000000040000000L });
  public static final BitSet FOLLOW_queryStatementExpression_in_explainStatement1109 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_queryStatementExpression_in_execStatement1178 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_loadStatement_in_execStatement1187 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_exportStatement_in_execStatement1195 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_importStatement_in_execStatement1203 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_ddlStatement_in_execStatement1211 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_deleteStatement_in_execStatement1219 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_updateStatement_in_execStatement1227 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_LOAD_in_loadStatement1254 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000200L });
  public static final BitSet FOLLOW_KW_DATA_in_loadStatement1256 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000008000080L });
  public static final BitSet FOLLOW_KW_LOCAL_in_loadStatement1261 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000080L });
  public static final BitSet FOLLOW_KW_INPATH_in_loadStatement1265 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_loadStatement1270 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0200000000002000L });
  public static final BitSet FOLLOW_KW_OVERWRITE_in_loadStatement1276 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000002000L });
  public static final BitSet FOLLOW_KW_INTO_in_loadStatement1280 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L });
  public static final BitSet FOLLOW_KW_TABLE_in_loadStatement1282 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_tableOrPartition_in_loadStatement1287 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_FOR_in_replicationClause1339 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000002000000000L, 0x0000000000200000L });
  public static final BitSet FOLLOW_KW_METADATA_in_replicationClause1344 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000200000L });
  public static final BitSet FOLLOW_KW_REPLICATION_in_replicationClause1348 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_LPAREN_in_replicationClause1350 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_replicationClause1355 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L });
  public static final BitSet FOLLOW_RPAREN_in_replicationClause1358 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_EXPORT_in_exportStatement1402 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L });
  public static final BitSet FOLLOW_KW_TABLE_in_exportStatement1410 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_tableOrPartition_in_exportStatement1415 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x8000000000000000L });
  public static final BitSet FOLLOW_KW_TO_in_exportStatement1424 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_exportStatement1429 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0008000000000000L });
  public static final BitSet FOLLOW_replicationClause_in_exportStatement1438 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_IMPORT_in_importStatement1488 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0040040000000000L, 0x0000000000000000L, 0x0040000000000000L });
  public static final BitSet FOLLOW_KW_EXTERNAL_in_importStatement1503 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L });
  public static final BitSet FOLLOW_KW_TABLE_in_importStatement1507 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_tableOrPartition_in_importStatement1512 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0040000000000000L });
  public static final BitSet FOLLOW_KW_FROM_in_importStatement1526 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_importStatement1531 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000010000000L });
  public static final BitSet FOLLOW_location_in_importStatement1543 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_createDatabaseStatement_in_ddlStatement1595 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_switchDatabaseStatement_in_ddlStatement1603 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_dropDatabaseStatement_in_ddlStatement1611 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_createTableStatement_in_ddlStatement1619 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_dropTableStatement_in_ddlStatement1627 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_truncateTableStatement_in_ddlStatement1635 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_alterStatement_in_ddlStatement1643 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_descStatement_in_ddlStatement1651 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_showStatement_in_ddlStatement1659 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_metastoreCheck_in_ddlStatement1667 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_createViewStatement_in_ddlStatement1675 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_dropViewStatement_in_ddlStatement1683 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_createFunctionStatement_in_ddlStatement1691 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_createMacroStatement_in_ddlStatement1699 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_createIndexStatement_in_ddlStatement1707 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_dropIndexStatement_in_ddlStatement1715 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_dropFunctionStatement_in_ddlStatement1723 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_reloadFunctionStatement_in_ddlStatement1731 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_dropMacroStatement_in_ddlStatement1739 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_analyzeStatement_in_ddlStatement1747 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_lockStatement_in_ddlStatement1755 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_unlockStatement_in_ddlStatement1763 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_lockDatabase_in_ddlStatement1771 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_unlockDatabase_in_ddlStatement1779 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_createRoleStatement_in_ddlStatement1787 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_dropRoleStatement_in_ddlStatement1795 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_grantPrivileges_in_ddlStatement1803 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_revokePrivileges_in_ddlStatement1811 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_showGrants_in_ddlStatement1819 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_showRoleGrants_in_ddlStatement1827 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_showRolePrincipals_in_ddlStatement1835 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_showRoles_in_ddlStatement1843 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_grantRole_in_ddlStatement1851 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_revokeRole_in_ddlStatement1859 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_setRole_in_ddlStatement1867 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_showCurrentRole_in_ddlStatement1875 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_IF_in_ifExists1902 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000004000000000L });
  public static final BitSet FOLLOW_KW_EXISTS_in_ifExists1904 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_RESTRICT_in_restrictOrCascade1941 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_CASCADE_in_restrictOrCascade1959 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_IF_in_ifNotExists1996 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000080000000000L });
  public static final BitSet FOLLOW_KW_NOT_in_ifNotExists1998 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000004000000000L });
  public static final BitSet FOLLOW_KW_EXISTS_in_ifNotExists2000 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_STORED_in_storedAsDirs2037 = new BitSet(new long[] { 0x0000001000000000L });
  public static final BitSet FOLLOW_KW_AS_in_storedAsDirs2039 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000001000000L });
  public static final BitSet FOLLOW_KW_DIRECTORIES_in_storedAsDirs2041 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_OR_in_orReplace2078 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000100000L });
  public static final BitSet FOLLOW_KW_REPLACE_in_orReplace2080 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_IGNORE_in_ignoreProtection2121 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000040L });
  public static final BitSet FOLLOW_KW_PROTECTION_in_ignoreProtection2123 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_CREATE_in_createDatabaseStatement2168 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000400L, 0x0000000000000000L, 0x0000000100000000L });
  public static final BitSet FOLLOW_KW_DATABASE_in_createDatabaseStatement2171 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFFL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_KW_SCHEMA_in_createDatabaseStatement2173 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFFL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_ifNotExists_in_createDatabaseStatement2184 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_identifier_in_createDatabaseStatement2197 = new BitSet(
      new long[] { 0x0800000000000002L, 0x0000000000000000L, 0x0000000010000000L, 0x0000000000000000L, 0x0000000040000000L });
  public static final BitSet FOLLOW_databaseComment_in_createDatabaseStatement2207 = new BitSet(
      new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000010000000L, 0x0000000000000000L, 0x0000000040000000L });
  public static final BitSet FOLLOW_location_in_createDatabaseStatement2218 = new BitSet(
      new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000040000000L });
  public static final BitSet FOLLOW_KW_WITH_in_createDatabaseStatement2230 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000004000L });
  public static final BitSet FOLLOW_KW_DBPROPERTIES_in_createDatabaseStatement2232 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_dbProperties_in_createDatabaseStatement2236 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_LOCATION_in_location2297 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_location2301 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_LPAREN_in_dbProperties2343 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_dbPropertiesList_in_dbProperties2345 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L });
  public static final BitSet FOLLOW_RPAREN_in_dbProperties2347 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_keyValueProperty_in_dbPropertiesList2388 =
      new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_COMMA_in_dbPropertiesList2391 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_keyValueProperty_in_dbPropertiesList2393 =
      new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_KW_USE_in_switchDatabaseStatement2432 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_identifier_in_switchDatabaseStatement2434 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_DROP_in_dropDatabaseStatement2473 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000400L, 0x0000000000000000L, 0x0000000100000000L });
  public static final BitSet FOLLOW_KW_DATABASE_in_dropDatabaseStatement2476 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFFL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_KW_SCHEMA_in_dropDatabaseStatement2478 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFFL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_ifExists_in_dropDatabaseStatement2481 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_identifier_in_dropDatabaseStatement2484 =
      new BitSet(new long[] { 0x0001000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000400000L });
  public static final BitSet FOLLOW_restrictOrCascade_in_dropDatabaseStatement2486 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_COMMENT_in_databaseComment2532 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_databaseComment2536 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_CREATE_in_createTableStatement2576 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000040000000000L, 0x0000000000000000L, 0x0440000000000000L });
  public static final BitSet FOLLOW_KW_TEMPORARY_in_createTableStatement2581 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000040000000000L, 0x0000000000000000L, 0x0040000000000000L });
  public static final BitSet FOLLOW_KW_EXTERNAL_in_createTableStatement2588 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L });
  public static final BitSet FOLLOW_KW_TABLE_in_createTableStatement2592 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFFL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_ifNotExists_in_createTableStatement2594 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_tableName_in_createTableStatement2599 = new BitSet(
      new long[] { 0x0840001000000002L, 0x0000000000000000L, 0x2000000010800000L, 0x0204100040000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_KW_LIKE_in_createTableStatement2612 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_tableName_in_createTableStatement2616 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000010000000L, 0x0204000040000000L });
  public static final BitSet FOLLOW_tableRowFormat_in_createTableStatement2627 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000010000000L, 0x0204000000000000L });
  public static final BitSet FOLLOW_tableFileFormat_in_createTableStatement2639 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000010000000L, 0x0200000000000000L });
  public static final BitSet FOLLOW_location_in_createTableStatement2651 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0200000000000000L });
  public static final BitSet FOLLOW_tablePropertiesPrefixed_in_createTableStatement2663 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_LPAREN_in_createTableStatement2676 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_columnNameTypeList_in_createTableStatement2678 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L });
  public static final BitSet FOLLOW_RPAREN_in_createTableStatement2680 =
      new BitSet(new long[] { 0x0840001000000002L, 0x0000000000000000L, 0x2000000010000000L, 0x0204100040000000L });
  public static final BitSet FOLLOW_tableComment_in_createTableStatement2693 =
      new BitSet(new long[] { 0x0040001000000002L, 0x0000000000000000L, 0x2000000010000000L, 0x0204100040000000L });
  public static final BitSet FOLLOW_tablePartition_in_createTableStatement2705 =
      new BitSet(new long[] { 0x0040001000000002L, 0x0000000000000000L, 0x0000000010000000L, 0x0204100040000000L });
  public static final BitSet FOLLOW_tableBuckets_in_createTableStatement2717 =
      new BitSet(new long[] { 0x0000001000000002L, 0x0000000000000000L, 0x0000000010000000L, 0x0204100040000000L });
  public static final BitSet FOLLOW_tableSkewed_in_createTableStatement2729 =
      new BitSet(new long[] { 0x0000001000000002L, 0x0000000000000000L, 0x0000000010000000L, 0x0204000040000000L });
  public static final BitSet FOLLOW_tableRowFormat_in_createTableStatement2741 =
      new BitSet(new long[] { 0x0000001000000002L, 0x0000000000000000L, 0x0000000010000000L, 0x0204000000000000L });
  public static final BitSet FOLLOW_tableFileFormat_in_createTableStatement2753 =
      new BitSet(new long[] { 0x0000001000000002L, 0x0000000000000000L, 0x0000000010000000L, 0x0200000000000000L });
  public static final BitSet FOLLOW_location_in_createTableStatement2765 =
      new BitSet(new long[] { 0x0000001000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0200000000000000L });
  public static final BitSet FOLLOW_tablePropertiesPrefixed_in_createTableStatement2777 =
      new BitSet(new long[] { 0x0000001000000002L });
  public static final BitSet FOLLOW_KW_AS_in_createTableStatement2790 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L, 0x0000000400008000L, 0x0000000040000000L });
  public static final BitSet FOLLOW_selectStatementWithCTE_in_createTableStatement2792 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_TRUNCATE_in_truncateTableStatement2999 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L });
  public static final BitSet FOLLOW_KW_TABLE_in_truncateTableStatement3001 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_tablePartitionPrefix_in_truncateTableStatement3003 =
      new BitSet(new long[] { 0x0400000000000002L });
  public static final BitSet FOLLOW_KW_COLUMNS_in_truncateTableStatement3006 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_LPAREN_in_truncateTableStatement3008 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_columnNameList_in_truncateTableStatement3010 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L });
  public static final BitSet FOLLOW_RPAREN_in_truncateTableStatement3012 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_CREATE_in_createIndexStatement3047 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000010L });
  public static final BitSet FOLLOW_KW_INDEX_in_createIndexStatement3049 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_identifier_in_createIndexStatement3053 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0001000000000000L });
  public static final BitSet FOLLOW_KW_ON_in_createIndexStatement3061 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L });
  public static final BitSet FOLLOW_KW_TABLE_in_createIndexStatement3063 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_tableName_in_createIndexStatement3067 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_LPAREN_in_createIndexStatement3069 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_columnNameList_in_createIndexStatement3073 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L });
  public static final BitSet FOLLOW_RPAREN_in_createIndexStatement3075 = new BitSet(new long[] { 0x0000001000000000L });
  public static final BitSet FOLLOW_KW_AS_in_createIndexStatement3083 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_createIndexStatement3087 = new BitSet(
      new long[] { 0x0800000000000002L, 0x8000000000000000L, 0x0000000010000008L, 0x0204000040000000L, 0x0000000040000000L });
  public static final BitSet FOLLOW_autoRebuild_in_createIndexStatement3095 =
      new BitSet(new long[] { 0x0800000000000002L, 0x8000000000000000L, 0x0000000010000008L, 0x0204000040000000L });
  public static final BitSet FOLLOW_indexPropertiesPrefixed_in_createIndexStatement3104 =
      new BitSet(new long[] { 0x0800000000000002L, 0x0000000000000000L, 0x0000000010000008L, 0x0204000040000000L });
  public static final BitSet FOLLOW_indexTblName_in_createIndexStatement3113 =
      new BitSet(new long[] { 0x0800000000000002L, 0x0000000000000000L, 0x0000000010000000L, 0x0204000040000000L });
  public static final BitSet FOLLOW_tableRowFormat_in_createIndexStatement3122 =
      new BitSet(new long[] { 0x0800000000000002L, 0x0000000000000000L, 0x0000000010000000L, 0x0204000000000000L });
  public static final BitSet FOLLOW_tableFileFormat_in_createIndexStatement3131 =
      new BitSet(new long[] { 0x0800000000000002L, 0x0000000000000000L, 0x0000000010000000L, 0x0200000000000000L });
  public static final BitSet FOLLOW_location_in_createIndexStatement3140 =
      new BitSet(new long[] { 0x0800000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0200000000000000L });
  public static final BitSet FOLLOW_tablePropertiesPrefixed_in_createIndexStatement3149 =
      new BitSet(new long[] { 0x0800000000000002L });
  public static final BitSet FOLLOW_indexComment_in_createIndexStatement3158 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_COMMENT_in_indexComment3315 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_indexComment3319 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_WITH_in_autoRebuild3360 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000020000L });
  public static final BitSet FOLLOW_KW_DEFERRED_in_autoRebuild3362 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000001000L });
  public static final BitSet FOLLOW_KW_REBUILD_in_autoRebuild3364 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_IN_in_indexTblName3400 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L });
  public static final BitSet FOLLOW_KW_TABLE_in_indexTblName3402 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_tableName_in_indexTblName3406 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_IDXPROPERTIES_in_indexPropertiesPrefixed3453 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_indexProperties_in_indexPropertiesPrefixed3456 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_LPAREN_in_indexProperties3489 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_indexPropertiesList_in_indexProperties3491 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L });
  public static final BitSet FOLLOW_RPAREN_in_indexProperties3493 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_keyValueProperty_in_indexPropertiesList3534 =
      new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_COMMA_in_indexPropertiesList3537 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_keyValueProperty_in_indexPropertiesList3539 =
      new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_KW_DROP_in_dropIndexStatement3577 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000010L });
  public static final BitSet FOLLOW_KW_INDEX_in_dropIndexStatement3579 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFFL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_ifExists_in_dropIndexStatement3581 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_identifier_in_dropIndexStatement3586 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0001000000000000L });
  public static final BitSet FOLLOW_KW_ON_in_dropIndexStatement3588 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_tableName_in_dropIndexStatement3592 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_DROP_in_dropTableStatement3637 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L });
  public static final BitSet FOLLOW_KW_TABLE_in_dropTableStatement3639 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFFL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_ifExists_in_dropTableStatement3641 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_tableName_in_dropTableStatement3644 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0008000000000000L, 0x0000000000000000L, 0x0000000000000080L });
  public static final BitSet FOLLOW_KW_PURGE_in_dropTableStatement3646 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0008000000000000L });
  public static final BitSet FOLLOW_replicationClause_in_dropTableStatement3649 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_ALTER_in_alterStatement3698 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L });
  public static final BitSet FOLLOW_KW_TABLE_in_alterStatement3700 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_tableName_in_alterStatement3702 = new BitSet(
      new long[] { 0x9048000408000000L, 0x0000001244000000L, 0x1000080000002000L, 0x0000108000140000L, 0x000000000000A041L });
  public static final BitSet FOLLOW_alterTableStatementSuffix_in_alterStatement3704 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_ALTER_in_alterStatement3722 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000002000000L });
  public static final BitSet FOLLOW_KW_VIEW_in_alterStatement3724 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_tableName_in_alterStatement3726 = new BitSet(
      new long[] { 0x0000001008000000L, 0x0000000040000000L, 0x0000000400000000L, 0x0000008400048000L, 0x0000000040002000L });
  public static final BitSet FOLLOW_KW_AS_in_alterStatement3728 = new BitSet(
      new long[] { 0x0000000008000000L, 0x0000000040000000L, 0x0000000400000000L, 0x0000008400048000L, 0x0000000040002000L });
  public static final BitSet FOLLOW_alterViewStatementSuffix_in_alterStatement3731 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_ALTER_in_alterStatement3749 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000010L });
  public static final BitSet FOLLOW_KW_INDEX_in_alterStatement3751 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_alterIndexStatementSuffix_in_alterStatement3753 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_ALTER_in_alterStatement3765 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000400L, 0x0000000000000000L, 0x0000000100000000L });
  public static final BitSet FOLLOW_KW_DATABASE_in_alterStatement3768 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_KW_SCHEMA_in_alterStatement3770 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_alterDatabaseStatementSuffix_in_alterStatement3773 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_alterStatementSuffixRename_in_alterTableStatementSuffix3804 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_alterStatementSuffixUpdateStatsCol_in_alterTableStatementSuffix3813 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_alterStatementSuffixDropPartitions_in_alterTableStatementSuffix3821 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_alterStatementSuffixAddPartitions_in_alterTableStatementSuffix3830 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_alterStatementSuffixTouch_in_alterTableStatementSuffix3839 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_alterStatementSuffixArchive_in_alterTableStatementSuffix3847 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_alterStatementSuffixUnArchive_in_alterTableStatementSuffix3855 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_alterStatementSuffixProperties_in_alterTableStatementSuffix3863 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_alterStatementSuffixSkewedby_in_alterTableStatementSuffix3871 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_alterStatementSuffixExchangePartition_in_alterTableStatementSuffix3879 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_alterStatementPartitionKeyType_in_alterTableStatementSuffix3887 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_partitionSpec_in_alterTableStatementSuffix3895 = new BitSet(
      new long[] { 0x9048000008000000L, 0x0000000204000000L, 0x0000080000002000L, 0x0000008000140000L, 0x0000000000008000L });
  public static final BitSet FOLLOW_alterTblPartitionStatementSuffix_in_alterTableStatementSuffix3898 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_alterStatementSuffixFileFormat_in_alterTblPartitionStatementSuffix3930 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_alterStatementSuffixLocation_in_alterTblPartitionStatementSuffix3936 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_alterStatementSuffixProtectMode_in_alterTblPartitionStatementSuffix3942 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_alterStatementSuffixMergeFiles_in_alterTblPartitionStatementSuffix3948 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_alterStatementSuffixSerdeProperties_in_alterTblPartitionStatementSuffix3954 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_alterStatementSuffixRenamePart_in_alterTblPartitionStatementSuffix3960 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_alterStatementSuffixBucketNum_in_alterTblPartitionStatementSuffix3966 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_alterTblPartitionStatementSuffixSkewedLocation_in_alterTblPartitionStatementSuffix3972 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_alterStatementSuffixClusterbySortby_in_alterTblPartitionStatementSuffix3978 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_alterStatementSuffixCompact_in_alterTblPartitionStatementSuffix3984 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_alterStatementSuffixUpdateStatsCol_in_alterTblPartitionStatementSuffix3990 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_alterStatementSuffixRenameCol_in_alterTblPartitionStatementSuffix3996 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_alterStatementSuffixAddCol_in_alterTblPartitionStatementSuffix4002 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_PARTITION_in_alterStatementPartitionKeyType4024 =
      new BitSet(new long[] { 0x0200000000000000L });
  public static final BitSet FOLLOW_KW_COLUMN_in_alterStatementPartitionKeyType4026 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_LPAREN_in_alterStatementPartitionKeyType4028 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_columnNameType_in_alterStatementPartitionKeyType4030 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L });
  public static final BitSet FOLLOW_RPAREN_in_alterStatementPartitionKeyType4032 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_alterViewSuffixProperties_in_alterViewStatementSuffix4065 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_alterStatementSuffixRename_in_alterViewStatementSuffix4073 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_alterStatementSuffixAddPartitions_in_alterViewStatementSuffix4082 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_alterStatementSuffixDropPartitions_in_alterViewStatementSuffix4091 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_selectStatementWithCTE_in_alterViewStatementSuffix4100 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_identifier_in_alterIndexStatementSuffix4129 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0001000000000000L });
  public static final BitSet FOLLOW_KW_ON_in_alterIndexStatementSuffix4131 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_tableName_in_alterIndexStatementSuffix4133 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x1000000000000000L, 0x0000008000001000L });
  public static final BitSet FOLLOW_partitionSpec_in_alterIndexStatementSuffix4135 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000008000001000L });
  public static final BitSet FOLLOW_KW_REBUILD_in_alterIndexStatementSuffix4150 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SET_in_alterIndexStatementSuffix4183 =
      new BitSet(new long[] { 0x0000000000000000L, 0x8000000000000000L });
  public static final BitSet FOLLOW_KW_IDXPROPERTIES_in_alterIndexStatementSuffix4185 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_indexProperties_in_alterIndexStatementSuffix4193 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_alterDatabaseSuffixProperties_in_alterDatabaseStatementSuffix4244 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_alterDatabaseSuffixSetOwner_in_alterDatabaseStatementSuffix4252 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_identifier_in_alterDatabaseSuffixProperties4281 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000008000000000L });
  public static final BitSet FOLLOW_KW_SET_in_alterDatabaseSuffixProperties4283 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000004000L });
  public static final BitSet FOLLOW_KW_DBPROPERTIES_in_alterDatabaseSuffixProperties4285 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_dbProperties_in_alterDatabaseSuffixProperties4287 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_identifier_in_alterDatabaseSuffixSetOwner4331 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000008000000000L });
  public static final BitSet FOLLOW_KW_SET_in_alterDatabaseSuffixSetOwner4333 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0400000000000000L });
  public static final BitSet FOLLOW_KW_OWNER_in_alterDatabaseSuffixSetOwner4335 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0800000000000000L, 0x0000000000000000L, 0x0000000008000000L, 0x0000000000040000L });
  public static final BitSet FOLLOW_principalName_in_alterDatabaseSuffixSetOwner4337 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_RENAME_in_alterStatementSuffixRename4380 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x8000000000000000L });
  public static final BitSet FOLLOW_KW_TO_in_alterStatementSuffixRename4382 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_tableName_in_alterStatementSuffixRename4384 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_ADD_in_alterStatementSuffixAddCol4451 =
      new BitSet(new long[] { 0x0400000000000000L });
  public static final BitSet FOLLOW_KW_REPLACE_in_alterStatementSuffixAddCol4457 =
      new BitSet(new long[] { 0x0400000000000000L });
  public static final BitSet FOLLOW_KW_COLUMNS_in_alterStatementSuffixAddCol4460 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_LPAREN_in_alterStatementSuffixAddCol4462 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_columnNameTypeList_in_alterStatementSuffixAddCol4464 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L });
  public static final BitSet FOLLOW_RPAREN_in_alterStatementSuffixAddCol4466 =
      new BitSet(new long[] { 0x0001000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000400000L });
  public static final BitSet FOLLOW_restrictOrCascade_in_alterStatementSuffixAddCol4468 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_CHANGE_in_alterStatementSuffixRenameCol4544 = new BitSet(
      new long[] { 0xFFE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_KW_COLUMN_in_alterStatementSuffixRenameCol4546 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_identifier_in_alterStatementSuffixRenameCol4551 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_identifier_in_alterStatementSuffixRenameCol4555 = new BitSet(
      new long[] { 0x00100E0800000000L, 0x000200002000B000L, 0x0000000400000800L, 0x6030200000000000L, 0x0000000001000400L });
  public static final BitSet FOLLOW_colType_in_alterStatementSuffixRenameCol4557 =
      new BitSet(new long[] { 0x0801000020000002L, 0x0001000000000000L, 0x0000000000000000L, 0x0000000000400000L });
  public static final BitSet FOLLOW_KW_COMMENT_in_alterStatementSuffixRenameCol4560 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_alterStatementSuffixRenameCol4564 =
      new BitSet(new long[] { 0x0001000020000002L, 0x0001000000000000L, 0x0000000000000000L, 0x0000000000400000L });
  public static final BitSet FOLLOW_alterStatementChangeColPosition_in_alterStatementSuffixRenameCol4568 =
      new BitSet(new long[] { 0x0001000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000400000L });
  public static final BitSet FOLLOW_restrictOrCascade_in_alterStatementSuffixRenameCol4571 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_UPDATE_in_alterStatementSuffixUpdateStatsCol4626 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0002000000000000L });
  public static final BitSet FOLLOW_KW_STATISTICS_in_alterStatementSuffixUpdateStatsCol4628 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_KW_FOR_in_alterStatementSuffixUpdateStatsCol4630 = new BitSet(
      new long[] { 0xFFE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_KW_COLUMN_in_alterStatementSuffixUpdateStatsCol4632 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_identifier_in_alterStatementSuffixUpdateStatsCol4637 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000008000000000L });
  public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixUpdateStatsCol4639 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixUpdateStatsCol4641 =
      new BitSet(new long[] { 0x0800000000000002L });
  public static final BitSet FOLLOW_KW_COMMENT_in_alterStatementSuffixUpdateStatsCol4644 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_alterStatementSuffixUpdateStatsCol4648 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_FIRST_in_alterStatementChangeColPosition4687 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_AFTER_in_alterStatementChangeColPosition4689 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_identifier_in_alterStatementChangeColPosition4693 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_ADD_in_alterStatementSuffixAddPartitions4746 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x1000000000000001L });
  public static final BitSet FOLLOW_ifNotExists_in_alterStatementSuffixAddPartitions4748 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x1000000000000000L });
  public static final BitSet FOLLOW_alterStatementSuffixAddPartitionsElement_in_alterStatementSuffixAddPartitions4751 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x1000000000000000L });
  public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixAddPartitionsElement4814 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000800000000000L, 0x0000000010000000L, 0x0000002000000000L });
  public static final BitSet FOLLOW_partitionFileFormat_in_alterStatementSuffixAddPartitionsElement4816 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000010000000L, 0x0000002000000000L });
  public static final BitSet FOLLOW_partitionSerdeProperties_in_alterStatementSuffixAddPartitionsElement4819 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000010000000L });
  public static final BitSet FOLLOW_location_in_alterStatementSuffixAddPartitionsElement4822 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_TOUCH_in_alterStatementSuffixTouch4850 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x1000000000000000L });
  public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixTouch4853 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x1000000000000000L });
  public static final BitSet FOLLOW_KW_ARCHIVE_in_alterStatementSuffixArchive4897 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x1000000000000000L });
  public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixArchive4900 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x1000000000000000L });
  public static final BitSet FOLLOW_KW_UNARCHIVE_in_alterStatementSuffixUnArchive4944 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x1000000000000000L });
  public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixUnArchive4947 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x1000000000000000L });
  public static final BitSet FOLLOW_KW_FILEFORMAT_in_partitionFileFormat4991 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_fileFormat_in_partitionFileFormat4993 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SERDEPROPERTIES_in_partitionSerdeProperties5028 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_tableProperties_in_partitionSerdeProperties5030 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_DROP_in_alterStatementSuffixDropPartitions5066 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x1000000000000001L });
  public static final BitSet FOLLOW_ifExists_in_alterStatementSuffixDropPartitions5068 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x1000000000000000L });
  public static final BitSet FOLLOW_dropPartitionSpec_in_alterStatementSuffixDropPartitions5071 =
      new BitSet(new long[] { 0x0000000000000402L, 0x0008000000000000L, 0x0000000000000002L, 0x0000000000000080L });
  public static final BitSet FOLLOW_COMMA_in_alterStatementSuffixDropPartitions5074 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x1000000000000000L });
  public static final BitSet FOLLOW_dropPartitionSpec_in_alterStatementSuffixDropPartitions5076 =
      new BitSet(new long[] { 0x0000000000000402L, 0x0008000000000000L, 0x0000000000000002L, 0x0000000000000080L });
  public static final BitSet FOLLOW_ignoreProtection_in_alterStatementSuffixDropPartitions5080 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0008000000000000L, 0x0000000000000000L, 0x0000000000000080L });
  public static final BitSet FOLLOW_KW_PURGE_in_alterStatementSuffixDropPartitions5083 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0008000000000000L });
  public static final BitSet FOLLOW_replicationClause_in_alterStatementSuffixDropPartitions5086 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixProperties5174 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0200000000000000L });
  public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_alterStatementSuffixProperties5176 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixProperties5178 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_UNSET_in_alterStatementSuffixProperties5198 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0200000000000000L });
  public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_alterStatementSuffixProperties5200 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000001L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_ifExists_in_alterStatementSuffixProperties5202 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixProperties5205 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SET_in_alterViewSuffixProperties5247 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0200000000000000L });
  public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_alterViewSuffixProperties5249 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_tableProperties_in_alterViewSuffixProperties5251 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_UNSET_in_alterViewSuffixProperties5271 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0200000000000000L });
  public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_alterViewSuffixProperties5273 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000001L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_ifExists_in_alterViewSuffixProperties5275 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_tableProperties_in_alterViewSuffixProperties5278 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixSerdeProperties5320 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000001000000000L });
  public static final BitSet FOLLOW_KW_SERDE_in_alterStatementSuffixSerdeProperties5322 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_alterStatementSuffixSerdeProperties5326 = new BitSet(
      new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000040000000L });
  public static final BitSet FOLLOW_KW_WITH_in_alterStatementSuffixSerdeProperties5329 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000002000000000L });
  public static final BitSet FOLLOW_KW_SERDEPROPERTIES_in_alterStatementSuffixSerdeProperties5331 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixSerdeProperties5333 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixSerdeProperties5359 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000002000000000L });
  public static final BitSet FOLLOW_KW_SERDEPROPERTIES_in_alterStatementSuffixSerdeProperties5361 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixSerdeProperties5363 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_tableName_in_tablePartitionPrefix5400 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x1000000000000000L });
  public static final BitSet FOLLOW_partitionSpec_in_tablePartitionPrefix5402 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixFileFormat5437 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000800000000000L });
  public static final BitSet FOLLOW_KW_FILEFORMAT_in_alterStatementSuffixFileFormat5439 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_fileFormat_in_alterStatementSuffixFileFormat5441 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_NOT_in_alterStatementSuffixClusterbySortby5472 =
      new BitSet(new long[] { 0x0040000000000000L });
  public static final BitSet FOLLOW_KW_CLUSTERED_in_alterStatementSuffixClusterbySortby5474 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_NOT_in_alterStatementSuffixClusterbySortby5488 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000800000000000L });
  public static final BitSet FOLLOW_KW_SORTED_in_alterStatementSuffixClusterbySortby5490 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_tableBuckets_in_alterStatementSuffixClusterbySortby5504 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SET_in_alterTblPartitionStatementSuffixSkewedLocation5535 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000100000000000L });
  public static final BitSet FOLLOW_KW_SKEWED_in_alterTblPartitionStatementSuffixSkewedLocation5537 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000010000000L });
  public static final BitSet FOLLOW_KW_LOCATION_in_alterTblPartitionStatementSuffixSkewedLocation5539 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_skewedLocations_in_alterTblPartitionStatementSuffixSkewedLocation5541 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_LPAREN_in_skewedLocations5584 = new BitSet(
      new long[] { 0x0000000000042080L, 0x0000080000001000L, 0x0000000000000000L, 0x2000000000000000L, 0x002C010400000010L });
  public static final BitSet FOLLOW_skewedLocationsList_in_skewedLocations5586 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L });
  public static final BitSet FOLLOW_RPAREN_in_skewedLocations5588 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_skewedLocationMap_in_skewedLocationsList5629 =
      new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_COMMA_in_skewedLocationsList5632 = new BitSet(
      new long[] { 0x0000000000042080L, 0x0000080000001000L, 0x0000000000000000L, 0x2000000000000000L, 0x002C010400000010L });
  public static final BitSet FOLLOW_skewedLocationMap_in_skewedLocationsList5634 =
      new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_skewedValueLocationElement_in_skewedLocationMap5680 =
      new BitSet(new long[] { 0x0000000000100000L });
  public static final BitSet FOLLOW_EQUAL_in_skewedLocationMap5682 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_skewedLocationMap5686 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixLocation5723 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000010000000L });
  public static final BitSet FOLLOW_location_in_alterStatementSuffixLocation5725 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_tableSkewed_in_alterStatementSuffixSkewedby5752 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_NOT_in_alterStatementSuffixSkewedby5767 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000100000000000L });
  public static final BitSet FOLLOW_KW_SKEWED_in_alterStatementSuffixSkewedby5769 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_NOT_in_alterStatementSuffixSkewedby5782 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0004000000000000L });
  public static final BitSet FOLLOW_storedAsDirs_in_alterStatementSuffixSkewedby5784 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_EXCHANGE_in_alterStatementSuffixExchangePartition5815 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x1000000000000000L });
  public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixExchangePartition5817 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000040000000L });
  public static final BitSet FOLLOW_KW_WITH_in_alterStatementSuffixExchangePartition5819 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L });
  public static final BitSet FOLLOW_KW_TABLE_in_alterStatementSuffixExchangePartition5821 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_tableName_in_alterStatementSuffixExchangePartition5825 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_alterProtectMode_in_alterStatementSuffixProtectMode5867 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_RENAME_in_alterStatementSuffixRenamePart5906 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x8000000000000000L });
  public static final BitSet FOLLOW_KW_TO_in_alterStatementSuffixRenamePart5908 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x1000000000000000L });
  public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixRenamePart5910 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_UPDATE_in_alterStatementSuffixStatsPart5948 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0002000000000000L });
  public static final BitSet FOLLOW_KW_STATISTICS_in_alterStatementSuffixStatsPart5950 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_KW_FOR_in_alterStatementSuffixStatsPart5952 = new BitSet(
      new long[] { 0xFFE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_KW_COLUMN_in_alterStatementSuffixStatsPart5954 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_identifier_in_alterStatementSuffixStatsPart5959 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000008000000000L });
  public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixStatsPart5961 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixStatsPart5963 =
      new BitSet(new long[] { 0x0800000000000002L });
  public static final BitSet FOLLOW_KW_COMMENT_in_alterStatementSuffixStatsPart5966 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_alterStatementSuffixStatsPart5970 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_CONCATENATE_in_alterStatementSuffixMergeFiles6017 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_ENABLE_in_alterProtectMode6054 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000900000000000L, 0x0000000000000400L });
  public static final BitSet FOLLOW_alterProtectModeMode_in_alterProtectMode6056 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_DISABLE_in_alterProtectMode6073 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000900000000000L, 0x0000000000000400L });
  public static final BitSet FOLLOW_alterProtectModeMode_in_alterProtectMode6075 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_OFFLINE_in_alterProtectModeMode6111 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_NO_DROP_in_alterProtectModeMode6126 =
      new BitSet(new long[] { 0x0001000000000002L });
  public static final BitSet FOLLOW_KW_CASCADE_in_alterProtectModeMode6128 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_READONLY_in_alterProtectModeMode6146 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_INTO_in_alterStatementSuffixBucketNum6180 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000010000000000L });
  public static final BitSet FOLLOW_Number_in_alterStatementSuffixBucketNum6184 =
      new BitSet(new long[] { 0x0000400000000000L });
  public static final BitSet FOLLOW_KW_BUCKETS_in_alterStatementSuffixBucketNum6186 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_COMPACT_in_alterStatementSuffixCompact6226 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_alterStatementSuffixCompact6230 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_INPUTFORMAT_in_fileFormat6271 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_fileFormat6275 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0080000000000000L });
  public static final BitSet FOLLOW_KW_OUTPUTFORMAT_in_fileFormat6277 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_fileFormat6281 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000001000000000L });
  public static final BitSet FOLLOW_KW_SERDE_in_fileFormat6283 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_fileFormat6287 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000000000100L });
  public static final BitSet FOLLOW_KW_INPUTDRIVER_in_fileFormat6290 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_fileFormat6294 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L });
  public static final BitSet FOLLOW_KW_OUTPUTDRIVER_in_fileFormat6296 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_fileFormat6300 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_identifier_in_fileFormat6341 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_identifier_in_tabTypeExpr6377 = new BitSet(new long[] { 0x0000000000020002L });
  public static final BitSet FOLLOW_DOT_in_tabTypeExpr6380 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_KW_ELEM_TYPE_in_tabTypeExpr6384 = new BitSet(new long[] { 0x0000000000020002L });
  public static final BitSet FOLLOW_KW_KEY_TYPE_in_tabTypeExpr6388 = new BitSet(new long[] { 0x0000000000020002L });
  public static final BitSet FOLLOW_KW_VALUE_TYPE_in_tabTypeExpr6392 = new BitSet(new long[] { 0x0000000000020002L });
  public static final BitSet FOLLOW_identifier_in_tabTypeExpr6396 = new BitSet(new long[] { 0x0000000000020002L });
  public static final BitSet FOLLOW_identifier_in_descTabTypeExpr6425 = new BitSet(
      new long[] { 0xFDE9FFFDFC020002L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_DOT_in_descTabTypeExpr6428 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_KW_ELEM_TYPE_in_descTabTypeExpr6432 = new BitSet(
      new long[] { 0xFDE9FFFDFC020002L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_KW_KEY_TYPE_in_descTabTypeExpr6436 = new BitSet(
      new long[] { 0xFDE9FFFDFC020002L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_KW_VALUE_TYPE_in_descTabTypeExpr6440 = new BitSet(
      new long[] { 0xFDE9FFFDFC020002L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_identifier_in_descTabTypeExpr6444 = new BitSet(
      new long[] { 0xFDE9FFFDFC020002L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_identifier_in_descTabTypeExpr6449 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_tabTypeExpr_in_partTypeExpr6477 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x1000000000000000L });
  public static final BitSet FOLLOW_partitionSpec_in_partTypeExpr6479 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_descTabTypeExpr_in_descPartTypeExpr6519 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x1000000000000000L });
  public static final BitSet FOLLOW_partitionSpec_in_descPartTypeExpr6521 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_DESCRIBE_in_descStatement6561 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000400L, 0x0000000000000000L, 0x0000000100000000L });
  public static final BitSet FOLLOW_KW_DESC_in_descStatement6563 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000400L, 0x0000000000000000L, 0x0000000100000000L });
  public static final BitSet FOLLOW_KW_DATABASE_in_descStatement6567 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFFEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_KW_SCHEMA_in_descStatement6569 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFFEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_KW_EXTENDED_in_descStatement6572 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_identifier_in_descStatement6578 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_DESCRIBE_in_descStatement6600 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFFEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_KW_DESC_in_descStatement6602 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFFEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_KW_FORMATTED_in_descStatement6608 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_KW_EXTENDED_in_descStatement6612 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_KW_PRETTY_in_descStatement6616 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_descPartTypeExpr_in_descStatement6623 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_DESCRIBE_in_descStatement6646 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0100000000000000L });
  public static final BitSet FOLLOW_KW_DESC_in_descStatement6648 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0100000000000000L });
  public static final BitSet FOLLOW_KW_FUNCTION_in_descStatement6651 = new BitSet(
      new long[] { 0xFDEBFFFFFDB0C070L, 0xDEBBFFEAF7FFFB16L, 0xF6FEFF7DFFBDFFFFL, 0xEEFFFFFBFFFF7FF9L, 0x001A02E356FFF77BL });
  public static final BitSet FOLLOW_KW_EXTENDED_in_descStatement6653 = new BitSet(
      new long[] { 0xFDEBFFFFFDB0C070L, 0xDEBBFDEAF7FFFB16L, 0xF6FEFF7DFFBDFFFFL, 0xEEFFFFFBFFFF7FF9L, 0x001A02E356FFF77BL });
  public static final BitSet FOLLOW_descFuncNames_in_descStatement6659 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_ANALYZE_in_analyzeStatement6700 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L });
  public static final BitSet FOLLOW_KW_TABLE_in_analyzeStatement6702 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_tableOrPartition_in_analyzeStatement6707 =
      new BitSet(new long[] { 0x4000000000000000L });
  public static final BitSet FOLLOW_KW_COMPUTE_in_analyzeStatement6710 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0002000000000000L });
  public static final BitSet FOLLOW_KW_STATISTICS_in_analyzeStatement6712 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0008000000000000L, 0x0800040000000000L });
  public static final BitSet FOLLOW_KW_NOSCAN_in_analyzeStatement6718 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_PARTIALSCAN_in_analyzeStatement6726 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_FOR_in_analyzeStatement6787 = new BitSet(new long[] { 0x0400000000000000L });
  public static final BitSet FOLLOW_KW_COLUMNS_in_analyzeStatement6789 = new BitSet(
      new long[] { 0xFDE9FFFDFC000002L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_columnNameList_in_analyzeStatement6794 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SHOW_in_showStatement6856 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000800L, 0x0000000000000000L, 0x0000000200000000L });
  public static final BitSet FOLLOW_KW_DATABASES_in_showStatement6859 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000000800000L });
  public static final BitSet FOLLOW_KW_SCHEMAS_in_showStatement6861 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000000800000L });
  public static final BitSet FOLLOW_KW_LIKE_in_showStatement6865 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0008000052FFF77BL });
  public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement6867 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SHOW_in_showStatement6886 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0080000000000000L });
  public static final BitSet FOLLOW_KW_TABLES_in_showStatement6888 = new BitSet(
      new long[] { 0xFDE9FFFDFC000002L, 0xDEFBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0008000052FFF77BL });
  public static final BitSet FOLLOW_KW_FROM_in_showStatement6892 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_KW_IN_in_showStatement6894 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_identifier_in_showStatement6899 = new BitSet(
      new long[] { 0xFDE9FFFDFC000002L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0008000052FFF77BL });
  public static final BitSet FOLLOW_KW_LIKE_in_showStatement6904 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0008000052FFF77BL });
  public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement6906 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement6908 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SHOW_in_showStatement6936 = new BitSet(new long[] { 0x0400000000000000L });
  public static final BitSet FOLLOW_KW_COLUMNS_in_showStatement6938 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0040000000000000L, 0x0000000000000008L });
  public static final BitSet FOLLOW_KW_FROM_in_showStatement6941 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_KW_IN_in_showStatement6943 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_tableName_in_showStatement6946 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0040000000000000L, 0x0000000000000008L });
  public static final BitSet FOLLOW_KW_FROM_in_showStatement6950 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_KW_IN_in_showStatement6952 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_identifier_in_showStatement6957 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SHOW_in_showStatement6983 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0200000000000000L });
  public static final BitSet FOLLOW_KW_FUNCTIONS_in_showStatement6985 = new BitSet(
      new long[] { 0xFDE9FFFDFC000002L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0008000052FFF77BL });
  public static final BitSet FOLLOW_KW_LIKE_in_showStatement6988 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0008000052FFF77BL });
  public static final BitSet FOLLOW_showFunctionIdentifier_in_showStatement6990 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_showFunctionIdentifier_in_showStatement6992 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SHOW_in_showStatement7015 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x4000000000000000L });
  public static final BitSet FOLLOW_KW_PARTITIONS_in_showStatement7017 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_tableName_in_showStatement7021 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x1000000000000000L });
  public static final BitSet FOLLOW_partitionSpec_in_showStatement7023 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SHOW_in_showStatement7045 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000004L });
  public static final BitSet FOLLOW_KW_CREATE_in_showStatement7047 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L });
  public static final BitSet FOLLOW_KW_TABLE_in_showStatement7049 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_tableName_in_showStatement7053 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SHOW_in_showStatement7070 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L });
  public static final BitSet FOLLOW_KW_TABLE_in_showStatement7072 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000020000000000L });
  public static final BitSet FOLLOW_KW_EXTENDED_in_showStatement7074 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0040000000000000L, 0x0000000000800008L });
  public static final BitSet FOLLOW_KW_FROM_in_showStatement7078 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_KW_IN_in_showStatement7080 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_identifier_in_showStatement7085 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000800000L });
  public static final BitSet FOLLOW_KW_LIKE_in_showStatement7089 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0008000052FFF77BL });
  public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement7091 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x1000000000000000L });
  public static final BitSet FOLLOW_partitionSpec_in_showStatement7093 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SHOW_in_showStatement7121 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0200000000000000L });
  public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_showStatement7123 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_tableName_in_showStatement7125 = new BitSet(
      new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_LPAREN_in_showStatement7128 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_showStatement7132 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L });
  public static final BitSet FOLLOW_RPAREN_in_showStatement7134 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SHOW_in_showStatement7156 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000040000000L });
  public static final BitSet FOLLOW_KW_LOCKS_in_showStatement7158 = new BitSet(
      new long[] { 0xFDE9FFFDFC000002L, 0xDEBBFFEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_partTypeExpr_in_showStatement7163 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000020000000000L });
  public static final BitSet FOLLOW_KW_EXTENDED_in_showStatement7170 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SHOW_in_showStatement7194 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000040000000L });
  public static final BitSet FOLLOW_KW_LOCKS_in_showStatement7196 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000400L, 0x0000000000000000L, 0x0000000100000000L });
  public static final BitSet FOLLOW_KW_DATABASE_in_showStatement7199 = new BitSet(new long[] { 0x0000000004000000L });
  public static final BitSet FOLLOW_KW_SCHEMA_in_showStatement7201 = new BitSet(new long[] { 0x0000000004000000L });
  public static final BitSet FOLLOW_Identifier_in_showStatement7207 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000020000000000L });
  public static final BitSet FOLLOW_KW_EXTENDED_in_showStatement7213 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SHOW_in_showStatement7236 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0020000000000000L, 0x0000000000000030L });
  public static final BitSet FOLLOW_KW_FORMATTED_in_showStatement7241 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000030L });
  public static final BitSet FOLLOW_KW_INDEX_in_showStatement7246 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0001000000000000L });
  public static final BitSet FOLLOW_KW_INDEXES_in_showStatement7248 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0001000000000000L });
  public static final BitSet FOLLOW_KW_ON_in_showStatement7251 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0008000052FFF77BL });
  public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement7253 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0040000000000000L, 0x0000000000000008L });
  public static final BitSet FOLLOW_KW_FROM_in_showStatement7257 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_KW_IN_in_showStatement7259 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_identifier_in_showStatement7264 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SHOW_in_showStatement7294 = new BitSet(new long[] { 0x2000000000000000L });
  public static final BitSet FOLLOW_KW_COMPACTIONS_in_showStatement7296 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SHOW_in_showStatement7310 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_TRANSACTIONS_in_showStatement7312 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SHOW_in_showStatement7326 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000001L });
  public static final BitSet FOLLOW_KW_CONF_in_showStatement7328 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_showStatement7330 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_LOCK_in_lockStatement7365 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L });
  public static final BitSet FOLLOW_KW_TABLE_in_lockStatement7367 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_tableName_in_lockStatement7369 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000002000000000L, 0x1000000000000000L, 0x0000020000000000L });
  public static final BitSet FOLLOW_partitionSpec_in_lockStatement7371 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000002000000000L, 0x0000000000000000L, 0x0000020000000000L });
  public static final BitSet FOLLOW_lockMode_in_lockStatement7374 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_LOCK_in_lockDatabase7414 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000400L, 0x0000000000000000L, 0x0000000100000000L });
  public static final BitSet FOLLOW_KW_DATABASE_in_lockDatabase7417 = new BitSet(new long[] { 0x0000000004000000L });
  public static final BitSet FOLLOW_KW_SCHEMA_in_lockDatabase7419 = new BitSet(new long[] { 0x0000000004000000L });
  public static final BitSet FOLLOW_Identifier_in_lockDatabase7425 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000002000000000L, 0x0000000000000000L, 0x0000020000000000L });
  public static final BitSet FOLLOW_lockMode_in_lockDatabase7428 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_UNLOCK_in_unlockStatement7497 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L });
  public static final BitSet FOLLOW_KW_TABLE_in_unlockStatement7499 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_tableName_in_unlockStatement7501 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x1000000000000000L });
  public static final BitSet FOLLOW_partitionSpec_in_unlockStatement7503 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_UNLOCK_in_unlockDatabase7543 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000400L, 0x0000000000000000L, 0x0000000100000000L });
  public static final BitSet FOLLOW_KW_DATABASE_in_unlockDatabase7546 = new BitSet(new long[] { 0x0000000004000000L });
  public static final BitSet FOLLOW_KW_SCHEMA_in_unlockDatabase7548 = new BitSet(new long[] { 0x0000000004000000L });
  public static final BitSet FOLLOW_Identifier_in_unlockDatabase7554 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_CREATE_in_createRoleStatement7591 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000008000000L });
  public static final BitSet FOLLOW_KW_ROLE_in_createRoleStatement7593 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_identifier_in_createRoleStatement7597 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_DROP_in_dropRoleStatement7637 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000008000000L });
  public static final BitSet FOLLOW_KW_ROLE_in_dropRoleStatement7639 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_identifier_in_dropRoleStatement7643 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_GRANT_in_grantPrivileges7683 = new BitSet(
      new long[] { 0x00000000C0000000L, 0x0000000040080004L, 0x0000000020000410L, 0x0000080400000000L, 0x0000000000008000L });
  public static final BitSet FOLLOW_privilegeList_in_grantPrivileges7687 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0001000000000000L, 0x8000000000000000L });
  public static final BitSet FOLLOW_privilegeObject_in_grantPrivileges7695 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x8000000000000000L });
  public static final BitSet FOLLOW_KW_TO_in_grantPrivileges7704 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0800000000000000L, 0x0000000000000000L, 0x0000000008000000L, 0x0000000000040000L });
  public static final BitSet FOLLOW_principalSpecification_in_grantPrivileges7706 = new BitSet(
      new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000040000000L });
  public static final BitSet FOLLOW_withGrantOption_in_grantPrivileges7714 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_REVOKE_in_revokePrivileges7763 = new BitSet(
      new long[] { 0x00000000C0000000L, 0x0400000040080004L, 0x0000000020000410L, 0x0000080400000000L, 0x0000000000008000L });
  public static final BitSet FOLLOW_grantOptionFor_in_revokePrivileges7765 = new BitSet(
      new long[] { 0x00000000C0000000L, 0x0000000040080004L, 0x0000000020000410L, 0x0000080400000000L, 0x0000000000008000L });
  public static final BitSet FOLLOW_privilegeList_in_revokePrivileges7768 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0040000000000000L, 0x0001000000000000L });
  public static final BitSet FOLLOW_privilegeObject_in_revokePrivileges7770 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0040000000000000L });
  public static final BitSet FOLLOW_KW_FROM_in_revokePrivileges7773 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0800000000000000L, 0x0000000000000000L, 0x0000000008000000L, 0x0000000000040000L });
  public static final BitSet FOLLOW_principalSpecification_in_revokePrivileges7775 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_GRANT_in_grantRole7822 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_KW_ROLE_in_grantRole7824 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_identifier_in_grantRole7827 =
      new BitSet(new long[] { 0x0000000000000400L, 0x0000000000000000L, 0x0000000000000000L, 0x8000000000000000L });
  public static final BitSet FOLLOW_COMMA_in_grantRole7830 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_identifier_in_grantRole7832 =
      new BitSet(new long[] { 0x0000000000000400L, 0x0000000000000000L, 0x0000000000000000L, 0x8000000000000000L });
  public static final BitSet FOLLOW_KW_TO_in_grantRole7836 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0800000000000000L, 0x0000000000000000L, 0x0000000008000000L, 0x0000000000040000L });
  public static final BitSet FOLLOW_principalSpecification_in_grantRole7838 = new BitSet(
      new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000040000000L });
  public static final BitSet FOLLOW_withAdminOption_in_grantRole7840 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_REVOKE_in_revokeRole7886 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_adminOptionFor_in_revokeRole7888 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_KW_ROLE_in_revokeRole7891 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_identifier_in_revokeRole7894 =
      new BitSet(new long[] { 0x0000000000000400L, 0x0040000000000000L });
  public static final BitSet FOLLOW_COMMA_in_revokeRole7897 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_identifier_in_revokeRole7899 =
      new BitSet(new long[] { 0x0000000000000400L, 0x0040000000000000L });
  public static final BitSet FOLLOW_KW_FROM_in_revokeRole7903 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0800000000000000L, 0x0000000000000000L, 0x0000000008000000L, 0x0000000000040000L });
  public static final BitSet FOLLOW_principalSpecification_in_revokeRole7905 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SHOW_in_showRoleGrants7950 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000008000000L });
  public static final BitSet FOLLOW_KW_ROLE_in_showRoleGrants7952 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0400000000000000L });
  public static final BitSet FOLLOW_KW_GRANT_in_showRoleGrants7954 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0800000000000000L, 0x0000000000000000L, 0x0000000008000000L, 0x0000000000040000L });
  public static final BitSet FOLLOW_principalName_in_showRoleGrants7956 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SHOW_in_showRoles7996 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000010000000L });
  public static final BitSet FOLLOW_KW_ROLES_in_showRoles7998 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SHOW_in_showCurrentRole8035 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000020L });
  public static final BitSet FOLLOW_KW_CURRENT_in_showCurrentRole8037 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000010000000L });
  public static final BitSet FOLLOW_KW_ROLES_in_showCurrentRole8039 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SET_in_setRole8076 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000008000000L });
  public static final BitSet FOLLOW_KW_ROLE_in_setRole8078 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_identifier_in_setRole8082 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SHOW_in_showGrants8122 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0400000000000000L });
  public static final BitSet FOLLOW_KW_GRANT_in_showGrants8124 = new BitSet(
      new long[] { 0x0000000000000002L, 0x0800000000000000L, 0x0001000000000000L, 0x0000000008000000L, 0x0000000000040000L });
  public static final BitSet FOLLOW_principalName_in_showGrants8126 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0001000000000000L });
  public static final BitSet FOLLOW_KW_ON_in_showGrants8130 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFF16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_privilegeIncludeColObject_in_showGrants8132 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SHOW_in_showRolePrincipals8177 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000010L });
  public static final BitSet FOLLOW_KW_PRINCIPALS_in_showRolePrincipals8179 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_identifier_in_showRolePrincipals8183 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_ALL_in_privilegeIncludeColObject8224 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_privObjectCols_in_privilegeIncludeColObject8238 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_ON_in_privilegeObject8273 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFF16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_privObject_in_privilegeObject8275 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_DATABASE_in_privObject8302 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_KW_SCHEMA_in_privObject8304 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_identifier_in_privObject8307 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_TABLE_in_privObject8323 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_tableName_in_privObject8326 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x1000000000000000L });
  public static final BitSet FOLLOW_partitionSpec_in_privObject8328 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_URI_in_privObject8348 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_privObject8353 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SERVER_in_privObject8372 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_identifier_in_privObject8374 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_DATABASE_in_privObjectCols8400 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_KW_SCHEMA_in_privObjectCols8402 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_identifier_in_privObjectCols8405 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_TABLE_in_privObjectCols8421 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_tableName_in_privObjectCols8424 = new BitSet(
      new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x1000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_LPAREN_in_privObjectCols8427 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_columnNameList_in_privObjectCols8431 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L });
  public static final BitSet FOLLOW_RPAREN_in_privObjectCols8433 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x1000000000000000L });
  public static final BitSet FOLLOW_partitionSpec_in_privObjectCols8437 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_URI_in_privObjectCols8461 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_privObjectCols8466 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SERVER_in_privObjectCols8485 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_identifier_in_privObjectCols8487 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_privlegeDef_in_privilegeList8522 = new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_COMMA_in_privilegeList8525 = new BitSet(
      new long[] { 0x00000000C0000000L, 0x0000000040080004L, 0x0000000020000410L, 0x0000080400000000L, 0x0000000000008000L });
  public static final BitSet FOLLOW_privlegeDef_in_privilegeList8527 = new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_privilegeType_in_privlegeDef8569 = new BitSet(
      new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_LPAREN_in_privlegeDef8572 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_columnNameList_in_privlegeDef8576 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L });
  public static final BitSet FOLLOW_RPAREN_in_privlegeDef8578 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_ALL_in_privilegeType8623 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_ALTER_in_privilegeType8637 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_UPDATE_in_privilegeType8651 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_CREATE_in_privilegeType8665 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_DROP_in_privilegeType8679 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_INDEX_in_privilegeType8693 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_LOCK_in_privilegeType8707 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SELECT_in_privilegeType8721 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SHOW_DATABASE_in_privilegeType8735 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_INSERT_in_privilegeType8749 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_DELETE_in_privilegeType8763 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_principalName_in_principalSpecification8796 =
      new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_COMMA_in_principalSpecification8799 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0800000000000000L, 0x0000000000000000L, 0x0000000008000000L, 0x0000000000040000L });
  public static final BitSet FOLLOW_principalName_in_principalSpecification8801 =
      new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_KW_USER_in_principalName8839 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000080052FFF77BL });
  public static final BitSet FOLLOW_principalIdentifier_in_principalName8841 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_GROUP_in_principalName8857 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000080052FFF77BL });
  public static final BitSet FOLLOW_principalIdentifier_in_principalName8859 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_ROLE_in_principalName8875 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_identifier_in_principalName8877 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_WITH_in_withGrantOption8912 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0400000000000000L });
  public static final BitSet FOLLOW_KW_GRANT_in_withGrantOption8914 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0002000000000000L });
  public static final BitSet FOLLOW_KW_OPTION_in_withGrantOption8916 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_GRANT_in_grantOptionFor8953 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0002000000000000L });
  public static final BitSet FOLLOW_KW_OPTION_in_grantOptionFor8955 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_KW_FOR_in_grantOptionFor8957 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_ADMIN_in_adminOptionFor8990 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0002000000000000L });
  public static final BitSet FOLLOW_KW_OPTION_in_adminOptionFor8992 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_KW_FOR_in_adminOptionFor8994 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_WITH_in_withAdminOption9027 = new BitSet(new long[] { 0x0000000010000000L });
  public static final BitSet FOLLOW_KW_ADMIN_in_withAdminOption9029 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0002000000000000L });
  public static final BitSet FOLLOW_KW_OPTION_in_withAdminOption9031 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_MSCK_in_metastoreCheck9068 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000080000L });
  public static final BitSet FOLLOW_KW_REPAIR_in_metastoreCheck9073 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L });
  public static final BitSet FOLLOW_KW_TABLE_in_metastoreCheck9078 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_tableName_in_metastoreCheck9080 =
      new BitSet(new long[] { 0x0000000000000402L, 0x0000000000000000L, 0x1000000000000000L });
  public static final BitSet FOLLOW_partitionSpec_in_metastoreCheck9082 =
      new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_COMMA_in_metastoreCheck9086 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x1000000000000000L });
  public static final BitSet FOLLOW_partitionSpec_in_metastoreCheck9088 =
      new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_resource_in_resourceList9141 = new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_COMMA_in_resourceList9144 =
      new BitSet(new long[] { 0x0000000400000000L, 0x0000400000000000L, 0x0000000000010000L });
  public static final BitSet FOLLOW_resource_in_resourceList9146 = new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_resourceType_in_resource9184 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_resource9188 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_JAR_in_resourceType9225 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_FILE_in_resourceType9239 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_ARCHIVE_in_resourceType9253 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_CREATE_in_createFunctionStatement9284 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0100000000000000L, 0x0000000000000000L, 0x0400000000000000L });
  public static final BitSet FOLLOW_KW_TEMPORARY_in_createFunctionStatement9289 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0100000000000000L });
  public static final BitSet FOLLOW_KW_FUNCTION_in_createFunctionStatement9293 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_functionIdentifier_in_createFunctionStatement9295 =
      new BitSet(new long[] { 0x0000001000000000L });
  public static final BitSet FOLLOW_KW_AS_in_createFunctionStatement9297 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_createFunctionStatement9299 = new BitSet(
      new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000080000L });
  public static final BitSet FOLLOW_KW_USING_in_createFunctionStatement9308 =
      new BitSet(new long[] { 0x0000000400000000L, 0x0000400000000000L, 0x0000000000010000L });
  public static final BitSet FOLLOW_resourceList_in_createFunctionStatement9312 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_DROP_in_dropFunctionStatement9398 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0100000000000000L, 0x0000000000000000L, 0x0400000000000000L });
  public static final BitSet FOLLOW_KW_TEMPORARY_in_dropFunctionStatement9403 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0100000000000000L });
  public static final BitSet FOLLOW_KW_FUNCTION_in_dropFunctionStatement9407 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFFL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_ifExists_in_dropFunctionStatement9409 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_functionIdentifier_in_dropFunctionStatement9412 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_RELOAD_in_reloadFunctionStatement9490 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0100000000000000L });
  public static final BitSet FOLLOW_KW_FUNCTION_in_reloadFunctionStatement9492 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_CREATE_in_createMacroStatement9520 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0400000000000000L });
  public static final BitSet FOLLOW_KW_TEMPORARY_in_createMacroStatement9522 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000200000000L });
  public static final BitSet FOLLOW_KW_MACRO_in_createMacroStatement9524 =
      new BitSet(new long[] { 0x0000000004000000L });
  public static final BitSet FOLLOW_Identifier_in_createMacroStatement9526 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_LPAREN_in_createMacroStatement9534 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000200052FFF77BL });
  public static final BitSet FOLLOW_columnNameTypeList_in_createMacroStatement9536 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L });
  public static final BitSet FOLLOW_RPAREN_in_createMacroStatement9539 = new BitSet(
      new long[] { 0xFDEFFFFDFC042080L, 0xDEBBFDEAF7FFFBD6L, 0xF6FAFF7DFFBDFFFFL, 0xEEFFFFFBFFFF7FF9L, 0x003C032452FFF77BL });
  public static final BitSet FOLLOW_expression_in_createMacroStatement9541 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_DROP_in_dropMacroStatement9585 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0400000000000000L });
  public static final BitSet FOLLOW_KW_TEMPORARY_in_dropMacroStatement9587 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000200000000L });
  public static final BitSet FOLLOW_KW_MACRO_in_dropMacroStatement9589 =
      new BitSet(new long[] { 0x0000000004000000L, 0x0000000000000000L, 0x0000000000000001L });
  public static final BitSet FOLLOW_ifExists_in_dropMacroStatement9591 = new BitSet(new long[] { 0x0000000004000000L });
  public static final BitSet FOLLOW_Identifier_in_dropMacroStatement9594 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_CREATE_in_createViewStatement9636 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0004000000000000L, 0x0000000000000000L, 0x0000000002000000L });
  public static final BitSet FOLLOW_orReplace_in_createViewStatement9639 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000002000000L });
  public static final BitSet FOLLOW_KW_VIEW_in_createViewStatement9643 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFFL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_ifNotExists_in_createViewStatement9646 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_tableName_in_createViewStatement9652 = new BitSet(
      new long[] { 0x0800001000000000L, 0x0000000000000000L, 0x2000000000000000L, 0x0200000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_LPAREN_in_createViewStatement9663 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_columnNameCommentList_in_createViewStatement9665 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L });
  public static final BitSet FOLLOW_RPAREN_in_createViewStatement9667 =
      new BitSet(new long[] { 0x0800001000000000L, 0x0000000000000000L, 0x2000000000000000L, 0x0200000000000000L });
  public static final BitSet FOLLOW_tableComment_in_createViewStatement9671 =
      new BitSet(new long[] { 0x0000001000000000L, 0x0000000000000000L, 0x2000000000000000L, 0x0200000000000000L });
  public static final BitSet FOLLOW_viewPartition_in_createViewStatement9674 =
      new BitSet(new long[] { 0x0000001000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0200000000000000L });
  public static final BitSet FOLLOW_tablePropertiesPrefixed_in_createViewStatement9685 =
      new BitSet(new long[] { 0x0000001000000000L });
  public static final BitSet FOLLOW_KW_AS_in_createViewStatement9696 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L, 0x0000000400008000L, 0x0000000040000000L });
  public static final BitSet FOLLOW_selectStatementWithCTE_in_createViewStatement9706 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_PARTITIONED_in_viewPartition9829 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0001000000000000L });
  public static final BitSet FOLLOW_KW_ON_in_viewPartition9831 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_LPAREN_in_viewPartition9833 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_columnNameList_in_viewPartition9835 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L });
  public static final BitSet FOLLOW_RPAREN_in_viewPartition9837 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_DROP_in_dropViewStatement9876 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000002000000L });
  public static final BitSet FOLLOW_KW_VIEW_in_dropViewStatement9878 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFFL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_ifExists_in_dropViewStatement9880 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_viewName_in_dropViewStatement9883 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_functionIdentifier_in_showFunctionIdentifier9921 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_StringLiteral_in_showFunctionIdentifier9929 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_identifier_in_showStmtIdentifier9956 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_StringLiteral_in_showStmtIdentifier9964 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_COMMENT_in_tableComment9997 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_tableComment10001 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_PARTITIONED_in_tablePartition10038 =
      new BitSet(new long[] { 0x0000800000000000L });
  public static final BitSet FOLLOW_KW_BY_in_tablePartition10040 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_LPAREN_in_tablePartition10042 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_columnNameTypeList_in_tablePartition10044 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L });
  public static final BitSet FOLLOW_RPAREN_in_tablePartition10046 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_CLUSTERED_in_tableBuckets10091 = new BitSet(new long[] { 0x0000800000000000L });
  public static final BitSet FOLLOW_KW_BY_in_tableBuckets10093 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_LPAREN_in_tableBuckets10095 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_columnNameList_in_tableBuckets10099 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L });
  public static final BitSet FOLLOW_RPAREN_in_tableBuckets10101 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000002000L, 0x0000800000000000L });
  public static final BitSet FOLLOW_KW_SORTED_in_tableBuckets10104 = new BitSet(new long[] { 0x0000800000000000L });
  public static final BitSet FOLLOW_KW_BY_in_tableBuckets10106 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_LPAREN_in_tableBuckets10108 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_columnNameOrderList_in_tableBuckets10112 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L });
  public static final BitSet FOLLOW_RPAREN_in_tableBuckets10114 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000002000L });
  public static final BitSet FOLLOW_KW_INTO_in_tableBuckets10118 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000010000000000L });
  public static final BitSet FOLLOW_Number_in_tableBuckets10122 = new BitSet(new long[] { 0x0000400000000000L });
  public static final BitSet FOLLOW_KW_BUCKETS_in_tableBuckets10124 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SKEWED_in_tableSkewed10176 = new BitSet(new long[] { 0x0000800000000000L });
  public static final BitSet FOLLOW_KW_BY_in_tableSkewed10178 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_LPAREN_in_tableSkewed10180 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_columnNameList_in_tableSkewed10184 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L });
  public static final BitSet FOLLOW_RPAREN_in_tableSkewed10186 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0001000000000000L });
  public static final BitSet FOLLOW_KW_ON_in_tableSkewed10188 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_LPAREN_in_tableSkewed10190 = new BitSet(
      new long[] { 0x0000000000042080L, 0x0000080000001000L, 0x0000000000000000L, 0x2000000000000000L, 0x002C010400000010L });
  public static final BitSet FOLLOW_skewedValueElement_in_tableSkewed10195 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L });
  public static final BitSet FOLLOW_RPAREN_in_tableSkewed10198 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0004000000000000L });
  public static final BitSet FOLLOW_storedAsDirs_in_tableSkewed10201 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_rowFormatSerde_in_rowFormat10249 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_rowFormatDelimited_in_rowFormat10265 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_RECORDREADER_in_recordReader10314 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_recordReader10316 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_RECORDWRITER_in_recordWriter10365 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_recordWriter10367 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_ROW_in_rowFormatSerde10416 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0010000000000000L });
  public static final BitSet FOLLOW_KW_FORMAT_in_rowFormatSerde10418 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000001000000000L });
  public static final BitSet FOLLOW_KW_SERDE_in_rowFormatSerde10420 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_rowFormatSerde10424 = new BitSet(
      new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000040000000L });
  public static final BitSet FOLLOW_KW_WITH_in_rowFormatSerde10427 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000002000000000L });
  public static final BitSet FOLLOW_KW_SERDEPROPERTIES_in_rowFormatSerde10429 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_tableProperties_in_rowFormatSerde10433 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_ROW_in_rowFormatDelimited10485 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0010000000000000L });
  public static final BitSet FOLLOW_KW_FORMAT_in_rowFormatDelimited10487 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000100000L });
  public static final BitSet FOLLOW_KW_DELIMITED_in_rowFormatDelimited10489 =
      new BitSet(new long[] { 0x0100000000000002L, 0x0000200000000000L, 0x0000200402000000L });
  public static final BitSet FOLLOW_tableRowFormatFieldIdentifier_in_rowFormatDelimited10491 =
      new BitSet(new long[] { 0x0100000000000002L, 0x0000000000000000L, 0x0000200402000000L });
  public static final BitSet FOLLOW_tableRowFormatCollItemsIdentifier_in_rowFormatDelimited10494 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000200402000000L });
  public static final BitSet FOLLOW_tableRowFormatMapKeysIdentifier_in_rowFormatDelimited10497 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000200002000000L });
  public static final BitSet FOLLOW_tableRowFormatLinesIdentifier_in_rowFormatDelimited10500 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000200000000000L });
  public static final BitSet FOLLOW_tableRowNullFormat_in_rowFormatDelimited10503 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_rowFormatDelimited_in_tableRowFormat10562 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_rowFormatSerde_in_tableRowFormat10582 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_tablePropertiesPrefixed10629 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_tableProperties_in_tablePropertiesPrefixed10632 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_LPAREN_in_tableProperties10665 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_tablePropertiesList_in_tableProperties10667 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L });
  public static final BitSet FOLLOW_RPAREN_in_tableProperties10669 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_keyValueProperty_in_tablePropertiesList10710 =
      new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_COMMA_in_tablePropertiesList10713 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_keyValueProperty_in_tablePropertiesList10715 =
      new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_keyProperty_in_tablePropertiesList10740 =
      new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_COMMA_in_tablePropertiesList10743 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_keyProperty_in_tablePropertiesList10745 =
      new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_StringLiteral_in_keyValueProperty10791 =
      new BitSet(new long[] { 0x0000000000100000L });
  public static final BitSet FOLLOW_EQUAL_in_keyValueProperty10793 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_keyValueProperty10797 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_StringLiteral_in_keyProperty10844 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_FIELDS_in_tableRowFormatFieldIdentifier10888 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0800000000000000L });
  public static final BitSet FOLLOW_KW_TERMINATED_in_tableRowFormatFieldIdentifier10890 =
      new BitSet(new long[] { 0x0000800000000000L });
  public static final BitSet FOLLOW_KW_BY_in_tableRowFormatFieldIdentifier10892 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_tableRowFormatFieldIdentifier10896 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000800000000L });
  public static final BitSet FOLLOW_KW_ESCAPED_in_tableRowFormatFieldIdentifier10899 =
      new BitSet(new long[] { 0x0000800000000000L });
  public static final BitSet FOLLOW_KW_BY_in_tableRowFormatFieldIdentifier10901 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_tableRowFormatFieldIdentifier10905 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_COLLECTION_in_tableRowFormatCollItemsIdentifier10957 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000008000L });
  public static final BitSet FOLLOW_KW_ITEMS_in_tableRowFormatCollItemsIdentifier10959 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0800000000000000L });
  public static final BitSet FOLLOW_KW_TERMINATED_in_tableRowFormatCollItemsIdentifier10961 =
      new BitSet(new long[] { 0x0000800000000000L });
  public static final BitSet FOLLOW_KW_BY_in_tableRowFormatCollItemsIdentifier10963 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_tableRowFormatCollItemsIdentifier10967 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_MAP_in_tableRowFormatMapKeysIdentifier11013 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000040000L });
  public static final BitSet FOLLOW_KW_KEYS_in_tableRowFormatMapKeysIdentifier11015 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0800000000000000L });
  public static final BitSet FOLLOW_KW_TERMINATED_in_tableRowFormatMapKeysIdentifier11017 =
      new BitSet(new long[] { 0x0000800000000000L });
  public static final BitSet FOLLOW_KW_BY_in_tableRowFormatMapKeysIdentifier11019 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_tableRowFormatMapKeysIdentifier11023 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_LINES_in_tableRowFormatLinesIdentifier11069 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0800000000000000L });
  public static final BitSet FOLLOW_KW_TERMINATED_in_tableRowFormatLinesIdentifier11071 =
      new BitSet(new long[] { 0x0000800000000000L });
  public static final BitSet FOLLOW_KW_BY_in_tableRowFormatLinesIdentifier11073 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_tableRowFormatLinesIdentifier11077 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_NULL_in_tableRowNullFormat11123 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000040000L });
  public static final BitSet FOLLOW_KW_DEFINED_in_tableRowNullFormat11125 =
      new BitSet(new long[] { 0x0000001000000000L });
  public static final BitSet FOLLOW_KW_AS_in_tableRowNullFormat11127 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_tableRowNullFormat11131 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_STORED_in_tableFileFormat11176 = new BitSet(new long[] { 0x0000001000000000L });
  public static final BitSet FOLLOW_KW_AS_in_tableFileFormat11178 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000200L });
  public static final BitSet FOLLOW_KW_INPUTFORMAT_in_tableFileFormat11180 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_tableFileFormat11184 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0080000000000000L });
  public static final BitSet FOLLOW_KW_OUTPUTFORMAT_in_tableFileFormat11186 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_tableFileFormat11190 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000000000100L });
  public static final BitSet FOLLOW_KW_INPUTDRIVER_in_tableFileFormat11193 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_tableFileFormat11197 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L });
  public static final BitSet FOLLOW_KW_OUTPUTDRIVER_in_tableFileFormat11199 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_tableFileFormat11203 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_STORED_in_tableFileFormat11241 = new BitSet(new long[] { 0x0000800000000000L });
  public static final BitSet FOLLOW_KW_BY_in_tableFileFormat11243 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_tableFileFormat11247 = new BitSet(
      new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000040000000L });
  public static final BitSet FOLLOW_KW_WITH_in_tableFileFormat11259 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000002000000000L });
  public static final BitSet FOLLOW_KW_SERDEPROPERTIES_in_tableFileFormat11261 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_tableProperties_in_tableFileFormat11265 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_STORED_in_tableFileFormat11296 = new BitSet(new long[] { 0x0000001000000000L });
  public static final BitSet FOLLOW_KW_AS_in_tableFileFormat11298 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_identifier_in_tableFileFormat11302 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_columnNameType_in_columnNameTypeList11344 =
      new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_COMMA_in_columnNameTypeList11347 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_columnNameType_in_columnNameTypeList11349 =
      new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_columnNameColonType_in_columnNameColonTypeList11387 =
      new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_COMMA_in_columnNameColonTypeList11390 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_columnNameColonType_in_columnNameColonTypeList11392 =
      new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_columnName_in_columnNameList11430 = new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_COMMA_in_columnNameList11433 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_columnName_in_columnNameList11435 = new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_identifier_in_columnName11479 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_columnNameOrder_in_columnNameOrderList11506 =
      new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_COMMA_in_columnNameOrderList11509 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_columnNameOrder_in_columnNameOrderList11511 =
      new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_skewedColumnValues_in_skewedValueElement11556 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_skewedColumnValuePairList_in_skewedValueElement11565 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_skewedColumnValuePair_in_skewedColumnValuePairList11592 =
      new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_COMMA_in_skewedColumnValuePairList11595 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_skewedColumnValuePair_in_skewedColumnValuePairList11597 =
      new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_LPAREN_in_skewedColumnValuePair11642 = new BitSet(
      new long[] { 0x0000000000042080L, 0x0000080000001000L, 0x0000000000000000L, 0x2000000000000000L, 0x002C010000000010L });
  public static final BitSet FOLLOW_skewedColumnValues_in_skewedColumnValuePair11646 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L });
  public static final BitSet FOLLOW_RPAREN_in_skewedColumnValuePair11648 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_skewedColumnValue_in_skewedColumnValues11691 =
      new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_COMMA_in_skewedColumnValues11694 = new BitSet(
      new long[] { 0x0000000000042080L, 0x0000080000001000L, 0x0000000000000000L, 0x2000000000000000L, 0x002C010000000010L });
  public static final BitSet FOLLOW_skewedColumnValue_in_skewedColumnValues11696 =
      new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_constant_in_skewedColumnValue11740 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_skewedColumnValue_in_skewedValueLocationElement11774 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_skewedColumnValuePair_in_skewedValueLocationElement11783 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_identifier_in_columnNameOrder11814 =
      new BitSet(new long[] { 0x0000002000000002L, 0x0000000000400000L });
  public static final BitSet FOLLOW_KW_ASC_in_columnNameOrder11819 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_DESC_in_columnNameOrder11825 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_columnNameComment_in_columnNameCommentList11897 =
      new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_COMMA_in_columnNameCommentList11900 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_columnNameComment_in_columnNameCommentList11902 =
      new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_identifier_in_columnNameComment11942 =
      new BitSet(new long[] { 0x0800000000000002L });
  public static final BitSet FOLLOW_KW_COMMENT_in_columnNameComment11945 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_columnNameComment11949 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_expression_in_columnRefOrder11997 =
      new BitSet(new long[] { 0x0000002000000002L, 0x0000000000400000L });
  public static final BitSet FOLLOW_KW_ASC_in_columnRefOrder12002 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_DESC_in_columnRefOrder12008 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_identifier_in_columnNameType12082 = new BitSet(
      new long[] { 0x00100E0800000000L, 0x000200002000B000L, 0x0000000400000800L, 0x6030200000000000L, 0x0000000001000400L });
  public static final BitSet FOLLOW_colType_in_columnNameType12084 = new BitSet(new long[] { 0x0800000000000002L });
  public static final BitSet FOLLOW_KW_COMMENT_in_columnNameType12087 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_columnNameType12091 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_identifier_in_columnNameColonType12177 =
      new BitSet(new long[] { 0x0000000000000200L });
  public static final BitSet FOLLOW_COLON_in_columnNameColonType12179 = new BitSet(
      new long[] { 0x00100E0800000000L, 0x000200002000B000L, 0x0000000400000800L, 0x6030200000000000L, 0x0000000001000400L });
  public static final BitSet FOLLOW_colType_in_columnNameColonType12181 =
      new BitSet(new long[] { 0x0800000000000002L });
  public static final BitSet FOLLOW_KW_COMMENT_in_columnNameColonType12184 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_columnNameColonType12188 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_type_in_colType12272 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_colType_in_colTypeList12299 = new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_COMMA_in_colTypeList12302 = new BitSet(
      new long[] { 0x00100E0800000000L, 0x000200002000B000L, 0x0000000400000800L, 0x6030200000000000L, 0x0000000001000400L });
  public static final BitSet FOLLOW_colType_in_colTypeList12304 = new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_primitiveType_in_type12332 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_listType_in_type12340 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_structType_in_type12348 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_mapType_in_type12356 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_unionType_in_type12364 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_TINYINT_in_primitiveType12386 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SMALLINT_in_primitiveType12407 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_INT_in_primitiveType12427 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_BIGINT_in_primitiveType12452 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_BOOLEAN_in_primitiveType12474 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_FLOAT_in_primitiveType12495 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_DOUBLE_in_primitiveType12518 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_DATE_in_primitiveType12540 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_DATETIME_in_primitiveType12564 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_TIMESTAMP_in_primitiveType12584 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_STRING_in_primitiveType12603 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_BINARY_in_primitiveType12625 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_DECIMAL_in_primitiveType12647 = new BitSet(
      new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_LPAREN_in_primitiveType12650 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000010000000000L });
  public static final BitSet FOLLOW_Number_in_primitiveType12654 = new BitSet(
      new long[] { 0x0000000000000400L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L });
  public static final BitSet FOLLOW_COMMA_in_primitiveType12657 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000010000000000L });
  public static final BitSet FOLLOW_Number_in_primitiveType12661 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L });
  public static final BitSet FOLLOW_RPAREN_in_primitiveType12665 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_VARCHAR_in_primitiveType12689 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_LPAREN_in_primitiveType12691 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000010000000000L });
  public static final BitSet FOLLOW_Number_in_primitiveType12695 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L });
  public static final BitSet FOLLOW_RPAREN_in_primitiveType12697 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_CHAR_in_primitiveType12722 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_LPAREN_in_primitiveType12724 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000010000000000L });
  public static final BitSet FOLLOW_Number_in_primitiveType12728 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L });
  public static final BitSet FOLLOW_RPAREN_in_primitiveType12730 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_ARRAY_in_listType12774 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000100000000L });
  public static final BitSet FOLLOW_LESSTHAN_in_listType12776 = new BitSet(
      new long[] { 0x00100E0800000000L, 0x000200002000B000L, 0x0000000400000800L, 0x6030200000000000L, 0x0000000001000400L });
  public static final BitSet FOLLOW_type_in_listType12778 = new BitSet(new long[] { 0x0000000000800000L });
  public static final BitSet FOLLOW_GREATERTHAN_in_listType12780 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_STRUCT_in_structType12817 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000100000000L });
  public static final BitSet FOLLOW_LESSTHAN_in_structType12819 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_columnNameColonTypeList_in_structType12821 =
      new BitSet(new long[] { 0x0000000000800000L });
  public static final BitSet FOLLOW_GREATERTHAN_in_structType12823 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_MAP_in_mapType12858 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000100000000L });
  public static final BitSet FOLLOW_LESSTHAN_in_mapType12860 = new BitSet(
      new long[] { 0x00100E0000000000L, 0x000200002000B000L, 0x0000000000000800L, 0x6010200000000000L, 0x0000000001000000L });
  public static final BitSet FOLLOW_primitiveType_in_mapType12864 = new BitSet(new long[] { 0x0000000000000400L });
  public static final BitSet FOLLOW_COMMA_in_mapType12866 = new BitSet(
      new long[] { 0x00100E0800000000L, 0x000200002000B000L, 0x0000000400000800L, 0x6030200000000000L, 0x0000000001000400L });
  public static final BitSet FOLLOW_type_in_mapType12870 = new BitSet(new long[] { 0x0000000000800000L });
  public static final BitSet FOLLOW_GREATERTHAN_in_mapType12872 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_UNIONTYPE_in_unionType12915 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000100000000L });
  public static final BitSet FOLLOW_LESSTHAN_in_unionType12917 = new BitSet(
      new long[] { 0x00100E0800000000L, 0x000200002000B000L, 0x0000000400000800L, 0x6030200000000000L, 0x0000000001000400L });
  public static final BitSet FOLLOW_colTypeList_in_unionType12919 = new BitSet(new long[] { 0x0000000000800000L });
  public static final BitSet FOLLOW_GREATERTHAN_in_unionType12921 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_UNION_in_setOperator12956 = new BitSet(new long[] { 0x0000000040000000L });
  public static final BitSet FOLLOW_KW_ALL_in_setOperator12958 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_withClause_in_queryStatementExpression12995 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0040000000000000L, 0x0000000400000400L, 0x0000000400008000L });
  public static final BitSet FOLLOW_queryStatementExpressionBody_in_queryStatementExpression13005 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_fromStatement_in_queryStatementExpressionBody13039 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_regularBody_in_queryStatementExpressionBody13048 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_WITH_in_withClause13066 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_cteStatement_in_withClause13068 = new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_COMMA_in_withClause13071 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_cteStatement_in_withClause13073 = new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_identifier_in_cteStatement13099 = new BitSet(new long[] { 0x0000001000000000L });
  public static final BitSet FOLLOW_KW_AS_in_cteStatement13101 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L });
  public static final BitSet FOLLOW_LPAREN_in_cteStatement13103 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0040000000000000L, 0x0000000400000400L, 0x0000000400008000L, 0x0000000040000000L });
  public static final BitSet FOLLOW_queryStatementExpression_in_cteStatement13105 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L });
  public static final BitSet FOLLOW_RPAREN_in_cteStatement13108 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_singleFromStatement_in_fromStatement13132 = new BitSet(
      new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000200L });
  public static final BitSet FOLLOW_setOperator_in_fromStatement13144 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0040000000000000L });
  public static final BitSet FOLLOW_singleFromStatement_in_fromStatement13148 = new BitSet(
      new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000200L });
  public static final BitSet FOLLOW_fromClause_in_singleFromStatement13355 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000400L, 0x0000000400008000L });
  public static final BitSet FOLLOW_body_in_singleFromStatement13365 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000400000400L, 0x0000000400008000L });
  public static final BitSet FOLLOW_insertClause_in_regularBody13403 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L, 0x0000000400008000L, 0x0000000000400000L });
  public static final BitSet FOLLOW_selectStatement_in_regularBody13415 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_valuesClause_in_regularBody13441 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_selectStatement_in_regularBody13565 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_singleSelectStatement_in_selectStatement13582 = new BitSet(
      new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000200L });
  public static final BitSet FOLLOW_setOperator_in_selectStatement13595 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L, 0x0000000400008000L });
  public static final BitSet FOLLOW_singleSelectStatement_in_selectStatement13599 = new BitSet(
      new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000200L });
  public static final BitSet FOLLOW_selectClause_in_singleSelectStatement13821 = new BitSet(
      new long[] { 0x0020000000000002L, 0x2840000010000000L, 0x0008000001000000L, 0x0000400000000000L, 0x0000000028000000L });
  public static final BitSet FOLLOW_fromClause_in_singleSelectStatement13826 = new BitSet(
      new long[] { 0x0020000000000002L, 0x2800000010000000L, 0x0008000001000000L, 0x0000400000000000L, 0x0000000028000000L });
  public static final BitSet FOLLOW_whereClause_in_singleSelectStatement13832 = new BitSet(
      new long[] { 0x0020000000000002L, 0x2800000010000000L, 0x0008000001000000L, 0x0000400000000000L, 0x0000000020000000L });
  public static final BitSet FOLLOW_groupByClause_in_singleSelectStatement13838 = new BitSet(
      new long[] { 0x0020000000000002L, 0x2000000010000000L, 0x0008000001000000L, 0x0000400000000000L, 0x0000000020000000L });
  public static final BitSet FOLLOW_havingClause_in_singleSelectStatement13844 = new BitSet(
      new long[] { 0x0020000000000002L, 0x0000000010000000L, 0x0008000001000000L, 0x0000400000000000L, 0x0000000020000000L });
  public static final BitSet FOLLOW_orderByClause_in_singleSelectStatement13850 = new BitSet(
      new long[] { 0x0020000000000002L, 0x0000000010000000L, 0x0000000001000000L, 0x0000400000000000L, 0x0000000020000000L });
  public static final BitSet FOLLOW_clusterByClause_in_singleSelectStatement13856 = new BitSet(
      new long[] { 0x0000000000000002L, 0x0000000010000000L, 0x0000000001000000L, 0x0000400000000000L, 0x0000000020000000L });
  public static final BitSet FOLLOW_distributeByClause_in_singleSelectStatement13862 = new BitSet(
      new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000001000000L, 0x0000400000000000L, 0x0000000020000000L });
  public static final BitSet FOLLOW_sortByClause_in_singleSelectStatement13868 = new BitSet(
      new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000001000000L, 0x0000000000000000L, 0x0000000020000000L });
  public static final BitSet FOLLOW_window_clause_in_singleSelectStatement13874 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000001000000L });
  public static final BitSet FOLLOW_limitClause_in_singleSelectStatement13880 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_withClause_in_selectStatementWithCTE13998 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L, 0x0000000400008000L });
  public static final BitSet FOLLOW_selectStatement_in_selectStatementWithCTE14006 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_insertClause_in_body14037 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L, 0x0000000400008000L });
  public static final BitSet FOLLOW_selectClause_in_body14042 = new BitSet(
      new long[] { 0x0020000000000002L, 0x2800000010000000L, 0x0008000001100000L, 0x0000400000000000L, 0x0000000028000000L });
  public static final BitSet FOLLOW_lateralView_in_body14047 = new BitSet(
      new long[] { 0x0020000000000002L, 0x2800000010000000L, 0x0008000001000000L, 0x0000400000000000L, 0x0000000028000000L });
  public static final BitSet FOLLOW_whereClause_in_body14053 = new BitSet(
      new long[] { 0x0020000000000002L, 0x2800000010000000L, 0x0008000001000000L, 0x0000400000000000L, 0x0000000020000000L });
  public static final BitSet FOLLOW_groupByClause_in_body14059 = new BitSet(
      new long[] { 0x0020000000000002L, 0x2000000010000000L, 0x0008000001000000L, 0x0000400000000000L, 0x0000000020000000L });
  public static final BitSet FOLLOW_havingClause_in_body14065 = new BitSet(
      new long[] { 0x0020000000000002L, 0x0000000010000000L, 0x0008000001000000L, 0x0000400000000000L, 0x0000000020000000L });
  public static final BitSet FOLLOW_orderByClause_in_body14071 = new BitSet(
      new long[] { 0x0020000000000002L, 0x0000000010000000L, 0x0000000001000000L, 0x0000400000000000L, 0x0000000020000000L });
  public static final BitSet FOLLOW_clusterByClause_in_body14077 = new BitSet(
      new long[] { 0x0000000000000002L, 0x0000000010000000L, 0x0000000001000000L, 0x0000400000000000L, 0x0000000020000000L });
  public static final BitSet FOLLOW_distributeByClause_in_body14083 = new BitSet(
      new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000001000000L, 0x0000400000000000L, 0x0000000020000000L });
  public static final BitSet FOLLOW_sortByClause_in_body14089 = new BitSet(
      new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000001000000L, 0x0000000000000000L, 0x0000000020000000L });
  public static final BitSet FOLLOW_window_clause_in_body14095 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000001000000L });
  public static final BitSet FOLLOW_limitClause_in_body14101 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_selectClause_in_body14194 = new BitSet(
      new long[] { 0x0020000000000002L, 0x2800000010000000L, 0x0008000001100000L, 0x0000400000000000L, 0x0000000028000000L });
  public static final BitSet FOLLOW_lateralView_in_body14199 = new BitSet(
      new long[] { 0x0020000000000002L, 0x2800000010000000L, 0x0008000001000000L, 0x0000400000000000L, 0x0000000028000000L });
  public static final BitSet FOLLOW_whereClause_in_body14205 = new BitSet(
      new long[] { 0x0020000000000002L, 0x2800000010000000L, 0x0008000001000000L, 0x0000400000000000L, 0x0000000020000000L });
  public static final BitSet FOLLOW_groupByClause_in_body14211 = new BitSet(
      new long[] { 0x0020000000000002L, 0x2000000010000000L, 0x0008000001000000L, 0x0000400000000000L, 0x0000000020000000L });
  public static final BitSet FOLLOW_havingClause_in_body14217 = new BitSet(
      new long[] { 0x0020000000000002L, 0x0000000010000000L, 0x0008000001000000L, 0x0000400000000000L, 0x0000000020000000L });
  public static final BitSet FOLLOW_orderByClause_in_body14223 = new BitSet(
      new long[] { 0x0020000000000002L, 0x0000000010000000L, 0x0000000001000000L, 0x0000400000000000L, 0x0000000020000000L });
  public static final BitSet FOLLOW_clusterByClause_in_body14229 = new BitSet(
      new long[] { 0x0000000000000002L, 0x0000000010000000L, 0x0000000001000000L, 0x0000400000000000L, 0x0000000020000000L });
  public static final BitSet FOLLOW_distributeByClause_in_body14235 = new BitSet(
      new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000001000000L, 0x0000400000000000L, 0x0000000020000000L });
  public static final BitSet FOLLOW_sortByClause_in_body14241 = new BitSet(
      new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000001000000L, 0x0000000000000000L, 0x0000000020000000L });
  public static final BitSet FOLLOW_window_clause_in_body14247 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000001000000L });
  public static final BitSet FOLLOW_limitClause_in_body14253 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_INSERT_in_insertClause14374 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0200000000000000L });
  public static final BitSet FOLLOW_KW_OVERWRITE_in_insertClause14376 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000002000000L, 0x0000000008000000L, 0x0040000000000000L });
  public static final BitSet FOLLOW_destination_in_insertClause14378 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000000000001L });
  public static final BitSet FOLLOW_ifNotExists_in_insertClause14380 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_INSERT_in_insertClause14399 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000002000L });
  public static final BitSet FOLLOW_KW_INTO_in_insertClause14401 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_KW_TABLE_in_insertClause14403 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_tableOrPartition_in_insertClause14406 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_LOCAL_in_destination14456 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000002000000L });
  public static final BitSet FOLLOW_KW_DIRECTORY_in_destination14460 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L });
  public static final BitSet FOLLOW_StringLiteral_in_destination14462 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0004000040000000L });
  public static final BitSet FOLLOW_tableRowFormat_in_destination14464 =
      new BitSet(new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0004000000000000L });
  public static final BitSet FOLLOW_tableFileFormat_in_destination14467 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_TABLE_in_destination14500 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_tableOrPartition_in_destination14502 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_LIMIT_in_limitClause14534 = new BitSet(
      new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000010000000000L });
  public static final BitSet FOLLOW_Number_in_limitClause14538 = new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_DELETE_in_deleteStatement14576 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0040000000000000L });
  public static final BitSet FOLLOW_KW_FROM_in_deleteStatement14578 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_tableName_in_deleteStatement14580 = new BitSet(
      new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000008000000L });
  public static final BitSet FOLLOW_whereClause_in_deleteStatement14583 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_tableOrColumn_in_columnAssignmentClause14616 =
      new BitSet(new long[] { 0x0000000000100000L });
  public static final BitSet FOLLOW_EQUAL_in_columnAssignmentClause14618 = new BitSet(
      new long[] { 0xFDEFFFFDFC042080L, 0xDEBBFDEAF7FFFBD6L, 0xF6FAF77DFFBDFFFFL, 0xEEFFFFFBFFFF7FF9L, 0x003C032452FFF77BL });
  public static final BitSet FOLLOW_precedencePlusExpression_in_columnAssignmentClause14621 =
      new BitSet(new long[] { 0x0000000000000002L });
  public static final BitSet FOLLOW_KW_SET_in_setColumnsClause14641 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_columnAssignmentClause_in_setColumnsClause14643 =
      new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_COMMA_in_setColumnsClause14646 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_columnAssignmentClause_in_setColumnsClause14648 =
      new BitSet(new long[] { 0x0000000000000402L });
  public static final BitSet FOLLOW_KW_UPDATE_in_updateStatement14690 = new BitSet(
      new long[] { 0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL });
  public static final BitSet FOLLOW_tableName_in_updateStatement14692 =
      new BitSet(new long[] { 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000008000000000L });
  public static final BitSet FOLLOW_setColumnsClause_in_updateStatement14694 = new BitSet(
      new long[] { 0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000008000000L });
  public static final BitSet FOLLOW_whereClause_in_updateStatement14696 =
      new BitSet(new long[] { 0x0000000000000002L });
}
//spotless:on
