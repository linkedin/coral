// $ANTLR 3.4 org/apache/hadoop/hive/ql/parse/HiveParser.g 2017-10-10 09:21:00

package com.linkedin.coral.hive.hive2rel.parsetree.parser;

import java.util.ArrayList;
import java.util.Collection;
import java.util.HashMap;
import java.util.List;
import java.util.Stack;
import org.antlr.runtime.BaseRecognizer;
import org.antlr.runtime.BitSet;
import org.antlr.runtime.DFA;
import org.antlr.runtime.EarlyExitException;
import org.antlr.runtime.FailedPredicateException;
import org.antlr.runtime.IntStream;
import org.antlr.runtime.MismatchedSetException;
import org.antlr.runtime.MismatchedTokenException;
import org.antlr.runtime.NoViableAltException;
import org.antlr.runtime.Parser;
import org.antlr.runtime.ParserRuleReturnScope;
import org.antlr.runtime.RecognitionException;
import org.antlr.runtime.RecognizerSharedState;
import org.antlr.runtime.RuleReturnScope;
import org.antlr.runtime.Token;
import org.antlr.runtime.TokenStream;
import org.antlr.runtime.tree.CommonTree;
import org.antlr.runtime.tree.CommonTreeAdaptor;
import org.antlr.runtime.tree.RewriteEarlyExitException;
import org.antlr.runtime.tree.RewriteRuleSubtreeStream;
import org.antlr.runtime.tree.RewriteRuleTokenStream;
import org.antlr.runtime.tree.TreeAdaptor;


/**
 Licensed to the Apache Software Foundation (ASF) under one or more
 contributor license agreements.  See the NOTICE file distributed with
 this work for additional information regarding copyright ownership.
 The ASF licenses this file to You under the Apache License, Version 2.0
 (the "License"); you may not use this file except in compliance with
 the License.  You may obtain a copy of the License at

 http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.
 */
//CHECKSTYLE:OFF
@SuppressWarnings({"all", "warnings", "unchecked"})
public class HiveParser extends Parser {
  public static final String[] tokenNames =
      new String[]{"<invalid>", "<EOR>", "<DOWN>", "<UP>", "AMPERSAND", "BITWISEOR", "BITWISEXOR", "BigintLiteral", "ByteLengthLiteral", "COLON", "COMMA", "COMMENT", "CharSetLiteral", "CharSetName", "DIV", "DIVIDE", "DOLLAR", "DOT", "DecimalLiteral", "Digit", "EQUAL", "EQUAL_NS", "Exponent", "GREATERTHAN", "GREATERTHANOREQUALTO", "HexDigit", "Identifier", "KW_ADD", "KW_ADMIN", "KW_AFTER", "KW_ALL", "KW_ALTER", "KW_ANALYZE", "KW_AND", "KW_ARCHIVE", "KW_ARRAY", "KW_AS", "KW_ASC", "KW_AUTHORIZATION", "KW_BEFORE", "KW_BETWEEN", "KW_BIGINT", "KW_BINARY", "KW_BOOLEAN", "KW_BOTH", "KW_BUCKET", "KW_BUCKETS", "KW_BY", "KW_CASCADE", "KW_CASE", "KW_CAST", "KW_CHANGE", "KW_CHAR", "KW_CLUSTER", "KW_CLUSTERED", "KW_CLUSTERSTATUS", "KW_COLLECTION", "KW_COLUMN", "KW_COLUMNS", "KW_COMMENT", "KW_COMPACT", "KW_COMPACTIONS", "KW_COMPUTE", "KW_CONCATENATE", "KW_CONF", "KW_CONTINUE", "KW_CREATE", "KW_CROSS", "KW_CUBE", "KW_CURRENT", "KW_CURRENT_DATE", "KW_CURRENT_TIMESTAMP", "KW_CURSOR", "KW_DATA", "KW_DATABASE", "KW_DATABASES", "KW_DATE", "KW_DATETIME", "KW_DBPROPERTIES", "KW_DECIMAL", "KW_DEFAULT", "KW_DEFERRED", "KW_DEFINED", "KW_DELETE", "KW_DELIMITED", "KW_DEPENDENCY", "KW_DESC", "KW_DESCRIBE", "KW_DIRECTORIES", "KW_DIRECTORY", "KW_DISABLE", "KW_DISTINCT", "KW_DISTRIBUTE", "KW_DOUBLE", "KW_DROP", "KW_ELEM_TYPE", "KW_ELSE", "KW_ENABLE", "KW_END", "KW_ESCAPED", "KW_EXCHANGE", "KW_EXCLUSIVE", "KW_EXISTS", "KW_EXPLAIN", "KW_EXPORT", "KW_EXTENDED", "KW_EXTERNAL", "KW_FALSE", "KW_FETCH", "KW_FIELDS", "KW_FILE", "KW_FILEFORMAT", "KW_FIRST", "KW_FLOAT", "KW_FOLLOWING", "KW_FOR", "KW_FORMAT", "KW_FORMATTED", "KW_FROM", "KW_FULL", "KW_FUNCTION", "KW_FUNCTIONS", "KW_GRANT", "KW_GROUP", "KW_GROUPING", "KW_HAVING", "KW_HOLD_DDLTIME", "KW_IDXPROPERTIES", "KW_IF", "KW_IGNORE", "KW_IMPORT", "KW_IN", "KW_INDEX", "KW_INDEXES", "KW_INNER", "KW_INPATH", "KW_INPUTDRIVER", "KW_INPUTFORMAT", "KW_INSERT", "KW_INT", "KW_INTERSECT", "KW_INTO", "KW_IS", "KW_ITEMS", "KW_JAR", "KW_JOIN", "KW_KEYS", "KW_KEY_TYPE", "KW_LATERAL", "KW_LEFT", "KW_LESS", "KW_LIKE", "KW_LIMIT", "KW_LINES", "KW_LOAD", "KW_LOCAL", "KW_LOCATION", "KW_LOCK", "KW_LOCKS", "KW_LOGICAL", "KW_LONG", "KW_MACRO", "KW_MAP", "KW_MAPJOIN", "KW_MATERIALIZED", "KW_METADATA", "KW_MINUS", "KW_MORE", "KW_MSCK", "KW_NONE", "KW_NOSCAN", "KW_NOT", "KW_NO_DROP", "KW_NULL", "KW_OF", "KW_OFFLINE", "KW_ON", "KW_OPTION", "KW_OR", "KW_ORDER", "KW_OUT", "KW_OUTER", "KW_OUTPUTDRIVER", "KW_OUTPUTFORMAT", "KW_OVER", "KW_OVERWRITE", "KW_OWNER", "KW_PARTIALSCAN", "KW_PARTITION", "KW_PARTITIONED", "KW_PARTITIONS", "KW_PERCENT", "KW_PLUS", "KW_PRECEDING", "KW_PRESERVE", "KW_PRETTY", "KW_PRINCIPALS", "KW_PROCEDURE", "KW_PROTECTION", "KW_PURGE", "KW_RANGE", "KW_READ", "KW_READONLY", "KW_READS", "KW_REBUILD", "KW_RECORDREADER", "KW_RECORDWRITER", "KW_REDUCE", "KW_REGEXP", "KW_RELOAD", "KW_RENAME", "KW_REPAIR", "KW_REPLACE", "KW_REPLICATION", "KW_RESTRICT", "KW_REVOKE", "KW_REWRITE", "KW_RIGHT", "KW_RLIKE", "KW_ROLE", "KW_ROLES", "KW_ROLLUP", "KW_ROW", "KW_ROWS", "KW_SCHEMA", "KW_SCHEMAS", "KW_SELECT", "KW_SEMI", "KW_SERDE", "KW_SERDEPROPERTIES", "KW_SERVER", "KW_SET", "KW_SETS", "KW_SHARED", "KW_SHOW", "KW_SHOW_DATABASE", "KW_SKEWED", "KW_SMALLINT", "KW_SORT", "KW_SORTED", "KW_SSL", "KW_STATISTICS", "KW_STORED", "KW_STREAMTABLE", "KW_STRING", "KW_STRUCT", "KW_TABLE", "KW_TABLES", "KW_TABLESAMPLE", "KW_TBLPROPERTIES", "KW_TEMPORARY", "KW_TERMINATED", "KW_THEN", "KW_TIMESTAMP", "KW_TINYINT", "KW_TO", "KW_TOUCH", "KW_TRANSACTIONS", "KW_TRANSFORM", "KW_TRIGGER", "KW_TRUE", "KW_TRUNCATE", "KW_UNARCHIVE", "KW_UNBOUNDED", "KW_UNDO", "KW_UNION", "KW_UNIONTYPE", "KW_UNIQUEJOIN", "KW_UNLOCK", "KW_UNSET", "KW_UNSIGNED", "KW_UPDATE", "KW_URI", "KW_USE", "KW_USER", "KW_USING", "KW_UTC", "KW_UTCTIMESTAMP", "KW_VALUES", "KW_VALUE_TYPE", "KW_VARCHAR", "KW_VIEW", "KW_WHEN", "KW_WHERE", "KW_WHILE", "KW_WINDOW", "KW_WITH", "LCURLY", "LESSTHAN", "LESSTHANOREQUALTO", "LPAREN", "LSQUARE", "Letter", "MINUS", "MOD", "NOTEQUAL", "Number", "PLUS", "QUESTION", "QuotedIdentifier", "RCURLY", "RPAREN", "RSQUARE", "RegexComponent", "SEMICOLON", "STAR", "SmallintLiteral", "StringLiteral", "TILDE", "TinyintLiteral", "WS", "TOK_ADMIN_OPTION_FOR", "TOK_ALIASLIST", "TOK_ALLCOLREF", "TOK_ALTERDATABASE_OWNER", "TOK_ALTERDATABASE_PROPERTIES", "TOK_ALTERINDEX_PROPERTIES", "TOK_ALTERINDEX_REBUILD", "TOK_ALTERTABLE", "TOK_ALTERTABLE_ADDCOLS", "TOK_ALTERTABLE_ADDPARTS", "TOK_ALTERTABLE_ARCHIVE", "TOK_ALTERTABLE_BUCKETS", "TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION", "TOK_ALTERTABLE_CLUSTER_SORT", "TOK_ALTERTABLE_COMPACT", "TOK_ALTERTABLE_DROPPARTS", "TOK_ALTERTABLE_DROPPROPERTIES", "TOK_ALTERTABLE_EXCHANGEPARTITION", "TOK_ALTERTABLE_FILEFORMAT", "TOK_ALTERTABLE_MERGEFILES", "TOK_ALTERTABLE_PARTCOLTYPE", "TOK_ALTERTABLE_PROPERTIES", "TOK_ALTERTABLE_PROTECTMODE", "TOK_ALTERTABLE_RENAME", "TOK_ALTERTABLE_RENAMECOL", "TOK_ALTERTABLE_RENAMEPART", "TOK_ALTERTABLE_REPLACECOLS", "TOK_ALTERTABLE_SERDEPROPERTIES", "TOK_ALTERTABLE_SERIALIZER", "TOK_ALTERTABLE_SKEWED", "TOK_ALTERTABLE_SKEWED_LOCATION", "TOK_ALTERTABLE_TOUCH", "TOK_ALTERTABLE_UNARCHIVE", "TOK_ALTERTABLE_UPDATECOLSTATS", "TOK_ALTERVIEW", "TOK_ALTERVIEW_ADDPARTS", "TOK_ALTERVIEW_DROPPARTS", "TOK_ALTERVIEW_DROPPROPERTIES", "TOK_ALTERVIEW_PROPERTIES", "TOK_ALTERVIEW_RENAME", "TOK_ANALYZE", "TOK_ANONYMOUS", "TOK_ARCHIVE", "TOK_BIGINT", "TOK_BINARY", "TOK_BOOLEAN", "TOK_CASCADE", "TOK_CHAR", "TOK_CHARSETLITERAL", "TOK_CLUSTERBY", "TOK_COLTYPELIST", "TOK_COL_NAME", "TOK_CREATEDATABASE", "TOK_CREATEFUNCTION", "TOK_CREATEINDEX", "TOK_CREATEINDEX_INDEXTBLNAME", "TOK_CREATEMACRO", "TOK_CREATEROLE", "TOK_CREATETABLE", "TOK_CREATEVIEW", "TOK_CROSSJOIN", "TOK_CTE", "TOK_CUBE_GROUPBY", "TOK_DATABASECOMMENT", "TOK_DATABASEPROPERTIES", "TOK_DATE", "TOK_DATELITERAL", "TOK_DATETIME", "TOK_DBPROPLIST", "TOK_DB_TYPE", "TOK_DECIMAL", "TOK_DEFERRED_REBUILDINDEX", "TOK_DELETE_FROM", "TOK_DESCDATABASE", "TOK_DESCFUNCTION", "TOK_DESCTABLE", "TOK_DESTINATION", "TOK_DIR", "TOK_DISABLE", "TOK_DISTRIBUTEBY", "TOK_DOUBLE", "TOK_DROPDATABASE", "TOK_DROPFUNCTION", "TOK_DROPINDEX", "TOK_DROPMACRO", "TOK_DROPROLE", "TOK_DROPTABLE", "TOK_DROPVIEW", "TOK_ENABLE", "TOK_EXPLAIN", "TOK_EXPLAIN_SQ_REWRITE", "TOK_EXPLIST", "TOK_EXPORT", "TOK_FALSE", "TOK_FILE", "TOK_FILEFORMAT_GENERIC", "TOK_FLOAT", "TOK_FROM", "TOK_FULLOUTERJOIN", "TOK_FUNCTION", "TOK_FUNCTIONDI", "TOK_FUNCTIONSTAR", "TOK_GRANT", "TOK_GRANT_OPTION_FOR", "TOK_GRANT_ROLE", "TOK_GRANT_WITH_ADMIN_OPTION", "TOK_GRANT_WITH_OPTION", "TOK_GROUP", "TOK_GROUPBY", "TOK_GROUPING_SETS", "TOK_GROUPING_SETS_EXPRESSION", "TOK_HAVING", "TOK_HINT", "TOK_HINTARGLIST", "TOK_HINTLIST", "TOK_HOLD_DDLTIME", "TOK_IFEXISTS", "TOK_IFNOTEXISTS", "TOK_IGNOREPROTECTION", "TOK_IMPORT", "TOK_INDEXCOMMENT", "TOK_INDEXPROPERTIES", "TOK_INDEXPROPLIST", "TOK_INSERT", "TOK_INSERT_INTO", "TOK_INT", "TOK_ISNOTNULL", "TOK_ISNULL", "TOK_JAR", "TOK_JOIN", "TOK_LATERAL_VIEW", "TOK_LATERAL_VIEW_OUTER", "TOK_LEFTOUTERJOIN", "TOK_LEFTSEMIJOIN", "TOK_LENGTH", "TOK_LIKETABLE", "TOK_LIMIT", "TOK_LIST", "TOK_LOAD", "TOK_LOCATION", "TOK_LOCKDB", "TOK_LOCKTABLE", "TOK_MAP", "TOK_MAPJOIN", "TOK_METADATA", "TOK_MSCK", "TOK_NOT_CLUSTERED", "TOK_NOT_SORTED", "TOK_NO_DROP", "TOK_NULL", "TOK_OFFLINE", "TOK_OP_ADD", "TOK_OP_AND", "TOK_OP_BITAND", "TOK_OP_BITNOT", "TOK_OP_BITOR", "TOK_OP_BITXOR", "TOK_OP_DIV", "TOK_OP_EQ", "TOK_OP_GE", "TOK_OP_GT", "TOK_OP_LE", "TOK_OP_LIKE", "TOK_OP_LT", "TOK_OP_MOD", "TOK_OP_MUL", "TOK_OP_NE", "TOK_OP_NOT", "TOK_OP_OR", "TOK_OP_SUB", "TOK_ORDERBY", "TOK_ORREPLACE", "TOK_PARTITIONFILEFORMAT", "TOK_PARTITIONINGSPEC", "TOK_PARTITIONSERDEPROPERTIES", "TOK_PARTSPEC", "TOK_PARTVAL", "TOK_PERCENT", "TOK_PRINCIPAL_NAME", "TOK_PRIVILEGE", "TOK_PRIVILEGE_LIST", "TOK_PRIV_ALL", "TOK_PRIV_ALTER_DATA", "TOK_PRIV_ALTER_METADATA", "TOK_PRIV_CREATE", "TOK_PRIV_DELETE", "TOK_PRIV_DROP", "TOK_PRIV_INDEX", "TOK_PRIV_INSERT", "TOK_PRIV_LOCK", "TOK_PRIV_OBJECT", "TOK_PRIV_OBJECT_COL", "TOK_PRIV_SELECT", "TOK_PRIV_SHOW_DATABASE", "TOK_PTBLFUNCTION", "TOK_QUERY", "TOK_READONLY", "TOK_RECORDREADER", "TOK_RECORDWRITER", "TOK_RELOADFUNCTION", "TOK_REPLICATION", "TOK_RESOURCE_ALL", "TOK_RESOURCE_LIST", "TOK_RESOURCE_URI", "TOK_RESTRICT", "TOK_REVOKE", "TOK_REVOKE_ROLE", "TOK_RIGHTOUTERJOIN", "TOK_ROLE", "TOK_ROLLUP_GROUPBY", "TOK_ROWCOUNT", "TOK_SELECT", "TOK_SELECTDI", "TOK_SELEXPR", "TOK_SERDE", "TOK_SERDENAME", "TOK_SERDEPROPS", "TOK_SERVER_TYPE", "TOK_SET_COLUMNS_CLAUSE", "TOK_SHOWCOLUMNS", "TOK_SHOWCONF", "TOK_SHOWDATABASES", "TOK_SHOWDBLOCKS", "TOK_SHOWFUNCTIONS", "TOK_SHOWINDEXES", "TOK_SHOWLOCKS", "TOK_SHOWPARTITIONS", "TOK_SHOWTABLES", "TOK_SHOW_COMPACTIONS", "TOK_SHOW_CREATETABLE", "TOK_SHOW_GRANT", "TOK_SHOW_ROLES", "TOK_SHOW_ROLE_GRANT", "TOK_SHOW_ROLE_PRINCIPALS", "TOK_SHOW_SET_ROLE", "TOK_SHOW_TABLESTATUS", "TOK_SHOW_TBLPROPERTIES", "TOK_SHOW_TRANSACTIONS", "TOK_SKEWED_LOCATIONS", "TOK_SKEWED_LOCATION_LIST", "TOK_SKEWED_LOCATION_MAP", "TOK_SMALLINT", "TOK_SORTBY", "TOK_STORAGEHANDLER", "TOK_STOREDASDIRS", "TOK_STREAMTABLE", "TOK_STRING", "TOK_STRINGLITERALSEQUENCE", "TOK_STRUCT", "TOK_SUBQUERY", "TOK_SUBQUERY_EXPR", "TOK_SUBQUERY_OP", "TOK_SUBQUERY_OP_NOTEXISTS", "TOK_SUBQUERY_OP_NOTIN", "TOK_SWITCHDATABASE", "TOK_TAB", "TOK_TABALIAS", "TOK_TABCOL", "TOK_TABCOLLIST", "TOK_TABCOLNAME", "TOK_TABCOLVALUE", "TOK_TABCOLVALUES", "TOK_TABCOLVALUE_PAIR", "TOK_TABLEBUCKETSAMPLE", "TOK_TABLECOMMENT", "TOK_TABLEFILEFORMAT", "TOK_TABLEPARTCOLS", "TOK_TABLEPROPERTIES", "TOK_TABLEPROPERTY", "TOK_TABLEPROPLIST", "TOK_TABLEROWFORMAT", "TOK_TABLEROWFORMATCOLLITEMS", "TOK_TABLEROWFORMATFIELD", "TOK_TABLEROWFORMATLINES", "TOK_TABLEROWFORMATMAPKEYS", "TOK_TABLEROWFORMATNULL", "TOK_TABLESERIALIZER", "TOK_TABLESKEWED", "TOK_TABLESPLITSAMPLE", "TOK_TABLE_OR_COL", "TOK_TABLE_PARTITION", "TOK_TABLE_TYPE", "TOK_TABNAME", "TOK_TABREF", "TOK_TABSORTCOLNAMEASC", "TOK_TABSORTCOLNAMEDESC", "TOK_TABSRC", "TOK_TABTYPE", "TOK_TEMPORARY", "TOK_TIMESTAMP", "TOK_TIMESTAMPLITERAL", "TOK_TINYINT", "TOK_TMP_FILE", "TOK_TRANSFORM", "TOK_TRUE", "TOK_TRUNCATETABLE", "TOK_UNION", "TOK_UNIONTYPE", "TOK_UNIQUEJOIN", "TOK_UNLOCKDB", "TOK_UNLOCKTABLE", "TOK_UPDATE_TABLE", "TOK_URI_TYPE", "TOK_USER", "TOK_USERSCRIPTCOLNAMES", "TOK_USERSCRIPTCOLSCHEMA", "TOK_VALUES_TABLE", "TOK_VALUE_ROW", "TOK_VARCHAR", "TOK_VIEWPARTCOLS", "TOK_VIRTUAL_TABLE", "TOK_VIRTUAL_TABREF", "TOK_WHERE", "TOK_WINDOWDEF", "TOK_WINDOWRANGE", "TOK_WINDOWSPEC", "TOK_WINDOWVALUES", "909"};

  public static final int EOF = -1;
  public static final int AMPERSAND = 4;
  public static final int BITWISEOR = 5;
  public static final int BITWISEXOR = 6;
  public static final int BigintLiteral = 7;
  public static final int ByteLengthLiteral = 8;
  public static final int COLON = 9;
  public static final int COMMA = 10;
  public static final int COMMENT = 11;
  public static final int CharSetLiteral = 12;
  public static final int CharSetName = 13;
  public static final int DIV = 14;
  public static final int DIVIDE = 15;
  public static final int DOLLAR = 16;
  public static final int DOT = 17;
  public static final int DecimalLiteral = 18;
  public static final int Digit = 19;
  public static final int EQUAL = 20;
  public static final int EQUAL_NS = 21;
  public static final int Exponent = 22;
  public static final int GREATERTHAN = 23;
  public static final int GREATERTHANOREQUALTO = 24;
  public static final int HexDigit = 25;
  public static final int Identifier = 26;
  public static final int KW_ADD = 27;
  public static final int KW_ADMIN = 28;
  public static final int KW_AFTER = 29;
  public static final int KW_ALL = 30;
  public static final int KW_ALTER = 31;
  public static final int KW_ANALYZE = 32;
  public static final int KW_AND = 33;
  public static final int KW_ARCHIVE = 34;
  public static final int KW_ARRAY = 35;
  public static final int KW_AS = 36;
  public static final int KW_ASC = 37;
  public static final int KW_AUTHORIZATION = 38;
  public static final int KW_BEFORE = 39;
  public static final int KW_BETWEEN = 40;
  public static final int KW_BIGINT = 41;
  public static final int KW_BINARY = 42;
  public static final int KW_BOOLEAN = 43;
  public static final int KW_BOTH = 44;
  public static final int KW_BUCKET = 45;
  public static final int KW_BUCKETS = 46;
  public static final int KW_BY = 47;
  public static final int KW_CASCADE = 48;
  public static final int KW_CASE = 49;
  public static final int KW_CAST = 50;
  public static final int KW_CHANGE = 51;
  public static final int KW_CHAR = 52;
  public static final int KW_CLUSTER = 53;
  public static final int KW_CLUSTERED = 54;
  public static final int KW_CLUSTERSTATUS = 55;
  public static final int KW_COLLECTION = 56;
  public static final int KW_COLUMN = 57;
  public static final int KW_COLUMNS = 58;
  public static final int KW_COMMENT = 59;
  public static final int KW_COMPACT = 60;
  public static final int KW_COMPACTIONS = 61;
  public static final int KW_COMPUTE = 62;
  public static final int KW_CONCATENATE = 63;
  public static final int KW_CONF = 64;
  public static final int KW_CONTINUE = 65;
  public static final int KW_CREATE = 66;
  public static final int KW_CROSS = 67;
  public static final int KW_CUBE = 68;
  public static final int KW_CURRENT = 69;
  public static final int KW_CURRENT_DATE = 70;
  public static final int KW_CURRENT_TIMESTAMP = 71;
  public static final int KW_CURSOR = 72;
  public static final int KW_DATA = 73;
  public static final int KW_DATABASE = 74;
  public static final int KW_DATABASES = 75;
  public static final int KW_DATE = 76;
  public static final int KW_DATETIME = 77;
  public static final int KW_DBPROPERTIES = 78;
  public static final int KW_DECIMAL = 79;
  public static final int KW_DEFAULT = 80;
  public static final int KW_DEFERRED = 81;
  public static final int KW_DEFINED = 82;
  public static final int KW_DELETE = 83;
  public static final int KW_DELIMITED = 84;
  public static final int KW_DEPENDENCY = 85;
  public static final int KW_DESC = 86;
  public static final int KW_DESCRIBE = 87;
  public static final int KW_DIRECTORIES = 88;
  public static final int KW_DIRECTORY = 89;
  public static final int KW_DISABLE = 90;
  public static final int KW_DISTINCT = 91;
  public static final int KW_DISTRIBUTE = 92;
  public static final int KW_DOUBLE = 93;
  public static final int KW_DROP = 94;
  public static final int KW_ELEM_TYPE = 95;
  public static final int KW_ELSE = 96;
  public static final int KW_ENABLE = 97;
  public static final int KW_END = 98;
  public static final int KW_ESCAPED = 99;
  public static final int KW_EXCHANGE = 100;
  public static final int KW_EXCLUSIVE = 101;
  public static final int KW_EXISTS = 102;
  public static final int KW_EXPLAIN = 103;
  public static final int KW_EXPORT = 104;
  public static final int KW_EXTENDED = 105;
  public static final int KW_EXTERNAL = 106;
  public static final int KW_FALSE = 107;
  public static final int KW_FETCH = 108;
  public static final int KW_FIELDS = 109;
  public static final int KW_FILE = 110;
  public static final int KW_FILEFORMAT = 111;
  public static final int KW_FIRST = 112;
  public static final int KW_FLOAT = 113;
  public static final int KW_FOLLOWING = 114;
  public static final int KW_FOR = 115;
  public static final int KW_FORMAT = 116;
  public static final int KW_FORMATTED = 117;
  public static final int KW_FROM = 118;
  public static final int KW_FULL = 119;
  public static final int KW_FUNCTION = 120;
  public static final int KW_FUNCTIONS = 121;
  public static final int KW_GRANT = 122;
  public static final int KW_GROUP = 123;
  public static final int KW_GROUPING = 124;
  public static final int KW_HAVING = 125;
  public static final int KW_HOLD_DDLTIME = 126;
  public static final int KW_IDXPROPERTIES = 127;
  public static final int KW_IF = 128;
  public static final int KW_IGNORE = 129;
  public static final int KW_IMPORT = 130;
  public static final int KW_IN = 131;
  public static final int KW_INDEX = 132;
  public static final int KW_INDEXES = 133;
  public static final int KW_INNER = 134;
  public static final int KW_INPATH = 135;
  public static final int KW_INPUTDRIVER = 136;
  public static final int KW_INPUTFORMAT = 137;
  public static final int KW_INSERT = 138;
  public static final int KW_INT = 139;
  public static final int KW_INTERSECT = 140;
  public static final int KW_INTO = 141;
  public static final int KW_IS = 142;
  public static final int KW_ITEMS = 143;
  public static final int KW_JAR = 144;
  public static final int KW_JOIN = 145;
  public static final int KW_KEYS = 146;
  public static final int KW_KEY_TYPE = 147;
  public static final int KW_LATERAL = 148;
  public static final int KW_LEFT = 149;
  public static final int KW_LESS = 150;
  public static final int KW_LIKE = 151;
  public static final int KW_LIMIT = 152;
  public static final int KW_LINES = 153;
  public static final int KW_LOAD = 154;
  public static final int KW_LOCAL = 155;
  public static final int KW_LOCATION = 156;
  public static final int KW_LOCK = 157;
  public static final int KW_LOCKS = 158;
  public static final int KW_LOGICAL = 159;
  public static final int KW_LONG = 160;
  public static final int KW_MACRO = 161;
  public static final int KW_MAP = 162;
  public static final int KW_MAPJOIN = 163;
  public static final int KW_MATERIALIZED = 164;
  public static final int KW_METADATA = 165;
  public static final int KW_MINUS = 166;
  public static final int KW_MORE = 167;
  public static final int KW_MSCK = 168;
  public static final int KW_NONE = 169;
  public static final int KW_NOSCAN = 170;
  public static final int KW_NOT = 171;
  public static final int KW_NO_DROP = 172;
  public static final int KW_NULL = 173;
  public static final int KW_OF = 174;
  public static final int KW_OFFLINE = 175;
  public static final int KW_ON = 176;
  public static final int KW_OPTION = 177;
  public static final int KW_OR = 178;
  public static final int KW_ORDER = 179;
  public static final int KW_OUT = 180;
  public static final int KW_OUTER = 181;
  public static final int KW_OUTPUTDRIVER = 182;
  public static final int KW_OUTPUTFORMAT = 183;
  public static final int KW_OVER = 184;
  public static final int KW_OVERWRITE = 185;
  public static final int KW_OWNER = 186;
  public static final int KW_PARTIALSCAN = 187;
  public static final int KW_PARTITION = 188;
  public static final int KW_PARTITIONED = 189;
  public static final int KW_PARTITIONS = 190;
  public static final int KW_PERCENT = 191;
  public static final int KW_PLUS = 192;
  public static final int KW_PRECEDING = 193;
  public static final int KW_PRESERVE = 194;
  public static final int KW_PRETTY = 195;
  public static final int KW_PRINCIPALS = 196;
  public static final int KW_PROCEDURE = 197;
  public static final int KW_PROTECTION = 198;
  public static final int KW_PURGE = 199;
  public static final int KW_RANGE = 200;
  public static final int KW_READ = 201;
  public static final int KW_READONLY = 202;
  public static final int KW_READS = 203;
  public static final int KW_REBUILD = 204;
  public static final int KW_RECORDREADER = 205;
  public static final int KW_RECORDWRITER = 206;
  public static final int KW_REDUCE = 207;
  public static final int KW_REGEXP = 208;
  public static final int KW_RELOAD = 209;
  public static final int KW_RENAME = 210;
  public static final int KW_REPAIR = 211;
  public static final int KW_REPLACE = 212;
  public static final int KW_REPLICATION = 213;
  public static final int KW_RESTRICT = 214;
  public static final int KW_REVOKE = 215;
  public static final int KW_REWRITE = 216;
  public static final int KW_RIGHT = 217;
  public static final int KW_RLIKE = 218;
  public static final int KW_ROLE = 219;
  public static final int KW_ROLES = 220;
  public static final int KW_ROLLUP = 221;
  public static final int KW_ROW = 222;
  public static final int KW_ROWS = 223;
  public static final int KW_SCHEMA = 224;
  public static final int KW_SCHEMAS = 225;
  public static final int KW_SELECT = 226;
  public static final int KW_SEMI = 227;
  public static final int KW_SERDE = 228;
  public static final int KW_SERDEPROPERTIES = 229;
  public static final int KW_SERVER = 230;
  public static final int KW_SET = 231;
  public static final int KW_SETS = 232;
  public static final int KW_SHARED = 233;
  public static final int KW_SHOW = 234;
  public static final int KW_SHOW_DATABASE = 235;
  public static final int KW_SKEWED = 236;
  public static final int KW_SMALLINT = 237;
  public static final int KW_SORT = 238;
  public static final int KW_SORTED = 239;
  public static final int KW_SSL = 240;
  public static final int KW_STATISTICS = 241;
  public static final int KW_STORED = 242;
  public static final int KW_STREAMTABLE = 243;
  public static final int KW_STRING = 244;
  public static final int KW_STRUCT = 245;
  public static final int KW_TABLE = 246;
  public static final int KW_TABLES = 247;
  public static final int KW_TABLESAMPLE = 248;
  public static final int KW_TBLPROPERTIES = 249;
  public static final int KW_TEMPORARY = 250;
  public static final int KW_TERMINATED = 251;
  public static final int KW_THEN = 252;
  public static final int KW_TIMESTAMP = 253;
  public static final int KW_TINYINT = 254;
  public static final int KW_TO = 255;
  public static final int KW_TOUCH = 256;
  public static final int KW_TRANSACTIONS = 257;
  public static final int KW_TRANSFORM = 258;
  public static final int KW_TRIGGER = 259;
  public static final int KW_TRUE = 260;
  public static final int KW_TRUNCATE = 261;
  public static final int KW_UNARCHIVE = 262;
  public static final int KW_UNBOUNDED = 263;
  public static final int KW_UNDO = 264;
  public static final int KW_UNION = 265;
  public static final int KW_UNIONTYPE = 266;
  public static final int KW_UNIQUEJOIN = 267;
  public static final int KW_UNLOCK = 268;
  public static final int KW_UNSET = 269;
  public static final int KW_UNSIGNED = 270;
  public static final int KW_UPDATE = 271;
  public static final int KW_URI = 272;
  public static final int KW_USE = 273;
  public static final int KW_USER = 274;
  public static final int KW_USING = 275;
  public static final int KW_UTC = 276;
  public static final int KW_UTCTIMESTAMP = 277;
  public static final int KW_VALUES = 278;
  public static final int KW_VALUE_TYPE = 279;
  public static final int KW_VARCHAR = 280;
  public static final int KW_VIEW = 281;
  public static final int KW_WHEN = 282;
  public static final int KW_WHERE = 283;
  public static final int KW_WHILE = 284;
  public static final int KW_WINDOW = 285;
  public static final int KW_WITH = 286;
  public static final int LCURLY = 287;
  public static final int LESSTHAN = 288;
  public static final int LESSTHANOREQUALTO = 289;
  public static final int LPAREN = 290;
  public static final int LSQUARE = 291;
  public static final int Letter = 292;
  public static final int MINUS = 293;
  public static final int MOD = 294;
  public static final int NOTEQUAL = 295;
  public static final int Number = 296;
  public static final int PLUS = 297;
  public static final int QUESTION = 298;
  public static final int QuotedIdentifier = 299;
  public static final int RCURLY = 300;
  public static final int RPAREN = 301;
  public static final int RSQUARE = 302;
  public static final int RegexComponent = 303;
  public static final int SEMICOLON = 304;
  public static final int STAR = 305;
  public static final int SmallintLiteral = 306;
  public static final int StringLiteral = 307;
  public static final int TILDE = 308;
  public static final int TinyintLiteral = 309;
  public static final int WS = 310;
  public static final int TOK_ADMIN_OPTION_FOR = 592;
  public static final int TOK_ALIASLIST = 593;
  public static final int TOK_ALLCOLREF = 594;
  public static final int TOK_ALTERDATABASE_OWNER = 595;
  public static final int TOK_ALTERDATABASE_PROPERTIES = 596;
  public static final int TOK_ALTERINDEX_PROPERTIES = 597;
  public static final int TOK_ALTERINDEX_REBUILD = 598;
  public static final int TOK_ALTERTABLE = 599;
  public static final int TOK_ALTERTABLE_ADDCOLS = 600;
  public static final int TOK_ALTERTABLE_ADDPARTS = 601;
  public static final int TOK_ALTERTABLE_ARCHIVE = 602;
  public static final int TOK_ALTERTABLE_BUCKETS = 603;
  public static final int TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION = 604;
  public static final int TOK_ALTERTABLE_CLUSTER_SORT = 605;
  public static final int TOK_ALTERTABLE_COMPACT = 606;
  public static final int TOK_ALTERTABLE_DROPPARTS = 607;
  public static final int TOK_ALTERTABLE_DROPPROPERTIES = 608;
  public static final int TOK_ALTERTABLE_EXCHANGEPARTITION = 609;
  public static final int TOK_ALTERTABLE_FILEFORMAT = 610;
  public static final int TOK_ALTERTABLE_MERGEFILES = 611;
  public static final int TOK_ALTERTABLE_PARTCOLTYPE = 612;
  public static final int TOK_ALTERTABLE_PROPERTIES = 613;
  public static final int TOK_ALTERTABLE_PROTECTMODE = 614;
  public static final int TOK_ALTERTABLE_RENAME = 615;
  public static final int TOK_ALTERTABLE_RENAMECOL = 616;
  public static final int TOK_ALTERTABLE_RENAMEPART = 617;
  public static final int TOK_ALTERTABLE_REPLACECOLS = 618;
  public static final int TOK_ALTERTABLE_SERDEPROPERTIES = 619;
  public static final int TOK_ALTERTABLE_SERIALIZER = 620;
  public static final int TOK_ALTERTABLE_SKEWED = 621;
  public static final int TOK_ALTERTABLE_SKEWED_LOCATION = 622;
  public static final int TOK_ALTERTABLE_TOUCH = 623;
  public static final int TOK_ALTERTABLE_UNARCHIVE = 624;
  public static final int TOK_ALTERTABLE_UPDATECOLSTATS = 625;
  public static final int TOK_ALTERVIEW = 626;
  public static final int TOK_ALTERVIEW_ADDPARTS = 627;
  public static final int TOK_ALTERVIEW_DROPPARTS = 628;
  public static final int TOK_ALTERVIEW_DROPPROPERTIES = 629;
  public static final int TOK_ALTERVIEW_PROPERTIES = 630;
  public static final int TOK_ALTERVIEW_RENAME = 631;
  public static final int TOK_ANALYZE = 632;
  public static final int TOK_ANONYMOUS = 633;
  public static final int TOK_ARCHIVE = 634;
  public static final int TOK_BIGINT = 635;
  public static final int TOK_BINARY = 636;
  public static final int TOK_BOOLEAN = 637;
  public static final int TOK_CASCADE = 638;
  public static final int TOK_CHAR = 639;
  public static final int TOK_CHARSETLITERAL = 640;
  public static final int TOK_CLUSTERBY = 641;
  public static final int TOK_COLTYPELIST = 642;
  public static final int TOK_COL_NAME = 643;
  public static final int TOK_CREATEDATABASE = 644;
  public static final int TOK_CREATEFUNCTION = 645;
  public static final int TOK_CREATEINDEX = 646;
  public static final int TOK_CREATEINDEX_INDEXTBLNAME = 647;
  public static final int TOK_CREATEMACRO = 648;
  public static final int TOK_CREATEROLE = 649;
  public static final int TOK_CREATETABLE = 650;
  public static final int TOK_CREATEVIEW = 651;
  public static final int TOK_CROSSJOIN = 652;
  public static final int TOK_CTE = 653;
  public static final int TOK_CUBE_GROUPBY = 654;
  public static final int TOK_DATABASECOMMENT = 655;
  public static final int TOK_DATABASEPROPERTIES = 656;
  public static final int TOK_DATE = 657;
  public static final int TOK_DATELITERAL = 658;
  public static final int TOK_DATETIME = 659;
  public static final int TOK_DBPROPLIST = 660;
  public static final int TOK_DB_TYPE = 661;
  public static final int TOK_DECIMAL = 662;
  public static final int TOK_DEFERRED_REBUILDINDEX = 663;
  public static final int TOK_DELETE_FROM = 664;
  public static final int TOK_DESCDATABASE = 665;
  public static final int TOK_DESCFUNCTION = 666;
  public static final int TOK_DESCTABLE = 667;
  public static final int TOK_DESTINATION = 668;
  public static final int TOK_DIR = 669;
  public static final int TOK_DISABLE = 670;
  public static final int TOK_DISTRIBUTEBY = 671;
  public static final int TOK_DOUBLE = 672;
  public static final int TOK_DROPDATABASE = 673;
  public static final int TOK_DROPFUNCTION = 674;
  public static final int TOK_DROPINDEX = 675;
  public static final int TOK_DROPMACRO = 676;
  public static final int TOK_DROPROLE = 677;
  public static final int TOK_DROPTABLE = 678;
  public static final int TOK_DROPVIEW = 679;
  public static final int TOK_ENABLE = 680;
  public static final int TOK_EXPLAIN = 681;
  public static final int TOK_EXPLAIN_SQ_REWRITE = 682;
  public static final int TOK_EXPLIST = 683;
  public static final int TOK_EXPORT = 684;
  public static final int TOK_FALSE = 685;
  public static final int TOK_FILE = 686;
  public static final int TOK_FILEFORMAT_GENERIC = 687;
  public static final int TOK_FLOAT = 688;
  public static final int TOK_FROM = 689;
  public static final int TOK_FULLOUTERJOIN = 690;
  public static final int TOK_FUNCTION = 691;
  public static final int TOK_FUNCTIONDI = 692;
  public static final int TOK_FUNCTIONSTAR = 693;
  public static final int TOK_GRANT = 694;
  public static final int TOK_GRANT_OPTION_FOR = 695;
  public static final int TOK_GRANT_ROLE = 696;
  public static final int TOK_GRANT_WITH_ADMIN_OPTION = 697;
  public static final int TOK_GRANT_WITH_OPTION = 698;
  public static final int TOK_GROUP = 699;
  public static final int TOK_GROUPBY = 700;
  public static final int TOK_GROUPING_SETS = 701;
  public static final int TOK_GROUPING_SETS_EXPRESSION = 702;
  public static final int TOK_HAVING = 703;
  public static final int TOK_HINT = 704;
  public static final int TOK_HINTARGLIST = 705;
  public static final int TOK_HINTLIST = 706;
  public static final int TOK_HOLD_DDLTIME = 707;
  public static final int TOK_IFEXISTS = 708;
  public static final int TOK_IFNOTEXISTS = 709;
  public static final int TOK_IGNOREPROTECTION = 710;
  public static final int TOK_IMPORT = 711;
  public static final int TOK_INDEXCOMMENT = 712;
  public static final int TOK_INDEXPROPERTIES = 713;
  public static final int TOK_INDEXPROPLIST = 714;
  public static final int TOK_INSERT = 715;
  public static final int TOK_INSERT_INTO = 716;
  public static final int TOK_INT = 717;
  public static final int TOK_ISNOTNULL = 718;
  public static final int TOK_ISNULL = 719;
  public static final int TOK_JAR = 720;
  public static final int TOK_JOIN = 721;
  public static final int TOK_LATERAL_VIEW = 722;
  public static final int TOK_LATERAL_VIEW_OUTER = 723;
  public static final int TOK_LEFTOUTERJOIN = 724;
  public static final int TOK_LEFTSEMIJOIN = 725;
  public static final int TOK_LENGTH = 726;
  public static final int TOK_LIKETABLE = 727;
  public static final int TOK_LIMIT = 728;
  public static final int TOK_LIST = 729;
  public static final int TOK_LOAD = 730;
  public static final int TOK_LOCATION = 731;
  public static final int TOK_LOCKDB = 732;
  public static final int TOK_LOCKTABLE = 733;
  public static final int TOK_MAP = 734;
  public static final int TOK_MAPJOIN = 735;
  public static final int TOK_METADATA = 736;
  public static final int TOK_MSCK = 737;
  public static final int TOK_NOT_CLUSTERED = 738;
  public static final int TOK_NOT_SORTED = 739;
  public static final int TOK_NO_DROP = 740;
  public static final int TOK_NULL = 741;
  public static final int TOK_OFFLINE = 742;
  public static final int TOK_OP_ADD = 743;
  public static final int TOK_OP_AND = 744;
  public static final int TOK_OP_BITAND = 745;
  public static final int TOK_OP_BITNOT = 746;
  public static final int TOK_OP_BITOR = 747;
  public static final int TOK_OP_BITXOR = 748;
  public static final int TOK_OP_DIV = 749;
  public static final int TOK_OP_EQ = 750;
  public static final int TOK_OP_GE = 751;
  public static final int TOK_OP_GT = 752;
  public static final int TOK_OP_LE = 753;
  public static final int TOK_OP_LIKE = 754;
  public static final int TOK_OP_LT = 755;
  public static final int TOK_OP_MOD = 756;
  public static final int TOK_OP_MUL = 757;
  public static final int TOK_OP_NE = 758;
  public static final int TOK_OP_NOT = 759;
  public static final int TOK_OP_OR = 760;
  public static final int TOK_OP_SUB = 761;
  public static final int TOK_ORDERBY = 762;
  public static final int TOK_ORREPLACE = 763;
  public static final int TOK_PARTITIONFILEFORMAT = 764;
  public static final int TOK_PARTITIONINGSPEC = 765;
  public static final int TOK_PARTITIONSERDEPROPERTIES = 766;
  public static final int TOK_PARTSPEC = 767;
  public static final int TOK_PARTVAL = 768;
  public static final int TOK_PERCENT = 769;
  public static final int TOK_PRINCIPAL_NAME = 770;
  public static final int TOK_PRIVILEGE = 771;
  public static final int TOK_PRIVILEGE_LIST = 772;
  public static final int TOK_PRIV_ALL = 773;
  public static final int TOK_PRIV_ALTER_DATA = 774;
  public static final int TOK_PRIV_ALTER_METADATA = 775;
  public static final int TOK_PRIV_CREATE = 776;
  public static final int TOK_PRIV_DELETE = 777;
  public static final int TOK_PRIV_DROP = 778;
  public static final int TOK_PRIV_INDEX = 779;
  public static final int TOK_PRIV_INSERT = 780;
  public static final int TOK_PRIV_LOCK = 781;
  public static final int TOK_PRIV_OBJECT = 782;
  public static final int TOK_PRIV_OBJECT_COL = 783;
  public static final int TOK_PRIV_SELECT = 784;
  public static final int TOK_PRIV_SHOW_DATABASE = 785;
  public static final int TOK_PTBLFUNCTION = 786;
  public static final int TOK_QUERY = 787;
  public static final int TOK_READONLY = 788;
  public static final int TOK_RECORDREADER = 789;
  public static final int TOK_RECORDWRITER = 790;
  public static final int TOK_RELOADFUNCTION = 791;
  public static final int TOK_REPLICATION = 792;
  public static final int TOK_RESOURCE_ALL = 793;
  public static final int TOK_RESOURCE_LIST = 794;
  public static final int TOK_RESOURCE_URI = 795;
  public static final int TOK_RESTRICT = 796;
  public static final int TOK_REVOKE = 797;
  public static final int TOK_REVOKE_ROLE = 798;
  public static final int TOK_RIGHTOUTERJOIN = 799;
  public static final int TOK_ROLE = 800;
  public static final int TOK_ROLLUP_GROUPBY = 801;
  public static final int TOK_ROWCOUNT = 802;
  public static final int TOK_SELECT = 803;
  public static final int TOK_SELECTDI = 804;
  public static final int TOK_SELEXPR = 805;
  public static final int TOK_SERDE = 806;
  public static final int TOK_SERDENAME = 807;
  public static final int TOK_SERDEPROPS = 808;
  public static final int TOK_SERVER_TYPE = 809;
  public static final int TOK_SET_COLUMNS_CLAUSE = 810;
  public static final int TOK_SHOWCOLUMNS = 811;
  public static final int TOK_SHOWCONF = 812;
  public static final int TOK_SHOWDATABASES = 813;
  public static final int TOK_SHOWDBLOCKS = 814;
  public static final int TOK_SHOWFUNCTIONS = 815;
  public static final int TOK_SHOWINDEXES = 816;
  public static final int TOK_SHOWLOCKS = 817;
  public static final int TOK_SHOWPARTITIONS = 818;
  public static final int TOK_SHOWTABLES = 819;
  public static final int TOK_SHOW_COMPACTIONS = 820;
  public static final int TOK_SHOW_CREATETABLE = 821;
  public static final int TOK_SHOW_GRANT = 822;
  public static final int TOK_SHOW_ROLES = 823;
  public static final int TOK_SHOW_ROLE_GRANT = 824;
  public static final int TOK_SHOW_ROLE_PRINCIPALS = 825;
  public static final int TOK_SHOW_SET_ROLE = 826;
  public static final int TOK_SHOW_TABLESTATUS = 827;
  public static final int TOK_SHOW_TBLPROPERTIES = 828;
  public static final int TOK_SHOW_TRANSACTIONS = 829;
  public static final int TOK_SKEWED_LOCATIONS = 830;
  public static final int TOK_SKEWED_LOCATION_LIST = 831;
  public static final int TOK_SKEWED_LOCATION_MAP = 832;
  public static final int TOK_SMALLINT = 833;
  public static final int TOK_SORTBY = 834;
  public static final int TOK_STORAGEHANDLER = 835;
  public static final int TOK_STOREDASDIRS = 836;
  public static final int TOK_STREAMTABLE = 837;
  public static final int TOK_STRING = 838;
  public static final int TOK_STRINGLITERALSEQUENCE = 839;
  public static final int TOK_STRUCT = 840;
  public static final int TOK_SUBQUERY = 841;
  public static final int TOK_SUBQUERY_EXPR = 842;
  public static final int TOK_SUBQUERY_OP = 843;
  public static final int TOK_SUBQUERY_OP_NOTEXISTS = 844;
  public static final int TOK_SUBQUERY_OP_NOTIN = 845;
  public static final int TOK_SWITCHDATABASE = 846;
  public static final int TOK_TAB = 847;
  public static final int TOK_TABALIAS = 848;
  public static final int TOK_TABCOL = 849;
  public static final int TOK_TABCOLLIST = 850;
  public static final int TOK_TABCOLNAME = 851;
  public static final int TOK_TABCOLVALUE = 852;
  public static final int TOK_TABCOLVALUES = 853;
  public static final int TOK_TABCOLVALUE_PAIR = 854;
  public static final int TOK_TABLEBUCKETSAMPLE = 855;
  public static final int TOK_TABLECOMMENT = 856;
  public static final int TOK_TABLEFILEFORMAT = 857;
  public static final int TOK_TABLEPARTCOLS = 858;
  public static final int TOK_TABLEPROPERTIES = 859;
  public static final int TOK_TABLEPROPERTY = 860;
  public static final int TOK_TABLEPROPLIST = 861;
  public static final int TOK_TABLEROWFORMAT = 862;
  public static final int TOK_TABLEROWFORMATCOLLITEMS = 863;
  public static final int TOK_TABLEROWFORMATFIELD = 864;
  public static final int TOK_TABLEROWFORMATLINES = 865;
  public static final int TOK_TABLEROWFORMATMAPKEYS = 866;
  public static final int TOK_TABLEROWFORMATNULL = 867;
  public static final int TOK_TABLESERIALIZER = 868;
  public static final int TOK_TABLESKEWED = 869;
  public static final int TOK_TABLESPLITSAMPLE = 870;
  public static final int TOK_TABLE_OR_COL = 871;
  public static final int TOK_TABLE_PARTITION = 872;
  public static final int TOK_TABLE_TYPE = 873;
  public static final int TOK_TABNAME = 874;
  public static final int TOK_TABREF = 875;
  public static final int TOK_TABSORTCOLNAMEASC = 876;
  public static final int TOK_TABSORTCOLNAMEDESC = 877;
  public static final int TOK_TABSRC = 878;
  public static final int TOK_TABTYPE = 879;
  public static final int TOK_TEMPORARY = 880;
  public static final int TOK_TIMESTAMP = 881;
  public static final int TOK_TIMESTAMPLITERAL = 882;
  public static final int TOK_TINYINT = 883;
  public static final int TOK_TMP_FILE = 884;
  public static final int TOK_TRANSFORM = 885;
  public static final int TOK_TRUE = 886;
  public static final int TOK_TRUNCATETABLE = 887;
  public static final int TOK_UNION = 888;
  public static final int TOK_UNIONTYPE = 889;
  public static final int TOK_UNIQUEJOIN = 890;
  public static final int TOK_UNLOCKDB = 891;
  public static final int TOK_UNLOCKTABLE = 892;
  public static final int TOK_UPDATE_TABLE = 893;
  public static final int TOK_URI_TYPE = 894;
  public static final int TOK_USER = 895;
  public static final int TOK_USERSCRIPTCOLNAMES = 896;
  public static final int TOK_USERSCRIPTCOLSCHEMA = 897;
  public static final int TOK_VALUES_TABLE = 898;
  public static final int TOK_VALUE_ROW = 899;
  public static final int TOK_VARCHAR = 900;
  public static final int TOK_VIEWPARTCOLS = 901;
  public static final int TOK_VIRTUAL_TABLE = 902;
  public static final int TOK_VIRTUAL_TABREF = 903;
  public static final int TOK_WHERE = 904;
  public static final int TOK_WINDOWDEF = 905;
  public static final int TOK_WINDOWRANGE = 906;
  public static final int TOK_WINDOWSPEC = 907;
  public static final int TOK_WINDOWVALUES = 908;

  // delegates
  public HiveParser_SelectClauseParser gSelectClauseParser;
  public HiveParser_FromClauseParser gFromClauseParser;
  public HiveParser_IdentifiersParser gIdentifiersParser;

  public Parser[] getDelegates() {
    return new Parser[]{gSelectClauseParser, gFromClauseParser, gIdentifiersParser};
  }

  // delegators

  public HiveParser(TokenStream input) {
    this(input, new RecognizerSharedState());
  }

  public HiveParser(TokenStream input, RecognizerSharedState state) {
    super(input, state);
    gSelectClauseParser = new HiveParser_SelectClauseParser(input, state, this);
    gFromClauseParser = new HiveParser_FromClauseParser(input, state, this);
    gIdentifiersParser = new HiveParser_IdentifiersParser(input, state, this);
  }

  protected TreeAdaptor adaptor = new CommonTreeAdaptor();

  public void setTreeAdaptor(TreeAdaptor adaptor) {
    this.adaptor = adaptor;
    gSelectClauseParser.setTreeAdaptor(this.adaptor);
    gFromClauseParser.setTreeAdaptor(this.adaptor);
    gIdentifiersParser.setTreeAdaptor(this.adaptor);
  }

  public TreeAdaptor getTreeAdaptor() {
    return adaptor;
  }

  public String[] getTokenNames() {
    return HiveParser.tokenNames;
  }

  public String getGrammarFileName() {
    return "org/apache/hadoop/hive/ql/parse/HiveParser.g";
  }

  ArrayList<ParseError> errors = new ArrayList<ParseError>();
  Stack msgs = new Stack<String>();

  private static HashMap<String, String> xlateMap;

  static {
    xlateMap = new HashMap<String, String>();

    // Keywords
    xlateMap.put("KW_TRUE", "TRUE");
    xlateMap.put("KW_FALSE", "FALSE");
    xlateMap.put("KW_ALL", "ALL");
    xlateMap.put("KW_NONE", "NONE");
    xlateMap.put("KW_DEFAULT", "DEFAULT");
    xlateMap.put("KW_AND", "AND");
    xlateMap.put("KW_OR", "OR");
    xlateMap.put("KW_NOT", "NOT");
    xlateMap.put("KW_LIKE", "LIKE");

    xlateMap.put("KW_ASC", "ASC");
    xlateMap.put("KW_DESC", "DESC");
    xlateMap.put("KW_ORDER", "ORDER");
    xlateMap.put("KW_BY", "BY");
    xlateMap.put("KW_GROUP", "GROUP");
    xlateMap.put("KW_WHERE", "WHERE");
    xlateMap.put("KW_FROM", "FROM");
    xlateMap.put("KW_AS", "AS");
    xlateMap.put("KW_SELECT", "SELECT");
    xlateMap.put("KW_DISTINCT", "DISTINCT");
    xlateMap.put("KW_INSERT", "INSERT");
    xlateMap.put("KW_OVERWRITE", "OVERWRITE");
    xlateMap.put("KW_OUTER", "OUTER");
    xlateMap.put("KW_JOIN", "JOIN");
    xlateMap.put("KW_LEFT", "LEFT");
    xlateMap.put("KW_RIGHT", "RIGHT");
    xlateMap.put("KW_FULL", "FULL");
    xlateMap.put("KW_ON", "ON");
    xlateMap.put("KW_PARTITION", "PARTITION");
    xlateMap.put("KW_PARTITIONS", "PARTITIONS");
    xlateMap.put("KW_TABLE", "TABLE");
    xlateMap.put("KW_TABLES", "TABLES");
    xlateMap.put("KW_TBLPROPERTIES", "TBLPROPERTIES");
    xlateMap.put("KW_SHOW", "SHOW");
    xlateMap.put("KW_MSCK", "MSCK");
    xlateMap.put("KW_DIRECTORY", "DIRECTORY");
    xlateMap.put("KW_LOCAL", "LOCAL");
    xlateMap.put("KW_TRANSFORM", "TRANSFORM");
    xlateMap.put("KW_USING", "USING");
    xlateMap.put("KW_CLUSTER", "CLUSTER");
    xlateMap.put("KW_DISTRIBUTE", "DISTRIBUTE");
    xlateMap.put("KW_SORT", "SORT");
    xlateMap.put("KW_UNION", "UNION");
    xlateMap.put("KW_LOAD", "LOAD");
    xlateMap.put("KW_DATA", "DATA");
    xlateMap.put("KW_INPATH", "INPATH");
    xlateMap.put("KW_IS", "IS");
    xlateMap.put("KW_NULL", "NULL");
    xlateMap.put("KW_CREATE", "CREATE");
    xlateMap.put("KW_EXTERNAL", "EXTERNAL");
    xlateMap.put("KW_ALTER", "ALTER");
    xlateMap.put("KW_DESCRIBE", "DESCRIBE");
    xlateMap.put("KW_DROP", "DROP");
    xlateMap.put("KW_RENAME", "RENAME");
    xlateMap.put("KW_TO", "TO");
    xlateMap.put("KW_COMMENT", "COMMENT");
    xlateMap.put("KW_BOOLEAN", "BOOLEAN");
    xlateMap.put("KW_TINYINT", "TINYINT");
    xlateMap.put("KW_SMALLINT", "SMALLINT");
    xlateMap.put("KW_INT", "INT");
    xlateMap.put("KW_BIGINT", "BIGINT");
    xlateMap.put("KW_FLOAT", "FLOAT");
    xlateMap.put("KW_DOUBLE", "DOUBLE");
    xlateMap.put("KW_DATE", "DATE");
    xlateMap.put("KW_DATETIME", "DATETIME");
    xlateMap.put("KW_TIMESTAMP", "TIMESTAMP");
    xlateMap.put("KW_STRING", "STRING");
    xlateMap.put("KW_BINARY", "BINARY");
    xlateMap.put("KW_ARRAY", "ARRAY");
    xlateMap.put("KW_MAP", "MAP");
    xlateMap.put("KW_REDUCE", "REDUCE");
    xlateMap.put("KW_PARTITIONED", "PARTITIONED");
    xlateMap.put("KW_CLUSTERED", "CLUSTERED");
    xlateMap.put("KW_SORTED", "SORTED");
    xlateMap.put("KW_INTO", "INTO");
    xlateMap.put("KW_BUCKETS", "BUCKETS");
    xlateMap.put("KW_ROW", "ROW");
    xlateMap.put("KW_FORMAT", "FORMAT");
    xlateMap.put("KW_DELIMITED", "DELIMITED");
    xlateMap.put("KW_FIELDS", "FIELDS");
    xlateMap.put("KW_TERMINATED", "TERMINATED");
    xlateMap.put("KW_COLLECTION", "COLLECTION");
    xlateMap.put("KW_ITEMS", "ITEMS");
    xlateMap.put("KW_KEYS", "KEYS");
    xlateMap.put("KW_KEY_TYPE", "$KEY$");
    xlateMap.put("KW_LINES", "LINES");
    xlateMap.put("KW_STORED", "STORED");
    xlateMap.put("KW_SEQUENCEFILE", "SEQUENCEFILE");
    xlateMap.put("KW_TEXTFILE", "TEXTFILE");
    xlateMap.put("KW_INPUTFORMAT", "INPUTFORMAT");
    xlateMap.put("KW_OUTPUTFORMAT", "OUTPUTFORMAT");
    xlateMap.put("KW_LOCATION", "LOCATION");
    xlateMap.put("KW_TABLESAMPLE", "TABLESAMPLE");
    xlateMap.put("KW_BUCKET", "BUCKET");
    xlateMap.put("KW_OUT", "OUT");
    xlateMap.put("KW_OF", "OF");
    xlateMap.put("KW_CAST", "CAST");
    xlateMap.put("KW_ADD", "ADD");
    xlateMap.put("KW_REPLACE", "REPLACE");
    xlateMap.put("KW_COLUMNS", "COLUMNS");
    xlateMap.put("KW_RLIKE", "RLIKE");
    xlateMap.put("KW_REGEXP", "REGEXP");
    xlateMap.put("KW_TEMPORARY", "TEMPORARY");
    xlateMap.put("KW_FUNCTION", "FUNCTION");
    xlateMap.put("KW_EXPLAIN", "EXPLAIN");
    xlateMap.put("KW_EXTENDED", "EXTENDED");
    xlateMap.put("KW_SERDE", "SERDE");
    xlateMap.put("KW_WITH", "WITH");
    xlateMap.put("KW_SERDEPROPERTIES", "SERDEPROPERTIES");
    xlateMap.put("KW_LIMIT", "LIMIT");
    xlateMap.put("KW_SET", "SET");
    xlateMap.put("KW_PROPERTIES", "TBLPROPERTIES");
    xlateMap.put("KW_VALUE_TYPE", "$VALUE$");
    xlateMap.put("KW_ELEM_TYPE", "$ELEM$");
    xlateMap.put("KW_DEFINED", "DEFINED");
    xlateMap.put("KW_SUBQUERY", "SUBQUERY");
    xlateMap.put("KW_REWRITE", "REWRITE");
    xlateMap.put("KW_UPDATE", "UPDATE");
    xlateMap.put("KW_VALUES", "VALUES");
    xlateMap.put("KW_PURGE", "PURGE");

    // Operators
    xlateMap.put("DOT", ".");
    xlateMap.put("COLON", ":");
    xlateMap.put("COMMA", ",");
    xlateMap.put("SEMICOLON", ");");

    xlateMap.put("LPAREN", "(");
    xlateMap.put("RPAREN", ")");
    xlateMap.put("LSQUARE", "[");
    xlateMap.put("RSQUARE", "]");

    xlateMap.put("EQUAL", "=");
    xlateMap.put("NOTEQUAL", "<>");
    xlateMap.put("EQUAL_NS", "<=>");
    xlateMap.put("LESSTHANOREQUALTO", "<=");
    xlateMap.put("LESSTHAN", "<");
    xlateMap.put("GREATERTHANOREQUALTO", ">=");
    xlateMap.put("GREATERTHAN", ">");

    xlateMap.put("DIVIDE", "/");
    xlateMap.put("PLUS", "+");
    xlateMap.put("MINUS", "-");
    xlateMap.put("STAR", "*");
    xlateMap.put("MOD", "%");

    xlateMap.put("AMPERSAND", "&");
    xlateMap.put("TILDE", "~");
    xlateMap.put("BITWISEOR", "|");
    xlateMap.put("BITWISEXOR", "^");
    xlateMap.put("CharSetLiteral", "\\'");
  }

  public static Collection<String> getKeywords() {
    return xlateMap.values();
  }

  private static String xlate(String name) {

    String ret = xlateMap.get(name);
    if (ret == null) {
      ret = name;
    }

    return ret;
  }

  @Override
  public Object recoverFromMismatchedSet(IntStream input, RecognitionException re, BitSet follow)
      throws RecognitionException {
    throw re;
  }

  @Override
  public void displayRecognitionError(String[] tokenNames, RecognitionException e) {
    errors.add(new ParseError(this, e, tokenNames));
  }

  @Override
  public String getErrorHeader(RecognitionException e) {
    String header = null;
    if (e.charPositionInLine < 0 && input.LT(-1) != null) {
      Token t = input.LT(-1);
      header = "line " + t.getLine() + ":" + t.getCharPositionInLine();
    } else {
      header = super.getErrorHeader(e);
    }

    return header;
  }

  @Override
  public String getErrorMessage(RecognitionException e, String[] tokenNames) {
    String msg = null;

    // Translate the token names to something that the user can understand
    String[] xlateNames = new String[tokenNames.length];
    for (int i = 0; i < tokenNames.length; ++i) {
      xlateNames[i] = HiveParser.xlate(tokenNames[i]);
    }

    if (e instanceof NoViableAltException) {
      @SuppressWarnings("unused")
      NoViableAltException nvae = (NoViableAltException) e;
      // for development, can add
      // "decision=<<"+nvae.grammarDecisionDescription+">>"
      // and "(decision="+nvae.decisionNumber+") and
      // "state "+nvae.stateNumber
      msg = "cannot recognize input near" + (input.LT(1) != null ? " " + getTokenErrorDisplay(input.LT(1)) : "") + (
          input.LT(2) != null ? " " + getTokenErrorDisplay(input.LT(2)) : "") + (input.LT(3) != null ? " "
          + getTokenErrorDisplay(input.LT(3)) : "");
    } else if (e instanceof MismatchedTokenException) {
      MismatchedTokenException mte = (MismatchedTokenException) e;
      msg =
          super.getErrorMessage(e, xlateNames) + (input.LT(-1) == null ? "" : " near '" + input.LT(-1).getText()) + "'";
    } else if (e instanceof FailedPredicateException) {
      FailedPredicateException fpe = (FailedPredicateException) e;
      msg = "Failed to recognize predicate '" + fpe.token.getText() + "'. Failed rule: '" + fpe.ruleName + "'";
    } else {
      msg = super.getErrorMessage(e, xlateNames);
    }

    if (msgs.size() > 0) {
      msg = msg + " in " + msgs.peek();
    }
    return msg;
  }

  public void pushMsg(String msg, RecognizerSharedState state) {
    // ANTLR generated code does not wrap the @init code wit this backtracking check,
    //  even if the matching @after has it. If we have parser rules with that are doing
    // some lookahead with syntactic predicates this can cause the push() and pop() calls
    // to become unbalanced, so make sure both push/pop check the backtracking state.
    if (state.backtracking == 0) {
      msgs.push(msg);
    }
  }

  public void popMsg(RecognizerSharedState state) {
    if (state.backtracking == 0) {
      msgs.pop();
    }
  }

  // counter to generate unique union aliases
  private int aliasCounter;

  private String generateUnionAlias() {
    return "_u" + (++aliasCounter);
  }

  public static class statement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "statement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:630:1: statement : ( explainStatement EOF | execStatement EOF );
  public final HiveParser.statement_return statement() throws RecognitionException {
    HiveParser.statement_return retval = new HiveParser.statement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token EOF2 = null;
    Token EOF4 = null;
    HiveParser.explainStatement_return explainStatement1 = null;

    HiveParser.execStatement_return execStatement3 = null;

    CommonTree EOF2_tree = null;
    CommonTree EOF4_tree = null;

    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:631:2: ( explainStatement EOF | execStatement EOF )
      int alt1 = 2;
      switch (input.LA(1)) {
        case KW_EXPLAIN: {
          alt1 = 1;
        }
        break;
        case KW_ALTER:
        case KW_ANALYZE:
        case KW_CREATE:
        case KW_DELETE:
        case KW_DESC:
        case KW_DESCRIBE:
        case KW_DROP:
        case KW_EXPORT:
        case KW_FROM:
        case KW_GRANT:
        case KW_IMPORT:
        case KW_INSERT:
        case KW_LOAD:
        case KW_LOCK:
        case KW_MAP:
        case KW_MSCK:
        case KW_REDUCE:
        case KW_RELOAD:
        case KW_REVOKE:
        case KW_SELECT:
        case KW_SET:
        case KW_SHOW:
        case KW_TRUNCATE:
        case KW_UNLOCK:
        case KW_UPDATE:
        case KW_USE:
        case KW_WITH: {
          alt1 = 2;
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 1, 0, input);

          throw nvae;
      }

      switch (alt1) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:631:4: explainStatement EOF
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_explainStatement_in_statement1034);
          explainStatement1 = explainStatement();

          state._fsp--;

          adaptor.addChild(root_0, explainStatement1.getTree());

          EOF2 = (Token) match(input, EOF, FOLLOW_EOF_in_statement1036);
          EOF2_tree = (CommonTree) adaptor.create(EOF2);
          adaptor.addChild(root_0, EOF2_tree);
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:632:4: execStatement EOF
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_execStatement_in_statement1041);
          execStatement3 = execStatement();

          state._fsp--;

          adaptor.addChild(root_0, execStatement3.getTree());

          EOF4 = (Token) match(input, EOF, FOLLOW_EOF_in_statement1043);
          EOF4_tree = (CommonTree) adaptor.create(EOF4);
          adaptor.addChild(root_0, EOF4_tree);
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "statement"

  public static class explainStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "explainStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:635:1: explainStatement : KW_EXPLAIN ( ( explainOption )* execStatement -> ^( TOK_EXPLAIN execStatement ( explainOption )* ) | KW_REWRITE queryStatementExpression[true] -> ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression ) ) ;
  public final HiveParser.explainStatement_return explainStatement() throws RecognitionException {
    HiveParser.explainStatement_return retval = new HiveParser.explainStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_EXPLAIN5 = null;
    Token KW_REWRITE8 = null;
    HiveParser.explainOption_return explainOption6 = null;

    HiveParser.execStatement_return execStatement7 = null;

    HiveParser.queryStatementExpression_return queryStatementExpression9 = null;

    CommonTree KW_EXPLAIN5_tree = null;
    CommonTree KW_REWRITE8_tree = null;
    RewriteRuleTokenStream stream_KW_REWRITE = new RewriteRuleTokenStream(adaptor, "token KW_REWRITE");
    RewriteRuleTokenStream stream_KW_EXPLAIN = new RewriteRuleTokenStream(adaptor, "token KW_EXPLAIN");
    RewriteRuleSubtreeStream stream_queryStatementExpression =
        new RewriteRuleSubtreeStream(adaptor, "rule queryStatementExpression");
    RewriteRuleSubtreeStream stream_explainOption = new RewriteRuleSubtreeStream(adaptor, "rule explainOption");
    RewriteRuleSubtreeStream stream_execStatement = new RewriteRuleSubtreeStream(adaptor, "rule execStatement");
    pushMsg("explain statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:638:2: ( KW_EXPLAIN ( ( explainOption )* execStatement -> ^( TOK_EXPLAIN execStatement ( explainOption )* ) | KW_REWRITE queryStatementExpression[true] -> ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression ) ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:638:4: KW_EXPLAIN ( ( explainOption )* execStatement -> ^( TOK_EXPLAIN execStatement ( explainOption )* ) | KW_REWRITE queryStatementExpression[true] -> ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression ) )
      {
        KW_EXPLAIN5 = (Token) match(input, KW_EXPLAIN, FOLLOW_KW_EXPLAIN_in_explainStatement1064);
        stream_KW_EXPLAIN.add(KW_EXPLAIN5);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:638:15: ( ( explainOption )* execStatement -> ^( TOK_EXPLAIN execStatement ( explainOption )* ) | KW_REWRITE queryStatementExpression[true] -> ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression ) )
        int alt3 = 2;
        switch (input.LA(1)) {
          case KW_ALTER:
          case KW_ANALYZE:
          case KW_AUTHORIZATION:
          case KW_CREATE:
          case KW_DELETE:
          case KW_DEPENDENCY:
          case KW_DESC:
          case KW_DESCRIBE:
          case KW_DROP:
          case KW_EXPORT:
          case KW_EXTENDED:
          case KW_FORMATTED:
          case KW_FROM:
          case KW_GRANT:
          case KW_IMPORT:
          case KW_INSERT:
          case KW_LOAD:
          case KW_LOCK:
          case KW_LOGICAL:
          case KW_MAP:
          case KW_MSCK:
          case KW_REDUCE:
          case KW_RELOAD:
          case KW_REVOKE:
          case KW_SELECT:
          case KW_SET:
          case KW_SHOW:
          case KW_TRUNCATE:
          case KW_UNLOCK:
          case KW_UPDATE:
          case KW_USE:
          case KW_WITH: {
            alt3 = 1;
          }
          break;
          case KW_REWRITE: {
            alt3 = 2;
          }
          break;
          default:
            NoViableAltException nvae = new NoViableAltException("", 3, 0, input);

            throw nvae;
        }

        switch (alt3) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:639:6: ( explainOption )* execStatement
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:639:6: ( explainOption )*
            loop2:
            do {
              int alt2 = 2;
              switch (input.LA(1)) {
                case KW_AUTHORIZATION:
                case KW_DEPENDENCY:
                case KW_EXTENDED:
                case KW_FORMATTED:
                case KW_LOGICAL: {
                  alt2 = 1;
                }
                break;
              }

              switch (alt2) {
                case 1:
                  // org/apache/hadoop/hive/ql/parse/HiveParser.g:639:6: explainOption
                {
                  pushFollow(FOLLOW_explainOption_in_explainStatement1073);
                  explainOption6 = explainOption();

                  state._fsp--;

                  stream_explainOption.add(explainOption6.getTree());
                }
                break;

                default:
                  break loop2;
              }
            } while (true);

            pushFollow(FOLLOW_execStatement_in_explainStatement1076);
            execStatement7 = execStatement();

            state._fsp--;

            stream_execStatement.add(execStatement7.getTree());

            // AST REWRITE
            // elements: explainOption, execStatement
            // token labels:
            // rule labels: retval
            // token list labels:
            // rule list labels:
            // wildcard labels:
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval =
                new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

            root_0 = (CommonTree) adaptor.nil();
            // 639:35: -> ^( TOK_EXPLAIN execStatement ( explainOption )* )
            {
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:639:38: ^( TOK_EXPLAIN execStatement ( explainOption )* )
              {
                CommonTree root_1 = (CommonTree) adaptor.nil();
                root_1 =
                    (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_EXPLAIN, "TOK_EXPLAIN"), root_1);

                adaptor.addChild(root_1, stream_execStatement.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:639:66: ( explainOption )*
                while (stream_explainOption.hasNext()) {
                  adaptor.addChild(root_1, stream_explainOption.nextTree());
                }
                stream_explainOption.reset();

                adaptor.addChild(root_0, root_1);
              }
            }

            retval.tree = root_0;
          }
          break;
          case 2:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:641:9: KW_REWRITE queryStatementExpression[true]
          {
            KW_REWRITE8 = (Token) match(input, KW_REWRITE, FOLLOW_KW_REWRITE_in_explainStatement1107);
            stream_KW_REWRITE.add(KW_REWRITE8);

            pushFollow(FOLLOW_queryStatementExpression_in_explainStatement1109);
            queryStatementExpression9 = queryStatementExpression(true);

            state._fsp--;

            stream_queryStatementExpression.add(queryStatementExpression9.getTree());

            // AST REWRITE
            // elements: queryStatementExpression
            // token labels:
            // rule labels: retval
            // token list labels:
            // rule list labels:
            // wildcard labels:
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval =
                new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

            root_0 = (CommonTree) adaptor.nil();
            // 641:51: -> ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression )
            {
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:641:54: ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression )
              {
                CommonTree root_1 = (CommonTree) adaptor.nil();
                root_1 = (CommonTree) adaptor.becomeRoot(
                    (CommonTree) adaptor.create(TOK_EXPLAIN_SQ_REWRITE, "TOK_EXPLAIN_SQ_REWRITE"), root_1);

                adaptor.addChild(root_1, stream_queryStatementExpression.nextTree());

                adaptor.addChild(root_0, root_1);
              }
            }

            retval.tree = root_0;
          }
          break;
        }
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "explainStatement"

  public static class explainOption_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "explainOption"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:644:1: explainOption : ( KW_EXTENDED | KW_FORMATTED | KW_DEPENDENCY | KW_LOGICAL | KW_AUTHORIZATION );
  public final HiveParser.explainOption_return explainOption() throws RecognitionException {
    HiveParser.explainOption_return retval = new HiveParser.explainOption_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token set10 = null;

    CommonTree set10_tree = null;

    msgs.push("explain option");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:647:5: ( KW_EXTENDED | KW_FORMATTED | KW_DEPENDENCY | KW_LOGICAL | KW_AUTHORIZATION )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:
      {
        root_0 = (CommonTree) adaptor.nil();

        set10 = (Token) input.LT(1);

        if (input.LA(1) == KW_AUTHORIZATION || input.LA(1) == KW_DEPENDENCY || input.LA(1) == KW_EXTENDED
            || input.LA(1) == KW_FORMATTED || input.LA(1) == KW_LOGICAL) {
          input.consume();
          adaptor.addChild(root_0, (CommonTree) adaptor.create(set10));
          state.errorRecovery = false;
        } else {
          MismatchedSetException mse = new MismatchedSetException(null, input);
          throw mse;
        }
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      msgs.pop();
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "explainOption"

  public static class execStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "execStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:650:1: execStatement : ( queryStatementExpression[true] | loadStatement | exportStatement | importStatement | ddlStatement | deleteStatement | updateStatement );
  public final HiveParser.execStatement_return execStatement() throws RecognitionException {
    HiveParser.execStatement_return retval = new HiveParser.execStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.queryStatementExpression_return queryStatementExpression11 = null;

    HiveParser.loadStatement_return loadStatement12 = null;

    HiveParser.exportStatement_return exportStatement13 = null;

    HiveParser.importStatement_return importStatement14 = null;

    HiveParser.ddlStatement_return ddlStatement15 = null;

    HiveParser.deleteStatement_return deleteStatement16 = null;

    HiveParser.updateStatement_return updateStatement17 = null;

    pushMsg("statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:653:5: ( queryStatementExpression[true] | loadStatement | exportStatement | importStatement | ddlStatement | deleteStatement | updateStatement )
      int alt4 = 7;
      switch (input.LA(1)) {
        case KW_FROM:
        case KW_INSERT:
        case KW_MAP:
        case KW_REDUCE:
        case KW_SELECT:
        case KW_WITH: {
          alt4 = 1;
        }
        break;
        case KW_LOAD: {
          alt4 = 2;
        }
        break;
        case KW_EXPORT: {
          alt4 = 3;
        }
        break;
        case KW_IMPORT: {
          alt4 = 4;
        }
        break;
        case KW_ALTER:
        case KW_ANALYZE:
        case KW_CREATE:
        case KW_DESC:
        case KW_DESCRIBE:
        case KW_DROP:
        case KW_GRANT:
        case KW_LOCK:
        case KW_MSCK:
        case KW_RELOAD:
        case KW_REVOKE:
        case KW_SET:
        case KW_SHOW:
        case KW_TRUNCATE:
        case KW_UNLOCK:
        case KW_USE: {
          alt4 = 5;
        }
        break;
        case KW_DELETE: {
          alt4 = 6;
        }
        break;
        case KW_UPDATE: {
          alt4 = 7;
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 4, 0, input);

          throw nvae;
      }

      switch (alt4) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:653:7: queryStatementExpression[true]
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_queryStatementExpression_in_execStatement1178);
          queryStatementExpression11 = queryStatementExpression(true);

          state._fsp--;

          adaptor.addChild(root_0, queryStatementExpression11.getTree());
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:654:7: loadStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_loadStatement_in_execStatement1187);
          loadStatement12 = loadStatement();

          state._fsp--;

          adaptor.addChild(root_0, loadStatement12.getTree());
        }
        break;
        case 3:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:655:7: exportStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_exportStatement_in_execStatement1195);
          exportStatement13 = exportStatement();

          state._fsp--;

          adaptor.addChild(root_0, exportStatement13.getTree());
        }
        break;
        case 4:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:656:7: importStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_importStatement_in_execStatement1203);
          importStatement14 = importStatement();

          state._fsp--;

          adaptor.addChild(root_0, importStatement14.getTree());
        }
        break;
        case 5:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:657:7: ddlStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_ddlStatement_in_execStatement1211);
          ddlStatement15 = ddlStatement();

          state._fsp--;

          adaptor.addChild(root_0, ddlStatement15.getTree());
        }
        break;
        case 6:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:658:7: deleteStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_deleteStatement_in_execStatement1219);
          deleteStatement16 = deleteStatement();

          state._fsp--;

          adaptor.addChild(root_0, deleteStatement16.getTree());
        }
        break;
        case 7:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:659:7: updateStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_updateStatement_in_execStatement1227);
          updateStatement17 = updateStatement();

          state._fsp--;

          adaptor.addChild(root_0, updateStatement17.getTree());
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "execStatement"

  public static class loadStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "loadStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:662:1: loadStatement : KW_LOAD KW_DATA (islocal= KW_LOCAL )? KW_INPATH (path= StringLiteral ) (isoverwrite= KW_OVERWRITE )? KW_INTO KW_TABLE (tab= tableOrPartition ) -> ^( TOK_LOAD $path $tab ( $islocal)? ( $isoverwrite)? ) ;
  public final HiveParser.loadStatement_return loadStatement() throws RecognitionException {
    HiveParser.loadStatement_return retval = new HiveParser.loadStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token islocal = null;
    Token path = null;
    Token isoverwrite = null;
    Token KW_LOAD18 = null;
    Token KW_DATA19 = null;
    Token KW_INPATH20 = null;
    Token KW_INTO21 = null;
    Token KW_TABLE22 = null;
    HiveParser_IdentifiersParser.tableOrPartition_return tab = null;

    CommonTree islocal_tree = null;
    CommonTree path_tree = null;
    CommonTree isoverwrite_tree = null;
    CommonTree KW_LOAD18_tree = null;
    CommonTree KW_DATA19_tree = null;
    CommonTree KW_INPATH20_tree = null;
    CommonTree KW_INTO21_tree = null;
    CommonTree KW_TABLE22_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_INTO = new RewriteRuleTokenStream(adaptor, "token KW_INTO");
    RewriteRuleTokenStream stream_KW_INPATH = new RewriteRuleTokenStream(adaptor, "token KW_INPATH");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleTokenStream stream_KW_OVERWRITE = new RewriteRuleTokenStream(adaptor, "token KW_OVERWRITE");
    RewriteRuleTokenStream stream_KW_LOAD = new RewriteRuleTokenStream(adaptor, "token KW_LOAD");
    RewriteRuleTokenStream stream_KW_DATA = new RewriteRuleTokenStream(adaptor, "token KW_DATA");
    RewriteRuleTokenStream stream_KW_LOCAL = new RewriteRuleTokenStream(adaptor, "token KW_LOCAL");
    RewriteRuleSubtreeStream stream_tableOrPartition = new RewriteRuleSubtreeStream(adaptor, "rule tableOrPartition");
    pushMsg("load statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:665:5: ( KW_LOAD KW_DATA (islocal= KW_LOCAL )? KW_INPATH (path= StringLiteral ) (isoverwrite= KW_OVERWRITE )? KW_INTO KW_TABLE (tab= tableOrPartition ) -> ^( TOK_LOAD $path $tab ( $islocal)? ( $isoverwrite)? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:665:7: KW_LOAD KW_DATA (islocal= KW_LOCAL )? KW_INPATH (path= StringLiteral ) (isoverwrite= KW_OVERWRITE )? KW_INTO KW_TABLE (tab= tableOrPartition )
      {
        KW_LOAD18 = (Token) match(input, KW_LOAD, FOLLOW_KW_LOAD_in_loadStatement1254);
        stream_KW_LOAD.add(KW_LOAD18);

        KW_DATA19 = (Token) match(input, KW_DATA, FOLLOW_KW_DATA_in_loadStatement1256);
        stream_KW_DATA.add(KW_DATA19);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:665:23: (islocal= KW_LOCAL )?
        int alt5 = 2;
        switch (input.LA(1)) {
          case KW_LOCAL: {
            alt5 = 1;
          }
          break;
        }

        switch (alt5) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:665:24: islocal= KW_LOCAL
          {
            islocal = (Token) match(input, KW_LOCAL, FOLLOW_KW_LOCAL_in_loadStatement1261);
            stream_KW_LOCAL.add(islocal);
          }
          break;
        }

        KW_INPATH20 = (Token) match(input, KW_INPATH, FOLLOW_KW_INPATH_in_loadStatement1265);
        stream_KW_INPATH.add(KW_INPATH20);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:665:53: (path= StringLiteral )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:665:54: path= StringLiteral
        {
          path = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_loadStatement1270);
          stream_StringLiteral.add(path);
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:665:74: (isoverwrite= KW_OVERWRITE )?
        int alt6 = 2;
        switch (input.LA(1)) {
          case KW_OVERWRITE: {
            alt6 = 1;
          }
          break;
        }

        switch (alt6) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:665:75: isoverwrite= KW_OVERWRITE
          {
            isoverwrite = (Token) match(input, KW_OVERWRITE, FOLLOW_KW_OVERWRITE_in_loadStatement1276);
            stream_KW_OVERWRITE.add(isoverwrite);
          }
          break;
        }

        KW_INTO21 = (Token) match(input, KW_INTO, FOLLOW_KW_INTO_in_loadStatement1280);
        stream_KW_INTO.add(KW_INTO21);

        KW_TABLE22 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_loadStatement1282);
        stream_KW_TABLE.add(KW_TABLE22);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:665:119: (tab= tableOrPartition )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:665:120: tab= tableOrPartition
        {
          pushFollow(FOLLOW_tableOrPartition_in_loadStatement1287);
          tab = tableOrPartition();

          state._fsp--;

          stream_tableOrPartition.add(tab.getTree());
        }

        // AST REWRITE
        // elements: isoverwrite, tab, islocal, path
        // token labels: islocal, path, isoverwrite
        // rule labels: tab, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_islocal = new RewriteRuleTokenStream(adaptor, "token islocal", islocal);
        RewriteRuleTokenStream stream_path = new RewriteRuleTokenStream(adaptor, "token path", path);
        RewriteRuleTokenStream stream_isoverwrite =
            new RewriteRuleTokenStream(adaptor, "token isoverwrite", isoverwrite);
        RewriteRuleSubtreeStream stream_tab =
            new RewriteRuleSubtreeStream(adaptor, "rule tab", tab != null ? tab.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 666:5: -> ^( TOK_LOAD $path $tab ( $islocal)? ( $isoverwrite)? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:666:8: ^( TOK_LOAD $path $tab ( $islocal)? ( $isoverwrite)? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_LOAD, "TOK_LOAD"), root_1);

            adaptor.addChild(root_1, stream_path.nextNode());

            adaptor.addChild(root_1, stream_tab.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:666:31: ( $islocal)?
            if (stream_islocal.hasNext()) {
              adaptor.addChild(root_1, stream_islocal.nextNode());
            }
            stream_islocal.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:666:41: ( $isoverwrite)?
            if (stream_isoverwrite.hasNext()) {
              adaptor.addChild(root_1, stream_isoverwrite.nextNode());
            }
            stream_isoverwrite.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "loadStatement"

  public static class replicationClause_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "replicationClause"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:669:1: replicationClause : KW_FOR (isMetadataOnly= KW_METADATA )? KW_REPLICATION LPAREN (replId= StringLiteral ) RPAREN -> ^( TOK_REPLICATION $replId ( $isMetadataOnly)? ) ;
  public final HiveParser.replicationClause_return replicationClause() throws RecognitionException {
    HiveParser.replicationClause_return retval = new HiveParser.replicationClause_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token isMetadataOnly = null;
    Token replId = null;
    Token KW_FOR23 = null;
    Token KW_REPLICATION24 = null;
    Token LPAREN25 = null;
    Token RPAREN26 = null;

    CommonTree isMetadataOnly_tree = null;
    CommonTree replId_tree = null;
    CommonTree KW_FOR23_tree = null;
    CommonTree KW_REPLICATION24_tree = null;
    CommonTree LPAREN25_tree = null;
    CommonTree RPAREN26_tree = null;
    RewriteRuleTokenStream stream_KW_REPLICATION = new RewriteRuleTokenStream(adaptor, "token KW_REPLICATION");
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_FOR = new RewriteRuleTokenStream(adaptor, "token KW_FOR");
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleTokenStream stream_KW_METADATA = new RewriteRuleTokenStream(adaptor, "token KW_METADATA");

    pushMsg("replication clause", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:672:5: ( KW_FOR (isMetadataOnly= KW_METADATA )? KW_REPLICATION LPAREN (replId= StringLiteral ) RPAREN -> ^( TOK_REPLICATION $replId ( $isMetadataOnly)? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:672:7: KW_FOR (isMetadataOnly= KW_METADATA )? KW_REPLICATION LPAREN (replId= StringLiteral ) RPAREN
      {
        KW_FOR23 = (Token) match(input, KW_FOR, FOLLOW_KW_FOR_in_replicationClause1339);
        stream_KW_FOR.add(KW_FOR23);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:672:14: (isMetadataOnly= KW_METADATA )?
        int alt7 = 2;
        switch (input.LA(1)) {
          case KW_METADATA: {
            alt7 = 1;
          }
          break;
        }

        switch (alt7) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:672:15: isMetadataOnly= KW_METADATA
          {
            isMetadataOnly = (Token) match(input, KW_METADATA, FOLLOW_KW_METADATA_in_replicationClause1344);
            stream_KW_METADATA.add(isMetadataOnly);
          }
          break;
        }

        KW_REPLICATION24 = (Token) match(input, KW_REPLICATION, FOLLOW_KW_REPLICATION_in_replicationClause1348);
        stream_KW_REPLICATION.add(KW_REPLICATION24);

        LPAREN25 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_replicationClause1350);
        stream_LPAREN.add(LPAREN25);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:672:66: (replId= StringLiteral )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:672:67: replId= StringLiteral
        {
          replId = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_replicationClause1355);
          stream_StringLiteral.add(replId);
        }

        RPAREN26 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_replicationClause1358);
        stream_RPAREN.add(RPAREN26);

        // AST REWRITE
        // elements: isMetadataOnly, replId
        // token labels: replId, isMetadataOnly
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_replId = new RewriteRuleTokenStream(adaptor, "token replId", replId);
        RewriteRuleTokenStream stream_isMetadataOnly =
            new RewriteRuleTokenStream(adaptor, "token isMetadataOnly", isMetadataOnly);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 673:5: -> ^( TOK_REPLICATION $replId ( $isMetadataOnly)? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:673:8: ^( TOK_REPLICATION $replId ( $isMetadataOnly)? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_REPLICATION, "TOK_REPLICATION"),
                root_1);

            adaptor.addChild(root_1, stream_replId.nextNode());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:673:35: ( $isMetadataOnly)?
            if (stream_isMetadataOnly.hasNext()) {
              adaptor.addChild(root_1, stream_isMetadataOnly.nextNode());
            }
            stream_isMetadataOnly.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "replicationClause"

  public static class exportStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "exportStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:676:1: exportStatement : KW_EXPORT KW_TABLE (tab= tableOrPartition ) KW_TO (path= StringLiteral ) ( replicationClause )? -> ^( TOK_EXPORT $tab $path ( replicationClause )? ) ;
  public final HiveParser.exportStatement_return exportStatement() throws RecognitionException {
    HiveParser.exportStatement_return retval = new HiveParser.exportStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token path = null;
    Token KW_EXPORT27 = null;
    Token KW_TABLE28 = null;
    Token KW_TO29 = null;
    HiveParser_IdentifiersParser.tableOrPartition_return tab = null;

    HiveParser.replicationClause_return replicationClause30 = null;

    CommonTree path_tree = null;
    CommonTree KW_EXPORT27_tree = null;
    CommonTree KW_TABLE28_tree = null;
    CommonTree KW_TO29_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_TO = new RewriteRuleTokenStream(adaptor, "token KW_TO");
    RewriteRuleTokenStream stream_KW_EXPORT = new RewriteRuleTokenStream(adaptor, "token KW_EXPORT");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleSubtreeStream stream_tableOrPartition = new RewriteRuleSubtreeStream(adaptor, "rule tableOrPartition");
    RewriteRuleSubtreeStream stream_replicationClause = new RewriteRuleSubtreeStream(adaptor, "rule replicationClause");
    pushMsg("export statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:679:5: ( KW_EXPORT KW_TABLE (tab= tableOrPartition ) KW_TO (path= StringLiteral ) ( replicationClause )? -> ^( TOK_EXPORT $tab $path ( replicationClause )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:679:7: KW_EXPORT KW_TABLE (tab= tableOrPartition ) KW_TO (path= StringLiteral ) ( replicationClause )?
      {
        KW_EXPORT27 = (Token) match(input, KW_EXPORT, FOLLOW_KW_EXPORT_in_exportStatement1402);
        stream_KW_EXPORT.add(KW_EXPORT27);

        KW_TABLE28 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_exportStatement1410);
        stream_KW_TABLE.add(KW_TABLE28);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:680:16: (tab= tableOrPartition )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:680:17: tab= tableOrPartition
        {
          pushFollow(FOLLOW_tableOrPartition_in_exportStatement1415);
          tab = tableOrPartition();

          state._fsp--;

          stream_tableOrPartition.add(tab.getTree());
        }

        KW_TO29 = (Token) match(input, KW_TO, FOLLOW_KW_TO_in_exportStatement1424);
        stream_KW_TO.add(KW_TO29);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:681:13: (path= StringLiteral )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:681:14: path= StringLiteral
        {
          path = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_exportStatement1429);
          stream_StringLiteral.add(path);
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:682:7: ( replicationClause )?
        int alt8 = 2;
        switch (input.LA(1)) {
          case KW_FOR: {
            alt8 = 1;
          }
          break;
        }

        switch (alt8) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:682:7: replicationClause
          {
            pushFollow(FOLLOW_replicationClause_in_exportStatement1438);
            replicationClause30 = replicationClause();

            state._fsp--;

            stream_replicationClause.add(replicationClause30.getTree());
          }
          break;
        }

        // AST REWRITE
        // elements: path, tab, replicationClause
        // token labels: path
        // rule labels: tab, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_path = new RewriteRuleTokenStream(adaptor, "token path", path);
        RewriteRuleSubtreeStream stream_tab =
            new RewriteRuleSubtreeStream(adaptor, "rule tab", tab != null ? tab.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 683:5: -> ^( TOK_EXPORT $tab $path ( replicationClause )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:683:8: ^( TOK_EXPORT $tab $path ( replicationClause )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_EXPORT, "TOK_EXPORT"), root_1);

            adaptor.addChild(root_1, stream_tab.nextTree());

            adaptor.addChild(root_1, stream_path.nextNode());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:683:32: ( replicationClause )?
            if (stream_replicationClause.hasNext()) {
              adaptor.addChild(root_1, stream_replicationClause.nextTree());
            }
            stream_replicationClause.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "exportStatement"

  public static class importStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "importStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:686:1: importStatement : KW_IMPORT ( (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition ) )? KW_FROM (path= StringLiteral ) ( location )? -> ^( TOK_IMPORT $path ( $tab)? ( $ext)? ( location )? ) ;
  public final HiveParser.importStatement_return importStatement() throws RecognitionException {
    HiveParser.importStatement_return retval = new HiveParser.importStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token ext = null;
    Token path = null;
    Token KW_IMPORT31 = null;
    Token KW_TABLE32 = null;
    Token KW_FROM33 = null;
    HiveParser_IdentifiersParser.tableOrPartition_return tab = null;

    HiveParser.location_return location34 = null;

    CommonTree ext_tree = null;
    CommonTree path_tree = null;
    CommonTree KW_IMPORT31_tree = null;
    CommonTree KW_TABLE32_tree = null;
    CommonTree KW_FROM33_tree = null;
    RewriteRuleTokenStream stream_KW_EXTERNAL = new RewriteRuleTokenStream(adaptor, "token KW_EXTERNAL");
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_FROM = new RewriteRuleTokenStream(adaptor, "token KW_FROM");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleTokenStream stream_KW_IMPORT = new RewriteRuleTokenStream(adaptor, "token KW_IMPORT");
    RewriteRuleSubtreeStream stream_location = new RewriteRuleSubtreeStream(adaptor, "rule location");
    RewriteRuleSubtreeStream stream_tableOrPartition = new RewriteRuleSubtreeStream(adaptor, "rule tableOrPartition");
    pushMsg("import statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:689:8: ( KW_IMPORT ( (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition ) )? KW_FROM (path= StringLiteral ) ( location )? -> ^( TOK_IMPORT $path ( $tab)? ( $ext)? ( location )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:689:10: KW_IMPORT ( (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition ) )? KW_FROM (path= StringLiteral ) ( location )?
      {
        KW_IMPORT31 = (Token) match(input, KW_IMPORT, FOLLOW_KW_IMPORT_in_importStatement1488);
        stream_KW_IMPORT.add(KW_IMPORT31);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:690:10: ( (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition ) )?
        int alt10 = 2;
        switch (input.LA(1)) {
          case KW_EXTERNAL:
          case KW_TABLE: {
            alt10 = 1;
          }
          break;
        }

        switch (alt10) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:690:11: (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:690:11: (ext= KW_EXTERNAL )?
            int alt9 = 2;
            switch (input.LA(1)) {
              case KW_EXTERNAL: {
                alt9 = 1;
              }
              break;
            }

            switch (alt9) {
              case 1:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:690:12: ext= KW_EXTERNAL
              {
                ext = (Token) match(input, KW_EXTERNAL, FOLLOW_KW_EXTERNAL_in_importStatement1503);
                stream_KW_EXTERNAL.add(ext);
              }
              break;
            }

            KW_TABLE32 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_importStatement1507);
            stream_KW_TABLE.add(KW_TABLE32);

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:690:39: (tab= tableOrPartition )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:690:40: tab= tableOrPartition
            {
              pushFollow(FOLLOW_tableOrPartition_in_importStatement1512);
              tab = tableOrPartition();

              state._fsp--;

              stream_tableOrPartition.add(tab.getTree());
            }
          }
          break;
        }

        KW_FROM33 = (Token) match(input, KW_FROM, FOLLOW_KW_FROM_in_importStatement1526);
        stream_KW_FROM.add(KW_FROM33);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:691:18: (path= StringLiteral )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:691:19: path= StringLiteral
        {
          path = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_importStatement1531);
          stream_StringLiteral.add(path);
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:692:10: ( location )?
        int alt11 = 2;
        switch (input.LA(1)) {
          case KW_LOCATION: {
            alt11 = 1;
          }
          break;
        }

        switch (alt11) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:692:10: location
          {
            pushFollow(FOLLOW_location_in_importStatement1543);
            location34 = location();

            state._fsp--;

            stream_location.add(location34.getTree());
          }
          break;
        }

        // AST REWRITE
        // elements: tab, location, ext, path
        // token labels: ext, path
        // rule labels: tab, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_ext = new RewriteRuleTokenStream(adaptor, "token ext", ext);
        RewriteRuleTokenStream stream_path = new RewriteRuleTokenStream(adaptor, "token path", path);
        RewriteRuleSubtreeStream stream_tab =
            new RewriteRuleSubtreeStream(adaptor, "rule tab", tab != null ? tab.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 693:5: -> ^( TOK_IMPORT $path ( $tab)? ( $ext)? ( location )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:693:8: ^( TOK_IMPORT $path ( $tab)? ( $ext)? ( location )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_IMPORT, "TOK_IMPORT"), root_1);

            adaptor.addChild(root_1, stream_path.nextNode());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:693:28: ( $tab)?
            if (stream_tab.hasNext()) {
              adaptor.addChild(root_1, stream_tab.nextTree());
            }
            stream_tab.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:693:34: ( $ext)?
            if (stream_ext.hasNext()) {
              adaptor.addChild(root_1, stream_ext.nextNode());
            }
            stream_ext.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:693:39: ( location )?
            if (stream_location.hasNext()) {
              adaptor.addChild(root_1, stream_location.nextTree());
            }
            stream_location.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "importStatement"

  public static class ddlStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "ddlStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:696:1: ddlStatement : ( createDatabaseStatement | switchDatabaseStatement | dropDatabaseStatement | createTableStatement | dropTableStatement | truncateTableStatement | alterStatement | descStatement | showStatement | metastoreCheck | createViewStatement | dropViewStatement | createFunctionStatement | createMacroStatement | createIndexStatement | dropIndexStatement | dropFunctionStatement | reloadFunctionStatement | dropMacroStatement | analyzeStatement | lockStatement | unlockStatement | lockDatabase | unlockDatabase | createRoleStatement | dropRoleStatement | grantPrivileges | revokePrivileges | showGrants | showRoleGrants | showRolePrincipals | showRoles | grantRole | revokeRole | setRole | showCurrentRole );
  public final HiveParser.ddlStatement_return ddlStatement() throws RecognitionException {
    HiveParser.ddlStatement_return retval = new HiveParser.ddlStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.createDatabaseStatement_return createDatabaseStatement35 = null;

    HiveParser.switchDatabaseStatement_return switchDatabaseStatement36 = null;

    HiveParser.dropDatabaseStatement_return dropDatabaseStatement37 = null;

    HiveParser.createTableStatement_return createTableStatement38 = null;

    HiveParser.dropTableStatement_return dropTableStatement39 = null;

    HiveParser.truncateTableStatement_return truncateTableStatement40 = null;

    HiveParser.alterStatement_return alterStatement41 = null;

    HiveParser.descStatement_return descStatement42 = null;

    HiveParser.showStatement_return showStatement43 = null;

    HiveParser.metastoreCheck_return metastoreCheck44 = null;

    HiveParser.createViewStatement_return createViewStatement45 = null;

    HiveParser.dropViewStatement_return dropViewStatement46 = null;

    HiveParser.createFunctionStatement_return createFunctionStatement47 = null;

    HiveParser.createMacroStatement_return createMacroStatement48 = null;

    HiveParser.createIndexStatement_return createIndexStatement49 = null;

    HiveParser.dropIndexStatement_return dropIndexStatement50 = null;

    HiveParser.dropFunctionStatement_return dropFunctionStatement51 = null;

    HiveParser.reloadFunctionStatement_return reloadFunctionStatement52 = null;

    HiveParser.dropMacroStatement_return dropMacroStatement53 = null;

    HiveParser.analyzeStatement_return analyzeStatement54 = null;

    HiveParser.lockStatement_return lockStatement55 = null;

    HiveParser.unlockStatement_return unlockStatement56 = null;

    HiveParser.lockDatabase_return lockDatabase57 = null;

    HiveParser.unlockDatabase_return unlockDatabase58 = null;

    HiveParser.createRoleStatement_return createRoleStatement59 = null;

    HiveParser.dropRoleStatement_return dropRoleStatement60 = null;

    HiveParser.grantPrivileges_return grantPrivileges61 = null;

    HiveParser.revokePrivileges_return revokePrivileges62 = null;

    HiveParser.showGrants_return showGrants63 = null;

    HiveParser.showRoleGrants_return showRoleGrants64 = null;

    HiveParser.showRolePrincipals_return showRolePrincipals65 = null;

    HiveParser.showRoles_return showRoles66 = null;

    HiveParser.grantRole_return grantRole67 = null;

    HiveParser.revokeRole_return revokeRole68 = null;

    HiveParser.setRole_return setRole69 = null;

    HiveParser.showCurrentRole_return showCurrentRole70 = null;

    pushMsg("ddl statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:699:5: ( createDatabaseStatement | switchDatabaseStatement | dropDatabaseStatement | createTableStatement | dropTableStatement | truncateTableStatement | alterStatement | descStatement | showStatement | metastoreCheck | createViewStatement | dropViewStatement | createFunctionStatement | createMacroStatement | createIndexStatement | dropIndexStatement | dropFunctionStatement | reloadFunctionStatement | dropMacroStatement | analyzeStatement | lockStatement | unlockStatement | lockDatabase | unlockDatabase | createRoleStatement | dropRoleStatement | grantPrivileges | revokePrivileges | showGrants | showRoleGrants | showRolePrincipals | showRoles | grantRole | revokeRole | setRole | showCurrentRole )
      int alt12 = 36;
      alt12 = dfa12.predict(input);
      switch (alt12) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:699:7: createDatabaseStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_createDatabaseStatement_in_ddlStatement1595);
          createDatabaseStatement35 = createDatabaseStatement();

          state._fsp--;

          adaptor.addChild(root_0, createDatabaseStatement35.getTree());
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:700:7: switchDatabaseStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_switchDatabaseStatement_in_ddlStatement1603);
          switchDatabaseStatement36 = switchDatabaseStatement();

          state._fsp--;

          adaptor.addChild(root_0, switchDatabaseStatement36.getTree());
        }
        break;
        case 3:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:701:7: dropDatabaseStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_dropDatabaseStatement_in_ddlStatement1611);
          dropDatabaseStatement37 = dropDatabaseStatement();

          state._fsp--;

          adaptor.addChild(root_0, dropDatabaseStatement37.getTree());
        }
        break;
        case 4:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:702:7: createTableStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_createTableStatement_in_ddlStatement1619);
          createTableStatement38 = createTableStatement();

          state._fsp--;

          adaptor.addChild(root_0, createTableStatement38.getTree());
        }
        break;
        case 5:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:703:7: dropTableStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_dropTableStatement_in_ddlStatement1627);
          dropTableStatement39 = dropTableStatement();

          state._fsp--;

          adaptor.addChild(root_0, dropTableStatement39.getTree());
        }
        break;
        case 6:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:704:7: truncateTableStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_truncateTableStatement_in_ddlStatement1635);
          truncateTableStatement40 = truncateTableStatement();

          state._fsp--;

          adaptor.addChild(root_0, truncateTableStatement40.getTree());
        }
        break;
        case 7:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:705:7: alterStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatement_in_ddlStatement1643);
          alterStatement41 = alterStatement();

          state._fsp--;

          adaptor.addChild(root_0, alterStatement41.getTree());
        }
        break;
        case 8:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:706:7: descStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_descStatement_in_ddlStatement1651);
          descStatement42 = descStatement();

          state._fsp--;

          adaptor.addChild(root_0, descStatement42.getTree());
        }
        break;
        case 9:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:707:7: showStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_showStatement_in_ddlStatement1659);
          showStatement43 = showStatement();

          state._fsp--;

          adaptor.addChild(root_0, showStatement43.getTree());
        }
        break;
        case 10:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:708:7: metastoreCheck
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_metastoreCheck_in_ddlStatement1667);
          metastoreCheck44 = metastoreCheck();

          state._fsp--;

          adaptor.addChild(root_0, metastoreCheck44.getTree());
        }
        break;
        case 11:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:709:7: createViewStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_createViewStatement_in_ddlStatement1675);
          createViewStatement45 = createViewStatement();

          state._fsp--;

          adaptor.addChild(root_0, createViewStatement45.getTree());
        }
        break;
        case 12:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:710:7: dropViewStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_dropViewStatement_in_ddlStatement1683);
          dropViewStatement46 = dropViewStatement();

          state._fsp--;

          adaptor.addChild(root_0, dropViewStatement46.getTree());
        }
        break;
        case 13:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:711:7: createFunctionStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_createFunctionStatement_in_ddlStatement1691);
          createFunctionStatement47 = createFunctionStatement();

          state._fsp--;

          adaptor.addChild(root_0, createFunctionStatement47.getTree());
        }
        break;
        case 14:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:712:7: createMacroStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_createMacroStatement_in_ddlStatement1699);
          createMacroStatement48 = createMacroStatement();

          state._fsp--;

          adaptor.addChild(root_0, createMacroStatement48.getTree());
        }
        break;
        case 15:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:713:7: createIndexStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_createIndexStatement_in_ddlStatement1707);
          createIndexStatement49 = createIndexStatement();

          state._fsp--;

          adaptor.addChild(root_0, createIndexStatement49.getTree());
        }
        break;
        case 16:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:714:7: dropIndexStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_dropIndexStatement_in_ddlStatement1715);
          dropIndexStatement50 = dropIndexStatement();

          state._fsp--;

          adaptor.addChild(root_0, dropIndexStatement50.getTree());
        }
        break;
        case 17:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:715:7: dropFunctionStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_dropFunctionStatement_in_ddlStatement1723);
          dropFunctionStatement51 = dropFunctionStatement();

          state._fsp--;

          adaptor.addChild(root_0, dropFunctionStatement51.getTree());
        }
        break;
        case 18:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:716:7: reloadFunctionStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_reloadFunctionStatement_in_ddlStatement1731);
          reloadFunctionStatement52 = reloadFunctionStatement();

          state._fsp--;

          adaptor.addChild(root_0, reloadFunctionStatement52.getTree());
        }
        break;
        case 19:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:717:7: dropMacroStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_dropMacroStatement_in_ddlStatement1739);
          dropMacroStatement53 = dropMacroStatement();

          state._fsp--;

          adaptor.addChild(root_0, dropMacroStatement53.getTree());
        }
        break;
        case 20:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:718:7: analyzeStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_analyzeStatement_in_ddlStatement1747);
          analyzeStatement54 = analyzeStatement();

          state._fsp--;

          adaptor.addChild(root_0, analyzeStatement54.getTree());
        }
        break;
        case 21:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:719:7: lockStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_lockStatement_in_ddlStatement1755);
          lockStatement55 = lockStatement();

          state._fsp--;

          adaptor.addChild(root_0, lockStatement55.getTree());
        }
        break;
        case 22:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:720:7: unlockStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_unlockStatement_in_ddlStatement1763);
          unlockStatement56 = unlockStatement();

          state._fsp--;

          adaptor.addChild(root_0, unlockStatement56.getTree());
        }
        break;
        case 23:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:721:7: lockDatabase
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_lockDatabase_in_ddlStatement1771);
          lockDatabase57 = lockDatabase();

          state._fsp--;

          adaptor.addChild(root_0, lockDatabase57.getTree());
        }
        break;
        case 24:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:722:7: unlockDatabase
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_unlockDatabase_in_ddlStatement1779);
          unlockDatabase58 = unlockDatabase();

          state._fsp--;

          adaptor.addChild(root_0, unlockDatabase58.getTree());
        }
        break;
        case 25:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:723:7: createRoleStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_createRoleStatement_in_ddlStatement1787);
          createRoleStatement59 = createRoleStatement();

          state._fsp--;

          adaptor.addChild(root_0, createRoleStatement59.getTree());
        }
        break;
        case 26:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:724:7: dropRoleStatement
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_dropRoleStatement_in_ddlStatement1795);
          dropRoleStatement60 = dropRoleStatement();

          state._fsp--;

          adaptor.addChild(root_0, dropRoleStatement60.getTree());
        }
        break;
        case 27:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:725:7: grantPrivileges
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_grantPrivileges_in_ddlStatement1803);
          grantPrivileges61 = grantPrivileges();

          state._fsp--;

          adaptor.addChild(root_0, grantPrivileges61.getTree());
        }
        break;
        case 28:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:726:7: revokePrivileges
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_revokePrivileges_in_ddlStatement1811);
          revokePrivileges62 = revokePrivileges();

          state._fsp--;

          adaptor.addChild(root_0, revokePrivileges62.getTree());
        }
        break;
        case 29:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:727:7: showGrants
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_showGrants_in_ddlStatement1819);
          showGrants63 = showGrants();

          state._fsp--;

          adaptor.addChild(root_0, showGrants63.getTree());
        }
        break;
        case 30:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:728:7: showRoleGrants
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_showRoleGrants_in_ddlStatement1827);
          showRoleGrants64 = showRoleGrants();

          state._fsp--;

          adaptor.addChild(root_0, showRoleGrants64.getTree());
        }
        break;
        case 31:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:729:7: showRolePrincipals
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_showRolePrincipals_in_ddlStatement1835);
          showRolePrincipals65 = showRolePrincipals();

          state._fsp--;

          adaptor.addChild(root_0, showRolePrincipals65.getTree());
        }
        break;
        case 32:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:730:7: showRoles
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_showRoles_in_ddlStatement1843);
          showRoles66 = showRoles();

          state._fsp--;

          adaptor.addChild(root_0, showRoles66.getTree());
        }
        break;
        case 33:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:731:7: grantRole
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_grantRole_in_ddlStatement1851);
          grantRole67 = grantRole();

          state._fsp--;

          adaptor.addChild(root_0, grantRole67.getTree());
        }
        break;
        case 34:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:732:7: revokeRole
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_revokeRole_in_ddlStatement1859);
          revokeRole68 = revokeRole();

          state._fsp--;

          adaptor.addChild(root_0, revokeRole68.getTree());
        }
        break;
        case 35:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:733:7: setRole
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_setRole_in_ddlStatement1867);
          setRole69 = setRole();

          state._fsp--;

          adaptor.addChild(root_0, setRole69.getTree());
        }
        break;
        case 36:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:734:7: showCurrentRole
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_showCurrentRole_in_ddlStatement1875);
          showCurrentRole70 = showCurrentRole();

          state._fsp--;

          adaptor.addChild(root_0, showCurrentRole70.getTree());
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "ddlStatement"

  public static class ifExists_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "ifExists"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:737:1: ifExists : KW_IF KW_EXISTS -> ^( TOK_IFEXISTS ) ;
  public final HiveParser.ifExists_return ifExists() throws RecognitionException {
    HiveParser.ifExists_return retval = new HiveParser.ifExists_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_IF71 = null;
    Token KW_EXISTS72 = null;

    CommonTree KW_IF71_tree = null;
    CommonTree KW_EXISTS72_tree = null;
    RewriteRuleTokenStream stream_KW_EXISTS = new RewriteRuleTokenStream(adaptor, "token KW_EXISTS");
    RewriteRuleTokenStream stream_KW_IF = new RewriteRuleTokenStream(adaptor, "token KW_IF");

    pushMsg("if exists clause", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:740:5: ( KW_IF KW_EXISTS -> ^( TOK_IFEXISTS ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:740:7: KW_IF KW_EXISTS
      {
        KW_IF71 = (Token) match(input, KW_IF, FOLLOW_KW_IF_in_ifExists1902);
        stream_KW_IF.add(KW_IF71);

        KW_EXISTS72 = (Token) match(input, KW_EXISTS, FOLLOW_KW_EXISTS_in_ifExists1904);
        stream_KW_EXISTS.add(KW_EXISTS72);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 741:5: -> ^( TOK_IFEXISTS )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:741:8: ^( TOK_IFEXISTS )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_IFEXISTS, "TOK_IFEXISTS"), root_1);

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "ifExists"

  public static class restrictOrCascade_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "restrictOrCascade"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:744:1: restrictOrCascade : ( KW_RESTRICT -> ^( TOK_RESTRICT ) | KW_CASCADE -> ^( TOK_CASCADE ) );
  public final HiveParser.restrictOrCascade_return restrictOrCascade() throws RecognitionException {
    HiveParser.restrictOrCascade_return retval = new HiveParser.restrictOrCascade_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_RESTRICT73 = null;
    Token KW_CASCADE74 = null;

    CommonTree KW_RESTRICT73_tree = null;
    CommonTree KW_CASCADE74_tree = null;
    RewriteRuleTokenStream stream_KW_CASCADE = new RewriteRuleTokenStream(adaptor, "token KW_CASCADE");
    RewriteRuleTokenStream stream_KW_RESTRICT = new RewriteRuleTokenStream(adaptor, "token KW_RESTRICT");

    pushMsg("restrict or cascade clause", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:747:5: ( KW_RESTRICT -> ^( TOK_RESTRICT ) | KW_CASCADE -> ^( TOK_CASCADE ) )
      int alt13 = 2;
      switch (input.LA(1)) {
        case KW_RESTRICT: {
          alt13 = 1;
        }
        break;
        case KW_CASCADE: {
          alt13 = 2;
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 13, 0, input);

          throw nvae;
      }

      switch (alt13) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:747:7: KW_RESTRICT
        {
          KW_RESTRICT73 = (Token) match(input, KW_RESTRICT, FOLLOW_KW_RESTRICT_in_restrictOrCascade1941);
          stream_KW_RESTRICT.add(KW_RESTRICT73);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 748:5: -> ^( TOK_RESTRICT )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:748:8: ^( TOK_RESTRICT )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_RESTRICT, "TOK_RESTRICT"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:749:7: KW_CASCADE
        {
          KW_CASCADE74 = (Token) match(input, KW_CASCADE, FOLLOW_KW_CASCADE_in_restrictOrCascade1959);
          stream_KW_CASCADE.add(KW_CASCADE74);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 750:5: -> ^( TOK_CASCADE )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:750:8: ^( TOK_CASCADE )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_CASCADE, "TOK_CASCADE"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "restrictOrCascade"

  public static class ifNotExists_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "ifNotExists"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:753:1: ifNotExists : KW_IF KW_NOT KW_EXISTS -> ^( TOK_IFNOTEXISTS ) ;
  public final HiveParser.ifNotExists_return ifNotExists() throws RecognitionException {
    HiveParser.ifNotExists_return retval = new HiveParser.ifNotExists_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_IF75 = null;
    Token KW_NOT76 = null;
    Token KW_EXISTS77 = null;

    CommonTree KW_IF75_tree = null;
    CommonTree KW_NOT76_tree = null;
    CommonTree KW_EXISTS77_tree = null;
    RewriteRuleTokenStream stream_KW_NOT = new RewriteRuleTokenStream(adaptor, "token KW_NOT");
    RewriteRuleTokenStream stream_KW_EXISTS = new RewriteRuleTokenStream(adaptor, "token KW_EXISTS");
    RewriteRuleTokenStream stream_KW_IF = new RewriteRuleTokenStream(adaptor, "token KW_IF");

    pushMsg("if not exists clause", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:756:5: ( KW_IF KW_NOT KW_EXISTS -> ^( TOK_IFNOTEXISTS ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:756:7: KW_IF KW_NOT KW_EXISTS
      {
        KW_IF75 = (Token) match(input, KW_IF, FOLLOW_KW_IF_in_ifNotExists1996);
        stream_KW_IF.add(KW_IF75);

        KW_NOT76 = (Token) match(input, KW_NOT, FOLLOW_KW_NOT_in_ifNotExists1998);
        stream_KW_NOT.add(KW_NOT76);

        KW_EXISTS77 = (Token) match(input, KW_EXISTS, FOLLOW_KW_EXISTS_in_ifNotExists2000);
        stream_KW_EXISTS.add(KW_EXISTS77);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 757:5: -> ^( TOK_IFNOTEXISTS )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:757:8: ^( TOK_IFNOTEXISTS )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_IFNOTEXISTS, "TOK_IFNOTEXISTS"),
                root_1);

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "ifNotExists"

  public static class storedAsDirs_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "storedAsDirs"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:760:1: storedAsDirs : KW_STORED KW_AS KW_DIRECTORIES -> ^( TOK_STOREDASDIRS ) ;
  public final HiveParser.storedAsDirs_return storedAsDirs() throws RecognitionException {
    HiveParser.storedAsDirs_return retval = new HiveParser.storedAsDirs_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_STORED78 = null;
    Token KW_AS79 = null;
    Token KW_DIRECTORIES80 = null;

    CommonTree KW_STORED78_tree = null;
    CommonTree KW_AS79_tree = null;
    CommonTree KW_DIRECTORIES80_tree = null;
    RewriteRuleTokenStream stream_KW_DIRECTORIES = new RewriteRuleTokenStream(adaptor, "token KW_DIRECTORIES");
    RewriteRuleTokenStream stream_KW_AS = new RewriteRuleTokenStream(adaptor, "token KW_AS");
    RewriteRuleTokenStream stream_KW_STORED = new RewriteRuleTokenStream(adaptor, "token KW_STORED");

    pushMsg("stored as directories", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:763:5: ( KW_STORED KW_AS KW_DIRECTORIES -> ^( TOK_STOREDASDIRS ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:763:7: KW_STORED KW_AS KW_DIRECTORIES
      {
        KW_STORED78 = (Token) match(input, KW_STORED, FOLLOW_KW_STORED_in_storedAsDirs2037);
        stream_KW_STORED.add(KW_STORED78);

        KW_AS79 = (Token) match(input, KW_AS, FOLLOW_KW_AS_in_storedAsDirs2039);
        stream_KW_AS.add(KW_AS79);

        KW_DIRECTORIES80 = (Token) match(input, KW_DIRECTORIES, FOLLOW_KW_DIRECTORIES_in_storedAsDirs2041);
        stream_KW_DIRECTORIES.add(KW_DIRECTORIES80);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 764:5: -> ^( TOK_STOREDASDIRS )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:764:8: ^( TOK_STOREDASDIRS )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_STOREDASDIRS, "TOK_STOREDASDIRS"),
                root_1);

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "storedAsDirs"

  public static class orReplace_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "orReplace"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:767:1: orReplace : KW_OR KW_REPLACE -> ^( TOK_ORREPLACE ) ;
  public final HiveParser.orReplace_return orReplace() throws RecognitionException {
    HiveParser.orReplace_return retval = new HiveParser.orReplace_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_OR81 = null;
    Token KW_REPLACE82 = null;

    CommonTree KW_OR81_tree = null;
    CommonTree KW_REPLACE82_tree = null;
    RewriteRuleTokenStream stream_KW_REPLACE = new RewriteRuleTokenStream(adaptor, "token KW_REPLACE");
    RewriteRuleTokenStream stream_KW_OR = new RewriteRuleTokenStream(adaptor, "token KW_OR");

    pushMsg("or replace clause", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:770:5: ( KW_OR KW_REPLACE -> ^( TOK_ORREPLACE ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:770:7: KW_OR KW_REPLACE
      {
        KW_OR81 = (Token) match(input, KW_OR, FOLLOW_KW_OR_in_orReplace2078);
        stream_KW_OR.add(KW_OR81);

        KW_REPLACE82 = (Token) match(input, KW_REPLACE, FOLLOW_KW_REPLACE_in_orReplace2080);
        stream_KW_REPLACE.add(KW_REPLACE82);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 771:5: -> ^( TOK_ORREPLACE )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:771:8: ^( TOK_ORREPLACE )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_ORREPLACE, "TOK_ORREPLACE"), root_1);

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "orReplace"

  public static class ignoreProtection_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "ignoreProtection"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:774:1: ignoreProtection : KW_IGNORE KW_PROTECTION -> ^( TOK_IGNOREPROTECTION ) ;
  public final HiveParser.ignoreProtection_return ignoreProtection() throws RecognitionException {
    HiveParser.ignoreProtection_return retval = new HiveParser.ignoreProtection_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_IGNORE83 = null;
    Token KW_PROTECTION84 = null;

    CommonTree KW_IGNORE83_tree = null;
    CommonTree KW_PROTECTION84_tree = null;
    RewriteRuleTokenStream stream_KW_PROTECTION = new RewriteRuleTokenStream(adaptor, "token KW_PROTECTION");
    RewriteRuleTokenStream stream_KW_IGNORE = new RewriteRuleTokenStream(adaptor, "token KW_IGNORE");

    pushMsg("ignore protection clause", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:777:9: ( KW_IGNORE KW_PROTECTION -> ^( TOK_IGNOREPROTECTION ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:777:11: KW_IGNORE KW_PROTECTION
      {
        KW_IGNORE83 = (Token) match(input, KW_IGNORE, FOLLOW_KW_IGNORE_in_ignoreProtection2121);
        stream_KW_IGNORE.add(KW_IGNORE83);

        KW_PROTECTION84 = (Token) match(input, KW_PROTECTION, FOLLOW_KW_PROTECTION_in_ignoreProtection2123);
        stream_KW_PROTECTION.add(KW_PROTECTION84);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 778:9: -> ^( TOK_IGNOREPROTECTION )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:778:12: ^( TOK_IGNOREPROTECTION )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_IGNOREPROTECTION, "TOK_IGNOREPROTECTION"), root_1);

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "ignoreProtection"

  public static class createDatabaseStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "createDatabaseStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:781:1: createDatabaseStatement : KW_CREATE ( KW_DATABASE | KW_SCHEMA ) ( ifNotExists )? name= identifier ( databaseComment )? ( location )? ( KW_WITH KW_DBPROPERTIES dbprops= dbProperties )? -> ^( TOK_CREATEDATABASE $name ( ifNotExists )? ( location )? ( databaseComment )? ( $dbprops)? ) ;
  public final HiveParser.createDatabaseStatement_return createDatabaseStatement() throws RecognitionException {
    HiveParser.createDatabaseStatement_return retval = new HiveParser.createDatabaseStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_CREATE85 = null;
    Token KW_DATABASE86 = null;
    Token KW_SCHEMA87 = null;
    Token KW_WITH91 = null;
    Token KW_DBPROPERTIES92 = null;
    HiveParser_IdentifiersParser.identifier_return name = null;

    HiveParser.dbProperties_return dbprops = null;

    HiveParser.ifNotExists_return ifNotExists88 = null;

    HiveParser.databaseComment_return databaseComment89 = null;

    HiveParser.location_return location90 = null;

    CommonTree KW_CREATE85_tree = null;
    CommonTree KW_DATABASE86_tree = null;
    CommonTree KW_SCHEMA87_tree = null;
    CommonTree KW_WITH91_tree = null;
    CommonTree KW_DBPROPERTIES92_tree = null;
    RewriteRuleTokenStream stream_KW_DBPROPERTIES = new RewriteRuleTokenStream(adaptor, "token KW_DBPROPERTIES");
    RewriteRuleTokenStream stream_KW_SCHEMA = new RewriteRuleTokenStream(adaptor, "token KW_SCHEMA");
    RewriteRuleTokenStream stream_KW_CREATE = new RewriteRuleTokenStream(adaptor, "token KW_CREATE");
    RewriteRuleTokenStream stream_KW_DATABASE = new RewriteRuleTokenStream(adaptor, "token KW_DATABASE");
    RewriteRuleTokenStream stream_KW_WITH = new RewriteRuleTokenStream(adaptor, "token KW_WITH");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_dbProperties = new RewriteRuleSubtreeStream(adaptor, "rule dbProperties");
    RewriteRuleSubtreeStream stream_databaseComment = new RewriteRuleSubtreeStream(adaptor, "rule databaseComment");
    RewriteRuleSubtreeStream stream_ifNotExists = new RewriteRuleSubtreeStream(adaptor, "rule ifNotExists");
    RewriteRuleSubtreeStream stream_location = new RewriteRuleSubtreeStream(adaptor, "rule location");
    pushMsg("create database statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:784:5: ( KW_CREATE ( KW_DATABASE | KW_SCHEMA ) ( ifNotExists )? name= identifier ( databaseComment )? ( location )? ( KW_WITH KW_DBPROPERTIES dbprops= dbProperties )? -> ^( TOK_CREATEDATABASE $name ( ifNotExists )? ( location )? ( databaseComment )? ( $dbprops)? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:784:7: KW_CREATE ( KW_DATABASE | KW_SCHEMA ) ( ifNotExists )? name= identifier ( databaseComment )? ( location )? ( KW_WITH KW_DBPROPERTIES dbprops= dbProperties )?
      {
        KW_CREATE85 = (Token) match(input, KW_CREATE, FOLLOW_KW_CREATE_in_createDatabaseStatement2168);
        stream_KW_CREATE.add(KW_CREATE85);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:784:17: ( KW_DATABASE | KW_SCHEMA )
        int alt14 = 2;
        switch (input.LA(1)) {
          case KW_DATABASE: {
            alt14 = 1;
          }
          break;
          case KW_SCHEMA: {
            alt14 = 2;
          }
          break;
          default:
            NoViableAltException nvae = new NoViableAltException("", 14, 0, input);

            throw nvae;
        }

        switch (alt14) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:784:18: KW_DATABASE
          {
            KW_DATABASE86 = (Token) match(input, KW_DATABASE, FOLLOW_KW_DATABASE_in_createDatabaseStatement2171);
            stream_KW_DATABASE.add(KW_DATABASE86);
          }
          break;
          case 2:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:784:30: KW_SCHEMA
          {
            KW_SCHEMA87 = (Token) match(input, KW_SCHEMA, FOLLOW_KW_SCHEMA_in_createDatabaseStatement2173);
            stream_KW_SCHEMA.add(KW_SCHEMA87);
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:785:9: ( ifNotExists )?
        int alt15 = 2;
        switch (input.LA(1)) {
          case KW_IF: {
            alt15 = 1;
          }
          break;
        }

        switch (alt15) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:785:9: ifNotExists
          {
            pushFollow(FOLLOW_ifNotExists_in_createDatabaseStatement2184);
            ifNotExists88 = ifNotExists();

            state._fsp--;

            stream_ifNotExists.add(ifNotExists88.getTree());
          }
          break;
        }

        pushFollow(FOLLOW_identifier_in_createDatabaseStatement2197);
        name = identifier();

        state._fsp--;

        stream_identifier.add(name.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:787:9: ( databaseComment )?
        int alt16 = 2;
        switch (input.LA(1)) {
          case KW_COMMENT: {
            alt16 = 1;
          }
          break;
        }

        switch (alt16) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:787:9: databaseComment
          {
            pushFollow(FOLLOW_databaseComment_in_createDatabaseStatement2207);
            databaseComment89 = databaseComment();

            state._fsp--;

            stream_databaseComment.add(databaseComment89.getTree());
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:788:9: ( location )?
        int alt17 = 2;
        switch (input.LA(1)) {
          case KW_LOCATION: {
            alt17 = 1;
          }
          break;
        }

        switch (alt17) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:788:9: location
          {
            pushFollow(FOLLOW_location_in_createDatabaseStatement2218);
            location90 = location();

            state._fsp--;

            stream_location.add(location90.getTree());
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:789:9: ( KW_WITH KW_DBPROPERTIES dbprops= dbProperties )?
        int alt18 = 2;
        switch (input.LA(1)) {
          case KW_WITH: {
            alt18 = 1;
          }
          break;
        }

        switch (alt18) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:789:10: KW_WITH KW_DBPROPERTIES dbprops= dbProperties
          {
            KW_WITH91 = (Token) match(input, KW_WITH, FOLLOW_KW_WITH_in_createDatabaseStatement2230);
            stream_KW_WITH.add(KW_WITH91);

            KW_DBPROPERTIES92 =
                (Token) match(input, KW_DBPROPERTIES, FOLLOW_KW_DBPROPERTIES_in_createDatabaseStatement2232);
            stream_KW_DBPROPERTIES.add(KW_DBPROPERTIES92);

            pushFollow(FOLLOW_dbProperties_in_createDatabaseStatement2236);
            dbprops = dbProperties();

            state._fsp--;

            stream_dbProperties.add(dbprops.getTree());
          }
          break;
        }

        // AST REWRITE
        // elements: ifNotExists, dbprops, name, location, databaseComment
        // token labels:
        // rule labels: name, dbprops, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_name =
            new RewriteRuleSubtreeStream(adaptor, "rule name", name != null ? name.tree : null);
        RewriteRuleSubtreeStream stream_dbprops =
            new RewriteRuleSubtreeStream(adaptor, "rule dbprops", dbprops != null ? dbprops.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 790:5: -> ^( TOK_CREATEDATABASE $name ( ifNotExists )? ( location )? ( databaseComment )? ( $dbprops)? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:790:8: ^( TOK_CREATEDATABASE $name ( ifNotExists )? ( location )? ( databaseComment )? ( $dbprops)? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_CREATEDATABASE, "TOK_CREATEDATABASE"),
                    root_1);

            adaptor.addChild(root_1, stream_name.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:790:35: ( ifNotExists )?
            if (stream_ifNotExists.hasNext()) {
              adaptor.addChild(root_1, stream_ifNotExists.nextTree());
            }
            stream_ifNotExists.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:790:48: ( location )?
            if (stream_location.hasNext()) {
              adaptor.addChild(root_1, stream_location.nextTree());
            }
            stream_location.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:790:58: ( databaseComment )?
            if (stream_databaseComment.hasNext()) {
              adaptor.addChild(root_1, stream_databaseComment.nextTree());
            }
            stream_databaseComment.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:790:76: ( $dbprops)?
            if (stream_dbprops.hasNext()) {
              adaptor.addChild(root_1, stream_dbprops.nextTree());
            }
            stream_dbprops.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "createDatabaseStatement"

  public static class location_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "location"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:793:1: location : KW_LOCATION locn= StringLiteral -> ^( TOK_LOCATION $locn) ;
  public final HiveParser.location_return location() throws RecognitionException {
    HiveParser.location_return retval = new HiveParser.location_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token locn = null;
    Token KW_LOCATION93 = null;

    CommonTree locn_tree = null;
    CommonTree KW_LOCATION93_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_LOCATION = new RewriteRuleTokenStream(adaptor, "token KW_LOCATION");

    pushMsg("location specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:796:5: ( KW_LOCATION locn= StringLiteral -> ^( TOK_LOCATION $locn) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:797:7: KW_LOCATION locn= StringLiteral
      {
        KW_LOCATION93 = (Token) match(input, KW_LOCATION, FOLLOW_KW_LOCATION_in_location2297);
        stream_KW_LOCATION.add(KW_LOCATION93);

        locn = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_location2301);
        stream_StringLiteral.add(locn);

        // AST REWRITE
        // elements: locn
        // token labels: locn
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_locn = new RewriteRuleTokenStream(adaptor, "token locn", locn);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 797:38: -> ^( TOK_LOCATION $locn)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:797:41: ^( TOK_LOCATION $locn)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_LOCATION, "TOK_LOCATION"), root_1);

            adaptor.addChild(root_1, stream_locn.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "location"

  public static class dbProperties_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "dbProperties"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:800:1: dbProperties : LPAREN dbPropertiesList RPAREN -> ^( TOK_DATABASEPROPERTIES dbPropertiesList ) ;
  public final HiveParser.dbProperties_return dbProperties() throws RecognitionException {
    HiveParser.dbProperties_return retval = new HiveParser.dbProperties_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token LPAREN94 = null;
    Token RPAREN96 = null;
    HiveParser.dbPropertiesList_return dbPropertiesList95 = null;

    CommonTree LPAREN94_tree = null;
    CommonTree RPAREN96_tree = null;
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleSubtreeStream stream_dbPropertiesList = new RewriteRuleSubtreeStream(adaptor, "rule dbPropertiesList");
    pushMsg("dbproperties", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:803:5: ( LPAREN dbPropertiesList RPAREN -> ^( TOK_DATABASEPROPERTIES dbPropertiesList ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:804:7: LPAREN dbPropertiesList RPAREN
      {
        LPAREN94 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_dbProperties2343);
        stream_LPAREN.add(LPAREN94);

        pushFollow(FOLLOW_dbPropertiesList_in_dbProperties2345);
        dbPropertiesList95 = dbPropertiesList();

        state._fsp--;

        stream_dbPropertiesList.add(dbPropertiesList95.getTree());

        RPAREN96 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_dbProperties2347);
        stream_RPAREN.add(RPAREN96);

        // AST REWRITE
        // elements: dbPropertiesList
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 804:38: -> ^( TOK_DATABASEPROPERTIES dbPropertiesList )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:804:41: ^( TOK_DATABASEPROPERTIES dbPropertiesList )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_DATABASEPROPERTIES, "TOK_DATABASEPROPERTIES"), root_1);

            adaptor.addChild(root_1, stream_dbPropertiesList.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "dbProperties"

  public static class dbPropertiesList_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "dbPropertiesList"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:807:1: dbPropertiesList : keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_DBPROPLIST ( keyValueProperty )+ ) ;
  public final HiveParser.dbPropertiesList_return dbPropertiesList() throws RecognitionException {
    HiveParser.dbPropertiesList_return retval = new HiveParser.dbPropertiesList_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token COMMA98 = null;
    HiveParser.keyValueProperty_return keyValueProperty97 = null;

    HiveParser.keyValueProperty_return keyValueProperty99 = null;

    CommonTree COMMA98_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleSubtreeStream stream_keyValueProperty = new RewriteRuleSubtreeStream(adaptor, "rule keyValueProperty");
    pushMsg("database properties list", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:810:5: ( keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_DBPROPLIST ( keyValueProperty )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:811:7: keyValueProperty ( COMMA keyValueProperty )*
      {
        pushFollow(FOLLOW_keyValueProperty_in_dbPropertiesList2388);
        keyValueProperty97 = keyValueProperty();

        state._fsp--;

        stream_keyValueProperty.add(keyValueProperty97.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:811:24: ( COMMA keyValueProperty )*
        loop19:
        do {
          int alt19 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt19 = 1;
            }
            break;
          }

          switch (alt19) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:811:25: COMMA keyValueProperty
            {
              COMMA98 = (Token) match(input, COMMA, FOLLOW_COMMA_in_dbPropertiesList2391);
              stream_COMMA.add(COMMA98);

              pushFollow(FOLLOW_keyValueProperty_in_dbPropertiesList2393);
              keyValueProperty99 = keyValueProperty();

              state._fsp--;

              stream_keyValueProperty.add(keyValueProperty99.getTree());
            }
            break;

            default:
              break loop19;
          }
        } while (true);

        // AST REWRITE
        // elements: keyValueProperty
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 811:50: -> ^( TOK_DBPROPLIST ( keyValueProperty )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:811:53: ^( TOK_DBPROPLIST ( keyValueProperty )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DBPROPLIST, "TOK_DBPROPLIST"), root_1);

            if (!(stream_keyValueProperty.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_keyValueProperty.hasNext()) {
              adaptor.addChild(root_1, stream_keyValueProperty.nextTree());
            }
            stream_keyValueProperty.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "dbPropertiesList"

  public static class switchDatabaseStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "switchDatabaseStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:815:1: switchDatabaseStatement : KW_USE identifier -> ^( TOK_SWITCHDATABASE identifier ) ;
  public final HiveParser.switchDatabaseStatement_return switchDatabaseStatement() throws RecognitionException {
    HiveParser.switchDatabaseStatement_return retval = new HiveParser.switchDatabaseStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_USE100 = null;
    HiveParser_IdentifiersParser.identifier_return identifier101 = null;

    CommonTree KW_USE100_tree = null;
    RewriteRuleTokenStream stream_KW_USE = new RewriteRuleTokenStream(adaptor, "token KW_USE");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    pushMsg("switch database statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:818:5: ( KW_USE identifier -> ^( TOK_SWITCHDATABASE identifier ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:818:7: KW_USE identifier
      {
        KW_USE100 = (Token) match(input, KW_USE, FOLLOW_KW_USE_in_switchDatabaseStatement2432);
        stream_KW_USE.add(KW_USE100);

        pushFollow(FOLLOW_identifier_in_switchDatabaseStatement2434);
        identifier101 = identifier();

        state._fsp--;

        stream_identifier.add(identifier101.getTree());

        // AST REWRITE
        // elements: identifier
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 819:5: -> ^( TOK_SWITCHDATABASE identifier )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:819:8: ^( TOK_SWITCHDATABASE identifier )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SWITCHDATABASE, "TOK_SWITCHDATABASE"),
                    root_1);

            adaptor.addChild(root_1, stream_identifier.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "switchDatabaseStatement"

  public static class dropDatabaseStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "dropDatabaseStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:822:1: dropDatabaseStatement : KW_DROP ( KW_DATABASE | KW_SCHEMA ) ( ifExists )? identifier ( restrictOrCascade )? -> ^( TOK_DROPDATABASE identifier ( ifExists )? ( restrictOrCascade )? ) ;
  public final HiveParser.dropDatabaseStatement_return dropDatabaseStatement() throws RecognitionException {
    HiveParser.dropDatabaseStatement_return retval = new HiveParser.dropDatabaseStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_DROP102 = null;
    Token KW_DATABASE103 = null;
    Token KW_SCHEMA104 = null;
    HiveParser.ifExists_return ifExists105 = null;

    HiveParser_IdentifiersParser.identifier_return identifier106 = null;

    HiveParser.restrictOrCascade_return restrictOrCascade107 = null;

    CommonTree KW_DROP102_tree = null;
    CommonTree KW_DATABASE103_tree = null;
    CommonTree KW_SCHEMA104_tree = null;
    RewriteRuleTokenStream stream_KW_DROP = new RewriteRuleTokenStream(adaptor, "token KW_DROP");
    RewriteRuleTokenStream stream_KW_SCHEMA = new RewriteRuleTokenStream(adaptor, "token KW_SCHEMA");
    RewriteRuleTokenStream stream_KW_DATABASE = new RewriteRuleTokenStream(adaptor, "token KW_DATABASE");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_ifExists = new RewriteRuleSubtreeStream(adaptor, "rule ifExists");
    RewriteRuleSubtreeStream stream_restrictOrCascade = new RewriteRuleSubtreeStream(adaptor, "rule restrictOrCascade");
    pushMsg("drop database statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:825:5: ( KW_DROP ( KW_DATABASE | KW_SCHEMA ) ( ifExists )? identifier ( restrictOrCascade )? -> ^( TOK_DROPDATABASE identifier ( ifExists )? ( restrictOrCascade )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:825:7: KW_DROP ( KW_DATABASE | KW_SCHEMA ) ( ifExists )? identifier ( restrictOrCascade )?
      {
        KW_DROP102 = (Token) match(input, KW_DROP, FOLLOW_KW_DROP_in_dropDatabaseStatement2473);
        stream_KW_DROP.add(KW_DROP102);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:825:15: ( KW_DATABASE | KW_SCHEMA )
        int alt20 = 2;
        switch (input.LA(1)) {
          case KW_DATABASE: {
            alt20 = 1;
          }
          break;
          case KW_SCHEMA: {
            alt20 = 2;
          }
          break;
          default:
            NoViableAltException nvae = new NoViableAltException("", 20, 0, input);

            throw nvae;
        }

        switch (alt20) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:825:16: KW_DATABASE
          {
            KW_DATABASE103 = (Token) match(input, KW_DATABASE, FOLLOW_KW_DATABASE_in_dropDatabaseStatement2476);
            stream_KW_DATABASE.add(KW_DATABASE103);
          }
          break;
          case 2:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:825:28: KW_SCHEMA
          {
            KW_SCHEMA104 = (Token) match(input, KW_SCHEMA, FOLLOW_KW_SCHEMA_in_dropDatabaseStatement2478);
            stream_KW_SCHEMA.add(KW_SCHEMA104);
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:825:39: ( ifExists )?
        int alt21 = 2;
        switch (input.LA(1)) {
          case KW_IF: {
            alt21 = 1;
          }
          break;
        }

        switch (alt21) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:825:39: ifExists
          {
            pushFollow(FOLLOW_ifExists_in_dropDatabaseStatement2481);
            ifExists105 = ifExists();

            state._fsp--;

            stream_ifExists.add(ifExists105.getTree());
          }
          break;
        }

        pushFollow(FOLLOW_identifier_in_dropDatabaseStatement2484);
        identifier106 = identifier();

        state._fsp--;

        stream_identifier.add(identifier106.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:825:60: ( restrictOrCascade )?
        int alt22 = 2;
        switch (input.LA(1)) {
          case KW_CASCADE:
          case KW_RESTRICT: {
            alt22 = 1;
          }
          break;
        }

        switch (alt22) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:825:60: restrictOrCascade
          {
            pushFollow(FOLLOW_restrictOrCascade_in_dropDatabaseStatement2486);
            restrictOrCascade107 = restrictOrCascade();

            state._fsp--;

            stream_restrictOrCascade.add(restrictOrCascade107.getTree());
          }
          break;
        }

        // AST REWRITE
        // elements: ifExists, restrictOrCascade, identifier
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 826:5: -> ^( TOK_DROPDATABASE identifier ( ifExists )? ( restrictOrCascade )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:826:8: ^( TOK_DROPDATABASE identifier ( ifExists )? ( restrictOrCascade )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DROPDATABASE, "TOK_DROPDATABASE"),
                root_1);

            adaptor.addChild(root_1, stream_identifier.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:826:38: ( ifExists )?
            if (stream_ifExists.hasNext()) {
              adaptor.addChild(root_1, stream_ifExists.nextTree());
            }
            stream_ifExists.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:826:48: ( restrictOrCascade )?
            if (stream_restrictOrCascade.hasNext()) {
              adaptor.addChild(root_1, stream_restrictOrCascade.nextTree());
            }
            stream_restrictOrCascade.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "dropDatabaseStatement"

  public static class databaseComment_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "databaseComment"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:829:1: databaseComment : KW_COMMENT comment= StringLiteral -> ^( TOK_DATABASECOMMENT $comment) ;
  public final HiveParser.databaseComment_return databaseComment() throws RecognitionException {
    HiveParser.databaseComment_return retval = new HiveParser.databaseComment_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token comment = null;
    Token KW_COMMENT108 = null;

    CommonTree comment_tree = null;
    CommonTree KW_COMMENT108_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_COMMENT = new RewriteRuleTokenStream(adaptor, "token KW_COMMENT");

    pushMsg("database's comment", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:832:5: ( KW_COMMENT comment= StringLiteral -> ^( TOK_DATABASECOMMENT $comment) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:832:7: KW_COMMENT comment= StringLiteral
      {
        KW_COMMENT108 = (Token) match(input, KW_COMMENT, FOLLOW_KW_COMMENT_in_databaseComment2532);
        stream_KW_COMMENT.add(KW_COMMENT108);

        comment = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_databaseComment2536);
        stream_StringLiteral.add(comment);

        // AST REWRITE
        // elements: comment
        // token labels: comment
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_comment = new RewriteRuleTokenStream(adaptor, "token comment", comment);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 833:5: -> ^( TOK_DATABASECOMMENT $comment)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:833:8: ^( TOK_DATABASECOMMENT $comment)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DATABASECOMMENT, "TOK_DATABASECOMMENT"),
                    root_1);

            adaptor.addChild(root_1, stream_comment.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "databaseComment"

  public static class createTableStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "createTableStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:836:1: createTableStatement : KW_CREATE (temp= KW_TEMPORARY )? (ext= KW_EXTERNAL )? KW_TABLE ( ifNotExists )? name= tableName (like= KW_LIKE likeName= tableName ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? | ( LPAREN columnNameTypeList RPAREN )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? ( KW_AS selectStatementWithCTE )? ) -> ^( TOK_CREATETABLE $name ( $temp)? ( $ext)? ( ifNotExists )? ^( TOK_LIKETABLE ( $likeName)? ) ( columnNameTypeList )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? ( selectStatementWithCTE )? ) ;
  public final HiveParser.createTableStatement_return createTableStatement() throws RecognitionException {
    HiveParser.createTableStatement_return retval = new HiveParser.createTableStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token temp = null;
    Token ext = null;
    Token like = null;
    Token KW_CREATE109 = null;
    Token KW_TABLE110 = null;
    Token LPAREN116 = null;
    Token RPAREN118 = null;
    Token KW_AS127 = null;
    HiveParser_FromClauseParser.tableName_return name = null;

    HiveParser_FromClauseParser.tableName_return likeName = null;

    HiveParser.ifNotExists_return ifNotExists111 = null;

    HiveParser.tableRowFormat_return tableRowFormat112 = null;

    HiveParser.tableFileFormat_return tableFileFormat113 = null;

    HiveParser.location_return location114 = null;

    HiveParser.tablePropertiesPrefixed_return tablePropertiesPrefixed115 = null;

    HiveParser.columnNameTypeList_return columnNameTypeList117 = null;

    HiveParser.tableComment_return tableComment119 = null;

    HiveParser.tablePartition_return tablePartition120 = null;

    HiveParser.tableBuckets_return tableBuckets121 = null;

    HiveParser.tableSkewed_return tableSkewed122 = null;

    HiveParser.tableRowFormat_return tableRowFormat123 = null;

    HiveParser.tableFileFormat_return tableFileFormat124 = null;

    HiveParser.location_return location125 = null;

    HiveParser.tablePropertiesPrefixed_return tablePropertiesPrefixed126 = null;

    HiveParser.selectStatementWithCTE_return selectStatementWithCTE128 = null;

    CommonTree temp_tree = null;
    CommonTree ext_tree = null;
    CommonTree like_tree = null;
    CommonTree KW_CREATE109_tree = null;
    CommonTree KW_TABLE110_tree = null;
    CommonTree LPAREN116_tree = null;
    CommonTree RPAREN118_tree = null;
    CommonTree KW_AS127_tree = null;
    RewriteRuleTokenStream stream_KW_TEMPORARY = new RewriteRuleTokenStream(adaptor, "token KW_TEMPORARY");
    RewriteRuleTokenStream stream_KW_CREATE = new RewriteRuleTokenStream(adaptor, "token KW_CREATE");
    RewriteRuleTokenStream stream_KW_EXTERNAL = new RewriteRuleTokenStream(adaptor, "token KW_EXTERNAL");
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleTokenStream stream_KW_AS = new RewriteRuleTokenStream(adaptor, "token KW_AS");
    RewriteRuleTokenStream stream_KW_LIKE = new RewriteRuleTokenStream(adaptor, "token KW_LIKE");
    RewriteRuleSubtreeStream stream_tableRowFormat = new RewriteRuleSubtreeStream(adaptor, "rule tableRowFormat");
    RewriteRuleSubtreeStream stream_selectStatementWithCTE =
        new RewriteRuleSubtreeStream(adaptor, "rule selectStatementWithCTE");
    RewriteRuleSubtreeStream stream_tableSkewed = new RewriteRuleSubtreeStream(adaptor, "rule tableSkewed");
    RewriteRuleSubtreeStream stream_tablePropertiesPrefixed =
        new RewriteRuleSubtreeStream(adaptor, "rule tablePropertiesPrefixed");
    RewriteRuleSubtreeStream stream_ifNotExists = new RewriteRuleSubtreeStream(adaptor, "rule ifNotExists");
    RewriteRuleSubtreeStream stream_tableFileFormat = new RewriteRuleSubtreeStream(adaptor, "rule tableFileFormat");
    RewriteRuleSubtreeStream stream_tableComment = new RewriteRuleSubtreeStream(adaptor, "rule tableComment");
    RewriteRuleSubtreeStream stream_location = new RewriteRuleSubtreeStream(adaptor, "rule location");
    RewriteRuleSubtreeStream stream_tablePartition = new RewriteRuleSubtreeStream(adaptor, "rule tablePartition");
    RewriteRuleSubtreeStream stream_tableBuckets = new RewriteRuleSubtreeStream(adaptor, "rule tableBuckets");
    RewriteRuleSubtreeStream stream_columnNameTypeList =
        new RewriteRuleSubtreeStream(adaptor, "rule columnNameTypeList");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    pushMsg("create table statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:839:5: ( KW_CREATE (temp= KW_TEMPORARY )? (ext= KW_EXTERNAL )? KW_TABLE ( ifNotExists )? name= tableName (like= KW_LIKE likeName= tableName ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? | ( LPAREN columnNameTypeList RPAREN )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? ( KW_AS selectStatementWithCTE )? ) -> ^( TOK_CREATETABLE $name ( $temp)? ( $ext)? ( ifNotExists )? ^( TOK_LIKETABLE ( $likeName)? ) ( columnNameTypeList )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? ( selectStatementWithCTE )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:839:7: KW_CREATE (temp= KW_TEMPORARY )? (ext= KW_EXTERNAL )? KW_TABLE ( ifNotExists )? name= tableName (like= KW_LIKE likeName= tableName ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? | ( LPAREN columnNameTypeList RPAREN )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? ( KW_AS selectStatementWithCTE )? )
      {
        KW_CREATE109 = (Token) match(input, KW_CREATE, FOLLOW_KW_CREATE_in_createTableStatement2576);
        stream_KW_CREATE.add(KW_CREATE109);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:839:17: (temp= KW_TEMPORARY )?
        int alt23 = 2;
        switch (input.LA(1)) {
          case KW_TEMPORARY: {
            alt23 = 1;
          }
          break;
        }

        switch (alt23) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:839:18: temp= KW_TEMPORARY
          {
            temp = (Token) match(input, KW_TEMPORARY, FOLLOW_KW_TEMPORARY_in_createTableStatement2581);
            stream_KW_TEMPORARY.add(temp);
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:839:38: (ext= KW_EXTERNAL )?
        int alt24 = 2;
        switch (input.LA(1)) {
          case KW_EXTERNAL: {
            alt24 = 1;
          }
          break;
        }

        switch (alt24) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:839:39: ext= KW_EXTERNAL
          {
            ext = (Token) match(input, KW_EXTERNAL, FOLLOW_KW_EXTERNAL_in_createTableStatement2588);
            stream_KW_EXTERNAL.add(ext);
          }
          break;
        }

        KW_TABLE110 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_createTableStatement2592);
        stream_KW_TABLE.add(KW_TABLE110);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:839:66: ( ifNotExists )?
        int alt25 = 2;
        switch (input.LA(1)) {
          case KW_IF: {
            alt25 = 1;
          }
          break;
        }

        switch (alt25) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:839:66: ifNotExists
          {
            pushFollow(FOLLOW_ifNotExists_in_createTableStatement2594);
            ifNotExists111 = ifNotExists();

            state._fsp--;

            stream_ifNotExists.add(ifNotExists111.getTree());
          }
          break;
        }

        pushFollow(FOLLOW_tableName_in_createTableStatement2599);
        name = tableName();

        state._fsp--;

        stream_tableName.add(name.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:840:7: (like= KW_LIKE likeName= tableName ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? | ( LPAREN columnNameTypeList RPAREN )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? ( KW_AS selectStatementWithCTE )? )
        int alt40 = 2;
        switch (input.LA(1)) {
          case KW_LIKE: {
            alt40 = 1;
          }
          break;
          case EOF:
          case KW_AS:
          case KW_CLUSTERED:
          case KW_COMMENT:
          case KW_LOCATION:
          case KW_PARTITIONED:
          case KW_ROW:
          case KW_SKEWED:
          case KW_STORED:
          case KW_TBLPROPERTIES:
          case LPAREN: {
            alt40 = 2;
          }
          break;
          default:
            NoViableAltException nvae = new NoViableAltException("", 40, 0, input);

            throw nvae;
        }

        switch (alt40) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:840:10: like= KW_LIKE likeName= tableName ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )?
          {
            like = (Token) match(input, KW_LIKE, FOLLOW_KW_LIKE_in_createTableStatement2612);
            stream_KW_LIKE.add(like);

            pushFollow(FOLLOW_tableName_in_createTableStatement2616);
            likeName = tableName();

            state._fsp--;

            stream_tableName.add(likeName.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:841:10: ( tableRowFormat )?
            int alt26 = 2;
            switch (input.LA(1)) {
              case KW_ROW: {
                alt26 = 1;
              }
              break;
            }

            switch (alt26) {
              case 1:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:841:10: tableRowFormat
              {
                pushFollow(FOLLOW_tableRowFormat_in_createTableStatement2627);
                tableRowFormat112 = tableRowFormat();

                state._fsp--;

                stream_tableRowFormat.add(tableRowFormat112.getTree());
              }
              break;
            }

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:842:10: ( tableFileFormat )?
            int alt27 = 2;
            switch (input.LA(1)) {
              case KW_STORED: {
                alt27 = 1;
              }
              break;
            }

            switch (alt27) {
              case 1:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:842:10: tableFileFormat
              {
                pushFollow(FOLLOW_tableFileFormat_in_createTableStatement2639);
                tableFileFormat113 = tableFileFormat();

                state._fsp--;

                stream_tableFileFormat.add(tableFileFormat113.getTree());
              }
              break;
            }

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:843:10: ( location )?
            int alt28 = 2;
            switch (input.LA(1)) {
              case KW_LOCATION: {
                alt28 = 1;
              }
              break;
            }

            switch (alt28) {
              case 1:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:843:10: location
              {
                pushFollow(FOLLOW_location_in_createTableStatement2651);
                location114 = location();

                state._fsp--;

                stream_location.add(location114.getTree());
              }
              break;
            }

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:844:10: ( tablePropertiesPrefixed )?
            int alt29 = 2;
            switch (input.LA(1)) {
              case KW_TBLPROPERTIES: {
                alt29 = 1;
              }
              break;
            }

            switch (alt29) {
              case 1:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:844:10: tablePropertiesPrefixed
              {
                pushFollow(FOLLOW_tablePropertiesPrefixed_in_createTableStatement2663);
                tablePropertiesPrefixed115 = tablePropertiesPrefixed();

                state._fsp--;

                stream_tablePropertiesPrefixed.add(tablePropertiesPrefixed115.getTree());
              }
              break;
            }
          }
          break;
          case 2:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:845:10: ( LPAREN columnNameTypeList RPAREN )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? ( KW_AS selectStatementWithCTE )?
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:845:10: ( LPAREN columnNameTypeList RPAREN )?
            int alt30 = 2;
            switch (input.LA(1)) {
              case LPAREN: {
                alt30 = 1;
              }
              break;
            }

            switch (alt30) {
              case 1:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:845:11: LPAREN columnNameTypeList RPAREN
              {
                LPAREN116 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_createTableStatement2676);
                stream_LPAREN.add(LPAREN116);

                pushFollow(FOLLOW_columnNameTypeList_in_createTableStatement2678);
                columnNameTypeList117 = columnNameTypeList();

                state._fsp--;

                stream_columnNameTypeList.add(columnNameTypeList117.getTree());

                RPAREN118 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_createTableStatement2680);
                stream_RPAREN.add(RPAREN118);
              }
              break;
            }

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:846:10: ( tableComment )?
            int alt31 = 2;
            switch (input.LA(1)) {
              case KW_COMMENT: {
                alt31 = 1;
              }
              break;
            }

            switch (alt31) {
              case 1:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:846:10: tableComment
              {
                pushFollow(FOLLOW_tableComment_in_createTableStatement2693);
                tableComment119 = tableComment();

                state._fsp--;

                stream_tableComment.add(tableComment119.getTree());
              }
              break;
            }

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:847:10: ( tablePartition )?
            int alt32 = 2;
            switch (input.LA(1)) {
              case KW_PARTITIONED: {
                alt32 = 1;
              }
              break;
            }

            switch (alt32) {
              case 1:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:847:10: tablePartition
              {
                pushFollow(FOLLOW_tablePartition_in_createTableStatement2705);
                tablePartition120 = tablePartition();

                state._fsp--;

                stream_tablePartition.add(tablePartition120.getTree());
              }
              break;
            }

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:848:10: ( tableBuckets )?
            int alt33 = 2;
            switch (input.LA(1)) {
              case KW_CLUSTERED: {
                alt33 = 1;
              }
              break;
            }

            switch (alt33) {
              case 1:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:848:10: tableBuckets
              {
                pushFollow(FOLLOW_tableBuckets_in_createTableStatement2717);
                tableBuckets121 = tableBuckets();

                state._fsp--;

                stream_tableBuckets.add(tableBuckets121.getTree());
              }
              break;
            }

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:849:10: ( tableSkewed )?
            int alt34 = 2;
            switch (input.LA(1)) {
              case KW_SKEWED: {
                alt34 = 1;
              }
              break;
            }

            switch (alt34) {
              case 1:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:849:10: tableSkewed
              {
                pushFollow(FOLLOW_tableSkewed_in_createTableStatement2729);
                tableSkewed122 = tableSkewed();

                state._fsp--;

                stream_tableSkewed.add(tableSkewed122.getTree());
              }
              break;
            }

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:850:10: ( tableRowFormat )?
            int alt35 = 2;
            switch (input.LA(1)) {
              case KW_ROW: {
                alt35 = 1;
              }
              break;
            }

            switch (alt35) {
              case 1:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:850:10: tableRowFormat
              {
                pushFollow(FOLLOW_tableRowFormat_in_createTableStatement2741);
                tableRowFormat123 = tableRowFormat();

                state._fsp--;

                stream_tableRowFormat.add(tableRowFormat123.getTree());
              }
              break;
            }

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:851:10: ( tableFileFormat )?
            int alt36 = 2;
            switch (input.LA(1)) {
              case KW_STORED: {
                alt36 = 1;
              }
              break;
            }

            switch (alt36) {
              case 1:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:851:10: tableFileFormat
              {
                pushFollow(FOLLOW_tableFileFormat_in_createTableStatement2753);
                tableFileFormat124 = tableFileFormat();

                state._fsp--;

                stream_tableFileFormat.add(tableFileFormat124.getTree());
              }
              break;
            }

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:852:10: ( location )?
            int alt37 = 2;
            switch (input.LA(1)) {
              case KW_LOCATION: {
                alt37 = 1;
              }
              break;
            }

            switch (alt37) {
              case 1:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:852:10: location
              {
                pushFollow(FOLLOW_location_in_createTableStatement2765);
                location125 = location();

                state._fsp--;

                stream_location.add(location125.getTree());
              }
              break;
            }

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:853:10: ( tablePropertiesPrefixed )?
            int alt38 = 2;
            switch (input.LA(1)) {
              case KW_TBLPROPERTIES: {
                alt38 = 1;
              }
              break;
            }

            switch (alt38) {
              case 1:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:853:10: tablePropertiesPrefixed
              {
                pushFollow(FOLLOW_tablePropertiesPrefixed_in_createTableStatement2777);
                tablePropertiesPrefixed126 = tablePropertiesPrefixed();

                state._fsp--;

                stream_tablePropertiesPrefixed.add(tablePropertiesPrefixed126.getTree());
              }
              break;
            }

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:854:10: ( KW_AS selectStatementWithCTE )?
            int alt39 = 2;
            switch (input.LA(1)) {
              case KW_AS: {
                alt39 = 1;
              }
              break;
            }

            switch (alt39) {
              case 1:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:854:11: KW_AS selectStatementWithCTE
              {
                KW_AS127 = (Token) match(input, KW_AS, FOLLOW_KW_AS_in_createTableStatement2790);
                stream_KW_AS.add(KW_AS127);

                pushFollow(FOLLOW_selectStatementWithCTE_in_createTableStatement2792);
                selectStatementWithCTE128 = selectStatementWithCTE();

                state._fsp--;

                stream_selectStatementWithCTE.add(selectStatementWithCTE128.getTree());
              }
              break;
            }
          }
          break;
        }

        // AST REWRITE
        // elements: temp, tableSkewed, tableRowFormat, tableBuckets, tableFileFormat, selectStatementWithCTE, tablePropertiesPrefixed, likeName, tablePartition, location, columnNameTypeList, ifNotExists, name, tableComment, ext
        // token labels: ext, temp
        // rule labels: likeName, name, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_ext = new RewriteRuleTokenStream(adaptor, "token ext", ext);
        RewriteRuleTokenStream stream_temp = new RewriteRuleTokenStream(adaptor, "token temp", temp);
        RewriteRuleSubtreeStream stream_likeName =
            new RewriteRuleSubtreeStream(adaptor, "rule likeName", likeName != null ? likeName.tree : null);
        RewriteRuleSubtreeStream stream_name =
            new RewriteRuleSubtreeStream(adaptor, "rule name", name != null ? name.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 856:5: -> ^( TOK_CREATETABLE $name ( $temp)? ( $ext)? ( ifNotExists )? ^( TOK_LIKETABLE ( $likeName)? ) ( columnNameTypeList )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? ( selectStatementWithCTE )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:856:8: ^( TOK_CREATETABLE $name ( $temp)? ( $ext)? ( ifNotExists )? ^( TOK_LIKETABLE ( $likeName)? ) ( columnNameTypeList )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? ( selectStatementWithCTE )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_CREATETABLE, "TOK_CREATETABLE"),
                root_1);

            adaptor.addChild(root_1, stream_name.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:856:33: ( $temp)?
            if (stream_temp.hasNext()) {
              adaptor.addChild(root_1, stream_temp.nextNode());
            }
            stream_temp.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:856:40: ( $ext)?
            if (stream_ext.hasNext()) {
              adaptor.addChild(root_1, stream_ext.nextNode());
            }
            stream_ext.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:856:45: ( ifNotExists )?
            if (stream_ifNotExists.hasNext()) {
              adaptor.addChild(root_1, stream_ifNotExists.nextTree());
            }
            stream_ifNotExists.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:857:10: ^( TOK_LIKETABLE ( $likeName)? )
            {
              CommonTree root_2 = (CommonTree) adaptor.nil();
              root_2 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_LIKETABLE, "TOK_LIKETABLE"), root_2);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:857:27: ( $likeName)?
              if (stream_likeName.hasNext()) {
                adaptor.addChild(root_2, stream_likeName.nextTree());
              }
              stream_likeName.reset();

              adaptor.addChild(root_1, root_2);
            }

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:858:10: ( columnNameTypeList )?
            if (stream_columnNameTypeList.hasNext()) {
              adaptor.addChild(root_1, stream_columnNameTypeList.nextTree());
            }
            stream_columnNameTypeList.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:859:10: ( tableComment )?
            if (stream_tableComment.hasNext()) {
              adaptor.addChild(root_1, stream_tableComment.nextTree());
            }
            stream_tableComment.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:860:10: ( tablePartition )?
            if (stream_tablePartition.hasNext()) {
              adaptor.addChild(root_1, stream_tablePartition.nextTree());
            }
            stream_tablePartition.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:861:10: ( tableBuckets )?
            if (stream_tableBuckets.hasNext()) {
              adaptor.addChild(root_1, stream_tableBuckets.nextTree());
            }
            stream_tableBuckets.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:862:10: ( tableSkewed )?
            if (stream_tableSkewed.hasNext()) {
              adaptor.addChild(root_1, stream_tableSkewed.nextTree());
            }
            stream_tableSkewed.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:863:10: ( tableRowFormat )?
            if (stream_tableRowFormat.hasNext()) {
              adaptor.addChild(root_1, stream_tableRowFormat.nextTree());
            }
            stream_tableRowFormat.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:864:10: ( tableFileFormat )?
            if (stream_tableFileFormat.hasNext()) {
              adaptor.addChild(root_1, stream_tableFileFormat.nextTree());
            }
            stream_tableFileFormat.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:865:10: ( location )?
            if (stream_location.hasNext()) {
              adaptor.addChild(root_1, stream_location.nextTree());
            }
            stream_location.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:866:10: ( tablePropertiesPrefixed )?
            if (stream_tablePropertiesPrefixed.hasNext()) {
              adaptor.addChild(root_1, stream_tablePropertiesPrefixed.nextTree());
            }
            stream_tablePropertiesPrefixed.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:867:10: ( selectStatementWithCTE )?
            if (stream_selectStatementWithCTE.hasNext()) {
              adaptor.addChild(root_1, stream_selectStatementWithCTE.nextTree());
            }
            stream_selectStatementWithCTE.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "createTableStatement"

  public static class truncateTableStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "truncateTableStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:871:1: truncateTableStatement : KW_TRUNCATE KW_TABLE tablePartitionPrefix ( KW_COLUMNS LPAREN columnNameList RPAREN )? -> ^( TOK_TRUNCATETABLE tablePartitionPrefix ( columnNameList )? ) ;
  public final HiveParser.truncateTableStatement_return truncateTableStatement() throws RecognitionException {
    HiveParser.truncateTableStatement_return retval = new HiveParser.truncateTableStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_TRUNCATE129 = null;
    Token KW_TABLE130 = null;
    Token KW_COLUMNS132 = null;
    Token LPAREN133 = null;
    Token RPAREN135 = null;
    HiveParser.tablePartitionPrefix_return tablePartitionPrefix131 = null;

    HiveParser.columnNameList_return columnNameList134 = null;

    CommonTree KW_TRUNCATE129_tree = null;
    CommonTree KW_TABLE130_tree = null;
    CommonTree KW_COLUMNS132_tree = null;
    CommonTree LPAREN133_tree = null;
    CommonTree RPAREN135_tree = null;
    RewriteRuleTokenStream stream_KW_COLUMNS = new RewriteRuleTokenStream(adaptor, "token KW_COLUMNS");
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_KW_TRUNCATE = new RewriteRuleTokenStream(adaptor, "token KW_TRUNCATE");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleSubtreeStream stream_tablePartitionPrefix =
        new RewriteRuleSubtreeStream(adaptor, "rule tablePartitionPrefix");
    RewriteRuleSubtreeStream stream_columnNameList = new RewriteRuleSubtreeStream(adaptor, "rule columnNameList");
    pushMsg("truncate table statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:874:5: ( KW_TRUNCATE KW_TABLE tablePartitionPrefix ( KW_COLUMNS LPAREN columnNameList RPAREN )? -> ^( TOK_TRUNCATETABLE tablePartitionPrefix ( columnNameList )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:874:7: KW_TRUNCATE KW_TABLE tablePartitionPrefix ( KW_COLUMNS LPAREN columnNameList RPAREN )?
      {
        KW_TRUNCATE129 = (Token) match(input, KW_TRUNCATE, FOLLOW_KW_TRUNCATE_in_truncateTableStatement2999);
        stream_KW_TRUNCATE.add(KW_TRUNCATE129);

        KW_TABLE130 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_truncateTableStatement3001);
        stream_KW_TABLE.add(KW_TABLE130);

        pushFollow(FOLLOW_tablePartitionPrefix_in_truncateTableStatement3003);
        tablePartitionPrefix131 = tablePartitionPrefix();

        state._fsp--;

        stream_tablePartitionPrefix.add(tablePartitionPrefix131.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:874:49: ( KW_COLUMNS LPAREN columnNameList RPAREN )?
        int alt41 = 2;
        switch (input.LA(1)) {
          case KW_COLUMNS: {
            alt41 = 1;
          }
          break;
        }

        switch (alt41) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:874:50: KW_COLUMNS LPAREN columnNameList RPAREN
          {
            KW_COLUMNS132 = (Token) match(input, KW_COLUMNS, FOLLOW_KW_COLUMNS_in_truncateTableStatement3006);
            stream_KW_COLUMNS.add(KW_COLUMNS132);

            LPAREN133 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_truncateTableStatement3008);
            stream_LPAREN.add(LPAREN133);

            pushFollow(FOLLOW_columnNameList_in_truncateTableStatement3010);
            columnNameList134 = columnNameList();

            state._fsp--;

            stream_columnNameList.add(columnNameList134.getTree());

            RPAREN135 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_truncateTableStatement3012);
            stream_RPAREN.add(RPAREN135);
          }
          break;
        }

        // AST REWRITE
        // elements: tablePartitionPrefix, columnNameList
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 874:92: -> ^( TOK_TRUNCATETABLE tablePartitionPrefix ( columnNameList )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:874:95: ^( TOK_TRUNCATETABLE tablePartitionPrefix ( columnNameList )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TRUNCATETABLE, "TOK_TRUNCATETABLE"),
                    root_1);

            adaptor.addChild(root_1, stream_tablePartitionPrefix.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:874:136: ( columnNameList )?
            if (stream_columnNameList.hasNext()) {
              adaptor.addChild(root_1, stream_columnNameList.nextTree());
            }
            stream_columnNameList.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "truncateTableStatement"

  public static class createIndexStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "createIndexStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:876:1: createIndexStatement : KW_CREATE KW_INDEX indexName= identifier KW_ON KW_TABLE tab= tableName LPAREN indexedCols= columnNameList RPAREN KW_AS typeName= StringLiteral ( autoRebuild )? ( indexPropertiesPrefixed )? ( indexTblName )? ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? ( indexComment )? -> ^( TOK_CREATEINDEX $indexName $typeName $tab $indexedCols ( autoRebuild )? ( indexPropertiesPrefixed )? ( indexTblName )? ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? ( indexComment )? ) ;
  public final HiveParser.createIndexStatement_return createIndexStatement() throws RecognitionException {
    HiveParser.createIndexStatement_return retval = new HiveParser.createIndexStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token typeName = null;
    Token KW_CREATE136 = null;
    Token KW_INDEX137 = null;
    Token KW_ON138 = null;
    Token KW_TABLE139 = null;
    Token LPAREN140 = null;
    Token RPAREN141 = null;
    Token KW_AS142 = null;
    HiveParser_IdentifiersParser.identifier_return indexName = null;

    HiveParser_FromClauseParser.tableName_return tab = null;

    HiveParser.columnNameList_return indexedCols = null;

    HiveParser.autoRebuild_return autoRebuild143 = null;

    HiveParser.indexPropertiesPrefixed_return indexPropertiesPrefixed144 = null;

    HiveParser.indexTblName_return indexTblName145 = null;

    HiveParser.tableRowFormat_return tableRowFormat146 = null;

    HiveParser.tableFileFormat_return tableFileFormat147 = null;

    HiveParser.location_return location148 = null;

    HiveParser.tablePropertiesPrefixed_return tablePropertiesPrefixed149 = null;

    HiveParser.indexComment_return indexComment150 = null;

    CommonTree typeName_tree = null;
    CommonTree KW_CREATE136_tree = null;
    CommonTree KW_INDEX137_tree = null;
    CommonTree KW_ON138_tree = null;
    CommonTree KW_TABLE139_tree = null;
    CommonTree LPAREN140_tree = null;
    CommonTree RPAREN141_tree = null;
    CommonTree KW_AS142_tree = null;
    RewriteRuleTokenStream stream_KW_CREATE = new RewriteRuleTokenStream(adaptor, "token KW_CREATE");
    RewriteRuleTokenStream stream_KW_INDEX = new RewriteRuleTokenStream(adaptor, "token KW_INDEX");
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_KW_ON = new RewriteRuleTokenStream(adaptor, "token KW_ON");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleTokenStream stream_KW_AS = new RewriteRuleTokenStream(adaptor, "token KW_AS");
    RewriteRuleSubtreeStream stream_tableRowFormat = new RewriteRuleSubtreeStream(adaptor, "rule tableRowFormat");
    RewriteRuleSubtreeStream stream_indexComment = new RewriteRuleSubtreeStream(adaptor, "rule indexComment");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_tablePropertiesPrefixed =
        new RewriteRuleSubtreeStream(adaptor, "rule tablePropertiesPrefixed");
    RewriteRuleSubtreeStream stream_tableFileFormat = new RewriteRuleSubtreeStream(adaptor, "rule tableFileFormat");
    RewriteRuleSubtreeStream stream_location = new RewriteRuleSubtreeStream(adaptor, "rule location");
    RewriteRuleSubtreeStream stream_columnNameList = new RewriteRuleSubtreeStream(adaptor, "rule columnNameList");
    RewriteRuleSubtreeStream stream_indexTblName = new RewriteRuleSubtreeStream(adaptor, "rule indexTblName");
    RewriteRuleSubtreeStream stream_autoRebuild = new RewriteRuleSubtreeStream(adaptor, "rule autoRebuild");
    RewriteRuleSubtreeStream stream_indexPropertiesPrefixed =
        new RewriteRuleSubtreeStream(adaptor, "rule indexPropertiesPrefixed");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    pushMsg("create index statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:879:5: ( KW_CREATE KW_INDEX indexName= identifier KW_ON KW_TABLE tab= tableName LPAREN indexedCols= columnNameList RPAREN KW_AS typeName= StringLiteral ( autoRebuild )? ( indexPropertiesPrefixed )? ( indexTblName )? ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? ( indexComment )? -> ^( TOK_CREATEINDEX $indexName $typeName $tab $indexedCols ( autoRebuild )? ( indexPropertiesPrefixed )? ( indexTblName )? ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? ( indexComment )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:879:7: KW_CREATE KW_INDEX indexName= identifier KW_ON KW_TABLE tab= tableName LPAREN indexedCols= columnNameList RPAREN KW_AS typeName= StringLiteral ( autoRebuild )? ( indexPropertiesPrefixed )? ( indexTblName )? ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? ( indexComment )?
      {
        KW_CREATE136 = (Token) match(input, KW_CREATE, FOLLOW_KW_CREATE_in_createIndexStatement3047);
        stream_KW_CREATE.add(KW_CREATE136);

        KW_INDEX137 = (Token) match(input, KW_INDEX, FOLLOW_KW_INDEX_in_createIndexStatement3049);
        stream_KW_INDEX.add(KW_INDEX137);

        pushFollow(FOLLOW_identifier_in_createIndexStatement3053);
        indexName = identifier();

        state._fsp--;

        stream_identifier.add(indexName.getTree());

        KW_ON138 = (Token) match(input, KW_ON, FOLLOW_KW_ON_in_createIndexStatement3061);
        stream_KW_ON.add(KW_ON138);

        KW_TABLE139 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_createIndexStatement3063);
        stream_KW_TABLE.add(KW_TABLE139);

        pushFollow(FOLLOW_tableName_in_createIndexStatement3067);
        tab = tableName();

        state._fsp--;

        stream_tableName.add(tab.getTree());

        LPAREN140 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_createIndexStatement3069);
        stream_LPAREN.add(LPAREN140);

        pushFollow(FOLLOW_columnNameList_in_createIndexStatement3073);
        indexedCols = columnNameList();

        state._fsp--;

        stream_columnNameList.add(indexedCols.getTree());

        RPAREN141 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_createIndexStatement3075);
        stream_RPAREN.add(RPAREN141);

        KW_AS142 = (Token) match(input, KW_AS, FOLLOW_KW_AS_in_createIndexStatement3083);
        stream_KW_AS.add(KW_AS142);

        typeName = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_createIndexStatement3087);
        stream_StringLiteral.add(typeName);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:882:7: ( autoRebuild )?
        int alt42 = 2;
        switch (input.LA(1)) {
          case KW_WITH: {
            alt42 = 1;
          }
          break;
        }

        switch (alt42) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:882:7: autoRebuild
          {
            pushFollow(FOLLOW_autoRebuild_in_createIndexStatement3095);
            autoRebuild143 = autoRebuild();

            state._fsp--;

            stream_autoRebuild.add(autoRebuild143.getTree());
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:883:7: ( indexPropertiesPrefixed )?
        int alt43 = 2;
        switch (input.LA(1)) {
          case KW_IDXPROPERTIES: {
            alt43 = 1;
          }
          break;
        }

        switch (alt43) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:883:7: indexPropertiesPrefixed
          {
            pushFollow(FOLLOW_indexPropertiesPrefixed_in_createIndexStatement3104);
            indexPropertiesPrefixed144 = indexPropertiesPrefixed();

            state._fsp--;

            stream_indexPropertiesPrefixed.add(indexPropertiesPrefixed144.getTree());
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:884:7: ( indexTblName )?
        int alt44 = 2;
        switch (input.LA(1)) {
          case KW_IN: {
            alt44 = 1;
          }
          break;
        }

        switch (alt44) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:884:7: indexTblName
          {
            pushFollow(FOLLOW_indexTblName_in_createIndexStatement3113);
            indexTblName145 = indexTblName();

            state._fsp--;

            stream_indexTblName.add(indexTblName145.getTree());
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:885:7: ( tableRowFormat )?
        int alt45 = 2;
        switch (input.LA(1)) {
          case KW_ROW: {
            alt45 = 1;
          }
          break;
        }

        switch (alt45) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:885:7: tableRowFormat
          {
            pushFollow(FOLLOW_tableRowFormat_in_createIndexStatement3122);
            tableRowFormat146 = tableRowFormat();

            state._fsp--;

            stream_tableRowFormat.add(tableRowFormat146.getTree());
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:886:7: ( tableFileFormat )?
        int alt46 = 2;
        switch (input.LA(1)) {
          case KW_STORED: {
            alt46 = 1;
          }
          break;
        }

        switch (alt46) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:886:7: tableFileFormat
          {
            pushFollow(FOLLOW_tableFileFormat_in_createIndexStatement3131);
            tableFileFormat147 = tableFileFormat();

            state._fsp--;

            stream_tableFileFormat.add(tableFileFormat147.getTree());
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:887:7: ( location )?
        int alt47 = 2;
        switch (input.LA(1)) {
          case KW_LOCATION: {
            alt47 = 1;
          }
          break;
        }

        switch (alt47) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:887:7: location
          {
            pushFollow(FOLLOW_location_in_createIndexStatement3140);
            location148 = location();

            state._fsp--;

            stream_location.add(location148.getTree());
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:888:7: ( tablePropertiesPrefixed )?
        int alt48 = 2;
        switch (input.LA(1)) {
          case KW_TBLPROPERTIES: {
            alt48 = 1;
          }
          break;
        }

        switch (alt48) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:888:7: tablePropertiesPrefixed
          {
            pushFollow(FOLLOW_tablePropertiesPrefixed_in_createIndexStatement3149);
            tablePropertiesPrefixed149 = tablePropertiesPrefixed();

            state._fsp--;

            stream_tablePropertiesPrefixed.add(tablePropertiesPrefixed149.getTree());
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:889:7: ( indexComment )?
        int alt49 = 2;
        switch (input.LA(1)) {
          case KW_COMMENT: {
            alt49 = 1;
          }
          break;
        }

        switch (alt49) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:889:7: indexComment
          {
            pushFollow(FOLLOW_indexComment_in_createIndexStatement3158);
            indexComment150 = indexComment();

            state._fsp--;

            stream_indexComment.add(indexComment150.getTree());
          }
          break;
        }

        // AST REWRITE
        // elements: autoRebuild, tableRowFormat, tab, indexName, indexTblName, tableFileFormat, location, indexPropertiesPrefixed, tablePropertiesPrefixed, indexedCols, indexComment, typeName
        // token labels: typeName
        // rule labels: indexedCols, tab, indexName, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_typeName = new RewriteRuleTokenStream(adaptor, "token typeName", typeName);
        RewriteRuleSubtreeStream stream_indexedCols =
            new RewriteRuleSubtreeStream(adaptor, "rule indexedCols", indexedCols != null ? indexedCols.tree : null);
        RewriteRuleSubtreeStream stream_tab =
            new RewriteRuleSubtreeStream(adaptor, "rule tab", tab != null ? tab.tree : null);
        RewriteRuleSubtreeStream stream_indexName =
            new RewriteRuleSubtreeStream(adaptor, "rule indexName", indexName != null ? indexName.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 890:5: -> ^( TOK_CREATEINDEX $indexName $typeName $tab $indexedCols ( autoRebuild )? ( indexPropertiesPrefixed )? ( indexTblName )? ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? ( indexComment )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:890:7: ^( TOK_CREATEINDEX $indexName $typeName $tab $indexedCols ( autoRebuild )? ( indexPropertiesPrefixed )? ( indexTblName )? ( tableRowFormat )? ( tableFileFormat )? ( location )? ( tablePropertiesPrefixed )? ( indexComment )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_CREATEINDEX, "TOK_CREATEINDEX"),
                root_1);

            adaptor.addChild(root_1, stream_indexName.nextTree());

            adaptor.addChild(root_1, stream_typeName.nextNode());

            adaptor.addChild(root_1, stream_tab.nextTree());

            adaptor.addChild(root_1, stream_indexedCols.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:891:9: ( autoRebuild )?
            if (stream_autoRebuild.hasNext()) {
              adaptor.addChild(root_1, stream_autoRebuild.nextTree());
            }
            stream_autoRebuild.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:892:9: ( indexPropertiesPrefixed )?
            if (stream_indexPropertiesPrefixed.hasNext()) {
              adaptor.addChild(root_1, stream_indexPropertiesPrefixed.nextTree());
            }
            stream_indexPropertiesPrefixed.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:893:9: ( indexTblName )?
            if (stream_indexTblName.hasNext()) {
              adaptor.addChild(root_1, stream_indexTblName.nextTree());
            }
            stream_indexTblName.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:894:9: ( tableRowFormat )?
            if (stream_tableRowFormat.hasNext()) {
              adaptor.addChild(root_1, stream_tableRowFormat.nextTree());
            }
            stream_tableRowFormat.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:895:9: ( tableFileFormat )?
            if (stream_tableFileFormat.hasNext()) {
              adaptor.addChild(root_1, stream_tableFileFormat.nextTree());
            }
            stream_tableFileFormat.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:896:9: ( location )?
            if (stream_location.hasNext()) {
              adaptor.addChild(root_1, stream_location.nextTree());
            }
            stream_location.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:897:9: ( tablePropertiesPrefixed )?
            if (stream_tablePropertiesPrefixed.hasNext()) {
              adaptor.addChild(root_1, stream_tablePropertiesPrefixed.nextTree());
            }
            stream_tablePropertiesPrefixed.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:898:9: ( indexComment )?
            if (stream_indexComment.hasNext()) {
              adaptor.addChild(root_1, stream_indexComment.nextTree());
            }
            stream_indexComment.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "createIndexStatement"

  public static class indexComment_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "indexComment"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:901:1: indexComment : KW_COMMENT comment= StringLiteral -> ^( TOK_INDEXCOMMENT $comment) ;
  public final HiveParser.indexComment_return indexComment() throws RecognitionException {
    HiveParser.indexComment_return retval = new HiveParser.indexComment_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token comment = null;
    Token KW_COMMENT151 = null;

    CommonTree comment_tree = null;
    CommonTree KW_COMMENT151_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_COMMENT = new RewriteRuleTokenStream(adaptor, "token KW_COMMENT");

    pushMsg("comment on an index", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:904:9: ( KW_COMMENT comment= StringLiteral -> ^( TOK_INDEXCOMMENT $comment) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:905:17: KW_COMMENT comment= StringLiteral
      {
        KW_COMMENT151 = (Token) match(input, KW_COMMENT, FOLLOW_KW_COMMENT_in_indexComment3315);
        stream_KW_COMMENT.add(KW_COMMENT151);

        comment = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_indexComment3319);
        stream_StringLiteral.add(comment);

        // AST REWRITE
        // elements: comment
        // token labels: comment
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_comment = new RewriteRuleTokenStream(adaptor, "token comment", comment);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 905:51: -> ^( TOK_INDEXCOMMENT $comment)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:905:54: ^( TOK_INDEXCOMMENT $comment)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_INDEXCOMMENT, "TOK_INDEXCOMMENT"),
                root_1);

            adaptor.addChild(root_1, stream_comment.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "indexComment"

  public static class autoRebuild_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "autoRebuild"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:908:1: autoRebuild : KW_WITH KW_DEFERRED KW_REBUILD -> ^( TOK_DEFERRED_REBUILDINDEX ) ;
  public final HiveParser.autoRebuild_return autoRebuild() throws RecognitionException {
    HiveParser.autoRebuild_return retval = new HiveParser.autoRebuild_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_WITH152 = null;
    Token KW_DEFERRED153 = null;
    Token KW_REBUILD154 = null;

    CommonTree KW_WITH152_tree = null;
    CommonTree KW_DEFERRED153_tree = null;
    CommonTree KW_REBUILD154_tree = null;
    RewriteRuleTokenStream stream_KW_REBUILD = new RewriteRuleTokenStream(adaptor, "token KW_REBUILD");
    RewriteRuleTokenStream stream_KW_WITH = new RewriteRuleTokenStream(adaptor, "token KW_WITH");
    RewriteRuleTokenStream stream_KW_DEFERRED = new RewriteRuleTokenStream(adaptor, "token KW_DEFERRED");

    pushMsg("auto rebuild index", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:911:5: ( KW_WITH KW_DEFERRED KW_REBUILD -> ^( TOK_DEFERRED_REBUILDINDEX ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:911:7: KW_WITH KW_DEFERRED KW_REBUILD
      {
        KW_WITH152 = (Token) match(input, KW_WITH, FOLLOW_KW_WITH_in_autoRebuild3360);
        stream_KW_WITH.add(KW_WITH152);

        KW_DEFERRED153 = (Token) match(input, KW_DEFERRED, FOLLOW_KW_DEFERRED_in_autoRebuild3362);
        stream_KW_DEFERRED.add(KW_DEFERRED153);

        KW_REBUILD154 = (Token) match(input, KW_REBUILD, FOLLOW_KW_REBUILD_in_autoRebuild3364);
        stream_KW_REBUILD.add(KW_REBUILD154);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 912:5: -> ^( TOK_DEFERRED_REBUILDINDEX )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:912:7: ^( TOK_DEFERRED_REBUILDINDEX )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_DEFERRED_REBUILDINDEX, "TOK_DEFERRED_REBUILDINDEX"), root_1);

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "autoRebuild"

  public static class indexTblName_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "indexTblName"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:915:1: indexTblName : KW_IN KW_TABLE indexTbl= tableName -> ^( TOK_CREATEINDEX_INDEXTBLNAME $indexTbl) ;
  public final HiveParser.indexTblName_return indexTblName() throws RecognitionException {
    HiveParser.indexTblName_return retval = new HiveParser.indexTblName_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_IN155 = null;
    Token KW_TABLE156 = null;
    HiveParser_FromClauseParser.tableName_return indexTbl = null;

    CommonTree KW_IN155_tree = null;
    CommonTree KW_TABLE156_tree = null;
    RewriteRuleTokenStream stream_KW_IN = new RewriteRuleTokenStream(adaptor, "token KW_IN");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    pushMsg("index table name", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:918:5: ( KW_IN KW_TABLE indexTbl= tableName -> ^( TOK_CREATEINDEX_INDEXTBLNAME $indexTbl) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:918:7: KW_IN KW_TABLE indexTbl= tableName
      {
        KW_IN155 = (Token) match(input, KW_IN, FOLLOW_KW_IN_in_indexTblName3400);
        stream_KW_IN.add(KW_IN155);

        KW_TABLE156 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_indexTblName3402);
        stream_KW_TABLE.add(KW_TABLE156);

        pushFollow(FOLLOW_tableName_in_indexTblName3406);
        indexTbl = tableName();

        state._fsp--;

        stream_tableName.add(indexTbl.getTree());

        // AST REWRITE
        // elements: indexTbl
        // token labels:
        // rule labels: indexTbl, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_indexTbl =
            new RewriteRuleSubtreeStream(adaptor, "rule indexTbl", indexTbl != null ? indexTbl.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 919:5: -> ^( TOK_CREATEINDEX_INDEXTBLNAME $indexTbl)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:919:7: ^( TOK_CREATEINDEX_INDEXTBLNAME $indexTbl)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_CREATEINDEX_INDEXTBLNAME, "TOK_CREATEINDEX_INDEXTBLNAME"), root_1);

            adaptor.addChild(root_1, stream_indexTbl.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "indexTblName"

  public static class indexPropertiesPrefixed_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "indexPropertiesPrefixed"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:922:1: indexPropertiesPrefixed : KW_IDXPROPERTIES ! indexProperties ;
  public final HiveParser.indexPropertiesPrefixed_return indexPropertiesPrefixed() throws RecognitionException {
    HiveParser.indexPropertiesPrefixed_return retval = new HiveParser.indexPropertiesPrefixed_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_IDXPROPERTIES157 = null;
    HiveParser.indexProperties_return indexProperties158 = null;

    CommonTree KW_IDXPROPERTIES157_tree = null;

    pushMsg("table properties with prefix", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:925:5: ( KW_IDXPROPERTIES ! indexProperties )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:926:9: KW_IDXPROPERTIES ! indexProperties
      {
        root_0 = (CommonTree) adaptor.nil();

        KW_IDXPROPERTIES157 =
            (Token) match(input, KW_IDXPROPERTIES, FOLLOW_KW_IDXPROPERTIES_in_indexPropertiesPrefixed3453);

        pushFollow(FOLLOW_indexProperties_in_indexPropertiesPrefixed3456);
        indexProperties158 = indexProperties();

        state._fsp--;

        adaptor.addChild(root_0, indexProperties158.getTree());
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "indexPropertiesPrefixed"

  public static class indexProperties_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "indexProperties"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:929:1: indexProperties : LPAREN indexPropertiesList RPAREN -> ^( TOK_INDEXPROPERTIES indexPropertiesList ) ;
  public final HiveParser.indexProperties_return indexProperties() throws RecognitionException {
    HiveParser.indexProperties_return retval = new HiveParser.indexProperties_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token LPAREN159 = null;
    Token RPAREN161 = null;
    HiveParser.indexPropertiesList_return indexPropertiesList160 = null;

    CommonTree LPAREN159_tree = null;
    CommonTree RPAREN161_tree = null;
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleSubtreeStream stream_indexPropertiesList =
        new RewriteRuleSubtreeStream(adaptor, "rule indexPropertiesList");
    pushMsg("index properties", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:932:5: ( LPAREN indexPropertiesList RPAREN -> ^( TOK_INDEXPROPERTIES indexPropertiesList ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:933:7: LPAREN indexPropertiesList RPAREN
      {
        LPAREN159 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_indexProperties3489);
        stream_LPAREN.add(LPAREN159);

        pushFollow(FOLLOW_indexPropertiesList_in_indexProperties3491);
        indexPropertiesList160 = indexPropertiesList();

        state._fsp--;

        stream_indexPropertiesList.add(indexPropertiesList160.getTree());

        RPAREN161 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_indexProperties3493);
        stream_RPAREN.add(RPAREN161);

        // AST REWRITE
        // elements: indexPropertiesList
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 933:41: -> ^( TOK_INDEXPROPERTIES indexPropertiesList )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:933:44: ^( TOK_INDEXPROPERTIES indexPropertiesList )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_INDEXPROPERTIES, "TOK_INDEXPROPERTIES"),
                    root_1);

            adaptor.addChild(root_1, stream_indexPropertiesList.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "indexProperties"

  public static class indexPropertiesList_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "indexPropertiesList"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:936:1: indexPropertiesList : keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_INDEXPROPLIST ( keyValueProperty )+ ) ;
  public final HiveParser.indexPropertiesList_return indexPropertiesList() throws RecognitionException {
    HiveParser.indexPropertiesList_return retval = new HiveParser.indexPropertiesList_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token COMMA163 = null;
    HiveParser.keyValueProperty_return keyValueProperty162 = null;

    HiveParser.keyValueProperty_return keyValueProperty164 = null;

    CommonTree COMMA163_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleSubtreeStream stream_keyValueProperty = new RewriteRuleSubtreeStream(adaptor, "rule keyValueProperty");
    pushMsg("index properties list", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:939:5: ( keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_INDEXPROPLIST ( keyValueProperty )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:940:7: keyValueProperty ( COMMA keyValueProperty )*
      {
        pushFollow(FOLLOW_keyValueProperty_in_indexPropertiesList3534);
        keyValueProperty162 = keyValueProperty();

        state._fsp--;

        stream_keyValueProperty.add(keyValueProperty162.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:940:24: ( COMMA keyValueProperty )*
        loop50:
        do {
          int alt50 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt50 = 1;
            }
            break;
          }

          switch (alt50) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:940:25: COMMA keyValueProperty
            {
              COMMA163 = (Token) match(input, COMMA, FOLLOW_COMMA_in_indexPropertiesList3537);
              stream_COMMA.add(COMMA163);

              pushFollow(FOLLOW_keyValueProperty_in_indexPropertiesList3539);
              keyValueProperty164 = keyValueProperty();

              state._fsp--;

              stream_keyValueProperty.add(keyValueProperty164.getTree());
            }
            break;

            default:
              break loop50;
          }
        } while (true);

        // AST REWRITE
        // elements: keyValueProperty
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 940:50: -> ^( TOK_INDEXPROPLIST ( keyValueProperty )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:940:53: ^( TOK_INDEXPROPLIST ( keyValueProperty )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_INDEXPROPLIST, "TOK_INDEXPROPLIST"),
                    root_1);

            if (!(stream_keyValueProperty.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_keyValueProperty.hasNext()) {
              adaptor.addChild(root_1, stream_keyValueProperty.nextTree());
            }
            stream_keyValueProperty.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "indexPropertiesList"

  public static class dropIndexStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "dropIndexStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:943:1: dropIndexStatement : KW_DROP KW_INDEX ( ifExists )? indexName= identifier KW_ON tab= tableName -> ^( TOK_DROPINDEX $indexName $tab ( ifExists )? ) ;
  public final HiveParser.dropIndexStatement_return dropIndexStatement() throws RecognitionException {
    HiveParser.dropIndexStatement_return retval = new HiveParser.dropIndexStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_DROP165 = null;
    Token KW_INDEX166 = null;
    Token KW_ON168 = null;
    HiveParser_IdentifiersParser.identifier_return indexName = null;

    HiveParser_FromClauseParser.tableName_return tab = null;

    HiveParser.ifExists_return ifExists167 = null;

    CommonTree KW_DROP165_tree = null;
    CommonTree KW_INDEX166_tree = null;
    CommonTree KW_ON168_tree = null;
    RewriteRuleTokenStream stream_KW_DROP = new RewriteRuleTokenStream(adaptor, "token KW_DROP");
    RewriteRuleTokenStream stream_KW_INDEX = new RewriteRuleTokenStream(adaptor, "token KW_INDEX");
    RewriteRuleTokenStream stream_KW_ON = new RewriteRuleTokenStream(adaptor, "token KW_ON");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_ifExists = new RewriteRuleSubtreeStream(adaptor, "rule ifExists");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    pushMsg("drop index statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:946:5: ( KW_DROP KW_INDEX ( ifExists )? indexName= identifier KW_ON tab= tableName -> ^( TOK_DROPINDEX $indexName $tab ( ifExists )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:946:7: KW_DROP KW_INDEX ( ifExists )? indexName= identifier KW_ON tab= tableName
      {
        KW_DROP165 = (Token) match(input, KW_DROP, FOLLOW_KW_DROP_in_dropIndexStatement3577);
        stream_KW_DROP.add(KW_DROP165);

        KW_INDEX166 = (Token) match(input, KW_INDEX, FOLLOW_KW_INDEX_in_dropIndexStatement3579);
        stream_KW_INDEX.add(KW_INDEX166);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:946:24: ( ifExists )?
        int alt51 = 2;
        switch (input.LA(1)) {
          case KW_IF: {
            alt51 = 1;
          }
          break;
        }

        switch (alt51) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:946:24: ifExists
          {
            pushFollow(FOLLOW_ifExists_in_dropIndexStatement3581);
            ifExists167 = ifExists();

            state._fsp--;

            stream_ifExists.add(ifExists167.getTree());
          }
          break;
        }

        pushFollow(FOLLOW_identifier_in_dropIndexStatement3586);
        indexName = identifier();

        state._fsp--;

        stream_identifier.add(indexName.getTree());

        KW_ON168 = (Token) match(input, KW_ON, FOLLOW_KW_ON_in_dropIndexStatement3588);
        stream_KW_ON.add(KW_ON168);

        pushFollow(FOLLOW_tableName_in_dropIndexStatement3592);
        tab = tableName();

        state._fsp--;

        stream_tableName.add(tab.getTree());

        // AST REWRITE
        // elements: ifExists, tab, indexName
        // token labels:
        // rule labels: tab, indexName, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_tab =
            new RewriteRuleSubtreeStream(adaptor, "rule tab", tab != null ? tab.tree : null);
        RewriteRuleSubtreeStream stream_indexName =
            new RewriteRuleSubtreeStream(adaptor, "rule indexName", indexName != null ? indexName.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 947:5: -> ^( TOK_DROPINDEX $indexName $tab ( ifExists )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:947:7: ^( TOK_DROPINDEX $indexName $tab ( ifExists )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DROPINDEX, "TOK_DROPINDEX"), root_1);

            adaptor.addChild(root_1, stream_indexName.nextTree());

            adaptor.addChild(root_1, stream_tab.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:947:39: ( ifExists )?
            if (stream_ifExists.hasNext()) {
              adaptor.addChild(root_1, stream_ifExists.nextTree());
            }
            stream_ifExists.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "dropIndexStatement"

  public static class dropTableStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "dropTableStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:950:1: dropTableStatement : KW_DROP KW_TABLE ( ifExists )? tableName ( KW_PURGE )? ( replicationClause )? -> ^( TOK_DROPTABLE tableName ( ifExists )? ( KW_PURGE )? ( replicationClause )? ) ;
  public final HiveParser.dropTableStatement_return dropTableStatement() throws RecognitionException {
    HiveParser.dropTableStatement_return retval = new HiveParser.dropTableStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_DROP169 = null;
    Token KW_TABLE170 = null;
    Token KW_PURGE173 = null;
    HiveParser.ifExists_return ifExists171 = null;

    HiveParser_FromClauseParser.tableName_return tableName172 = null;

    HiveParser.replicationClause_return replicationClause174 = null;

    CommonTree KW_DROP169_tree = null;
    CommonTree KW_TABLE170_tree = null;
    CommonTree KW_PURGE173_tree = null;
    RewriteRuleTokenStream stream_KW_DROP = new RewriteRuleTokenStream(adaptor, "token KW_DROP");
    RewriteRuleTokenStream stream_KW_PURGE = new RewriteRuleTokenStream(adaptor, "token KW_PURGE");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleSubtreeStream stream_ifExists = new RewriteRuleSubtreeStream(adaptor, "rule ifExists");
    RewriteRuleSubtreeStream stream_replicationClause = new RewriteRuleSubtreeStream(adaptor, "rule replicationClause");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    pushMsg("drop statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:953:5: ( KW_DROP KW_TABLE ( ifExists )? tableName ( KW_PURGE )? ( replicationClause )? -> ^( TOK_DROPTABLE tableName ( ifExists )? ( KW_PURGE )? ( replicationClause )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:953:7: KW_DROP KW_TABLE ( ifExists )? tableName ( KW_PURGE )? ( replicationClause )?
      {
        KW_DROP169 = (Token) match(input, KW_DROP, FOLLOW_KW_DROP_in_dropTableStatement3637);
        stream_KW_DROP.add(KW_DROP169);

        KW_TABLE170 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_dropTableStatement3639);
        stream_KW_TABLE.add(KW_TABLE170);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:953:24: ( ifExists )?
        int alt52 = 2;
        switch (input.LA(1)) {
          case KW_IF: {
            alt52 = 1;
          }
          break;
        }

        switch (alt52) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:953:24: ifExists
          {
            pushFollow(FOLLOW_ifExists_in_dropTableStatement3641);
            ifExists171 = ifExists();

            state._fsp--;

            stream_ifExists.add(ifExists171.getTree());
          }
          break;
        }

        pushFollow(FOLLOW_tableName_in_dropTableStatement3644);
        tableName172 = tableName();

        state._fsp--;

        stream_tableName.add(tableName172.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:953:44: ( KW_PURGE )?
        int alt53 = 2;
        switch (input.LA(1)) {
          case KW_PURGE: {
            alt53 = 1;
          }
          break;
        }

        switch (alt53) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:953:44: KW_PURGE
          {
            KW_PURGE173 = (Token) match(input, KW_PURGE, FOLLOW_KW_PURGE_in_dropTableStatement3646);
            stream_KW_PURGE.add(KW_PURGE173);
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:953:54: ( replicationClause )?
        int alt54 = 2;
        switch (input.LA(1)) {
          case KW_FOR: {
            alt54 = 1;
          }
          break;
        }

        switch (alt54) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:953:54: replicationClause
          {
            pushFollow(FOLLOW_replicationClause_in_dropTableStatement3649);
            replicationClause174 = replicationClause();

            state._fsp--;

            stream_replicationClause.add(replicationClause174.getTree());
          }
          break;
        }

        // AST REWRITE
        // elements: tableName, KW_PURGE, replicationClause, ifExists
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 954:5: -> ^( TOK_DROPTABLE tableName ( ifExists )? ( KW_PURGE )? ( replicationClause )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:954:8: ^( TOK_DROPTABLE tableName ( ifExists )? ( KW_PURGE )? ( replicationClause )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DROPTABLE, "TOK_DROPTABLE"), root_1);

            adaptor.addChild(root_1, stream_tableName.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:954:34: ( ifExists )?
            if (stream_ifExists.hasNext()) {
              adaptor.addChild(root_1, stream_ifExists.nextTree());
            }
            stream_ifExists.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:954:44: ( KW_PURGE )?
            if (stream_KW_PURGE.hasNext()) {
              adaptor.addChild(root_1, stream_KW_PURGE.nextNode());
            }
            stream_KW_PURGE.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:954:54: ( replicationClause )?
            if (stream_replicationClause.hasNext()) {
              adaptor.addChild(root_1, stream_replicationClause.nextTree());
            }
            stream_replicationClause.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "dropTableStatement"

  public static class alterStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:957:1: alterStatement : ( KW_ALTER KW_TABLE tableName alterTableStatementSuffix -> ^( TOK_ALTERTABLE tableName alterTableStatementSuffix ) | KW_ALTER KW_VIEW tableName ( KW_AS )? alterViewStatementSuffix -> ^( TOK_ALTERVIEW tableName alterViewStatementSuffix ) | KW_ALTER KW_INDEX alterIndexStatementSuffix -> alterIndexStatementSuffix | KW_ALTER ( KW_DATABASE | KW_SCHEMA ) alterDatabaseStatementSuffix -> alterDatabaseStatementSuffix );
  public final HiveParser.alterStatement_return alterStatement() throws RecognitionException {
    HiveParser.alterStatement_return retval = new HiveParser.alterStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_ALTER175 = null;
    Token KW_TABLE176 = null;
    Token KW_ALTER179 = null;
    Token KW_VIEW180 = null;
    Token KW_AS182 = null;
    Token KW_ALTER184 = null;
    Token KW_INDEX185 = null;
    Token KW_ALTER187 = null;
    Token KW_DATABASE188 = null;
    Token KW_SCHEMA189 = null;
    HiveParser_FromClauseParser.tableName_return tableName177 = null;

    HiveParser.alterTableStatementSuffix_return alterTableStatementSuffix178 = null;

    HiveParser_FromClauseParser.tableName_return tableName181 = null;

    HiveParser.alterViewStatementSuffix_return alterViewStatementSuffix183 = null;

    HiveParser.alterIndexStatementSuffix_return alterIndexStatementSuffix186 = null;

    HiveParser.alterDatabaseStatementSuffix_return alterDatabaseStatementSuffix190 = null;

    CommonTree KW_ALTER175_tree = null;
    CommonTree KW_TABLE176_tree = null;
    CommonTree KW_ALTER179_tree = null;
    CommonTree KW_VIEW180_tree = null;
    CommonTree KW_AS182_tree = null;
    CommonTree KW_ALTER184_tree = null;
    CommonTree KW_INDEX185_tree = null;
    CommonTree KW_ALTER187_tree = null;
    CommonTree KW_DATABASE188_tree = null;
    CommonTree KW_SCHEMA189_tree = null;
    RewriteRuleTokenStream stream_KW_SCHEMA = new RewriteRuleTokenStream(adaptor, "token KW_SCHEMA");
    RewriteRuleTokenStream stream_KW_VIEW = new RewriteRuleTokenStream(adaptor, "token KW_VIEW");
    RewriteRuleTokenStream stream_KW_INDEX = new RewriteRuleTokenStream(adaptor, "token KW_INDEX");
    RewriteRuleTokenStream stream_KW_DATABASE = new RewriteRuleTokenStream(adaptor, "token KW_DATABASE");
    RewriteRuleTokenStream stream_KW_ALTER = new RewriteRuleTokenStream(adaptor, "token KW_ALTER");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleTokenStream stream_KW_AS = new RewriteRuleTokenStream(adaptor, "token KW_AS");
    RewriteRuleSubtreeStream stream_alterTableStatementSuffix =
        new RewriteRuleSubtreeStream(adaptor, "rule alterTableStatementSuffix");
    RewriteRuleSubtreeStream stream_alterViewStatementSuffix =
        new RewriteRuleSubtreeStream(adaptor, "rule alterViewStatementSuffix");
    RewriteRuleSubtreeStream stream_alterDatabaseStatementSuffix =
        new RewriteRuleSubtreeStream(adaptor, "rule alterDatabaseStatementSuffix");
    RewriteRuleSubtreeStream stream_alterIndexStatementSuffix =
        new RewriteRuleSubtreeStream(adaptor, "rule alterIndexStatementSuffix");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    pushMsg("alter statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:960:5: ( KW_ALTER KW_TABLE tableName alterTableStatementSuffix -> ^( TOK_ALTERTABLE tableName alterTableStatementSuffix ) | KW_ALTER KW_VIEW tableName ( KW_AS )? alterViewStatementSuffix -> ^( TOK_ALTERVIEW tableName alterViewStatementSuffix ) | KW_ALTER KW_INDEX alterIndexStatementSuffix -> alterIndexStatementSuffix | KW_ALTER ( KW_DATABASE | KW_SCHEMA ) alterDatabaseStatementSuffix -> alterDatabaseStatementSuffix )
      int alt57 = 4;
      switch (input.LA(1)) {
        case KW_ALTER: {
          switch (input.LA(2)) {
            case KW_TABLE: {
              alt57 = 1;
            }
            break;
            case KW_VIEW: {
              alt57 = 2;
            }
            break;
            case KW_INDEX: {
              alt57 = 3;
            }
            break;
            case KW_DATABASE:
            case KW_SCHEMA: {
              alt57 = 4;
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 57, 1, input);

              throw nvae;
          }
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 57, 0, input);

          throw nvae;
      }

      switch (alt57) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:960:7: KW_ALTER KW_TABLE tableName alterTableStatementSuffix
        {
          KW_ALTER175 = (Token) match(input, KW_ALTER, FOLLOW_KW_ALTER_in_alterStatement3698);
          stream_KW_ALTER.add(KW_ALTER175);

          KW_TABLE176 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_alterStatement3700);
          stream_KW_TABLE.add(KW_TABLE176);

          pushFollow(FOLLOW_tableName_in_alterStatement3702);
          tableName177 = tableName();

          state._fsp--;

          stream_tableName.add(tableName177.getTree());

          pushFollow(FOLLOW_alterTableStatementSuffix_in_alterStatement3704);
          alterTableStatementSuffix178 = alterTableStatementSuffix();

          state._fsp--;

          stream_alterTableStatementSuffix.add(alterTableStatementSuffix178.getTree());

          // AST REWRITE
          // elements: alterTableStatementSuffix, tableName
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 960:61: -> ^( TOK_ALTERTABLE tableName alterTableStatementSuffix )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:960:64: ^( TOK_ALTERTABLE tableName alterTableStatementSuffix )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_ALTERTABLE, "TOK_ALTERTABLE"),
                  root_1);

              adaptor.addChild(root_1, stream_tableName.nextTree());

              adaptor.addChild(root_1, stream_alterTableStatementSuffix.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:961:7: KW_ALTER KW_VIEW tableName ( KW_AS )? alterViewStatementSuffix
        {
          KW_ALTER179 = (Token) match(input, KW_ALTER, FOLLOW_KW_ALTER_in_alterStatement3722);
          stream_KW_ALTER.add(KW_ALTER179);

          KW_VIEW180 = (Token) match(input, KW_VIEW, FOLLOW_KW_VIEW_in_alterStatement3724);
          stream_KW_VIEW.add(KW_VIEW180);

          pushFollow(FOLLOW_tableName_in_alterStatement3726);
          tableName181 = tableName();

          state._fsp--;

          stream_tableName.add(tableName181.getTree());

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:961:34: ( KW_AS )?
          int alt55 = 2;
          switch (input.LA(1)) {
            case KW_AS: {
              alt55 = 1;
            }
            break;
          }

          switch (alt55) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:961:34: KW_AS
            {
              KW_AS182 = (Token) match(input, KW_AS, FOLLOW_KW_AS_in_alterStatement3728);
              stream_KW_AS.add(KW_AS182);
            }
            break;
          }

          pushFollow(FOLLOW_alterViewStatementSuffix_in_alterStatement3731);
          alterViewStatementSuffix183 = alterViewStatementSuffix();

          state._fsp--;

          stream_alterViewStatementSuffix.add(alterViewStatementSuffix183.getTree());

          // AST REWRITE
          // elements: tableName, alterViewStatementSuffix
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 961:66: -> ^( TOK_ALTERVIEW tableName alterViewStatementSuffix )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:961:69: ^( TOK_ALTERVIEW tableName alterViewStatementSuffix )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_ALTERVIEW, "TOK_ALTERVIEW"), root_1);

              adaptor.addChild(root_1, stream_tableName.nextTree());

              adaptor.addChild(root_1, stream_alterViewStatementSuffix.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 3:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:962:7: KW_ALTER KW_INDEX alterIndexStatementSuffix
        {
          KW_ALTER184 = (Token) match(input, KW_ALTER, FOLLOW_KW_ALTER_in_alterStatement3749);
          stream_KW_ALTER.add(KW_ALTER184);

          KW_INDEX185 = (Token) match(input, KW_INDEX, FOLLOW_KW_INDEX_in_alterStatement3751);
          stream_KW_INDEX.add(KW_INDEX185);

          pushFollow(FOLLOW_alterIndexStatementSuffix_in_alterStatement3753);
          alterIndexStatementSuffix186 = alterIndexStatementSuffix();

          state._fsp--;

          stream_alterIndexStatementSuffix.add(alterIndexStatementSuffix186.getTree());

          // AST REWRITE
          // elements: alterIndexStatementSuffix
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 962:51: -> alterIndexStatementSuffix
          {
            adaptor.addChild(root_0, stream_alterIndexStatementSuffix.nextTree());
          }

          retval.tree = root_0;
        }
        break;
        case 4:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:963:7: KW_ALTER ( KW_DATABASE | KW_SCHEMA ) alterDatabaseStatementSuffix
        {
          KW_ALTER187 = (Token) match(input, KW_ALTER, FOLLOW_KW_ALTER_in_alterStatement3765);
          stream_KW_ALTER.add(KW_ALTER187);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:963:16: ( KW_DATABASE | KW_SCHEMA )
          int alt56 = 2;
          switch (input.LA(1)) {
            case KW_DATABASE: {
              alt56 = 1;
            }
            break;
            case KW_SCHEMA: {
              alt56 = 2;
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 56, 0, input);

              throw nvae;
          }

          switch (alt56) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:963:17: KW_DATABASE
            {
              KW_DATABASE188 = (Token) match(input, KW_DATABASE, FOLLOW_KW_DATABASE_in_alterStatement3768);
              stream_KW_DATABASE.add(KW_DATABASE188);
            }
            break;
            case 2:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:963:29: KW_SCHEMA
            {
              KW_SCHEMA189 = (Token) match(input, KW_SCHEMA, FOLLOW_KW_SCHEMA_in_alterStatement3770);
              stream_KW_SCHEMA.add(KW_SCHEMA189);
            }
            break;
          }

          pushFollow(FOLLOW_alterDatabaseStatementSuffix_in_alterStatement3773);
          alterDatabaseStatementSuffix190 = alterDatabaseStatementSuffix();

          state._fsp--;

          stream_alterDatabaseStatementSuffix.add(alterDatabaseStatementSuffix190.getTree());

          // AST REWRITE
          // elements: alterDatabaseStatementSuffix
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 963:69: -> alterDatabaseStatementSuffix
          {
            adaptor.addChild(root_0, stream_alterDatabaseStatementSuffix.nextTree());
          }

          retval.tree = root_0;
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatement"

  public static class alterTableStatementSuffix_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterTableStatementSuffix"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:966:1: alterTableStatementSuffix : ( alterStatementSuffixRename[true] | alterStatementSuffixUpdateStatsCol | alterStatementSuffixDropPartitions[true] | alterStatementSuffixAddPartitions[true] | alterStatementSuffixTouch | alterStatementSuffixArchive | alterStatementSuffixUnArchive | alterStatementSuffixProperties | alterStatementSuffixSkewedby | alterStatementSuffixExchangePartition | alterStatementPartitionKeyType | ( partitionSpec )? alterTblPartitionStatementSuffix -> alterTblPartitionStatementSuffix ( partitionSpec )? );
  public final HiveParser.alterTableStatementSuffix_return alterTableStatementSuffix() throws RecognitionException {
    HiveParser.alterTableStatementSuffix_return retval = new HiveParser.alterTableStatementSuffix_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.alterStatementSuffixRename_return alterStatementSuffixRename191 = null;

    HiveParser.alterStatementSuffixUpdateStatsCol_return alterStatementSuffixUpdateStatsCol192 = null;

    HiveParser.alterStatementSuffixDropPartitions_return alterStatementSuffixDropPartitions193 = null;

    HiveParser.alterStatementSuffixAddPartitions_return alterStatementSuffixAddPartitions194 = null;

    HiveParser.alterStatementSuffixTouch_return alterStatementSuffixTouch195 = null;

    HiveParser.alterStatementSuffixArchive_return alterStatementSuffixArchive196 = null;

    HiveParser.alterStatementSuffixUnArchive_return alterStatementSuffixUnArchive197 = null;

    HiveParser.alterStatementSuffixProperties_return alterStatementSuffixProperties198 = null;

    HiveParser.alterStatementSuffixSkewedby_return alterStatementSuffixSkewedby199 = null;

    HiveParser.alterStatementSuffixExchangePartition_return alterStatementSuffixExchangePartition200 = null;

    HiveParser.alterStatementPartitionKeyType_return alterStatementPartitionKeyType201 = null;

    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec202 = null;

    HiveParser.alterTblPartitionStatementSuffix_return alterTblPartitionStatementSuffix203 = null;

    RewriteRuleSubtreeStream stream_alterTblPartitionStatementSuffix =
        new RewriteRuleSubtreeStream(adaptor, "rule alterTblPartitionStatementSuffix");
    RewriteRuleSubtreeStream stream_partitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule partitionSpec");
    pushMsg("alter table statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:969:5: ( alterStatementSuffixRename[true] | alterStatementSuffixUpdateStatsCol | alterStatementSuffixDropPartitions[true] | alterStatementSuffixAddPartitions[true] | alterStatementSuffixTouch | alterStatementSuffixArchive | alterStatementSuffixUnArchive | alterStatementSuffixProperties | alterStatementSuffixSkewedby | alterStatementSuffixExchangePartition | alterStatementPartitionKeyType | ( partitionSpec )? alterTblPartitionStatementSuffix -> alterTblPartitionStatementSuffix ( partitionSpec )? )
      int alt59 = 12;
      switch (input.LA(1)) {
        case KW_RENAME: {
          switch (input.LA(2)) {
            case KW_TO: {
              switch (input.LA(3)) {
                case Identifier:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFAULT:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_METADATA:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NONE:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH: {
                  alt59 = 1;
                }
                break;
                case KW_PARTITION: {
                  alt59 = 1;
                }
                break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 59, 22, input);

                  throw nvae;
              }
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 59, 1, input);

              throw nvae;
          }
        }
        break;
        case KW_UPDATE: {
          switch (input.LA(2)) {
            case KW_STATISTICS: {
              switch (input.LA(3)) {
                case KW_FOR: {
                  alt59 = 2;
                }
                break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 59, 23, input);

                  throw nvae;
              }
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 59, 2, input);

              throw nvae;
          }
        }
        break;
        case KW_DROP: {
          alt59 = 3;
        }
        break;
        case KW_ADD: {
          switch (input.LA(2)) {
            case KW_IF:
            case KW_PARTITION: {
              alt59 = 4;
            }
            break;
            case KW_COLUMNS: {
              alt59 = 12;
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 59, 4, input);

              throw nvae;
          }
        }
        break;
        case KW_TOUCH: {
          alt59 = 5;
        }
        break;
        case KW_ARCHIVE: {
          alt59 = 6;
        }
        break;
        case KW_UNARCHIVE: {
          alt59 = 7;
        }
        break;
        case KW_SET: {
          switch (input.LA(2)) {
            case KW_TBLPROPERTIES: {
              alt59 = 8;
            }
            break;
            case KW_FILEFORMAT:
            case KW_LOCATION:
            case KW_SERDE:
            case KW_SERDEPROPERTIES:
            case KW_SKEWED: {
              alt59 = 12;
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 59, 8, input);

              throw nvae;
          }
        }
        break;
        case KW_UNSET: {
          alt59 = 8;
        }
        break;
        case KW_SKEWED: {
          alt59 = 9;
        }
        break;
        case KW_NOT: {
          switch (input.LA(2)) {
            case KW_SKEWED:
            case KW_STORED: {
              alt59 = 9;
            }
            break;
            case KW_CLUSTERED:
            case KW_SORTED: {
              alt59 = 12;
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 59, 11, input);

              throw nvae;
          }
        }
        break;
        case KW_EXCHANGE: {
          alt59 = 10;
        }
        break;
        case KW_PARTITION: {
          switch (input.LA(2)) {
            case KW_COLUMN: {
              alt59 = 11;
            }
            break;
            case LPAREN: {
              alt59 = 12;
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 59, 13, input);

              throw nvae;
          }
        }
        break;
        case KW_CHANGE:
        case KW_CLUSTERED:
        case KW_COMPACT:
        case KW_CONCATENATE:
        case KW_DISABLE:
        case KW_ENABLE:
        case KW_INTO:
        case KW_REPLACE: {
          alt59 = 12;
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 59, 0, input);

          throw nvae;
      }

      switch (alt59) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:969:7: alterStatementSuffixRename[true]
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixRename_in_alterTableStatementSuffix3804);
          alterStatementSuffixRename191 = alterStatementSuffixRename(true);

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixRename191.getTree());
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:970:7: alterStatementSuffixUpdateStatsCol
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixUpdateStatsCol_in_alterTableStatementSuffix3813);
          alterStatementSuffixUpdateStatsCol192 = alterStatementSuffixUpdateStatsCol();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixUpdateStatsCol192.getTree());
        }
        break;
        case 3:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:971:7: alterStatementSuffixDropPartitions[true]
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixDropPartitions_in_alterTableStatementSuffix3821);
          alterStatementSuffixDropPartitions193 = alterStatementSuffixDropPartitions(true);

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixDropPartitions193.getTree());
        }
        break;
        case 4:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:972:7: alterStatementSuffixAddPartitions[true]
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixAddPartitions_in_alterTableStatementSuffix3830);
          alterStatementSuffixAddPartitions194 = alterStatementSuffixAddPartitions(true);

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixAddPartitions194.getTree());
        }
        break;
        case 5:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:973:7: alterStatementSuffixTouch
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixTouch_in_alterTableStatementSuffix3839);
          alterStatementSuffixTouch195 = alterStatementSuffixTouch();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixTouch195.getTree());
        }
        break;
        case 6:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:974:7: alterStatementSuffixArchive
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixArchive_in_alterTableStatementSuffix3847);
          alterStatementSuffixArchive196 = alterStatementSuffixArchive();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixArchive196.getTree());
        }
        break;
        case 7:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:975:7: alterStatementSuffixUnArchive
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixUnArchive_in_alterTableStatementSuffix3855);
          alterStatementSuffixUnArchive197 = alterStatementSuffixUnArchive();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixUnArchive197.getTree());
        }
        break;
        case 8:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:976:7: alterStatementSuffixProperties
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixProperties_in_alterTableStatementSuffix3863);
          alterStatementSuffixProperties198 = alterStatementSuffixProperties();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixProperties198.getTree());
        }
        break;
        case 9:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:977:7: alterStatementSuffixSkewedby
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixSkewedby_in_alterTableStatementSuffix3871);
          alterStatementSuffixSkewedby199 = alterStatementSuffixSkewedby();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixSkewedby199.getTree());
        }
        break;
        case 10:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:978:7: alterStatementSuffixExchangePartition
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixExchangePartition_in_alterTableStatementSuffix3879);
          alterStatementSuffixExchangePartition200 = alterStatementSuffixExchangePartition();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixExchangePartition200.getTree());
        }
        break;
        case 11:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:979:7: alterStatementPartitionKeyType
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementPartitionKeyType_in_alterTableStatementSuffix3887);
          alterStatementPartitionKeyType201 = alterStatementPartitionKeyType();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementPartitionKeyType201.getTree());
        }
        break;
        case 12:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:980:7: ( partitionSpec )? alterTblPartitionStatementSuffix
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:980:7: ( partitionSpec )?
          int alt58 = 2;
          switch (input.LA(1)) {
            case KW_PARTITION: {
              alt58 = 1;
            }
            break;
          }

          switch (alt58) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:980:7: partitionSpec
            {
              pushFollow(FOLLOW_partitionSpec_in_alterTableStatementSuffix3895);
              partitionSpec202 = partitionSpec();

              state._fsp--;

              stream_partitionSpec.add(partitionSpec202.getTree());
            }
            break;
          }

          pushFollow(FOLLOW_alterTblPartitionStatementSuffix_in_alterTableStatementSuffix3898);
          alterTblPartitionStatementSuffix203 = alterTblPartitionStatementSuffix();

          state._fsp--;

          stream_alterTblPartitionStatementSuffix.add(alterTblPartitionStatementSuffix203.getTree());

          // AST REWRITE
          // elements: alterTblPartitionStatementSuffix, partitionSpec
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 980:55: -> alterTblPartitionStatementSuffix ( partitionSpec )?
          {
            adaptor.addChild(root_0, stream_alterTblPartitionStatementSuffix.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:980:91: ( partitionSpec )?
            if (stream_partitionSpec.hasNext()) {
              adaptor.addChild(root_0, stream_partitionSpec.nextTree());
            }
            stream_partitionSpec.reset();
          }

          retval.tree = root_0;
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterTableStatementSuffix"

  public static class alterTblPartitionStatementSuffix_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterTblPartitionStatementSuffix"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:983:1: alterTblPartitionStatementSuffix : ( alterStatementSuffixFileFormat | alterStatementSuffixLocation | alterStatementSuffixProtectMode | alterStatementSuffixMergeFiles | alterStatementSuffixSerdeProperties | alterStatementSuffixRenamePart | alterStatementSuffixBucketNum | alterTblPartitionStatementSuffixSkewedLocation | alterStatementSuffixClusterbySortby | alterStatementSuffixCompact | alterStatementSuffixUpdateStatsCol | alterStatementSuffixRenameCol | alterStatementSuffixAddCol );
  public final HiveParser.alterTblPartitionStatementSuffix_return alterTblPartitionStatementSuffix()
      throws RecognitionException {
    HiveParser.alterTblPartitionStatementSuffix_return retval =
        new HiveParser.alterTblPartitionStatementSuffix_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.alterStatementSuffixFileFormat_return alterStatementSuffixFileFormat204 = null;

    HiveParser.alterStatementSuffixLocation_return alterStatementSuffixLocation205 = null;

    HiveParser.alterStatementSuffixProtectMode_return alterStatementSuffixProtectMode206 = null;

    HiveParser.alterStatementSuffixMergeFiles_return alterStatementSuffixMergeFiles207 = null;

    HiveParser.alterStatementSuffixSerdeProperties_return alterStatementSuffixSerdeProperties208 = null;

    HiveParser.alterStatementSuffixRenamePart_return alterStatementSuffixRenamePart209 = null;

    HiveParser.alterStatementSuffixBucketNum_return alterStatementSuffixBucketNum210 = null;

    HiveParser.alterTblPartitionStatementSuffixSkewedLocation_return alterTblPartitionStatementSuffixSkewedLocation211 =
        null;

    HiveParser.alterStatementSuffixClusterbySortby_return alterStatementSuffixClusterbySortby212 = null;

    HiveParser.alterStatementSuffixCompact_return alterStatementSuffixCompact213 = null;

    HiveParser.alterStatementSuffixUpdateStatsCol_return alterStatementSuffixUpdateStatsCol214 = null;

    HiveParser.alterStatementSuffixRenameCol_return alterStatementSuffixRenameCol215 = null;

    HiveParser.alterStatementSuffixAddCol_return alterStatementSuffixAddCol216 = null;

    pushMsg("alter table partition statement suffix", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:986:3: ( alterStatementSuffixFileFormat | alterStatementSuffixLocation | alterStatementSuffixProtectMode | alterStatementSuffixMergeFiles | alterStatementSuffixSerdeProperties | alterStatementSuffixRenamePart | alterStatementSuffixBucketNum | alterTblPartitionStatementSuffixSkewedLocation | alterStatementSuffixClusterbySortby | alterStatementSuffixCompact | alterStatementSuffixUpdateStatsCol | alterStatementSuffixRenameCol | alterStatementSuffixAddCol )
      int alt60 = 13;
      switch (input.LA(1)) {
        case KW_SET: {
          switch (input.LA(2)) {
            case KW_FILEFORMAT: {
              alt60 = 1;
            }
            break;
            case KW_SERDE:
            case KW_SERDEPROPERTIES: {
              alt60 = 5;
            }
            break;
            case KW_SKEWED: {
              alt60 = 8;
            }
            break;
            case KW_LOCATION: {
              alt60 = 2;
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 60, 1, input);

              throw nvae;
          }
        }
        break;
        case KW_DISABLE:
        case KW_ENABLE: {
          alt60 = 3;
        }
        break;
        case KW_CONCATENATE: {
          alt60 = 4;
        }
        break;
        case KW_RENAME: {
          alt60 = 6;
        }
        break;
        case KW_INTO: {
          alt60 = 7;
        }
        break;
        case KW_CLUSTERED:
        case KW_NOT: {
          alt60 = 9;
        }
        break;
        case KW_COMPACT: {
          alt60 = 10;
        }
        break;
        case KW_UPDATE: {
          alt60 = 11;
        }
        break;
        case KW_CHANGE: {
          alt60 = 12;
        }
        break;
        case KW_ADD:
        case KW_REPLACE: {
          alt60 = 13;
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 60, 0, input);

          throw nvae;
      }

      switch (alt60) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:986:5: alterStatementSuffixFileFormat
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixFileFormat_in_alterTblPartitionStatementSuffix3930);
          alterStatementSuffixFileFormat204 = alterStatementSuffixFileFormat();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixFileFormat204.getTree());
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:987:5: alterStatementSuffixLocation
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixLocation_in_alterTblPartitionStatementSuffix3936);
          alterStatementSuffixLocation205 = alterStatementSuffixLocation();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixLocation205.getTree());
        }
        break;
        case 3:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:988:5: alterStatementSuffixProtectMode
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixProtectMode_in_alterTblPartitionStatementSuffix3942);
          alterStatementSuffixProtectMode206 = alterStatementSuffixProtectMode();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixProtectMode206.getTree());
        }
        break;
        case 4:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:989:5: alterStatementSuffixMergeFiles
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixMergeFiles_in_alterTblPartitionStatementSuffix3948);
          alterStatementSuffixMergeFiles207 = alterStatementSuffixMergeFiles();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixMergeFiles207.getTree());
        }
        break;
        case 5:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:990:5: alterStatementSuffixSerdeProperties
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixSerdeProperties_in_alterTblPartitionStatementSuffix3954);
          alterStatementSuffixSerdeProperties208 = alterStatementSuffixSerdeProperties();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixSerdeProperties208.getTree());
        }
        break;
        case 6:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:991:5: alterStatementSuffixRenamePart
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixRenamePart_in_alterTblPartitionStatementSuffix3960);
          alterStatementSuffixRenamePart209 = alterStatementSuffixRenamePart();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixRenamePart209.getTree());
        }
        break;
        case 7:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:992:5: alterStatementSuffixBucketNum
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixBucketNum_in_alterTblPartitionStatementSuffix3966);
          alterStatementSuffixBucketNum210 = alterStatementSuffixBucketNum();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixBucketNum210.getTree());
        }
        break;
        case 8:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:993:5: alterTblPartitionStatementSuffixSkewedLocation
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterTblPartitionStatementSuffixSkewedLocation_in_alterTblPartitionStatementSuffix3972);
          alterTblPartitionStatementSuffixSkewedLocation211 = alterTblPartitionStatementSuffixSkewedLocation();

          state._fsp--;

          adaptor.addChild(root_0, alterTblPartitionStatementSuffixSkewedLocation211.getTree());
        }
        break;
        case 9:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:994:5: alterStatementSuffixClusterbySortby
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixClusterbySortby_in_alterTblPartitionStatementSuffix3978);
          alterStatementSuffixClusterbySortby212 = alterStatementSuffixClusterbySortby();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixClusterbySortby212.getTree());
        }
        break;
        case 10:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:995:5: alterStatementSuffixCompact
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixCompact_in_alterTblPartitionStatementSuffix3984);
          alterStatementSuffixCompact213 = alterStatementSuffixCompact();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixCompact213.getTree());
        }
        break;
        case 11:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:996:5: alterStatementSuffixUpdateStatsCol
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixUpdateStatsCol_in_alterTblPartitionStatementSuffix3990);
          alterStatementSuffixUpdateStatsCol214 = alterStatementSuffixUpdateStatsCol();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixUpdateStatsCol214.getTree());
        }
        break;
        case 12:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:997:5: alterStatementSuffixRenameCol
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixRenameCol_in_alterTblPartitionStatementSuffix3996);
          alterStatementSuffixRenameCol215 = alterStatementSuffixRenameCol();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixRenameCol215.getTree());
        }
        break;
        case 13:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:998:5: alterStatementSuffixAddCol
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixAddCol_in_alterTblPartitionStatementSuffix4002);
          alterStatementSuffixAddCol216 = alterStatementSuffixAddCol();

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixAddCol216.getTree());
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterTblPartitionStatementSuffix"

  public static class alterStatementPartitionKeyType_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementPartitionKeyType"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1001:1: alterStatementPartitionKeyType : KW_PARTITION KW_COLUMN LPAREN columnNameType RPAREN -> ^( TOK_ALTERTABLE_PARTCOLTYPE columnNameType ) ;
  public final HiveParser.alterStatementPartitionKeyType_return alterStatementPartitionKeyType()
      throws RecognitionException {
    HiveParser.alterStatementPartitionKeyType_return retval = new HiveParser.alterStatementPartitionKeyType_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_PARTITION217 = null;
    Token KW_COLUMN218 = null;
    Token LPAREN219 = null;
    Token RPAREN221 = null;
    HiveParser.columnNameType_return columnNameType220 = null;

    CommonTree KW_PARTITION217_tree = null;
    CommonTree KW_COLUMN218_tree = null;
    CommonTree LPAREN219_tree = null;
    CommonTree RPAREN221_tree = null;
    RewriteRuleTokenStream stream_KW_PARTITION = new RewriteRuleTokenStream(adaptor, "token KW_PARTITION");
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleTokenStream stream_KW_COLUMN = new RewriteRuleTokenStream(adaptor, "token KW_COLUMN");
    RewriteRuleSubtreeStream stream_columnNameType = new RewriteRuleSubtreeStream(adaptor, "rule columnNameType");
    msgs.push("alter partition key type");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1004:2: ( KW_PARTITION KW_COLUMN LPAREN columnNameType RPAREN -> ^( TOK_ALTERTABLE_PARTCOLTYPE columnNameType ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1004:4: KW_PARTITION KW_COLUMN LPAREN columnNameType RPAREN
      {
        KW_PARTITION217 = (Token) match(input, KW_PARTITION, FOLLOW_KW_PARTITION_in_alterStatementPartitionKeyType4024);
        stream_KW_PARTITION.add(KW_PARTITION217);

        KW_COLUMN218 = (Token) match(input, KW_COLUMN, FOLLOW_KW_COLUMN_in_alterStatementPartitionKeyType4026);
        stream_KW_COLUMN.add(KW_COLUMN218);

        LPAREN219 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_alterStatementPartitionKeyType4028);
        stream_LPAREN.add(LPAREN219);

        pushFollow(FOLLOW_columnNameType_in_alterStatementPartitionKeyType4030);
        columnNameType220 = columnNameType();

        state._fsp--;

        stream_columnNameType.add(columnNameType220.getTree());

        RPAREN221 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_alterStatementPartitionKeyType4032);
        stream_RPAREN.add(RPAREN221);

        // AST REWRITE
        // elements: columnNameType
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1005:2: -> ^( TOK_ALTERTABLE_PARTCOLTYPE columnNameType )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1005:5: ^( TOK_ALTERTABLE_PARTCOLTYPE columnNameType )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERTABLE_PARTCOLTYPE, "TOK_ALTERTABLE_PARTCOLTYPE"), root_1);

            adaptor.addChild(root_1, stream_columnNameType.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      msgs.pop();
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementPartitionKeyType"

  public static class alterViewStatementSuffix_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterViewStatementSuffix"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1008:1: alterViewStatementSuffix : ( alterViewSuffixProperties | alterStatementSuffixRename[false] | alterStatementSuffixAddPartitions[false] | alterStatementSuffixDropPartitions[false] | selectStatementWithCTE );
  public final HiveParser.alterViewStatementSuffix_return alterViewStatementSuffix() throws RecognitionException {
    HiveParser.alterViewStatementSuffix_return retval = new HiveParser.alterViewStatementSuffix_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.alterViewSuffixProperties_return alterViewSuffixProperties222 = null;

    HiveParser.alterStatementSuffixRename_return alterStatementSuffixRename223 = null;

    HiveParser.alterStatementSuffixAddPartitions_return alterStatementSuffixAddPartitions224 = null;

    HiveParser.alterStatementSuffixDropPartitions_return alterStatementSuffixDropPartitions225 = null;

    HiveParser.selectStatementWithCTE_return selectStatementWithCTE226 = null;

    pushMsg("alter view statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1011:5: ( alterViewSuffixProperties | alterStatementSuffixRename[false] | alterStatementSuffixAddPartitions[false] | alterStatementSuffixDropPartitions[false] | selectStatementWithCTE )
      int alt61 = 5;
      switch (input.LA(1)) {
        case KW_SET:
        case KW_UNSET: {
          alt61 = 1;
        }
        break;
        case KW_RENAME: {
          alt61 = 2;
        }
        break;
        case KW_ADD: {
          alt61 = 3;
        }
        break;
        case KW_DROP: {
          alt61 = 4;
        }
        break;
        case KW_MAP:
        case KW_REDUCE:
        case KW_SELECT:
        case KW_WITH: {
          alt61 = 5;
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 61, 0, input);

          throw nvae;
      }

      switch (alt61) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1011:7: alterViewSuffixProperties
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterViewSuffixProperties_in_alterViewStatementSuffix4065);
          alterViewSuffixProperties222 = alterViewSuffixProperties();

          state._fsp--;

          adaptor.addChild(root_0, alterViewSuffixProperties222.getTree());
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1012:7: alterStatementSuffixRename[false]
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixRename_in_alterViewStatementSuffix4073);
          alterStatementSuffixRename223 = alterStatementSuffixRename(false);

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixRename223.getTree());
        }
        break;
        case 3:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1013:7: alterStatementSuffixAddPartitions[false]
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixAddPartitions_in_alterViewStatementSuffix4082);
          alterStatementSuffixAddPartitions224 = alterStatementSuffixAddPartitions(false);

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixAddPartitions224.getTree());
        }
        break;
        case 4:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1014:7: alterStatementSuffixDropPartitions[false]
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterStatementSuffixDropPartitions_in_alterViewStatementSuffix4091);
          alterStatementSuffixDropPartitions225 = alterStatementSuffixDropPartitions(false);

          state._fsp--;

          adaptor.addChild(root_0, alterStatementSuffixDropPartitions225.getTree());
        }
        break;
        case 5:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1015:7: selectStatementWithCTE
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_selectStatementWithCTE_in_alterViewStatementSuffix4100);
          selectStatementWithCTE226 = selectStatementWithCTE();

          state._fsp--;

          adaptor.addChild(root_0, selectStatementWithCTE226.getTree());
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterViewStatementSuffix"

  public static class alterIndexStatementSuffix_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterIndexStatementSuffix"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1018:1: alterIndexStatementSuffix : indexName= identifier KW_ON tableName ( partitionSpec )? ( KW_REBUILD -> ^( TOK_ALTERINDEX_REBUILD tableName $indexName ( partitionSpec )? ) | KW_SET KW_IDXPROPERTIES indexProperties -> ^( TOK_ALTERINDEX_PROPERTIES tableName $indexName indexProperties ) ) ;
  public final HiveParser.alterIndexStatementSuffix_return alterIndexStatementSuffix() throws RecognitionException {
    HiveParser.alterIndexStatementSuffix_return retval = new HiveParser.alterIndexStatementSuffix_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_ON227 = null;
    Token KW_REBUILD230 = null;
    Token KW_SET231 = null;
    Token KW_IDXPROPERTIES232 = null;
    HiveParser_IdentifiersParser.identifier_return indexName = null;

    HiveParser_FromClauseParser.tableName_return tableName228 = null;

    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec229 = null;

    HiveParser.indexProperties_return indexProperties233 = null;

    CommonTree KW_ON227_tree = null;
    CommonTree KW_REBUILD230_tree = null;
    CommonTree KW_SET231_tree = null;
    CommonTree KW_IDXPROPERTIES232_tree = null;
    RewriteRuleTokenStream stream_KW_IDXPROPERTIES = new RewriteRuleTokenStream(adaptor, "token KW_IDXPROPERTIES");
    RewriteRuleTokenStream stream_KW_REBUILD = new RewriteRuleTokenStream(adaptor, "token KW_REBUILD");
    RewriteRuleTokenStream stream_KW_ON = new RewriteRuleTokenStream(adaptor, "token KW_ON");
    RewriteRuleTokenStream stream_KW_SET = new RewriteRuleTokenStream(adaptor, "token KW_SET");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_indexProperties = new RewriteRuleSubtreeStream(adaptor, "rule indexProperties");
    RewriteRuleSubtreeStream stream_partitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule partitionSpec");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    pushMsg("alter index statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1021:5: (indexName= identifier KW_ON tableName ( partitionSpec )? ( KW_REBUILD -> ^( TOK_ALTERINDEX_REBUILD tableName $indexName ( partitionSpec )? ) | KW_SET KW_IDXPROPERTIES indexProperties -> ^( TOK_ALTERINDEX_PROPERTIES tableName $indexName indexProperties ) ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1021:7: indexName= identifier KW_ON tableName ( partitionSpec )? ( KW_REBUILD -> ^( TOK_ALTERINDEX_REBUILD tableName $indexName ( partitionSpec )? ) | KW_SET KW_IDXPROPERTIES indexProperties -> ^( TOK_ALTERINDEX_PROPERTIES tableName $indexName indexProperties ) )
      {
        pushFollow(FOLLOW_identifier_in_alterIndexStatementSuffix4129);
        indexName = identifier();

        state._fsp--;

        stream_identifier.add(indexName.getTree());

        KW_ON227 = (Token) match(input, KW_ON, FOLLOW_KW_ON_in_alterIndexStatementSuffix4131);
        stream_KW_ON.add(KW_ON227);

        pushFollow(FOLLOW_tableName_in_alterIndexStatementSuffix4133);
        tableName228 = tableName();

        state._fsp--;

        stream_tableName.add(tableName228.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1021:44: ( partitionSpec )?
        int alt62 = 2;
        switch (input.LA(1)) {
          case KW_PARTITION: {
            alt62 = 1;
          }
          break;
        }

        switch (alt62) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1021:44: partitionSpec
          {
            pushFollow(FOLLOW_partitionSpec_in_alterIndexStatementSuffix4135);
            partitionSpec229 = partitionSpec();

            state._fsp--;

            stream_partitionSpec.add(partitionSpec229.getTree());
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1022:5: ( KW_REBUILD -> ^( TOK_ALTERINDEX_REBUILD tableName $indexName ( partitionSpec )? ) | KW_SET KW_IDXPROPERTIES indexProperties -> ^( TOK_ALTERINDEX_PROPERTIES tableName $indexName indexProperties ) )
        int alt63 = 2;
        switch (input.LA(1)) {
          case KW_REBUILD: {
            alt63 = 1;
          }
          break;
          case KW_SET: {
            alt63 = 2;
          }
          break;
          default:
            NoViableAltException nvae = new NoViableAltException("", 63, 0, input);

            throw nvae;
        }

        switch (alt63) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1023:7: KW_REBUILD
          {
            KW_REBUILD230 = (Token) match(input, KW_REBUILD, FOLLOW_KW_REBUILD_in_alterIndexStatementSuffix4150);
            stream_KW_REBUILD.add(KW_REBUILD230);

            // AST REWRITE
            // elements: indexName, partitionSpec, tableName
            // token labels:
            // rule labels: indexName, retval
            // token list labels:
            // rule list labels:
            // wildcard labels:
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_indexName =
                new RewriteRuleSubtreeStream(adaptor, "rule indexName", indexName != null ? indexName.tree : null);
            RewriteRuleSubtreeStream stream_retval =
                new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

            root_0 = (CommonTree) adaptor.nil();
            // 1024:7: -> ^( TOK_ALTERINDEX_REBUILD tableName $indexName ( partitionSpec )? )
            {
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1024:9: ^( TOK_ALTERINDEX_REBUILD tableName $indexName ( partitionSpec )? )
              {
                CommonTree root_1 = (CommonTree) adaptor.nil();
                root_1 = (CommonTree) adaptor.becomeRoot(
                    (CommonTree) adaptor.create(TOK_ALTERINDEX_REBUILD, "TOK_ALTERINDEX_REBUILD"), root_1);

                adaptor.addChild(root_1, stream_tableName.nextTree());

                adaptor.addChild(root_1, stream_indexName.nextTree());

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1024:55: ( partitionSpec )?
                if (stream_partitionSpec.hasNext()) {
                  adaptor.addChild(root_1, stream_partitionSpec.nextTree());
                }
                stream_partitionSpec.reset();

                adaptor.addChild(root_0, root_1);
              }
            }

            retval.tree = root_0;
          }
          break;
          case 2:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1026:7: KW_SET KW_IDXPROPERTIES indexProperties
          {
            KW_SET231 = (Token) match(input, KW_SET, FOLLOW_KW_SET_in_alterIndexStatementSuffix4183);
            stream_KW_SET.add(KW_SET231);

            KW_IDXPROPERTIES232 =
                (Token) match(input, KW_IDXPROPERTIES, FOLLOW_KW_IDXPROPERTIES_in_alterIndexStatementSuffix4185);
            stream_KW_IDXPROPERTIES.add(KW_IDXPROPERTIES232);

            pushFollow(FOLLOW_indexProperties_in_alterIndexStatementSuffix4193);
            indexProperties233 = indexProperties();

            state._fsp--;

            stream_indexProperties.add(indexProperties233.getTree());

            // AST REWRITE
            // elements: indexProperties, indexName, tableName
            // token labels:
            // rule labels: indexName, retval
            // token list labels:
            // rule list labels:
            // wildcard labels:
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_indexName =
                new RewriteRuleSubtreeStream(adaptor, "rule indexName", indexName != null ? indexName.tree : null);
            RewriteRuleSubtreeStream stream_retval =
                new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

            root_0 = (CommonTree) adaptor.nil();
            // 1028:7: -> ^( TOK_ALTERINDEX_PROPERTIES tableName $indexName indexProperties )
            {
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1028:9: ^( TOK_ALTERINDEX_PROPERTIES tableName $indexName indexProperties )
              {
                CommonTree root_1 = (CommonTree) adaptor.nil();
                root_1 = (CommonTree) adaptor.becomeRoot(
                    (CommonTree) adaptor.create(TOK_ALTERINDEX_PROPERTIES, "TOK_ALTERINDEX_PROPERTIES"), root_1);

                adaptor.addChild(root_1, stream_tableName.nextTree());

                adaptor.addChild(root_1, stream_indexName.nextTree());

                adaptor.addChild(root_1, stream_indexProperties.nextTree());

                adaptor.addChild(root_0, root_1);
              }
            }

            retval.tree = root_0;
          }
          break;
        }
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterIndexStatementSuffix"

  public static class alterDatabaseStatementSuffix_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterDatabaseStatementSuffix"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1032:1: alterDatabaseStatementSuffix : ( alterDatabaseSuffixProperties | alterDatabaseSuffixSetOwner );
  public final HiveParser.alterDatabaseStatementSuffix_return alterDatabaseStatementSuffix()
      throws RecognitionException {
    HiveParser.alterDatabaseStatementSuffix_return retval = new HiveParser.alterDatabaseStatementSuffix_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.alterDatabaseSuffixProperties_return alterDatabaseSuffixProperties234 = null;

    HiveParser.alterDatabaseSuffixSetOwner_return alterDatabaseSuffixSetOwner235 = null;

    pushMsg("alter database statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1035:5: ( alterDatabaseSuffixProperties | alterDatabaseSuffixSetOwner )
      int alt64 = 2;
      switch (input.LA(1)) {
        case Identifier: {
          switch (input.LA(2)) {
            case KW_SET: {
              switch (input.LA(3)) {
                case KW_DBPROPERTIES: {
                  alt64 = 1;
                }
                break;
                case KW_OWNER: {
                  alt64 = 2;
                }
                break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 64, 3, input);

                  throw nvae;
              }
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 64, 1, input);

              throw nvae;
          }
        }
        break;
        case KW_ADD:
        case KW_ADMIN:
        case KW_AFTER:
        case KW_ALL:
        case KW_ALTER:
        case KW_ANALYZE:
        case KW_ARCHIVE:
        case KW_ARRAY:
        case KW_AS:
        case KW_ASC:
        case KW_AUTHORIZATION:
        case KW_BEFORE:
        case KW_BETWEEN:
        case KW_BIGINT:
        case KW_BINARY:
        case KW_BOOLEAN:
        case KW_BOTH:
        case KW_BUCKET:
        case KW_BUCKETS:
        case KW_BY:
        case KW_CASCADE:
        case KW_CHANGE:
        case KW_CLUSTER:
        case KW_CLUSTERED:
        case KW_CLUSTERSTATUS:
        case KW_COLLECTION:
        case KW_COLUMNS:
        case KW_COMMENT:
        case KW_COMPACT:
        case KW_COMPACTIONS:
        case KW_COMPUTE:
        case KW_CONCATENATE:
        case KW_CONTINUE:
        case KW_CREATE:
        case KW_CUBE:
        case KW_CURSOR:
        case KW_DATA:
        case KW_DATABASES:
        case KW_DATE:
        case KW_DATETIME:
        case KW_DBPROPERTIES:
        case KW_DECIMAL:
        case KW_DEFAULT:
        case KW_DEFERRED:
        case KW_DEFINED:
        case KW_DELETE:
        case KW_DELIMITED:
        case KW_DEPENDENCY:
        case KW_DESC:
        case KW_DESCRIBE:
        case KW_DIRECTORIES:
        case KW_DIRECTORY:
        case KW_DISABLE:
        case KW_DISTRIBUTE:
        case KW_DOUBLE:
        case KW_DROP:
        case KW_ELEM_TYPE:
        case KW_ENABLE:
        case KW_ESCAPED:
        case KW_EXCLUSIVE:
        case KW_EXISTS:
        case KW_EXPLAIN:
        case KW_EXPORT:
        case KW_EXTERNAL:
        case KW_FALSE:
        case KW_FETCH:
        case KW_FIELDS:
        case KW_FILE:
        case KW_FILEFORMAT:
        case KW_FIRST:
        case KW_FLOAT:
        case KW_FOR:
        case KW_FORMAT:
        case KW_FORMATTED:
        case KW_FULL:
        case KW_FUNCTIONS:
        case KW_GRANT:
        case KW_GROUP:
        case KW_GROUPING:
        case KW_HOLD_DDLTIME:
        case KW_IDXPROPERTIES:
        case KW_IGNORE:
        case KW_IMPORT:
        case KW_IN:
        case KW_INDEX:
        case KW_INDEXES:
        case KW_INNER:
        case KW_INPATH:
        case KW_INPUTDRIVER:
        case KW_INPUTFORMAT:
        case KW_INSERT:
        case KW_INT:
        case KW_INTERSECT:
        case KW_INTO:
        case KW_IS:
        case KW_ITEMS:
        case KW_JAR:
        case KW_KEYS:
        case KW_KEY_TYPE:
        case KW_LATERAL:
        case KW_LEFT:
        case KW_LIKE:
        case KW_LIMIT:
        case KW_LINES:
        case KW_LOAD:
        case KW_LOCAL:
        case KW_LOCATION:
        case KW_LOCK:
        case KW_LOCKS:
        case KW_LOGICAL:
        case KW_LONG:
        case KW_MAPJOIN:
        case KW_MATERIALIZED:
        case KW_METADATA:
        case KW_MINUS:
        case KW_MSCK:
        case KW_NONE:
        case KW_NOSCAN:
        case KW_NO_DROP:
        case KW_NULL:
        case KW_OF:
        case KW_OFFLINE:
        case KW_OPTION:
        case KW_ORDER:
        case KW_OUT:
        case KW_OUTER:
        case KW_OUTPUTDRIVER:
        case KW_OUTPUTFORMAT:
        case KW_OVERWRITE:
        case KW_OWNER:
        case KW_PARTITION:
        case KW_PARTITIONED:
        case KW_PARTITIONS:
        case KW_PERCENT:
        case KW_PLUS:
        case KW_PRETTY:
        case KW_PRINCIPALS:
        case KW_PROCEDURE:
        case KW_PROTECTION:
        case KW_PURGE:
        case KW_RANGE:
        case KW_READ:
        case KW_READONLY:
        case KW_READS:
        case KW_REBUILD:
        case KW_RECORDREADER:
        case KW_RECORDWRITER:
        case KW_REGEXP:
        case KW_RELOAD:
        case KW_RENAME:
        case KW_REPAIR:
        case KW_REPLACE:
        case KW_REPLICATION:
        case KW_RESTRICT:
        case KW_REVOKE:
        case KW_REWRITE:
        case KW_RIGHT:
        case KW_RLIKE:
        case KW_ROLE:
        case KW_ROLES:
        case KW_ROLLUP:
        case KW_ROW:
        case KW_ROWS:
        case KW_SCHEMA:
        case KW_SCHEMAS:
        case KW_SEMI:
        case KW_SERDE:
        case KW_SERDEPROPERTIES:
        case KW_SERVER:
        case KW_SET:
        case KW_SETS:
        case KW_SHARED:
        case KW_SHOW:
        case KW_SHOW_DATABASE:
        case KW_SKEWED:
        case KW_SMALLINT:
        case KW_SORT:
        case KW_SORTED:
        case KW_SSL:
        case KW_STATISTICS:
        case KW_STORED:
        case KW_STREAMTABLE:
        case KW_STRING:
        case KW_STRUCT:
        case KW_TABLE:
        case KW_TABLES:
        case KW_TBLPROPERTIES:
        case KW_TEMPORARY:
        case KW_TERMINATED:
        case KW_TIMESTAMP:
        case KW_TINYINT:
        case KW_TO:
        case KW_TOUCH:
        case KW_TRANSACTIONS:
        case KW_TRIGGER:
        case KW_TRUE:
        case KW_TRUNCATE:
        case KW_UNARCHIVE:
        case KW_UNDO:
        case KW_UNION:
        case KW_UNIONTYPE:
        case KW_UNLOCK:
        case KW_UNSET:
        case KW_UNSIGNED:
        case KW_UPDATE:
        case KW_URI:
        case KW_USE:
        case KW_USER:
        case KW_USING:
        case KW_UTC:
        case KW_UTCTIMESTAMP:
        case KW_VALUES:
        case KW_VALUE_TYPE:
        case KW_VIEW:
        case KW_WHILE:
        case KW_WITH: {
          switch (input.LA(2)) {
            case KW_SET: {
              switch (input.LA(3)) {
                case KW_DBPROPERTIES: {
                  alt64 = 1;
                }
                break;
                case KW_OWNER: {
                  alt64 = 2;
                }
                break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 64, 4, input);

                  throw nvae;
              }
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 64, 2, input);

              throw nvae;
          }
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 64, 0, input);

          throw nvae;
      }

      switch (alt64) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1035:7: alterDatabaseSuffixProperties
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterDatabaseSuffixProperties_in_alterDatabaseStatementSuffix4244);
          alterDatabaseSuffixProperties234 = alterDatabaseSuffixProperties();

          state._fsp--;

          adaptor.addChild(root_0, alterDatabaseSuffixProperties234.getTree());
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1036:7: alterDatabaseSuffixSetOwner
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_alterDatabaseSuffixSetOwner_in_alterDatabaseStatementSuffix4252);
          alterDatabaseSuffixSetOwner235 = alterDatabaseSuffixSetOwner();

          state._fsp--;

          adaptor.addChild(root_0, alterDatabaseSuffixSetOwner235.getTree());
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterDatabaseStatementSuffix"

  public static class alterDatabaseSuffixProperties_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterDatabaseSuffixProperties"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1039:1: alterDatabaseSuffixProperties : name= identifier KW_SET KW_DBPROPERTIES dbProperties -> ^( TOK_ALTERDATABASE_PROPERTIES $name dbProperties ) ;
  public final HiveParser.alterDatabaseSuffixProperties_return alterDatabaseSuffixProperties()
      throws RecognitionException {
    HiveParser.alterDatabaseSuffixProperties_return retval = new HiveParser.alterDatabaseSuffixProperties_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_SET236 = null;
    Token KW_DBPROPERTIES237 = null;
    HiveParser_IdentifiersParser.identifier_return name = null;

    HiveParser.dbProperties_return dbProperties238 = null;

    CommonTree KW_SET236_tree = null;
    CommonTree KW_DBPROPERTIES237_tree = null;
    RewriteRuleTokenStream stream_KW_DBPROPERTIES = new RewriteRuleTokenStream(adaptor, "token KW_DBPROPERTIES");
    RewriteRuleTokenStream stream_KW_SET = new RewriteRuleTokenStream(adaptor, "token KW_SET");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_dbProperties = new RewriteRuleSubtreeStream(adaptor, "rule dbProperties");
    pushMsg("alter database properties statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1042:5: (name= identifier KW_SET KW_DBPROPERTIES dbProperties -> ^( TOK_ALTERDATABASE_PROPERTIES $name dbProperties ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1042:7: name= identifier KW_SET KW_DBPROPERTIES dbProperties
      {
        pushFollow(FOLLOW_identifier_in_alterDatabaseSuffixProperties4281);
        name = identifier();

        state._fsp--;

        stream_identifier.add(name.getTree());

        KW_SET236 = (Token) match(input, KW_SET, FOLLOW_KW_SET_in_alterDatabaseSuffixProperties4283);
        stream_KW_SET.add(KW_SET236);

        KW_DBPROPERTIES237 =
            (Token) match(input, KW_DBPROPERTIES, FOLLOW_KW_DBPROPERTIES_in_alterDatabaseSuffixProperties4285);
        stream_KW_DBPROPERTIES.add(KW_DBPROPERTIES237);

        pushFollow(FOLLOW_dbProperties_in_alterDatabaseSuffixProperties4287);
        dbProperties238 = dbProperties();

        state._fsp--;

        stream_dbProperties.add(dbProperties238.getTree());

        // AST REWRITE
        // elements: name, dbProperties
        // token labels:
        // rule labels: name, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_name =
            new RewriteRuleSubtreeStream(adaptor, "rule name", name != null ? name.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1043:5: -> ^( TOK_ALTERDATABASE_PROPERTIES $name dbProperties )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1043:8: ^( TOK_ALTERDATABASE_PROPERTIES $name dbProperties )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERDATABASE_PROPERTIES, "TOK_ALTERDATABASE_PROPERTIES"), root_1);

            adaptor.addChild(root_1, stream_name.nextTree());

            adaptor.addChild(root_1, stream_dbProperties.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterDatabaseSuffixProperties"

  public static class alterDatabaseSuffixSetOwner_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterDatabaseSuffixSetOwner"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1046:1: alterDatabaseSuffixSetOwner : dbName= identifier KW_SET KW_OWNER principalName -> ^( TOK_ALTERDATABASE_OWNER $dbName principalName ) ;
  public final HiveParser.alterDatabaseSuffixSetOwner_return alterDatabaseSuffixSetOwner() throws RecognitionException {
    HiveParser.alterDatabaseSuffixSetOwner_return retval = new HiveParser.alterDatabaseSuffixSetOwner_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_SET239 = null;
    Token KW_OWNER240 = null;
    HiveParser_IdentifiersParser.identifier_return dbName = null;

    HiveParser.principalName_return principalName241 = null;

    CommonTree KW_SET239_tree = null;
    CommonTree KW_OWNER240_tree = null;
    RewriteRuleTokenStream stream_KW_OWNER = new RewriteRuleTokenStream(adaptor, "token KW_OWNER");
    RewriteRuleTokenStream stream_KW_SET = new RewriteRuleTokenStream(adaptor, "token KW_SET");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_principalName = new RewriteRuleSubtreeStream(adaptor, "rule principalName");
    pushMsg("alter database set owner", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1049:5: (dbName= identifier KW_SET KW_OWNER principalName -> ^( TOK_ALTERDATABASE_OWNER $dbName principalName ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1049:7: dbName= identifier KW_SET KW_OWNER principalName
      {
        pushFollow(FOLLOW_identifier_in_alterDatabaseSuffixSetOwner4331);
        dbName = identifier();

        state._fsp--;

        stream_identifier.add(dbName.getTree());

        KW_SET239 = (Token) match(input, KW_SET, FOLLOW_KW_SET_in_alterDatabaseSuffixSetOwner4333);
        stream_KW_SET.add(KW_SET239);

        KW_OWNER240 = (Token) match(input, KW_OWNER, FOLLOW_KW_OWNER_in_alterDatabaseSuffixSetOwner4335);
        stream_KW_OWNER.add(KW_OWNER240);

        pushFollow(FOLLOW_principalName_in_alterDatabaseSuffixSetOwner4337);
        principalName241 = principalName();

        state._fsp--;

        stream_principalName.add(principalName241.getTree());

        // AST REWRITE
        // elements: dbName, principalName
        // token labels:
        // rule labels: dbName, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_dbName =
            new RewriteRuleSubtreeStream(adaptor, "rule dbName", dbName != null ? dbName.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1050:5: -> ^( TOK_ALTERDATABASE_OWNER $dbName principalName )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1050:8: ^( TOK_ALTERDATABASE_OWNER $dbName principalName )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERDATABASE_OWNER, "TOK_ALTERDATABASE_OWNER"), root_1);

            adaptor.addChild(root_1, stream_dbName.nextTree());

            adaptor.addChild(root_1, stream_principalName.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterDatabaseSuffixSetOwner"

  public static class alterStatementSuffixRename_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixRename"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1053:1: alterStatementSuffixRename[boolean table] : KW_RENAME KW_TO tableName -> { table }? ^( TOK_ALTERTABLE_RENAME tableName ) -> ^( TOK_ALTERVIEW_RENAME tableName ) ;
  public final HiveParser.alterStatementSuffixRename_return alterStatementSuffixRename(boolean table)
      throws RecognitionException {
    HiveParser.alterStatementSuffixRename_return retval = new HiveParser.alterStatementSuffixRename_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_RENAME242 = null;
    Token KW_TO243 = null;
    HiveParser_FromClauseParser.tableName_return tableName244 = null;

    CommonTree KW_RENAME242_tree = null;
    CommonTree KW_TO243_tree = null;
    RewriteRuleTokenStream stream_KW_RENAME = new RewriteRuleTokenStream(adaptor, "token KW_RENAME");
    RewriteRuleTokenStream stream_KW_TO = new RewriteRuleTokenStream(adaptor, "token KW_TO");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    pushMsg("rename statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1056:5: ( KW_RENAME KW_TO tableName -> { table }? ^( TOK_ALTERTABLE_RENAME tableName ) -> ^( TOK_ALTERVIEW_RENAME tableName ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1056:7: KW_RENAME KW_TO tableName
      {
        KW_RENAME242 = (Token) match(input, KW_RENAME, FOLLOW_KW_RENAME_in_alterStatementSuffixRename4380);
        stream_KW_RENAME.add(KW_RENAME242);

        KW_TO243 = (Token) match(input, KW_TO, FOLLOW_KW_TO_in_alterStatementSuffixRename4382);
        stream_KW_TO.add(KW_TO243);

        pushFollow(FOLLOW_tableName_in_alterStatementSuffixRename4384);
        tableName244 = tableName();

        state._fsp--;

        stream_tableName.add(tableName244.getTree());

        // AST REWRITE
        // elements: tableName, tableName
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1057:5: -> { table }? ^( TOK_ALTERTABLE_RENAME tableName )
        if (table) {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1057:19: ^( TOK_ALTERTABLE_RENAME tableName )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERTABLE_RENAME, "TOK_ALTERTABLE_RENAME"), root_1);

            adaptor.addChild(root_1, stream_tableName.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        } else // 1058:5: -> ^( TOK_ALTERVIEW_RENAME tableName )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1058:19: ^( TOK_ALTERVIEW_RENAME tableName )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERVIEW_RENAME, "TOK_ALTERVIEW_RENAME"), root_1);

            adaptor.addChild(root_1, stream_tableName.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixRename"

  public static class alterStatementSuffixAddCol_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixAddCol"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1061:1: alterStatementSuffixAddCol : (add= KW_ADD |replace= KW_REPLACE ) KW_COLUMNS LPAREN columnNameTypeList RPAREN ( restrictOrCascade )? -> {$add != null}? ^( TOK_ALTERTABLE_ADDCOLS columnNameTypeList ( restrictOrCascade )? ) -> ^( TOK_ALTERTABLE_REPLACECOLS columnNameTypeList ( restrictOrCascade )? ) ;
  public final HiveParser.alterStatementSuffixAddCol_return alterStatementSuffixAddCol() throws RecognitionException {
    HiveParser.alterStatementSuffixAddCol_return retval = new HiveParser.alterStatementSuffixAddCol_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token add = null;
    Token replace = null;
    Token KW_COLUMNS245 = null;
    Token LPAREN246 = null;
    Token RPAREN248 = null;
    HiveParser.columnNameTypeList_return columnNameTypeList247 = null;

    HiveParser.restrictOrCascade_return restrictOrCascade249 = null;

    CommonTree add_tree = null;
    CommonTree replace_tree = null;
    CommonTree KW_COLUMNS245_tree = null;
    CommonTree LPAREN246_tree = null;
    CommonTree RPAREN248_tree = null;
    RewriteRuleTokenStream stream_KW_COLUMNS = new RewriteRuleTokenStream(adaptor, "token KW_COLUMNS");
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleTokenStream stream_KW_REPLACE = new RewriteRuleTokenStream(adaptor, "token KW_REPLACE");
    RewriteRuleTokenStream stream_KW_ADD = new RewriteRuleTokenStream(adaptor, "token KW_ADD");
    RewriteRuleSubtreeStream stream_columnNameTypeList =
        new RewriteRuleSubtreeStream(adaptor, "rule columnNameTypeList");
    RewriteRuleSubtreeStream stream_restrictOrCascade = new RewriteRuleSubtreeStream(adaptor, "rule restrictOrCascade");
    pushMsg("add column statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1064:5: ( (add= KW_ADD |replace= KW_REPLACE ) KW_COLUMNS LPAREN columnNameTypeList RPAREN ( restrictOrCascade )? -> {$add != null}? ^( TOK_ALTERTABLE_ADDCOLS columnNameTypeList ( restrictOrCascade )? ) -> ^( TOK_ALTERTABLE_REPLACECOLS columnNameTypeList ( restrictOrCascade )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1064:7: (add= KW_ADD |replace= KW_REPLACE ) KW_COLUMNS LPAREN columnNameTypeList RPAREN ( restrictOrCascade )?
      {
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1064:7: (add= KW_ADD |replace= KW_REPLACE )
        int alt65 = 2;
        switch (input.LA(1)) {
          case KW_ADD: {
            alt65 = 1;
          }
          break;
          case KW_REPLACE: {
            alt65 = 2;
          }
          break;
          default:
            NoViableAltException nvae = new NoViableAltException("", 65, 0, input);

            throw nvae;
        }

        switch (alt65) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1064:8: add= KW_ADD
          {
            add = (Token) match(input, KW_ADD, FOLLOW_KW_ADD_in_alterStatementSuffixAddCol4451);
            stream_KW_ADD.add(add);
          }
          break;
          case 2:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1064:21: replace= KW_REPLACE
          {
            replace = (Token) match(input, KW_REPLACE, FOLLOW_KW_REPLACE_in_alterStatementSuffixAddCol4457);
            stream_KW_REPLACE.add(replace);
          }
          break;
        }

        KW_COLUMNS245 = (Token) match(input, KW_COLUMNS, FOLLOW_KW_COLUMNS_in_alterStatementSuffixAddCol4460);
        stream_KW_COLUMNS.add(KW_COLUMNS245);

        LPAREN246 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_alterStatementSuffixAddCol4462);
        stream_LPAREN.add(LPAREN246);

        pushFollow(FOLLOW_columnNameTypeList_in_alterStatementSuffixAddCol4464);
        columnNameTypeList247 = columnNameTypeList();

        state._fsp--;

        stream_columnNameTypeList.add(columnNameTypeList247.getTree());

        RPAREN248 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_alterStatementSuffixAddCol4466);
        stream_RPAREN.add(RPAREN248);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1064:85: ( restrictOrCascade )?
        int alt66 = 2;
        switch (input.LA(1)) {
          case KW_CASCADE:
          case KW_RESTRICT: {
            alt66 = 1;
          }
          break;
        }

        switch (alt66) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1064:85: restrictOrCascade
          {
            pushFollow(FOLLOW_restrictOrCascade_in_alterStatementSuffixAddCol4468);
            restrictOrCascade249 = restrictOrCascade();

            state._fsp--;

            stream_restrictOrCascade.add(restrictOrCascade249.getTree());
          }
          break;
        }

        // AST REWRITE
        // elements: columnNameTypeList, restrictOrCascade, restrictOrCascade, columnNameTypeList
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1065:5: -> {$add != null}? ^( TOK_ALTERTABLE_ADDCOLS columnNameTypeList ( restrictOrCascade )? )
        if (add != null) {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1065:24: ^( TOK_ALTERTABLE_ADDCOLS columnNameTypeList ( restrictOrCascade )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERTABLE_ADDCOLS, "TOK_ALTERTABLE_ADDCOLS"), root_1);

            adaptor.addChild(root_1, stream_columnNameTypeList.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1065:68: ( restrictOrCascade )?
            if (stream_restrictOrCascade.hasNext()) {
              adaptor.addChild(root_1, stream_restrictOrCascade.nextTree());
            }
            stream_restrictOrCascade.reset();

            adaptor.addChild(root_0, root_1);
          }
        } else // 1066:5: -> ^( TOK_ALTERTABLE_REPLACECOLS columnNameTypeList ( restrictOrCascade )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1066:24: ^( TOK_ALTERTABLE_REPLACECOLS columnNameTypeList ( restrictOrCascade )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERTABLE_REPLACECOLS, "TOK_ALTERTABLE_REPLACECOLS"), root_1);

            adaptor.addChild(root_1, stream_columnNameTypeList.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1066:72: ( restrictOrCascade )?
            if (stream_restrictOrCascade.hasNext()) {
              adaptor.addChild(root_1, stream_restrictOrCascade.nextTree());
            }
            stream_restrictOrCascade.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixAddCol"

  public static class alterStatementSuffixRenameCol_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixRenameCol"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1069:1: alterStatementSuffixRenameCol : KW_CHANGE ( KW_COLUMN )? oldName= identifier newName= identifier colType ( KW_COMMENT comment= StringLiteral )? ( alterStatementChangeColPosition )? ( restrictOrCascade )? -> ^( TOK_ALTERTABLE_RENAMECOL $oldName $newName colType ( $comment)? ( alterStatementChangeColPosition )? ( restrictOrCascade )? ) ;
  public final HiveParser.alterStatementSuffixRenameCol_return alterStatementSuffixRenameCol()
      throws RecognitionException {
    HiveParser.alterStatementSuffixRenameCol_return retval = new HiveParser.alterStatementSuffixRenameCol_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token comment = null;
    Token KW_CHANGE250 = null;
    Token KW_COLUMN251 = null;
    Token KW_COMMENT253 = null;
    HiveParser_IdentifiersParser.identifier_return oldName = null;

    HiveParser_IdentifiersParser.identifier_return newName = null;

    HiveParser.colType_return colType252 = null;

    HiveParser.alterStatementChangeColPosition_return alterStatementChangeColPosition254 = null;

    HiveParser.restrictOrCascade_return restrictOrCascade255 = null;

    CommonTree comment_tree = null;
    CommonTree KW_CHANGE250_tree = null;
    CommonTree KW_COLUMN251_tree = null;
    CommonTree KW_COMMENT253_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_COMMENT = new RewriteRuleTokenStream(adaptor, "token KW_COMMENT");
    RewriteRuleTokenStream stream_KW_COLUMN = new RewriteRuleTokenStream(adaptor, "token KW_COLUMN");
    RewriteRuleTokenStream stream_KW_CHANGE = new RewriteRuleTokenStream(adaptor, "token KW_CHANGE");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_colType = new RewriteRuleSubtreeStream(adaptor, "rule colType");
    RewriteRuleSubtreeStream stream_alterStatementChangeColPosition =
        new RewriteRuleSubtreeStream(adaptor, "rule alterStatementChangeColPosition");
    RewriteRuleSubtreeStream stream_restrictOrCascade = new RewriteRuleSubtreeStream(adaptor, "rule restrictOrCascade");
    pushMsg("rename column name", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1072:5: ( KW_CHANGE ( KW_COLUMN )? oldName= identifier newName= identifier colType ( KW_COMMENT comment= StringLiteral )? ( alterStatementChangeColPosition )? ( restrictOrCascade )? -> ^( TOK_ALTERTABLE_RENAMECOL $oldName $newName colType ( $comment)? ( alterStatementChangeColPosition )? ( restrictOrCascade )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1072:7: KW_CHANGE ( KW_COLUMN )? oldName= identifier newName= identifier colType ( KW_COMMENT comment= StringLiteral )? ( alterStatementChangeColPosition )? ( restrictOrCascade )?
      {
        KW_CHANGE250 = (Token) match(input, KW_CHANGE, FOLLOW_KW_CHANGE_in_alterStatementSuffixRenameCol4544);
        stream_KW_CHANGE.add(KW_CHANGE250);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1072:17: ( KW_COLUMN )?
        int alt67 = 2;
        switch (input.LA(1)) {
          case KW_COLUMN: {
            alt67 = 1;
          }
          break;
        }

        switch (alt67) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1072:17: KW_COLUMN
          {
            KW_COLUMN251 = (Token) match(input, KW_COLUMN, FOLLOW_KW_COLUMN_in_alterStatementSuffixRenameCol4546);
            stream_KW_COLUMN.add(KW_COLUMN251);
          }
          break;
        }

        pushFollow(FOLLOW_identifier_in_alterStatementSuffixRenameCol4551);
        oldName = identifier();

        state._fsp--;

        stream_identifier.add(oldName.getTree());

        pushFollow(FOLLOW_identifier_in_alterStatementSuffixRenameCol4555);
        newName = identifier();

        state._fsp--;

        stream_identifier.add(newName.getTree());

        pushFollow(FOLLOW_colType_in_alterStatementSuffixRenameCol4557);
        colType252 = colType();

        state._fsp--;

        stream_colType.add(colType252.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1072:74: ( KW_COMMENT comment= StringLiteral )?
        int alt68 = 2;
        switch (input.LA(1)) {
          case KW_COMMENT: {
            alt68 = 1;
          }
          break;
        }

        switch (alt68) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1072:75: KW_COMMENT comment= StringLiteral
          {
            KW_COMMENT253 = (Token) match(input, KW_COMMENT, FOLLOW_KW_COMMENT_in_alterStatementSuffixRenameCol4560);
            stream_KW_COMMENT.add(KW_COMMENT253);

            comment = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_alterStatementSuffixRenameCol4564);
            stream_StringLiteral.add(comment);
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1072:110: ( alterStatementChangeColPosition )?
        int alt69 = 2;
        switch (input.LA(1)) {
          case KW_AFTER:
          case KW_FIRST: {
            alt69 = 1;
          }
          break;
        }

        switch (alt69) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1072:110: alterStatementChangeColPosition
          {
            pushFollow(FOLLOW_alterStatementChangeColPosition_in_alterStatementSuffixRenameCol4568);
            alterStatementChangeColPosition254 = alterStatementChangeColPosition();

            state._fsp--;

            stream_alterStatementChangeColPosition.add(alterStatementChangeColPosition254.getTree());
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1072:143: ( restrictOrCascade )?
        int alt70 = 2;
        switch (input.LA(1)) {
          case KW_CASCADE:
          case KW_RESTRICT: {
            alt70 = 1;
          }
          break;
        }

        switch (alt70) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1072:143: restrictOrCascade
          {
            pushFollow(FOLLOW_restrictOrCascade_in_alterStatementSuffixRenameCol4571);
            restrictOrCascade255 = restrictOrCascade();

            state._fsp--;

            stream_restrictOrCascade.add(restrictOrCascade255.getTree());
          }
          break;
        }

        // AST REWRITE
        // elements: newName, oldName, comment, alterStatementChangeColPosition, colType, restrictOrCascade
        // token labels: comment
        // rule labels: newName, oldName, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_comment = new RewriteRuleTokenStream(adaptor, "token comment", comment);
        RewriteRuleSubtreeStream stream_newName =
            new RewriteRuleSubtreeStream(adaptor, "rule newName", newName != null ? newName.tree : null);
        RewriteRuleSubtreeStream stream_oldName =
            new RewriteRuleSubtreeStream(adaptor, "rule oldName", oldName != null ? oldName.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1073:5: -> ^( TOK_ALTERTABLE_RENAMECOL $oldName $newName colType ( $comment)? ( alterStatementChangeColPosition )? ( restrictOrCascade )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1073:7: ^( TOK_ALTERTABLE_RENAMECOL $oldName $newName colType ( $comment)? ( alterStatementChangeColPosition )? ( restrictOrCascade )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERTABLE_RENAMECOL, "TOK_ALTERTABLE_RENAMECOL"), root_1);

            adaptor.addChild(root_1, stream_oldName.nextTree());

            adaptor.addChild(root_1, stream_newName.nextTree());

            adaptor.addChild(root_1, stream_colType.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1073:61: ( $comment)?
            if (stream_comment.hasNext()) {
              adaptor.addChild(root_1, stream_comment.nextNode());
            }
            stream_comment.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1073:70: ( alterStatementChangeColPosition )?
            if (stream_alterStatementChangeColPosition.hasNext()) {
              adaptor.addChild(root_1, stream_alterStatementChangeColPosition.nextTree());
            }
            stream_alterStatementChangeColPosition.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1073:103: ( restrictOrCascade )?
            if (stream_restrictOrCascade.hasNext()) {
              adaptor.addChild(root_1, stream_restrictOrCascade.nextTree());
            }
            stream_restrictOrCascade.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixRenameCol"

  public static class alterStatementSuffixUpdateStatsCol_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixUpdateStatsCol"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1076:1: alterStatementSuffixUpdateStatsCol : KW_UPDATE KW_STATISTICS KW_FOR ( KW_COLUMN )? colName= identifier KW_SET tableProperties ( KW_COMMENT comment= StringLiteral )? -> ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? ) ;
  public final HiveParser.alterStatementSuffixUpdateStatsCol_return alterStatementSuffixUpdateStatsCol()
      throws RecognitionException {
    HiveParser.alterStatementSuffixUpdateStatsCol_return retval =
        new HiveParser.alterStatementSuffixUpdateStatsCol_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token comment = null;
    Token KW_UPDATE256 = null;
    Token KW_STATISTICS257 = null;
    Token KW_FOR258 = null;
    Token KW_COLUMN259 = null;
    Token KW_SET260 = null;
    Token KW_COMMENT262 = null;
    HiveParser_IdentifiersParser.identifier_return colName = null;

    HiveParser.tableProperties_return tableProperties261 = null;

    CommonTree comment_tree = null;
    CommonTree KW_UPDATE256_tree = null;
    CommonTree KW_STATISTICS257_tree = null;
    CommonTree KW_FOR258_tree = null;
    CommonTree KW_COLUMN259_tree = null;
    CommonTree KW_SET260_tree = null;
    CommonTree KW_COMMENT262_tree = null;
    RewriteRuleTokenStream stream_KW_STATISTICS = new RewriteRuleTokenStream(adaptor, "token KW_STATISTICS");
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_FOR = new RewriteRuleTokenStream(adaptor, "token KW_FOR");
    RewriteRuleTokenStream stream_KW_UPDATE = new RewriteRuleTokenStream(adaptor, "token KW_UPDATE");
    RewriteRuleTokenStream stream_KW_COMMENT = new RewriteRuleTokenStream(adaptor, "token KW_COMMENT");
    RewriteRuleTokenStream stream_KW_COLUMN = new RewriteRuleTokenStream(adaptor, "token KW_COLUMN");
    RewriteRuleTokenStream stream_KW_SET = new RewriteRuleTokenStream(adaptor, "token KW_SET");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_tableProperties = new RewriteRuleSubtreeStream(adaptor, "rule tableProperties");
    pushMsg("update column statistics", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1079:5: ( KW_UPDATE KW_STATISTICS KW_FOR ( KW_COLUMN )? colName= identifier KW_SET tableProperties ( KW_COMMENT comment= StringLiteral )? -> ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1079:7: KW_UPDATE KW_STATISTICS KW_FOR ( KW_COLUMN )? colName= identifier KW_SET tableProperties ( KW_COMMENT comment= StringLiteral )?
      {
        KW_UPDATE256 = (Token) match(input, KW_UPDATE, FOLLOW_KW_UPDATE_in_alterStatementSuffixUpdateStatsCol4626);
        stream_KW_UPDATE.add(KW_UPDATE256);

        KW_STATISTICS257 =
            (Token) match(input, KW_STATISTICS, FOLLOW_KW_STATISTICS_in_alterStatementSuffixUpdateStatsCol4628);
        stream_KW_STATISTICS.add(KW_STATISTICS257);

        KW_FOR258 = (Token) match(input, KW_FOR, FOLLOW_KW_FOR_in_alterStatementSuffixUpdateStatsCol4630);
        stream_KW_FOR.add(KW_FOR258);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1079:38: ( KW_COLUMN )?
        int alt71 = 2;
        switch (input.LA(1)) {
          case KW_COLUMN: {
            alt71 = 1;
          }
          break;
        }

        switch (alt71) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1079:38: KW_COLUMN
          {
            KW_COLUMN259 = (Token) match(input, KW_COLUMN, FOLLOW_KW_COLUMN_in_alterStatementSuffixUpdateStatsCol4632);
            stream_KW_COLUMN.add(KW_COLUMN259);
          }
          break;
        }

        pushFollow(FOLLOW_identifier_in_alterStatementSuffixUpdateStatsCol4637);
        colName = identifier();

        state._fsp--;

        stream_identifier.add(colName.getTree());

        KW_SET260 = (Token) match(input, KW_SET, FOLLOW_KW_SET_in_alterStatementSuffixUpdateStatsCol4639);
        stream_KW_SET.add(KW_SET260);

        pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixUpdateStatsCol4641);
        tableProperties261 = tableProperties();

        state._fsp--;

        stream_tableProperties.add(tableProperties261.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1079:91: ( KW_COMMENT comment= StringLiteral )?
        int alt72 = 2;
        switch (input.LA(1)) {
          case KW_COMMENT: {
            alt72 = 1;
          }
          break;
        }

        switch (alt72) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1079:92: KW_COMMENT comment= StringLiteral
          {
            KW_COMMENT262 =
                (Token) match(input, KW_COMMENT, FOLLOW_KW_COMMENT_in_alterStatementSuffixUpdateStatsCol4644);
            stream_KW_COMMENT.add(KW_COMMENT262);

            comment =
                (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_alterStatementSuffixUpdateStatsCol4648);
            stream_StringLiteral.add(comment);
          }
          break;
        }

        // AST REWRITE
        // elements: comment, tableProperties, colName
        // token labels: comment
        // rule labels: colName, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_comment = new RewriteRuleTokenStream(adaptor, "token comment", comment);
        RewriteRuleSubtreeStream stream_colName =
            new RewriteRuleSubtreeStream(adaptor, "rule colName", colName != null ? colName.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1080:5: -> ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1080:7: ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERTABLE_UPDATECOLSTATS, "TOK_ALTERTABLE_UPDATECOLSTATS"), root_1);

            adaptor.addChild(root_1, stream_colName.nextTree());

            adaptor.addChild(root_1, stream_tableProperties.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1080:65: ( $comment)?
            if (stream_comment.hasNext()) {
              adaptor.addChild(root_1, stream_comment.nextNode());
            }
            stream_comment.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixUpdateStatsCol"

  public static class alterStatementChangeColPosition_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementChangeColPosition"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1083:1: alterStatementChangeColPosition : (first= KW_FIRST | KW_AFTER afterCol= identifier -> {$first != null}? ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION ) -> ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION $afterCol) );
  public final HiveParser.alterStatementChangeColPosition_return alterStatementChangeColPosition()
      throws RecognitionException {
    HiveParser.alterStatementChangeColPosition_return retval = new HiveParser.alterStatementChangeColPosition_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token first = null;
    Token KW_AFTER263 = null;
    HiveParser_IdentifiersParser.identifier_return afterCol = null;

    CommonTree first_tree = null;
    CommonTree KW_AFTER263_tree = null;
    RewriteRuleTokenStream stream_KW_AFTER = new RewriteRuleTokenStream(adaptor, "token KW_AFTER");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1084:5: (first= KW_FIRST | KW_AFTER afterCol= identifier -> {$first != null}? ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION ) -> ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION $afterCol) )
      int alt73 = 2;
      switch (input.LA(1)) {
        case KW_FIRST: {
          alt73 = 1;
        }
        break;
        case KW_AFTER: {
          alt73 = 2;
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 73, 0, input);

          throw nvae;
      }

      switch (alt73) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1084:7: first= KW_FIRST
        {
          root_0 = (CommonTree) adaptor.nil();

          first = (Token) match(input, KW_FIRST, FOLLOW_KW_FIRST_in_alterStatementChangeColPosition4687);
          first_tree = (CommonTree) adaptor.create(first);
          adaptor.addChild(root_0, first_tree);
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1084:22: KW_AFTER afterCol= identifier
        {
          KW_AFTER263 = (Token) match(input, KW_AFTER, FOLLOW_KW_AFTER_in_alterStatementChangeColPosition4689);
          stream_KW_AFTER.add(KW_AFTER263);

          pushFollow(FOLLOW_identifier_in_alterStatementChangeColPosition4693);
          afterCol = identifier();

          state._fsp--;

          stream_identifier.add(afterCol.getTree());

          // AST REWRITE
          // elements: afterCol
          // token labels:
          // rule labels: afterCol, retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_afterCol =
              new RewriteRuleSubtreeStream(adaptor, "rule afterCol", afterCol != null ? afterCol.tree : null);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1085:5: -> {$first != null}? ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION )
          if (first != null) {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1085:25: ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION,
                      "TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          } else // 1086:5: -> ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION $afterCol)
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1086:8: ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION $afterCol)
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION,
                      "TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION"), root_1);

              adaptor.addChild(root_1, stream_afterCol.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementChangeColPosition"

  public static class alterStatementSuffixAddPartitions_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixAddPartitions"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1089:1: alterStatementSuffixAddPartitions[boolean table] : KW_ADD ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ -> { table }? ^( TOK_ALTERTABLE_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ ) -> ^( TOK_ALTERVIEW_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ ) ;
  public final HiveParser.alterStatementSuffixAddPartitions_return alterStatementSuffixAddPartitions(boolean table)
      throws RecognitionException {
    HiveParser.alterStatementSuffixAddPartitions_return retval =
        new HiveParser.alterStatementSuffixAddPartitions_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_ADD264 = null;
    HiveParser.ifNotExists_return ifNotExists265 = null;

    HiveParser.alterStatementSuffixAddPartitionsElement_return alterStatementSuffixAddPartitionsElement266 = null;

    CommonTree KW_ADD264_tree = null;
    RewriteRuleTokenStream stream_KW_ADD = new RewriteRuleTokenStream(adaptor, "token KW_ADD");
    RewriteRuleSubtreeStream stream_ifNotExists = new RewriteRuleSubtreeStream(adaptor, "rule ifNotExists");
    RewriteRuleSubtreeStream stream_alterStatementSuffixAddPartitionsElement =
        new RewriteRuleSubtreeStream(adaptor, "rule alterStatementSuffixAddPartitionsElement");
    pushMsg("add partition statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1092:5: ( KW_ADD ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ -> { table }? ^( TOK_ALTERTABLE_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ ) -> ^( TOK_ALTERVIEW_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1092:7: KW_ADD ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+
      {
        KW_ADD264 = (Token) match(input, KW_ADD, FOLLOW_KW_ADD_in_alterStatementSuffixAddPartitions4746);
        stream_KW_ADD.add(KW_ADD264);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1092:14: ( ifNotExists )?
        int alt74 = 2;
        switch (input.LA(1)) {
          case KW_IF: {
            alt74 = 1;
          }
          break;
        }

        switch (alt74) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1092:14: ifNotExists
          {
            pushFollow(FOLLOW_ifNotExists_in_alterStatementSuffixAddPartitions4748);
            ifNotExists265 = ifNotExists();

            state._fsp--;

            stream_ifNotExists.add(ifNotExists265.getTree());
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1092:27: ( alterStatementSuffixAddPartitionsElement )+
        int cnt75 = 0;
        loop75:
        do {
          int alt75 = 2;
          switch (input.LA(1)) {
            case KW_PARTITION: {
              alt75 = 1;
            }
            break;
          }

          switch (alt75) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1092:27: alterStatementSuffixAddPartitionsElement
            {
              pushFollow(FOLLOW_alterStatementSuffixAddPartitionsElement_in_alterStatementSuffixAddPartitions4751);
              alterStatementSuffixAddPartitionsElement266 = alterStatementSuffixAddPartitionsElement();

              state._fsp--;

              stream_alterStatementSuffixAddPartitionsElement.add(
                  alterStatementSuffixAddPartitionsElement266.getTree());
            }
            break;

            default:
              if (cnt75 >= 1) {
                break loop75;
              }
              EarlyExitException eee = new EarlyExitException(75, input);
              throw eee;
          }
          cnt75++;
        } while (true);

        // AST REWRITE
        // elements: ifNotExists, ifNotExists, alterStatementSuffixAddPartitionsElement, alterStatementSuffixAddPartitionsElement
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1093:5: -> { table }? ^( TOK_ALTERTABLE_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ )
        if (table) {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1093:19: ^( TOK_ALTERTABLE_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERTABLE_ADDPARTS, "TOK_ALTERTABLE_ADDPARTS"), root_1);

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1093:45: ( ifNotExists )?
            if (stream_ifNotExists.hasNext()) {
              adaptor.addChild(root_1, stream_ifNotExists.nextTree());
            }
            stream_ifNotExists.reset();

            if (!(stream_alterStatementSuffixAddPartitionsElement.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_alterStatementSuffixAddPartitionsElement.hasNext()) {
              adaptor.addChild(root_1, stream_alterStatementSuffixAddPartitionsElement.nextTree());
            }
            stream_alterStatementSuffixAddPartitionsElement.reset();

            adaptor.addChild(root_0, root_1);
          }
        } else // 1094:5: -> ^( TOK_ALTERVIEW_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1094:19: ^( TOK_ALTERVIEW_ADDPARTS ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERVIEW_ADDPARTS, "TOK_ALTERVIEW_ADDPARTS"), root_1);

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1094:44: ( ifNotExists )?
            if (stream_ifNotExists.hasNext()) {
              adaptor.addChild(root_1, stream_ifNotExists.nextTree());
            }
            stream_ifNotExists.reset();

            if (!(stream_alterStatementSuffixAddPartitionsElement.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_alterStatementSuffixAddPartitionsElement.hasNext()) {
              adaptor.addChild(root_1, stream_alterStatementSuffixAddPartitionsElement.nextTree());
            }
            stream_alterStatementSuffixAddPartitionsElement.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixAddPartitions"

  public static class alterStatementSuffixAddPartitionsElement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixAddPartitionsElement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1097:1: alterStatementSuffixAddPartitionsElement : partitionSpec ( partitionFileFormat )? ( partitionSerdeProperties )? ( location )? ;
  public final HiveParser.alterStatementSuffixAddPartitionsElement_return alterStatementSuffixAddPartitionsElement()
      throws RecognitionException {
    HiveParser.alterStatementSuffixAddPartitionsElement_return retval =
        new HiveParser.alterStatementSuffixAddPartitionsElement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec267 = null;

    HiveParser.partitionFileFormat_return partitionFileFormat268 = null;

    HiveParser.partitionSerdeProperties_return partitionSerdeProperties269 = null;

    HiveParser.location_return location270 = null;

    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1098:5: ( partitionSpec ( partitionFileFormat )? ( partitionSerdeProperties )? ( location )? )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1098:7: partitionSpec ( partitionFileFormat )? ( partitionSerdeProperties )? ( location )?
      {
        root_0 = (CommonTree) adaptor.nil();

        pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixAddPartitionsElement4814);
        partitionSpec267 = partitionSpec();

        state._fsp--;

        adaptor.addChild(root_0, partitionSpec267.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1098:21: ( partitionFileFormat )?
        int alt76 = 2;
        switch (input.LA(1)) {
          case KW_FILEFORMAT: {
            alt76 = 1;
          }
          break;
        }

        switch (alt76) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1098:21: partitionFileFormat
          {
            pushFollow(FOLLOW_partitionFileFormat_in_alterStatementSuffixAddPartitionsElement4816);
            partitionFileFormat268 = partitionFileFormat();

            state._fsp--;

            adaptor.addChild(root_0, partitionFileFormat268.getTree());
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1098:42: ( partitionSerdeProperties )?
        int alt77 = 2;
        switch (input.LA(1)) {
          case KW_SERDEPROPERTIES: {
            alt77 = 1;
          }
          break;
        }

        switch (alt77) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1098:42: partitionSerdeProperties
          {
            pushFollow(FOLLOW_partitionSerdeProperties_in_alterStatementSuffixAddPartitionsElement4819);
            partitionSerdeProperties269 = partitionSerdeProperties();

            state._fsp--;

            adaptor.addChild(root_0, partitionSerdeProperties269.getTree());
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1098:68: ( location )?
        int alt78 = 2;
        switch (input.LA(1)) {
          case KW_LOCATION: {
            alt78 = 1;
          }
          break;
        }

        switch (alt78) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1098:68: location
          {
            pushFollow(FOLLOW_location_in_alterStatementSuffixAddPartitionsElement4822);
            location270 = location();

            state._fsp--;

            adaptor.addChild(root_0, location270.getTree());
          }
          break;
        }
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixAddPartitionsElement"

  public static class alterStatementSuffixTouch_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixTouch"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1101:1: alterStatementSuffixTouch : KW_TOUCH ( partitionSpec )* -> ^( TOK_ALTERTABLE_TOUCH ( partitionSpec )* ) ;
  public final HiveParser.alterStatementSuffixTouch_return alterStatementSuffixTouch() throws RecognitionException {
    HiveParser.alterStatementSuffixTouch_return retval = new HiveParser.alterStatementSuffixTouch_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_TOUCH271 = null;
    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec272 = null;

    CommonTree KW_TOUCH271_tree = null;
    RewriteRuleTokenStream stream_KW_TOUCH = new RewriteRuleTokenStream(adaptor, "token KW_TOUCH");
    RewriteRuleSubtreeStream stream_partitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule partitionSpec");
    pushMsg("touch statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1104:5: ( KW_TOUCH ( partitionSpec )* -> ^( TOK_ALTERTABLE_TOUCH ( partitionSpec )* ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1104:7: KW_TOUCH ( partitionSpec )*
      {
        KW_TOUCH271 = (Token) match(input, KW_TOUCH, FOLLOW_KW_TOUCH_in_alterStatementSuffixTouch4850);
        stream_KW_TOUCH.add(KW_TOUCH271);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1104:16: ( partitionSpec )*
        loop79:
        do {
          int alt79 = 2;
          switch (input.LA(1)) {
            case KW_PARTITION: {
              alt79 = 1;
            }
            break;
          }

          switch (alt79) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1104:17: partitionSpec
            {
              pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixTouch4853);
              partitionSpec272 = partitionSpec();

              state._fsp--;

              stream_partitionSpec.add(partitionSpec272.getTree());
            }
            break;

            default:
              break loop79;
          }
        } while (true);

        // AST REWRITE
        // elements: partitionSpec
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1105:5: -> ^( TOK_ALTERTABLE_TOUCH ( partitionSpec )* )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1105:8: ^( TOK_ALTERTABLE_TOUCH ( partitionSpec )* )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERTABLE_TOUCH, "TOK_ALTERTABLE_TOUCH"), root_1);

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1105:31: ( partitionSpec )*
            while (stream_partitionSpec.hasNext()) {
              adaptor.addChild(root_1, stream_partitionSpec.nextTree());
            }
            stream_partitionSpec.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixTouch"

  public static class alterStatementSuffixArchive_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixArchive"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1108:1: alterStatementSuffixArchive : KW_ARCHIVE ( partitionSpec )* -> ^( TOK_ALTERTABLE_ARCHIVE ( partitionSpec )* ) ;
  public final HiveParser.alterStatementSuffixArchive_return alterStatementSuffixArchive() throws RecognitionException {
    HiveParser.alterStatementSuffixArchive_return retval = new HiveParser.alterStatementSuffixArchive_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_ARCHIVE273 = null;
    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec274 = null;

    CommonTree KW_ARCHIVE273_tree = null;
    RewriteRuleTokenStream stream_KW_ARCHIVE = new RewriteRuleTokenStream(adaptor, "token KW_ARCHIVE");
    RewriteRuleSubtreeStream stream_partitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule partitionSpec");
    pushMsg("archive statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1111:5: ( KW_ARCHIVE ( partitionSpec )* -> ^( TOK_ALTERTABLE_ARCHIVE ( partitionSpec )* ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1111:7: KW_ARCHIVE ( partitionSpec )*
      {
        KW_ARCHIVE273 = (Token) match(input, KW_ARCHIVE, FOLLOW_KW_ARCHIVE_in_alterStatementSuffixArchive4897);
        stream_KW_ARCHIVE.add(KW_ARCHIVE273);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1111:18: ( partitionSpec )*
        loop80:
        do {
          int alt80 = 2;
          switch (input.LA(1)) {
            case KW_PARTITION: {
              alt80 = 1;
            }
            break;
          }

          switch (alt80) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1111:19: partitionSpec
            {
              pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixArchive4900);
              partitionSpec274 = partitionSpec();

              state._fsp--;

              stream_partitionSpec.add(partitionSpec274.getTree());
            }
            break;

            default:
              break loop80;
          }
        } while (true);

        // AST REWRITE
        // elements: partitionSpec
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1112:5: -> ^( TOK_ALTERTABLE_ARCHIVE ( partitionSpec )* )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1112:8: ^( TOK_ALTERTABLE_ARCHIVE ( partitionSpec )* )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERTABLE_ARCHIVE, "TOK_ALTERTABLE_ARCHIVE"), root_1);

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1112:33: ( partitionSpec )*
            while (stream_partitionSpec.hasNext()) {
              adaptor.addChild(root_1, stream_partitionSpec.nextTree());
            }
            stream_partitionSpec.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixArchive"

  public static class alterStatementSuffixUnArchive_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixUnArchive"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1115:1: alterStatementSuffixUnArchive : KW_UNARCHIVE ( partitionSpec )* -> ^( TOK_ALTERTABLE_UNARCHIVE ( partitionSpec )* ) ;
  public final HiveParser.alterStatementSuffixUnArchive_return alterStatementSuffixUnArchive()
      throws RecognitionException {
    HiveParser.alterStatementSuffixUnArchive_return retval = new HiveParser.alterStatementSuffixUnArchive_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_UNARCHIVE275 = null;
    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec276 = null;

    CommonTree KW_UNARCHIVE275_tree = null;
    RewriteRuleTokenStream stream_KW_UNARCHIVE = new RewriteRuleTokenStream(adaptor, "token KW_UNARCHIVE");
    RewriteRuleSubtreeStream stream_partitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule partitionSpec");
    pushMsg("unarchive statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1118:5: ( KW_UNARCHIVE ( partitionSpec )* -> ^( TOK_ALTERTABLE_UNARCHIVE ( partitionSpec )* ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1118:7: KW_UNARCHIVE ( partitionSpec )*
      {
        KW_UNARCHIVE275 = (Token) match(input, KW_UNARCHIVE, FOLLOW_KW_UNARCHIVE_in_alterStatementSuffixUnArchive4944);
        stream_KW_UNARCHIVE.add(KW_UNARCHIVE275);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1118:20: ( partitionSpec )*
        loop81:
        do {
          int alt81 = 2;
          switch (input.LA(1)) {
            case KW_PARTITION: {
              alt81 = 1;
            }
            break;
          }

          switch (alt81) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1118:21: partitionSpec
            {
              pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixUnArchive4947);
              partitionSpec276 = partitionSpec();

              state._fsp--;

              stream_partitionSpec.add(partitionSpec276.getTree());
            }
            break;

            default:
              break loop81;
          }
        } while (true);

        // AST REWRITE
        // elements: partitionSpec
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1119:5: -> ^( TOK_ALTERTABLE_UNARCHIVE ( partitionSpec )* )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1119:8: ^( TOK_ALTERTABLE_UNARCHIVE ( partitionSpec )* )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERTABLE_UNARCHIVE, "TOK_ALTERTABLE_UNARCHIVE"), root_1);

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1119:35: ( partitionSpec )*
            while (stream_partitionSpec.hasNext()) {
              adaptor.addChild(root_1, stream_partitionSpec.nextTree());
            }
            stream_partitionSpec.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixUnArchive"

  public static class partitionFileFormat_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "partitionFileFormat"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1122:1: partitionFileFormat : KW_FILEFORMAT fileFormat -> ^( TOK_PARTITIONFILEFORMAT fileFormat ) ;
  public final HiveParser.partitionFileFormat_return partitionFileFormat() throws RecognitionException {
    HiveParser.partitionFileFormat_return retval = new HiveParser.partitionFileFormat_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_FILEFORMAT277 = null;
    HiveParser.fileFormat_return fileFormat278 = null;

    CommonTree KW_FILEFORMAT277_tree = null;
    RewriteRuleTokenStream stream_KW_FILEFORMAT = new RewriteRuleTokenStream(adaptor, "token KW_FILEFORMAT");
    RewriteRuleSubtreeStream stream_fileFormat = new RewriteRuleSubtreeStream(adaptor, "rule fileFormat");
    pushMsg("partition fileformat", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1125:5: ( KW_FILEFORMAT fileFormat -> ^( TOK_PARTITIONFILEFORMAT fileFormat ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1125:7: KW_FILEFORMAT fileFormat
      {
        KW_FILEFORMAT277 = (Token) match(input, KW_FILEFORMAT, FOLLOW_KW_FILEFORMAT_in_partitionFileFormat4991);
        stream_KW_FILEFORMAT.add(KW_FILEFORMAT277);

        pushFollow(FOLLOW_fileFormat_in_partitionFileFormat4993);
        fileFormat278 = fileFormat();

        state._fsp--;

        stream_fileFormat.add(fileFormat278.getTree());

        // AST REWRITE
        // elements: fileFormat
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1125:32: -> ^( TOK_PARTITIONFILEFORMAT fileFormat )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1125:35: ^( TOK_PARTITIONFILEFORMAT fileFormat )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_PARTITIONFILEFORMAT, "TOK_PARTITIONFILEFORMAT"), root_1);

            adaptor.addChild(root_1, stream_fileFormat.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "partitionFileFormat"

  public static class partitionSerdeProperties_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "partitionSerdeProperties"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1128:1: partitionSerdeProperties : KW_SERDEPROPERTIES tableProperties -> ^( TOK_PARTITIONSERDEPROPERTIES tableProperties ) ;
  public final HiveParser.partitionSerdeProperties_return partitionSerdeProperties() throws RecognitionException {
    HiveParser.partitionSerdeProperties_return retval = new HiveParser.partitionSerdeProperties_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_SERDEPROPERTIES279 = null;
    HiveParser.tableProperties_return tableProperties280 = null;

    CommonTree KW_SERDEPROPERTIES279_tree = null;
    RewriteRuleTokenStream stream_KW_SERDEPROPERTIES = new RewriteRuleTokenStream(adaptor, "token KW_SERDEPROPERTIES");
    RewriteRuleSubtreeStream stream_tableProperties = new RewriteRuleSubtreeStream(adaptor, "rule tableProperties");
    pushMsg("partition serdeproperties", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1131:5: ( KW_SERDEPROPERTIES tableProperties -> ^( TOK_PARTITIONSERDEPROPERTIES tableProperties ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1131:7: KW_SERDEPROPERTIES tableProperties
      {
        KW_SERDEPROPERTIES279 =
            (Token) match(input, KW_SERDEPROPERTIES, FOLLOW_KW_SERDEPROPERTIES_in_partitionSerdeProperties5028);
        stream_KW_SERDEPROPERTIES.add(KW_SERDEPROPERTIES279);

        pushFollow(FOLLOW_tableProperties_in_partitionSerdeProperties5030);
        tableProperties280 = tableProperties();

        state._fsp--;

        stream_tableProperties.add(tableProperties280.getTree());

        // AST REWRITE
        // elements: tableProperties
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1131:42: -> ^( TOK_PARTITIONSERDEPROPERTIES tableProperties )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1131:45: ^( TOK_PARTITIONSERDEPROPERTIES tableProperties )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_PARTITIONSERDEPROPERTIES, "TOK_PARTITIONSERDEPROPERTIES"), root_1);

            adaptor.addChild(root_1, stream_tableProperties.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "partitionSerdeProperties"

  public static class alterStatementSuffixDropPartitions_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixDropPartitions"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1134:1: alterStatementSuffixDropPartitions[boolean table] : KW_DROP ( ifExists )? dropPartitionSpec ( COMMA dropPartitionSpec )* ( ignoreProtection )? ( KW_PURGE )? ( replicationClause )? -> { table }? ^( TOK_ALTERTABLE_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( ignoreProtection )? ( KW_PURGE )? ( replicationClause )? ) -> ^( TOK_ALTERVIEW_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( ignoreProtection )? ( replicationClause )? ) ;
  public final HiveParser.alterStatementSuffixDropPartitions_return alterStatementSuffixDropPartitions(boolean table)
      throws RecognitionException {
    HiveParser.alterStatementSuffixDropPartitions_return retval =
        new HiveParser.alterStatementSuffixDropPartitions_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_DROP281 = null;
    Token COMMA284 = null;
    Token KW_PURGE287 = null;
    HiveParser.ifExists_return ifExists282 = null;

    HiveParser_IdentifiersParser.dropPartitionSpec_return dropPartitionSpec283 = null;

    HiveParser_IdentifiersParser.dropPartitionSpec_return dropPartitionSpec285 = null;

    HiveParser.ignoreProtection_return ignoreProtection286 = null;

    HiveParser.replicationClause_return replicationClause288 = null;

    CommonTree KW_DROP281_tree = null;
    CommonTree COMMA284_tree = null;
    CommonTree KW_PURGE287_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleTokenStream stream_KW_DROP = new RewriteRuleTokenStream(adaptor, "token KW_DROP");
    RewriteRuleTokenStream stream_KW_PURGE = new RewriteRuleTokenStream(adaptor, "token KW_PURGE");
    RewriteRuleSubtreeStream stream_dropPartitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule dropPartitionSpec");
    RewriteRuleSubtreeStream stream_ifExists = new RewriteRuleSubtreeStream(adaptor, "rule ifExists");
    RewriteRuleSubtreeStream stream_ignoreProtection = new RewriteRuleSubtreeStream(adaptor, "rule ignoreProtection");
    RewriteRuleSubtreeStream stream_replicationClause = new RewriteRuleSubtreeStream(adaptor, "rule replicationClause");
    pushMsg("drop partition statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:5: ( KW_DROP ( ifExists )? dropPartitionSpec ( COMMA dropPartitionSpec )* ( ignoreProtection )? ( KW_PURGE )? ( replicationClause )? -> { table }? ^( TOK_ALTERTABLE_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( ignoreProtection )? ( KW_PURGE )? ( replicationClause )? ) -> ^( TOK_ALTERVIEW_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( ignoreProtection )? ( replicationClause )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:7: KW_DROP ( ifExists )? dropPartitionSpec ( COMMA dropPartitionSpec )* ( ignoreProtection )? ( KW_PURGE )? ( replicationClause )?
      {
        KW_DROP281 = (Token) match(input, KW_DROP, FOLLOW_KW_DROP_in_alterStatementSuffixDropPartitions5066);
        stream_KW_DROP.add(KW_DROP281);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:15: ( ifExists )?
        int alt82 = 2;
        switch (input.LA(1)) {
          case KW_IF: {
            alt82 = 1;
          }
          break;
        }

        switch (alt82) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:15: ifExists
          {
            pushFollow(FOLLOW_ifExists_in_alterStatementSuffixDropPartitions5068);
            ifExists282 = ifExists();

            state._fsp--;

            stream_ifExists.add(ifExists282.getTree());
          }
          break;
        }

        pushFollow(FOLLOW_dropPartitionSpec_in_alterStatementSuffixDropPartitions5071);
        dropPartitionSpec283 = dropPartitionSpec();

        state._fsp--;

        stream_dropPartitionSpec.add(dropPartitionSpec283.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:43: ( COMMA dropPartitionSpec )*
        loop83:
        do {
          int alt83 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt83 = 1;
            }
            break;
          }

          switch (alt83) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:44: COMMA dropPartitionSpec
            {
              COMMA284 = (Token) match(input, COMMA, FOLLOW_COMMA_in_alterStatementSuffixDropPartitions5074);
              stream_COMMA.add(COMMA284);

              pushFollow(FOLLOW_dropPartitionSpec_in_alterStatementSuffixDropPartitions5076);
              dropPartitionSpec285 = dropPartitionSpec();

              state._fsp--;

              stream_dropPartitionSpec.add(dropPartitionSpec285.getTree());
            }
            break;

            default:
              break loop83;
          }
        } while (true);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:70: ( ignoreProtection )?
        int alt84 = 2;
        switch (input.LA(1)) {
          case KW_IGNORE: {
            alt84 = 1;
          }
          break;
        }

        switch (alt84) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:70: ignoreProtection
          {
            pushFollow(FOLLOW_ignoreProtection_in_alterStatementSuffixDropPartitions5080);
            ignoreProtection286 = ignoreProtection();

            state._fsp--;

            stream_ignoreProtection.add(ignoreProtection286.getTree());
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:88: ( KW_PURGE )?
        int alt85 = 2;
        switch (input.LA(1)) {
          case KW_PURGE: {
            alt85 = 1;
          }
          break;
        }

        switch (alt85) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:88: KW_PURGE
          {
            KW_PURGE287 = (Token) match(input, KW_PURGE, FOLLOW_KW_PURGE_in_alterStatementSuffixDropPartitions5083);
            stream_KW_PURGE.add(KW_PURGE287);
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:98: ( replicationClause )?
        int alt86 = 2;
        switch (input.LA(1)) {
          case KW_FOR: {
            alt86 = 1;
          }
          break;
        }

        switch (alt86) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:98: replicationClause
          {
            pushFollow(FOLLOW_replicationClause_in_alterStatementSuffixDropPartitions5086);
            replicationClause288 = replicationClause();

            state._fsp--;

            stream_replicationClause.add(replicationClause288.getTree());
          }
          break;
        }

        // AST REWRITE
        // elements: replicationClause, ifExists, ignoreProtection, KW_PURGE, dropPartitionSpec, replicationClause, ignoreProtection, dropPartitionSpec, ifExists
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1138:5: -> { table }? ^( TOK_ALTERTABLE_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( ignoreProtection )? ( KW_PURGE )? ( replicationClause )? )
        if (table) {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1138:19: ^( TOK_ALTERTABLE_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( ignoreProtection )? ( KW_PURGE )? ( replicationClause )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERTABLE_DROPPARTS, "TOK_ALTERTABLE_DROPPARTS"), root_1);

            if (!(stream_dropPartitionSpec.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_dropPartitionSpec.hasNext()) {
              adaptor.addChild(root_1, stream_dropPartitionSpec.nextTree());
            }
            stream_dropPartitionSpec.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1138:65: ( ifExists )?
            if (stream_ifExists.hasNext()) {
              adaptor.addChild(root_1, stream_ifExists.nextTree());
            }
            stream_ifExists.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1138:75: ( ignoreProtection )?
            if (stream_ignoreProtection.hasNext()) {
              adaptor.addChild(root_1, stream_ignoreProtection.nextTree());
            }
            stream_ignoreProtection.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1138:93: ( KW_PURGE )?
            if (stream_KW_PURGE.hasNext()) {
              adaptor.addChild(root_1, stream_KW_PURGE.nextNode());
            }
            stream_KW_PURGE.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1138:103: ( replicationClause )?
            if (stream_replicationClause.hasNext()) {
              adaptor.addChild(root_1, stream_replicationClause.nextTree());
            }
            stream_replicationClause.reset();

            adaptor.addChild(root_0, root_1);
          }
        } else // 1139:5: -> ^( TOK_ALTERVIEW_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( ignoreProtection )? ( replicationClause )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1139:19: ^( TOK_ALTERVIEW_DROPPARTS ( dropPartitionSpec )+ ( ifExists )? ( ignoreProtection )? ( replicationClause )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERVIEW_DROPPARTS, "TOK_ALTERVIEW_DROPPARTS"), root_1);

            if (!(stream_dropPartitionSpec.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_dropPartitionSpec.hasNext()) {
              adaptor.addChild(root_1, stream_dropPartitionSpec.nextTree());
            }
            stream_dropPartitionSpec.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1139:64: ( ifExists )?
            if (stream_ifExists.hasNext()) {
              adaptor.addChild(root_1, stream_ifExists.nextTree());
            }
            stream_ifExists.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1139:74: ( ignoreProtection )?
            if (stream_ignoreProtection.hasNext()) {
              adaptor.addChild(root_1, stream_ignoreProtection.nextTree());
            }
            stream_ignoreProtection.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1139:92: ( replicationClause )?
            if (stream_replicationClause.hasNext()) {
              adaptor.addChild(root_1, stream_replicationClause.nextTree());
            }
            stream_replicationClause.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixDropPartitions"

  public static class alterStatementSuffixProperties_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixProperties"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1142:1: alterStatementSuffixProperties : ( KW_SET KW_TBLPROPERTIES tableProperties -> ^( TOK_ALTERTABLE_PROPERTIES tableProperties ) | KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties -> ^( TOK_ALTERTABLE_DROPPROPERTIES tableProperties ( ifExists )? ) );
  public final HiveParser.alterStatementSuffixProperties_return alterStatementSuffixProperties()
      throws RecognitionException {
    HiveParser.alterStatementSuffixProperties_return retval = new HiveParser.alterStatementSuffixProperties_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_SET289 = null;
    Token KW_TBLPROPERTIES290 = null;
    Token KW_UNSET292 = null;
    Token KW_TBLPROPERTIES293 = null;
    HiveParser.tableProperties_return tableProperties291 = null;

    HiveParser.ifExists_return ifExists294 = null;

    HiveParser.tableProperties_return tableProperties295 = null;

    CommonTree KW_SET289_tree = null;
    CommonTree KW_TBLPROPERTIES290_tree = null;
    CommonTree KW_UNSET292_tree = null;
    CommonTree KW_TBLPROPERTIES293_tree = null;
    RewriteRuleTokenStream stream_KW_UNSET = new RewriteRuleTokenStream(adaptor, "token KW_UNSET");
    RewriteRuleTokenStream stream_KW_TBLPROPERTIES = new RewriteRuleTokenStream(adaptor, "token KW_TBLPROPERTIES");
    RewriteRuleTokenStream stream_KW_SET = new RewriteRuleTokenStream(adaptor, "token KW_SET");
    RewriteRuleSubtreeStream stream_tableProperties = new RewriteRuleSubtreeStream(adaptor, "rule tableProperties");
    RewriteRuleSubtreeStream stream_ifExists = new RewriteRuleSubtreeStream(adaptor, "rule ifExists");
    pushMsg("alter properties statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1145:5: ( KW_SET KW_TBLPROPERTIES tableProperties -> ^( TOK_ALTERTABLE_PROPERTIES tableProperties ) | KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties -> ^( TOK_ALTERTABLE_DROPPROPERTIES tableProperties ( ifExists )? ) )
      int alt88 = 2;
      switch (input.LA(1)) {
        case KW_SET: {
          alt88 = 1;
        }
        break;
        case KW_UNSET: {
          alt88 = 2;
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 88, 0, input);

          throw nvae;
      }

      switch (alt88) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1145:7: KW_SET KW_TBLPROPERTIES tableProperties
        {
          KW_SET289 = (Token) match(input, KW_SET, FOLLOW_KW_SET_in_alterStatementSuffixProperties5174);
          stream_KW_SET.add(KW_SET289);

          KW_TBLPROPERTIES290 =
              (Token) match(input, KW_TBLPROPERTIES, FOLLOW_KW_TBLPROPERTIES_in_alterStatementSuffixProperties5176);
          stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES290);

          pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixProperties5178);
          tableProperties291 = tableProperties();

          state._fsp--;

          stream_tableProperties.add(tableProperties291.getTree());

          // AST REWRITE
          // elements: tableProperties
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1146:5: -> ^( TOK_ALTERTABLE_PROPERTIES tableProperties )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1146:8: ^( TOK_ALTERTABLE_PROPERTIES tableProperties )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_ALTERTABLE_PROPERTIES, "TOK_ALTERTABLE_PROPERTIES"), root_1);

              adaptor.addChild(root_1, stream_tableProperties.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1147:7: KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties
        {
          KW_UNSET292 = (Token) match(input, KW_UNSET, FOLLOW_KW_UNSET_in_alterStatementSuffixProperties5198);
          stream_KW_UNSET.add(KW_UNSET292);

          KW_TBLPROPERTIES293 =
              (Token) match(input, KW_TBLPROPERTIES, FOLLOW_KW_TBLPROPERTIES_in_alterStatementSuffixProperties5200);
          stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES293);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1147:33: ( ifExists )?
          int alt87 = 2;
          switch (input.LA(1)) {
            case KW_IF: {
              alt87 = 1;
            }
            break;
          }

          switch (alt87) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1147:33: ifExists
            {
              pushFollow(FOLLOW_ifExists_in_alterStatementSuffixProperties5202);
              ifExists294 = ifExists();

              state._fsp--;

              stream_ifExists.add(ifExists294.getTree());
            }
            break;
          }

          pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixProperties5205);
          tableProperties295 = tableProperties();

          state._fsp--;

          stream_tableProperties.add(tableProperties295.getTree());

          // AST REWRITE
          // elements: tableProperties, ifExists
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1148:5: -> ^( TOK_ALTERTABLE_DROPPROPERTIES tableProperties ( ifExists )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1148:8: ^( TOK_ALTERTABLE_DROPPROPERTIES tableProperties ( ifExists )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_ALTERTABLE_DROPPROPERTIES, "TOK_ALTERTABLE_DROPPROPERTIES"), root_1);

              adaptor.addChild(root_1, stream_tableProperties.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1148:56: ( ifExists )?
              if (stream_ifExists.hasNext()) {
                adaptor.addChild(root_1, stream_ifExists.nextTree());
              }
              stream_ifExists.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixProperties"

  public static class alterViewSuffixProperties_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterViewSuffixProperties"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1151:1: alterViewSuffixProperties : ( KW_SET KW_TBLPROPERTIES tableProperties -> ^( TOK_ALTERVIEW_PROPERTIES tableProperties ) | KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties -> ^( TOK_ALTERVIEW_DROPPROPERTIES tableProperties ( ifExists )? ) );
  public final HiveParser.alterViewSuffixProperties_return alterViewSuffixProperties() throws RecognitionException {
    HiveParser.alterViewSuffixProperties_return retval = new HiveParser.alterViewSuffixProperties_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_SET296 = null;
    Token KW_TBLPROPERTIES297 = null;
    Token KW_UNSET299 = null;
    Token KW_TBLPROPERTIES300 = null;
    HiveParser.tableProperties_return tableProperties298 = null;

    HiveParser.ifExists_return ifExists301 = null;

    HiveParser.tableProperties_return tableProperties302 = null;

    CommonTree KW_SET296_tree = null;
    CommonTree KW_TBLPROPERTIES297_tree = null;
    CommonTree KW_UNSET299_tree = null;
    CommonTree KW_TBLPROPERTIES300_tree = null;
    RewriteRuleTokenStream stream_KW_UNSET = new RewriteRuleTokenStream(adaptor, "token KW_UNSET");
    RewriteRuleTokenStream stream_KW_TBLPROPERTIES = new RewriteRuleTokenStream(adaptor, "token KW_TBLPROPERTIES");
    RewriteRuleTokenStream stream_KW_SET = new RewriteRuleTokenStream(adaptor, "token KW_SET");
    RewriteRuleSubtreeStream stream_tableProperties = new RewriteRuleSubtreeStream(adaptor, "rule tableProperties");
    RewriteRuleSubtreeStream stream_ifExists = new RewriteRuleSubtreeStream(adaptor, "rule ifExists");
    pushMsg("alter view properties statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1154:5: ( KW_SET KW_TBLPROPERTIES tableProperties -> ^( TOK_ALTERVIEW_PROPERTIES tableProperties ) | KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties -> ^( TOK_ALTERVIEW_DROPPROPERTIES tableProperties ( ifExists )? ) )
      int alt90 = 2;
      switch (input.LA(1)) {
        case KW_SET: {
          alt90 = 1;
        }
        break;
        case KW_UNSET: {
          alt90 = 2;
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 90, 0, input);

          throw nvae;
      }

      switch (alt90) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1154:7: KW_SET KW_TBLPROPERTIES tableProperties
        {
          KW_SET296 = (Token) match(input, KW_SET, FOLLOW_KW_SET_in_alterViewSuffixProperties5247);
          stream_KW_SET.add(KW_SET296);

          KW_TBLPROPERTIES297 =
              (Token) match(input, KW_TBLPROPERTIES, FOLLOW_KW_TBLPROPERTIES_in_alterViewSuffixProperties5249);
          stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES297);

          pushFollow(FOLLOW_tableProperties_in_alterViewSuffixProperties5251);
          tableProperties298 = tableProperties();

          state._fsp--;

          stream_tableProperties.add(tableProperties298.getTree());

          // AST REWRITE
          // elements: tableProperties
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1155:5: -> ^( TOK_ALTERVIEW_PROPERTIES tableProperties )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1155:8: ^( TOK_ALTERVIEW_PROPERTIES tableProperties )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_ALTERVIEW_PROPERTIES, "TOK_ALTERVIEW_PROPERTIES"), root_1);

              adaptor.addChild(root_1, stream_tableProperties.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1156:7: KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties
        {
          KW_UNSET299 = (Token) match(input, KW_UNSET, FOLLOW_KW_UNSET_in_alterViewSuffixProperties5271);
          stream_KW_UNSET.add(KW_UNSET299);

          KW_TBLPROPERTIES300 =
              (Token) match(input, KW_TBLPROPERTIES, FOLLOW_KW_TBLPROPERTIES_in_alterViewSuffixProperties5273);
          stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES300);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1156:33: ( ifExists )?
          int alt89 = 2;
          switch (input.LA(1)) {
            case KW_IF: {
              alt89 = 1;
            }
            break;
          }

          switch (alt89) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1156:33: ifExists
            {
              pushFollow(FOLLOW_ifExists_in_alterViewSuffixProperties5275);
              ifExists301 = ifExists();

              state._fsp--;

              stream_ifExists.add(ifExists301.getTree());
            }
            break;
          }

          pushFollow(FOLLOW_tableProperties_in_alterViewSuffixProperties5278);
          tableProperties302 = tableProperties();

          state._fsp--;

          stream_tableProperties.add(tableProperties302.getTree());

          // AST REWRITE
          // elements: tableProperties, ifExists
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1157:5: -> ^( TOK_ALTERVIEW_DROPPROPERTIES tableProperties ( ifExists )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1157:8: ^( TOK_ALTERVIEW_DROPPROPERTIES tableProperties ( ifExists )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_ALTERVIEW_DROPPROPERTIES, "TOK_ALTERVIEW_DROPPROPERTIES"), root_1);

              adaptor.addChild(root_1, stream_tableProperties.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1157:55: ( ifExists )?
              if (stream_ifExists.hasNext()) {
                adaptor.addChild(root_1, stream_ifExists.nextTree());
              }
              stream_ifExists.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterViewSuffixProperties"

  public static class alterStatementSuffixSerdeProperties_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixSerdeProperties"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1160:1: alterStatementSuffixSerdeProperties : ( KW_SET KW_SERDE serdeName= StringLiteral ( KW_WITH KW_SERDEPROPERTIES tableProperties )? -> ^( TOK_ALTERTABLE_SERIALIZER $serdeName ( tableProperties )? ) | KW_SET KW_SERDEPROPERTIES tableProperties -> ^( TOK_ALTERTABLE_SERDEPROPERTIES tableProperties ) );
  public final HiveParser.alterStatementSuffixSerdeProperties_return alterStatementSuffixSerdeProperties()
      throws RecognitionException {
    HiveParser.alterStatementSuffixSerdeProperties_return retval =
        new HiveParser.alterStatementSuffixSerdeProperties_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token serdeName = null;
    Token KW_SET303 = null;
    Token KW_SERDE304 = null;
    Token KW_WITH305 = null;
    Token KW_SERDEPROPERTIES306 = null;
    Token KW_SET308 = null;
    Token KW_SERDEPROPERTIES309 = null;
    HiveParser.tableProperties_return tableProperties307 = null;

    HiveParser.tableProperties_return tableProperties310 = null;

    CommonTree serdeName_tree = null;
    CommonTree KW_SET303_tree = null;
    CommonTree KW_SERDE304_tree = null;
    CommonTree KW_WITH305_tree = null;
    CommonTree KW_SERDEPROPERTIES306_tree = null;
    CommonTree KW_SET308_tree = null;
    CommonTree KW_SERDEPROPERTIES309_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_WITH = new RewriteRuleTokenStream(adaptor, "token KW_WITH");
    RewriteRuleTokenStream stream_KW_SERDEPROPERTIES = new RewriteRuleTokenStream(adaptor, "token KW_SERDEPROPERTIES");
    RewriteRuleTokenStream stream_KW_SERDE = new RewriteRuleTokenStream(adaptor, "token KW_SERDE");
    RewriteRuleTokenStream stream_KW_SET = new RewriteRuleTokenStream(adaptor, "token KW_SET");
    RewriteRuleSubtreeStream stream_tableProperties = new RewriteRuleSubtreeStream(adaptor, "rule tableProperties");
    pushMsg("alter serdes statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1163:5: ( KW_SET KW_SERDE serdeName= StringLiteral ( KW_WITH KW_SERDEPROPERTIES tableProperties )? -> ^( TOK_ALTERTABLE_SERIALIZER $serdeName ( tableProperties )? ) | KW_SET KW_SERDEPROPERTIES tableProperties -> ^( TOK_ALTERTABLE_SERDEPROPERTIES tableProperties ) )
      int alt92 = 2;
      switch (input.LA(1)) {
        case KW_SET: {
          switch (input.LA(2)) {
            case KW_SERDE: {
              alt92 = 1;
            }
            break;
            case KW_SERDEPROPERTIES: {
              alt92 = 2;
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 92, 1, input);

              throw nvae;
          }
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 92, 0, input);

          throw nvae;
      }

      switch (alt92) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1163:7: KW_SET KW_SERDE serdeName= StringLiteral ( KW_WITH KW_SERDEPROPERTIES tableProperties )?
        {
          KW_SET303 = (Token) match(input, KW_SET, FOLLOW_KW_SET_in_alterStatementSuffixSerdeProperties5320);
          stream_KW_SET.add(KW_SET303);

          KW_SERDE304 = (Token) match(input, KW_SERDE, FOLLOW_KW_SERDE_in_alterStatementSuffixSerdeProperties5322);
          stream_KW_SERDE.add(KW_SERDE304);

          serdeName =
              (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_alterStatementSuffixSerdeProperties5326);
          stream_StringLiteral.add(serdeName);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1163:47: ( KW_WITH KW_SERDEPROPERTIES tableProperties )?
          int alt91 = 2;
          switch (input.LA(1)) {
            case KW_WITH: {
              alt91 = 1;
            }
            break;
          }

          switch (alt91) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1163:48: KW_WITH KW_SERDEPROPERTIES tableProperties
            {
              KW_WITH305 = (Token) match(input, KW_WITH, FOLLOW_KW_WITH_in_alterStatementSuffixSerdeProperties5329);
              stream_KW_WITH.add(KW_WITH305);

              KW_SERDEPROPERTIES306 = (Token) match(input, KW_SERDEPROPERTIES,
                  FOLLOW_KW_SERDEPROPERTIES_in_alterStatementSuffixSerdeProperties5331);
              stream_KW_SERDEPROPERTIES.add(KW_SERDEPROPERTIES306);

              pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixSerdeProperties5333);
              tableProperties307 = tableProperties();

              state._fsp--;

              stream_tableProperties.add(tableProperties307.getTree());
            }
            break;
          }

          // AST REWRITE
          // elements: serdeName, tableProperties
          // token labels: serdeName
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleTokenStream stream_serdeName = new RewriteRuleTokenStream(adaptor, "token serdeName", serdeName);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1164:5: -> ^( TOK_ALTERTABLE_SERIALIZER $serdeName ( tableProperties )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1164:8: ^( TOK_ALTERTABLE_SERIALIZER $serdeName ( tableProperties )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_ALTERTABLE_SERIALIZER, "TOK_ALTERTABLE_SERIALIZER"), root_1);

              adaptor.addChild(root_1, stream_serdeName.nextNode());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1164:47: ( tableProperties )?
              if (stream_tableProperties.hasNext()) {
                adaptor.addChild(root_1, stream_tableProperties.nextTree());
              }
              stream_tableProperties.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1165:7: KW_SET KW_SERDEPROPERTIES tableProperties
        {
          KW_SET308 = (Token) match(input, KW_SET, FOLLOW_KW_SET_in_alterStatementSuffixSerdeProperties5359);
          stream_KW_SET.add(KW_SET308);

          KW_SERDEPROPERTIES309 = (Token) match(input, KW_SERDEPROPERTIES,
              FOLLOW_KW_SERDEPROPERTIES_in_alterStatementSuffixSerdeProperties5361);
          stream_KW_SERDEPROPERTIES.add(KW_SERDEPROPERTIES309);

          pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixSerdeProperties5363);
          tableProperties310 = tableProperties();

          state._fsp--;

          stream_tableProperties.add(tableProperties310.getTree());

          // AST REWRITE
          // elements: tableProperties
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1166:5: -> ^( TOK_ALTERTABLE_SERDEPROPERTIES tableProperties )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1166:8: ^( TOK_ALTERTABLE_SERDEPROPERTIES tableProperties )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_ALTERTABLE_SERDEPROPERTIES, "TOK_ALTERTABLE_SERDEPROPERTIES"),
                  root_1);

              adaptor.addChild(root_1, stream_tableProperties.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixSerdeProperties"

  public static class tablePartitionPrefix_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "tablePartitionPrefix"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1169:1: tablePartitionPrefix : tableName ( partitionSpec )? -> ^( TOK_TABLE_PARTITION tableName ( partitionSpec )? ) ;
  public final HiveParser.tablePartitionPrefix_return tablePartitionPrefix() throws RecognitionException {
    HiveParser.tablePartitionPrefix_return retval = new HiveParser.tablePartitionPrefix_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser_FromClauseParser.tableName_return tableName311 = null;

    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec312 = null;

    RewriteRuleSubtreeStream stream_partitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule partitionSpec");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    pushMsg("table partition prefix", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1172:3: ( tableName ( partitionSpec )? -> ^( TOK_TABLE_PARTITION tableName ( partitionSpec )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1172:5: tableName ( partitionSpec )?
      {
        pushFollow(FOLLOW_tableName_in_tablePartitionPrefix5400);
        tableName311 = tableName();

        state._fsp--;

        stream_tableName.add(tableName311.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1172:15: ( partitionSpec )?
        int alt93 = 2;
        switch (input.LA(1)) {
          case KW_PARTITION: {
            alt93 = 1;
          }
          break;
        }

        switch (alt93) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1172:15: partitionSpec
          {
            pushFollow(FOLLOW_partitionSpec_in_tablePartitionPrefix5402);
            partitionSpec312 = partitionSpec();

            state._fsp--;

            stream_partitionSpec.add(partitionSpec312.getTree());
          }
          break;
        }

        // AST REWRITE
        // elements: tableName, partitionSpec
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1173:3: -> ^( TOK_TABLE_PARTITION tableName ( partitionSpec )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1173:5: ^( TOK_TABLE_PARTITION tableName ( partitionSpec )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABLE_PARTITION, "TOK_TABLE_PARTITION"),
                    root_1);

            adaptor.addChild(root_1, stream_tableName.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1173:37: ( partitionSpec )?
            if (stream_partitionSpec.hasNext()) {
              adaptor.addChild(root_1, stream_partitionSpec.nextTree());
            }
            stream_partitionSpec.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "tablePartitionPrefix"

  public static class alterStatementSuffixFileFormat_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixFileFormat"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1176:1: alterStatementSuffixFileFormat : KW_SET KW_FILEFORMAT fileFormat -> ^( TOK_ALTERTABLE_FILEFORMAT fileFormat ) ;
  public final HiveParser.alterStatementSuffixFileFormat_return alterStatementSuffixFileFormat()
      throws RecognitionException {
    HiveParser.alterStatementSuffixFileFormat_return retval = new HiveParser.alterStatementSuffixFileFormat_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_SET313 = null;
    Token KW_FILEFORMAT314 = null;
    HiveParser.fileFormat_return fileFormat315 = null;

    CommonTree KW_SET313_tree = null;
    CommonTree KW_FILEFORMAT314_tree = null;
    RewriteRuleTokenStream stream_KW_FILEFORMAT = new RewriteRuleTokenStream(adaptor, "token KW_FILEFORMAT");
    RewriteRuleTokenStream stream_KW_SET = new RewriteRuleTokenStream(adaptor, "token KW_SET");
    RewriteRuleSubtreeStream stream_fileFormat = new RewriteRuleSubtreeStream(adaptor, "rule fileFormat");
    pushMsg("alter fileformat statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1179:2: ( KW_SET KW_FILEFORMAT fileFormat -> ^( TOK_ALTERTABLE_FILEFORMAT fileFormat ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1179:4: KW_SET KW_FILEFORMAT fileFormat
      {
        KW_SET313 = (Token) match(input, KW_SET, FOLLOW_KW_SET_in_alterStatementSuffixFileFormat5437);
        stream_KW_SET.add(KW_SET313);

        KW_FILEFORMAT314 =
            (Token) match(input, KW_FILEFORMAT, FOLLOW_KW_FILEFORMAT_in_alterStatementSuffixFileFormat5439);
        stream_KW_FILEFORMAT.add(KW_FILEFORMAT314);

        pushFollow(FOLLOW_fileFormat_in_alterStatementSuffixFileFormat5441);
        fileFormat315 = fileFormat();

        state._fsp--;

        stream_fileFormat.add(fileFormat315.getTree());

        // AST REWRITE
        // elements: fileFormat
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1180:2: -> ^( TOK_ALTERTABLE_FILEFORMAT fileFormat )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1180:5: ^( TOK_ALTERTABLE_FILEFORMAT fileFormat )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERTABLE_FILEFORMAT, "TOK_ALTERTABLE_FILEFORMAT"), root_1);

            adaptor.addChild(root_1, stream_fileFormat.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixFileFormat"

  public static class alterStatementSuffixClusterbySortby_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixClusterbySortby"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1183:1: alterStatementSuffixClusterbySortby : ( KW_NOT KW_CLUSTERED -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_CLUSTERED ) | KW_NOT KW_SORTED -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_SORTED ) | tableBuckets -> ^( TOK_ALTERTABLE_CLUSTER_SORT tableBuckets ) );
  public final HiveParser.alterStatementSuffixClusterbySortby_return alterStatementSuffixClusterbySortby()
      throws RecognitionException {
    HiveParser.alterStatementSuffixClusterbySortby_return retval =
        new HiveParser.alterStatementSuffixClusterbySortby_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_NOT316 = null;
    Token KW_CLUSTERED317 = null;
    Token KW_NOT318 = null;
    Token KW_SORTED319 = null;
    HiveParser.tableBuckets_return tableBuckets320 = null;

    CommonTree KW_NOT316_tree = null;
    CommonTree KW_CLUSTERED317_tree = null;
    CommonTree KW_NOT318_tree = null;
    CommonTree KW_SORTED319_tree = null;
    RewriteRuleTokenStream stream_KW_NOT = new RewriteRuleTokenStream(adaptor, "token KW_NOT");
    RewriteRuleTokenStream stream_KW_SORTED = new RewriteRuleTokenStream(adaptor, "token KW_SORTED");
    RewriteRuleTokenStream stream_KW_CLUSTERED = new RewriteRuleTokenStream(adaptor, "token KW_CLUSTERED");
    RewriteRuleSubtreeStream stream_tableBuckets = new RewriteRuleSubtreeStream(adaptor, "rule tableBuckets");
    pushMsg("alter partition cluster by sort by statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1186:3: ( KW_NOT KW_CLUSTERED -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_CLUSTERED ) | KW_NOT KW_SORTED -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_SORTED ) | tableBuckets -> ^( TOK_ALTERTABLE_CLUSTER_SORT tableBuckets ) )
      int alt94 = 3;
      switch (input.LA(1)) {
        case KW_NOT: {
          switch (input.LA(2)) {
            case KW_CLUSTERED: {
              alt94 = 1;
            }
            break;
            case KW_SORTED: {
              alt94 = 2;
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 94, 1, input);

              throw nvae;
          }
        }
        break;
        case KW_CLUSTERED: {
          alt94 = 3;
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 94, 0, input);

          throw nvae;
      }

      switch (alt94) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1186:5: KW_NOT KW_CLUSTERED
        {
          KW_NOT316 = (Token) match(input, KW_NOT, FOLLOW_KW_NOT_in_alterStatementSuffixClusterbySortby5472);
          stream_KW_NOT.add(KW_NOT316);

          KW_CLUSTERED317 =
              (Token) match(input, KW_CLUSTERED, FOLLOW_KW_CLUSTERED_in_alterStatementSuffixClusterbySortby5474);
          stream_KW_CLUSTERED.add(KW_CLUSTERED317);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1186:25: -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_CLUSTERED )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1186:28: ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_CLUSTERED )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_ALTERTABLE_CLUSTER_SORT, "TOK_ALTERTABLE_CLUSTER_SORT"), root_1);

              adaptor.addChild(root_1, (CommonTree) adaptor.create(TOK_NOT_CLUSTERED, "TOK_NOT_CLUSTERED"));

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1187:5: KW_NOT KW_SORTED
        {
          KW_NOT318 = (Token) match(input, KW_NOT, FOLLOW_KW_NOT_in_alterStatementSuffixClusterbySortby5488);
          stream_KW_NOT.add(KW_NOT318);

          KW_SORTED319 = (Token) match(input, KW_SORTED, FOLLOW_KW_SORTED_in_alterStatementSuffixClusterbySortby5490);
          stream_KW_SORTED.add(KW_SORTED319);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1187:22: -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_SORTED )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1187:25: ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_SORTED )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_ALTERTABLE_CLUSTER_SORT, "TOK_ALTERTABLE_CLUSTER_SORT"), root_1);

              adaptor.addChild(root_1, (CommonTree) adaptor.create(TOK_NOT_SORTED, "TOK_NOT_SORTED"));

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 3:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1188:5: tableBuckets
        {
          pushFollow(FOLLOW_tableBuckets_in_alterStatementSuffixClusterbySortby5504);
          tableBuckets320 = tableBuckets();

          state._fsp--;

          stream_tableBuckets.add(tableBuckets320.getTree());

          // AST REWRITE
          // elements: tableBuckets
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1188:18: -> ^( TOK_ALTERTABLE_CLUSTER_SORT tableBuckets )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1188:21: ^( TOK_ALTERTABLE_CLUSTER_SORT tableBuckets )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_ALTERTABLE_CLUSTER_SORT, "TOK_ALTERTABLE_CLUSTER_SORT"), root_1);

              adaptor.addChild(root_1, stream_tableBuckets.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixClusterbySortby"

  public static class alterTblPartitionStatementSuffixSkewedLocation_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterTblPartitionStatementSuffixSkewedLocation"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1191:1: alterTblPartitionStatementSuffixSkewedLocation : KW_SET KW_SKEWED KW_LOCATION skewedLocations -> ^( TOK_ALTERTABLE_SKEWED_LOCATION skewedLocations ) ;
  public final HiveParser.alterTblPartitionStatementSuffixSkewedLocation_return alterTblPartitionStatementSuffixSkewedLocation()
      throws RecognitionException {
    HiveParser.alterTblPartitionStatementSuffixSkewedLocation_return retval =
        new HiveParser.alterTblPartitionStatementSuffixSkewedLocation_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_SET321 = null;
    Token KW_SKEWED322 = null;
    Token KW_LOCATION323 = null;
    HiveParser.skewedLocations_return skewedLocations324 = null;

    CommonTree KW_SET321_tree = null;
    CommonTree KW_SKEWED322_tree = null;
    CommonTree KW_LOCATION323_tree = null;
    RewriteRuleTokenStream stream_KW_LOCATION = new RewriteRuleTokenStream(adaptor, "token KW_LOCATION");
    RewriteRuleTokenStream stream_KW_SKEWED = new RewriteRuleTokenStream(adaptor, "token KW_SKEWED");
    RewriteRuleTokenStream stream_KW_SET = new RewriteRuleTokenStream(adaptor, "token KW_SET");
    RewriteRuleSubtreeStream stream_skewedLocations = new RewriteRuleSubtreeStream(adaptor, "rule skewedLocations");
    pushMsg("alter partition skewed location", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1194:3: ( KW_SET KW_SKEWED KW_LOCATION skewedLocations -> ^( TOK_ALTERTABLE_SKEWED_LOCATION skewedLocations ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1194:5: KW_SET KW_SKEWED KW_LOCATION skewedLocations
      {
        KW_SET321 = (Token) match(input, KW_SET, FOLLOW_KW_SET_in_alterTblPartitionStatementSuffixSkewedLocation5535);
        stream_KW_SET.add(KW_SET321);

        KW_SKEWED322 =
            (Token) match(input, KW_SKEWED, FOLLOW_KW_SKEWED_in_alterTblPartitionStatementSuffixSkewedLocation5537);
        stream_KW_SKEWED.add(KW_SKEWED322);

        KW_LOCATION323 =
            (Token) match(input, KW_LOCATION, FOLLOW_KW_LOCATION_in_alterTblPartitionStatementSuffixSkewedLocation5539);
        stream_KW_LOCATION.add(KW_LOCATION323);

        pushFollow(FOLLOW_skewedLocations_in_alterTblPartitionStatementSuffixSkewedLocation5541);
        skewedLocations324 = skewedLocations();

        state._fsp--;

        stream_skewedLocations.add(skewedLocations324.getTree());

        // AST REWRITE
        // elements: skewedLocations
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1195:3: -> ^( TOK_ALTERTABLE_SKEWED_LOCATION skewedLocations )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1195:6: ^( TOK_ALTERTABLE_SKEWED_LOCATION skewedLocations )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERTABLE_SKEWED_LOCATION, "TOK_ALTERTABLE_SKEWED_LOCATION"), root_1);

            adaptor.addChild(root_1, stream_skewedLocations.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterTblPartitionStatementSuffixSkewedLocation"

  public static class skewedLocations_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "skewedLocations"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1198:1: skewedLocations : LPAREN skewedLocationsList RPAREN -> ^( TOK_SKEWED_LOCATIONS skewedLocationsList ) ;
  public final HiveParser.skewedLocations_return skewedLocations() throws RecognitionException {
    HiveParser.skewedLocations_return retval = new HiveParser.skewedLocations_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token LPAREN325 = null;
    Token RPAREN327 = null;
    HiveParser.skewedLocationsList_return skewedLocationsList326 = null;

    CommonTree LPAREN325_tree = null;
    CommonTree RPAREN327_tree = null;
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleSubtreeStream stream_skewedLocationsList =
        new RewriteRuleSubtreeStream(adaptor, "rule skewedLocationsList");
    pushMsg("skewed locations", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1201:5: ( LPAREN skewedLocationsList RPAREN -> ^( TOK_SKEWED_LOCATIONS skewedLocationsList ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1202:7: LPAREN skewedLocationsList RPAREN
      {
        LPAREN325 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_skewedLocations5584);
        stream_LPAREN.add(LPAREN325);

        pushFollow(FOLLOW_skewedLocationsList_in_skewedLocations5586);
        skewedLocationsList326 = skewedLocationsList();

        state._fsp--;

        stream_skewedLocationsList.add(skewedLocationsList326.getTree());

        RPAREN327 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_skewedLocations5588);
        stream_RPAREN.add(RPAREN327);

        // AST REWRITE
        // elements: skewedLocationsList
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1202:41: -> ^( TOK_SKEWED_LOCATIONS skewedLocationsList )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1202:44: ^( TOK_SKEWED_LOCATIONS skewedLocationsList )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_SKEWED_LOCATIONS, "TOK_SKEWED_LOCATIONS"), root_1);

            adaptor.addChild(root_1, stream_skewedLocationsList.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "skewedLocations"

  public static class skewedLocationsList_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "skewedLocationsList"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1205:1: skewedLocationsList : skewedLocationMap ( COMMA skewedLocationMap )* -> ^( TOK_SKEWED_LOCATION_LIST ( skewedLocationMap )+ ) ;
  public final HiveParser.skewedLocationsList_return skewedLocationsList() throws RecognitionException {
    HiveParser.skewedLocationsList_return retval = new HiveParser.skewedLocationsList_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token COMMA329 = null;
    HiveParser.skewedLocationMap_return skewedLocationMap328 = null;

    HiveParser.skewedLocationMap_return skewedLocationMap330 = null;

    CommonTree COMMA329_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleSubtreeStream stream_skewedLocationMap = new RewriteRuleSubtreeStream(adaptor, "rule skewedLocationMap");
    pushMsg("skewed locations list", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1208:5: ( skewedLocationMap ( COMMA skewedLocationMap )* -> ^( TOK_SKEWED_LOCATION_LIST ( skewedLocationMap )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1209:7: skewedLocationMap ( COMMA skewedLocationMap )*
      {
        pushFollow(FOLLOW_skewedLocationMap_in_skewedLocationsList5629);
        skewedLocationMap328 = skewedLocationMap();

        state._fsp--;

        stream_skewedLocationMap.add(skewedLocationMap328.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1209:25: ( COMMA skewedLocationMap )*
        loop95:
        do {
          int alt95 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt95 = 1;
            }
            break;
          }

          switch (alt95) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1209:26: COMMA skewedLocationMap
            {
              COMMA329 = (Token) match(input, COMMA, FOLLOW_COMMA_in_skewedLocationsList5632);
              stream_COMMA.add(COMMA329);

              pushFollow(FOLLOW_skewedLocationMap_in_skewedLocationsList5634);
              skewedLocationMap330 = skewedLocationMap();

              state._fsp--;

              stream_skewedLocationMap.add(skewedLocationMap330.getTree());
            }
            break;

            default:
              break loop95;
          }
        } while (true);

        // AST REWRITE
        // elements: skewedLocationMap
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1209:52: -> ^( TOK_SKEWED_LOCATION_LIST ( skewedLocationMap )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1209:55: ^( TOK_SKEWED_LOCATION_LIST ( skewedLocationMap )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_SKEWED_LOCATION_LIST, "TOK_SKEWED_LOCATION_LIST"), root_1);

            if (!(stream_skewedLocationMap.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_skewedLocationMap.hasNext()) {
              adaptor.addChild(root_1, stream_skewedLocationMap.nextTree());
            }
            stream_skewedLocationMap.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "skewedLocationsList"

  public static class skewedLocationMap_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "skewedLocationMap"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1212:1: skewedLocationMap : key= skewedValueLocationElement EQUAL value= StringLiteral -> ^( TOK_SKEWED_LOCATION_MAP $key $value) ;
  public final HiveParser.skewedLocationMap_return skewedLocationMap() throws RecognitionException {
    HiveParser.skewedLocationMap_return retval = new HiveParser.skewedLocationMap_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token value = null;
    Token EQUAL331 = null;
    HiveParser.skewedValueLocationElement_return key = null;

    CommonTree value_tree = null;
    CommonTree EQUAL331_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_EQUAL = new RewriteRuleTokenStream(adaptor, "token EQUAL");
    RewriteRuleSubtreeStream stream_skewedValueLocationElement =
        new RewriteRuleSubtreeStream(adaptor, "rule skewedValueLocationElement");
    pushMsg("specifying skewed location map", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1215:5: (key= skewedValueLocationElement EQUAL value= StringLiteral -> ^( TOK_SKEWED_LOCATION_MAP $key $value) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1216:7: key= skewedValueLocationElement EQUAL value= StringLiteral
      {
        pushFollow(FOLLOW_skewedValueLocationElement_in_skewedLocationMap5680);
        key = skewedValueLocationElement();

        state._fsp--;

        stream_skewedValueLocationElement.add(key.getTree());

        EQUAL331 = (Token) match(input, EQUAL, FOLLOW_EQUAL_in_skewedLocationMap5682);
        stream_EQUAL.add(EQUAL331);

        value = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_skewedLocationMap5686);
        stream_StringLiteral.add(value);

        // AST REWRITE
        // elements: key, value
        // token labels: value
        // rule labels: key, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_value = new RewriteRuleTokenStream(adaptor, "token value", value);
        RewriteRuleSubtreeStream stream_key =
            new RewriteRuleSubtreeStream(adaptor, "rule key", key != null ? key.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1216:64: -> ^( TOK_SKEWED_LOCATION_MAP $key $value)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1216:67: ^( TOK_SKEWED_LOCATION_MAP $key $value)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_SKEWED_LOCATION_MAP, "TOK_SKEWED_LOCATION_MAP"), root_1);

            adaptor.addChild(root_1, stream_key.nextTree());

            adaptor.addChild(root_1, stream_value.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "skewedLocationMap"

  public static class alterStatementSuffixLocation_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixLocation"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1219:1: alterStatementSuffixLocation : KW_SET location -> location ;
  public final HiveParser.alterStatementSuffixLocation_return alterStatementSuffixLocation()
      throws RecognitionException {
    HiveParser.alterStatementSuffixLocation_return retval = new HiveParser.alterStatementSuffixLocation_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_SET332 = null;
    HiveParser.location_return location333 = null;

    CommonTree KW_SET332_tree = null;
    RewriteRuleTokenStream stream_KW_SET = new RewriteRuleTokenStream(adaptor, "token KW_SET");
    RewriteRuleSubtreeStream stream_location = new RewriteRuleSubtreeStream(adaptor, "rule location");
    pushMsg("alter location", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1222:3: ( KW_SET location -> location )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1222:5: KW_SET location
      {
        KW_SET332 = (Token) match(input, KW_SET, FOLLOW_KW_SET_in_alterStatementSuffixLocation5723);
        stream_KW_SET.add(KW_SET332);

        pushFollow(FOLLOW_location_in_alterStatementSuffixLocation5725);
        location333 = location();

        state._fsp--;

        stream_location.add(location333.getTree());

        // AST REWRITE
        // elements: location
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1222:21: -> location
        {
          adaptor.addChild(root_0, stream_location.nextTree());
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixLocation"

  public static class alterStatementSuffixSkewedby_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixSkewedby"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1226:1: alterStatementSuffixSkewedby : ( tableSkewed -> ^( TOK_ALTERTABLE_SKEWED tableSkewed ) | KW_NOT KW_SKEWED -> ^( TOK_ALTERTABLE_SKEWED ) | KW_NOT storedAsDirs -> ^( TOK_ALTERTABLE_SKEWED storedAsDirs ) );
  public final HiveParser.alterStatementSuffixSkewedby_return alterStatementSuffixSkewedby()
      throws RecognitionException {
    HiveParser.alterStatementSuffixSkewedby_return retval = new HiveParser.alterStatementSuffixSkewedby_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_NOT335 = null;
    Token KW_SKEWED336 = null;
    Token KW_NOT337 = null;
    HiveParser.tableSkewed_return tableSkewed334 = null;

    HiveParser.storedAsDirs_return storedAsDirs338 = null;

    CommonTree KW_NOT335_tree = null;
    CommonTree KW_SKEWED336_tree = null;
    CommonTree KW_NOT337_tree = null;
    RewriteRuleTokenStream stream_KW_NOT = new RewriteRuleTokenStream(adaptor, "token KW_NOT");
    RewriteRuleTokenStream stream_KW_SKEWED = new RewriteRuleTokenStream(adaptor, "token KW_SKEWED");
    RewriteRuleSubtreeStream stream_tableSkewed = new RewriteRuleSubtreeStream(adaptor, "rule tableSkewed");
    RewriteRuleSubtreeStream stream_storedAsDirs = new RewriteRuleSubtreeStream(adaptor, "rule storedAsDirs");
    pushMsg("alter skewed by statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1229:2: ( tableSkewed -> ^( TOK_ALTERTABLE_SKEWED tableSkewed ) | KW_NOT KW_SKEWED -> ^( TOK_ALTERTABLE_SKEWED ) | KW_NOT storedAsDirs -> ^( TOK_ALTERTABLE_SKEWED storedAsDirs ) )
      int alt96 = 3;
      switch (input.LA(1)) {
        case KW_SKEWED: {
          alt96 = 1;
        }
        break;
        case KW_NOT: {
          switch (input.LA(2)) {
            case KW_SKEWED: {
              alt96 = 2;
            }
            break;
            case KW_STORED: {
              alt96 = 3;
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 96, 2, input);

              throw nvae;
          }
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 96, 0, input);

          throw nvae;
      }

      switch (alt96) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1229:4: tableSkewed
        {
          pushFollow(FOLLOW_tableSkewed_in_alterStatementSuffixSkewedby5752);
          tableSkewed334 = tableSkewed();

          state._fsp--;

          stream_tableSkewed.add(tableSkewed334.getTree());

          // AST REWRITE
          // elements: tableSkewed
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1230:2: -> ^( TOK_ALTERTABLE_SKEWED tableSkewed )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1230:4: ^( TOK_ALTERTABLE_SKEWED tableSkewed )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_ALTERTABLE_SKEWED, "TOK_ALTERTABLE_SKEWED"), root_1);

              adaptor.addChild(root_1, stream_tableSkewed.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1232:3: KW_NOT KW_SKEWED
        {
          KW_NOT335 = (Token) match(input, KW_NOT, FOLLOW_KW_NOT_in_alterStatementSuffixSkewedby5767);
          stream_KW_NOT.add(KW_NOT335);

          KW_SKEWED336 = (Token) match(input, KW_SKEWED, FOLLOW_KW_SKEWED_in_alterStatementSuffixSkewedby5769);
          stream_KW_SKEWED.add(KW_SKEWED336);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1233:2: -> ^( TOK_ALTERTABLE_SKEWED )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1233:4: ^( TOK_ALTERTABLE_SKEWED )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_ALTERTABLE_SKEWED, "TOK_ALTERTABLE_SKEWED"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 3:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1235:3: KW_NOT storedAsDirs
        {
          KW_NOT337 = (Token) match(input, KW_NOT, FOLLOW_KW_NOT_in_alterStatementSuffixSkewedby5782);
          stream_KW_NOT.add(KW_NOT337);

          pushFollow(FOLLOW_storedAsDirs_in_alterStatementSuffixSkewedby5784);
          storedAsDirs338 = storedAsDirs();

          state._fsp--;

          stream_storedAsDirs.add(storedAsDirs338.getTree());

          // AST REWRITE
          // elements: storedAsDirs
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1236:2: -> ^( TOK_ALTERTABLE_SKEWED storedAsDirs )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1236:4: ^( TOK_ALTERTABLE_SKEWED storedAsDirs )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_ALTERTABLE_SKEWED, "TOK_ALTERTABLE_SKEWED"), root_1);

              adaptor.addChild(root_1, stream_storedAsDirs.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixSkewedby"

  public static class alterStatementSuffixExchangePartition_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixExchangePartition"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1239:1: alterStatementSuffixExchangePartition : KW_EXCHANGE partitionSpec KW_WITH KW_TABLE exchangename= tableName -> ^( TOK_ALTERTABLE_EXCHANGEPARTITION partitionSpec $exchangename) ;
  public final HiveParser.alterStatementSuffixExchangePartition_return alterStatementSuffixExchangePartition()
      throws RecognitionException {
    HiveParser.alterStatementSuffixExchangePartition_return retval =
        new HiveParser.alterStatementSuffixExchangePartition_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_EXCHANGE339 = null;
    Token KW_WITH341 = null;
    Token KW_TABLE342 = null;
    HiveParser_FromClauseParser.tableName_return exchangename = null;

    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec340 = null;

    CommonTree KW_EXCHANGE339_tree = null;
    CommonTree KW_WITH341_tree = null;
    CommonTree KW_TABLE342_tree = null;
    RewriteRuleTokenStream stream_KW_WITH = new RewriteRuleTokenStream(adaptor, "token KW_WITH");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleTokenStream stream_KW_EXCHANGE = new RewriteRuleTokenStream(adaptor, "token KW_EXCHANGE");
    RewriteRuleSubtreeStream stream_partitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule partitionSpec");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    pushMsg("alter exchange partition", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1242:5: ( KW_EXCHANGE partitionSpec KW_WITH KW_TABLE exchangename= tableName -> ^( TOK_ALTERTABLE_EXCHANGEPARTITION partitionSpec $exchangename) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1242:7: KW_EXCHANGE partitionSpec KW_WITH KW_TABLE exchangename= tableName
      {
        KW_EXCHANGE339 =
            (Token) match(input, KW_EXCHANGE, FOLLOW_KW_EXCHANGE_in_alterStatementSuffixExchangePartition5815);
        stream_KW_EXCHANGE.add(KW_EXCHANGE339);

        pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixExchangePartition5817);
        partitionSpec340 = partitionSpec();

        state._fsp--;

        stream_partitionSpec.add(partitionSpec340.getTree());

        KW_WITH341 = (Token) match(input, KW_WITH, FOLLOW_KW_WITH_in_alterStatementSuffixExchangePartition5819);
        stream_KW_WITH.add(KW_WITH341);

        KW_TABLE342 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_alterStatementSuffixExchangePartition5821);
        stream_KW_TABLE.add(KW_TABLE342);

        pushFollow(FOLLOW_tableName_in_alterStatementSuffixExchangePartition5825);
        exchangename = tableName();

        state._fsp--;

        stream_tableName.add(exchangename.getTree());

        // AST REWRITE
        // elements: exchangename, partitionSpec
        // token labels:
        // rule labels: exchangename, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_exchangename =
            new RewriteRuleSubtreeStream(adaptor, "rule exchangename", exchangename != null ? exchangename.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1243:5: -> ^( TOK_ALTERTABLE_EXCHANGEPARTITION partitionSpec $exchangename)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1243:8: ^( TOK_ALTERTABLE_EXCHANGEPARTITION partitionSpec $exchangename)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERTABLE_EXCHANGEPARTITION, "TOK_ALTERTABLE_EXCHANGEPARTITION"),
                root_1);

            adaptor.addChild(root_1, stream_partitionSpec.nextTree());

            adaptor.addChild(root_1, stream_exchangename.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixExchangePartition"

  public static class alterStatementSuffixProtectMode_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixProtectMode"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1246:1: alterStatementSuffixProtectMode : alterProtectMode -> ^( TOK_ALTERTABLE_PROTECTMODE alterProtectMode ) ;
  public final HiveParser.alterStatementSuffixProtectMode_return alterStatementSuffixProtectMode()
      throws RecognitionException {
    HiveParser.alterStatementSuffixProtectMode_return retval = new HiveParser.alterStatementSuffixProtectMode_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.alterProtectMode_return alterProtectMode343 = null;

    RewriteRuleSubtreeStream stream_alterProtectMode = new RewriteRuleSubtreeStream(adaptor, "rule alterProtectMode");
    pushMsg("alter partition protect mode statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1249:5: ( alterProtectMode -> ^( TOK_ALTERTABLE_PROTECTMODE alterProtectMode ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1249:7: alterProtectMode
      {
        pushFollow(FOLLOW_alterProtectMode_in_alterStatementSuffixProtectMode5867);
        alterProtectMode343 = alterProtectMode();

        state._fsp--;

        stream_alterProtectMode.add(alterProtectMode343.getTree());

        // AST REWRITE
        // elements: alterProtectMode
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1250:5: -> ^( TOK_ALTERTABLE_PROTECTMODE alterProtectMode )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1250:8: ^( TOK_ALTERTABLE_PROTECTMODE alterProtectMode )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERTABLE_PROTECTMODE, "TOK_ALTERTABLE_PROTECTMODE"), root_1);

            adaptor.addChild(root_1, stream_alterProtectMode.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixProtectMode"

  public static class alterStatementSuffixRenamePart_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixRenamePart"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1253:1: alterStatementSuffixRenamePart : KW_RENAME KW_TO partitionSpec -> ^( TOK_ALTERTABLE_RENAMEPART partitionSpec ) ;
  public final HiveParser.alterStatementSuffixRenamePart_return alterStatementSuffixRenamePart()
      throws RecognitionException {
    HiveParser.alterStatementSuffixRenamePart_return retval = new HiveParser.alterStatementSuffixRenamePart_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_RENAME344 = null;
    Token KW_TO345 = null;
    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec346 = null;

    CommonTree KW_RENAME344_tree = null;
    CommonTree KW_TO345_tree = null;
    RewriteRuleTokenStream stream_KW_RENAME = new RewriteRuleTokenStream(adaptor, "token KW_RENAME");
    RewriteRuleTokenStream stream_KW_TO = new RewriteRuleTokenStream(adaptor, "token KW_TO");
    RewriteRuleSubtreeStream stream_partitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule partitionSpec");
    pushMsg("alter table rename partition statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1256:5: ( KW_RENAME KW_TO partitionSpec -> ^( TOK_ALTERTABLE_RENAMEPART partitionSpec ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1256:7: KW_RENAME KW_TO partitionSpec
      {
        KW_RENAME344 = (Token) match(input, KW_RENAME, FOLLOW_KW_RENAME_in_alterStatementSuffixRenamePart5906);
        stream_KW_RENAME.add(KW_RENAME344);

        KW_TO345 = (Token) match(input, KW_TO, FOLLOW_KW_TO_in_alterStatementSuffixRenamePart5908);
        stream_KW_TO.add(KW_TO345);

        pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixRenamePart5910);
        partitionSpec346 = partitionSpec();

        state._fsp--;

        stream_partitionSpec.add(partitionSpec346.getTree());

        // AST REWRITE
        // elements: partitionSpec
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1257:5: -> ^( TOK_ALTERTABLE_RENAMEPART partitionSpec )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1257:7: ^( TOK_ALTERTABLE_RENAMEPART partitionSpec )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERTABLE_RENAMEPART, "TOK_ALTERTABLE_RENAMEPART"), root_1);

            adaptor.addChild(root_1, stream_partitionSpec.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixRenamePart"

  public static class alterStatementSuffixStatsPart_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixStatsPart"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1260:1: alterStatementSuffixStatsPart : KW_UPDATE KW_STATISTICS KW_FOR ( KW_COLUMN )? colName= identifier KW_SET tableProperties ( KW_COMMENT comment= StringLiteral )? -> ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? ) ;
  public final HiveParser.alterStatementSuffixStatsPart_return alterStatementSuffixStatsPart()
      throws RecognitionException {
    HiveParser.alterStatementSuffixStatsPart_return retval = new HiveParser.alterStatementSuffixStatsPart_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token comment = null;
    Token KW_UPDATE347 = null;
    Token KW_STATISTICS348 = null;
    Token KW_FOR349 = null;
    Token KW_COLUMN350 = null;
    Token KW_SET351 = null;
    Token KW_COMMENT353 = null;
    HiveParser_IdentifiersParser.identifier_return colName = null;

    HiveParser.tableProperties_return tableProperties352 = null;

    CommonTree comment_tree = null;
    CommonTree KW_UPDATE347_tree = null;
    CommonTree KW_STATISTICS348_tree = null;
    CommonTree KW_FOR349_tree = null;
    CommonTree KW_COLUMN350_tree = null;
    CommonTree KW_SET351_tree = null;
    CommonTree KW_COMMENT353_tree = null;
    RewriteRuleTokenStream stream_KW_STATISTICS = new RewriteRuleTokenStream(adaptor, "token KW_STATISTICS");
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_FOR = new RewriteRuleTokenStream(adaptor, "token KW_FOR");
    RewriteRuleTokenStream stream_KW_UPDATE = new RewriteRuleTokenStream(adaptor, "token KW_UPDATE");
    RewriteRuleTokenStream stream_KW_COMMENT = new RewriteRuleTokenStream(adaptor, "token KW_COMMENT");
    RewriteRuleTokenStream stream_KW_COLUMN = new RewriteRuleTokenStream(adaptor, "token KW_COLUMN");
    RewriteRuleTokenStream stream_KW_SET = new RewriteRuleTokenStream(adaptor, "token KW_SET");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_tableProperties = new RewriteRuleSubtreeStream(adaptor, "rule tableProperties");
    pushMsg("alter table stats partition statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1263:5: ( KW_UPDATE KW_STATISTICS KW_FOR ( KW_COLUMN )? colName= identifier KW_SET tableProperties ( KW_COMMENT comment= StringLiteral )? -> ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1263:7: KW_UPDATE KW_STATISTICS KW_FOR ( KW_COLUMN )? colName= identifier KW_SET tableProperties ( KW_COMMENT comment= StringLiteral )?
      {
        KW_UPDATE347 = (Token) match(input, KW_UPDATE, FOLLOW_KW_UPDATE_in_alterStatementSuffixStatsPart5948);
        stream_KW_UPDATE.add(KW_UPDATE347);

        KW_STATISTICS348 =
            (Token) match(input, KW_STATISTICS, FOLLOW_KW_STATISTICS_in_alterStatementSuffixStatsPart5950);
        stream_KW_STATISTICS.add(KW_STATISTICS348);

        KW_FOR349 = (Token) match(input, KW_FOR, FOLLOW_KW_FOR_in_alterStatementSuffixStatsPart5952);
        stream_KW_FOR.add(KW_FOR349);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1263:38: ( KW_COLUMN )?
        int alt97 = 2;
        switch (input.LA(1)) {
          case KW_COLUMN: {
            alt97 = 1;
          }
          break;
        }

        switch (alt97) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1263:38: KW_COLUMN
          {
            KW_COLUMN350 = (Token) match(input, KW_COLUMN, FOLLOW_KW_COLUMN_in_alterStatementSuffixStatsPart5954);
            stream_KW_COLUMN.add(KW_COLUMN350);
          }
          break;
        }

        pushFollow(FOLLOW_identifier_in_alterStatementSuffixStatsPart5959);
        colName = identifier();

        state._fsp--;

        stream_identifier.add(colName.getTree());

        KW_SET351 = (Token) match(input, KW_SET, FOLLOW_KW_SET_in_alterStatementSuffixStatsPart5961);
        stream_KW_SET.add(KW_SET351);

        pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixStatsPart5963);
        tableProperties352 = tableProperties();

        state._fsp--;

        stream_tableProperties.add(tableProperties352.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1263:91: ( KW_COMMENT comment= StringLiteral )?
        int alt98 = 2;
        switch (input.LA(1)) {
          case KW_COMMENT: {
            alt98 = 1;
          }
          break;
        }

        switch (alt98) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1263:92: KW_COMMENT comment= StringLiteral
          {
            KW_COMMENT353 = (Token) match(input, KW_COMMENT, FOLLOW_KW_COMMENT_in_alterStatementSuffixStatsPart5966);
            stream_KW_COMMENT.add(KW_COMMENT353);

            comment = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_alterStatementSuffixStatsPart5970);
            stream_StringLiteral.add(comment);
          }
          break;
        }

        // AST REWRITE
        // elements: tableProperties, comment, colName
        // token labels: comment
        // rule labels: colName, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_comment = new RewriteRuleTokenStream(adaptor, "token comment", comment);
        RewriteRuleSubtreeStream stream_colName =
            new RewriteRuleSubtreeStream(adaptor, "rule colName", colName != null ? colName.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1264:5: -> ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1264:7: ^( TOK_ALTERTABLE_UPDATECOLSTATS $colName tableProperties ( $comment)? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERTABLE_UPDATECOLSTATS, "TOK_ALTERTABLE_UPDATECOLSTATS"), root_1);

            adaptor.addChild(root_1, stream_colName.nextTree());

            adaptor.addChild(root_1, stream_tableProperties.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1264:65: ( $comment)?
            if (stream_comment.hasNext()) {
              adaptor.addChild(root_1, stream_comment.nextNode());
            }
            stream_comment.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixStatsPart"

  public static class alterStatementSuffixMergeFiles_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixMergeFiles"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1267:1: alterStatementSuffixMergeFiles : KW_CONCATENATE -> ^( TOK_ALTERTABLE_MERGEFILES ) ;
  public final HiveParser.alterStatementSuffixMergeFiles_return alterStatementSuffixMergeFiles()
      throws RecognitionException {
    HiveParser.alterStatementSuffixMergeFiles_return retval = new HiveParser.alterStatementSuffixMergeFiles_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_CONCATENATE354 = null;

    CommonTree KW_CONCATENATE354_tree = null;
    RewriteRuleTokenStream stream_KW_CONCATENATE = new RewriteRuleTokenStream(adaptor, "token KW_CONCATENATE");

    pushMsg("", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1270:5: ( KW_CONCATENATE -> ^( TOK_ALTERTABLE_MERGEFILES ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1270:7: KW_CONCATENATE
      {
        KW_CONCATENATE354 =
            (Token) match(input, KW_CONCATENATE, FOLLOW_KW_CONCATENATE_in_alterStatementSuffixMergeFiles6017);
        stream_KW_CONCATENATE.add(KW_CONCATENATE354);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1271:5: -> ^( TOK_ALTERTABLE_MERGEFILES )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1271:8: ^( TOK_ALTERTABLE_MERGEFILES )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERTABLE_MERGEFILES, "TOK_ALTERTABLE_MERGEFILES"), root_1);

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixMergeFiles"

  public static class alterProtectMode_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterProtectMode"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1274:1: alterProtectMode : ( KW_ENABLE alterProtectModeMode -> ^( TOK_ENABLE alterProtectModeMode ) | KW_DISABLE alterProtectModeMode -> ^( TOK_DISABLE alterProtectModeMode ) );
  public final HiveParser.alterProtectMode_return alterProtectMode() throws RecognitionException {
    HiveParser.alterProtectMode_return retval = new HiveParser.alterProtectMode_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_ENABLE355 = null;
    Token KW_DISABLE357 = null;
    HiveParser.alterProtectModeMode_return alterProtectModeMode356 = null;

    HiveParser.alterProtectModeMode_return alterProtectModeMode358 = null;

    CommonTree KW_ENABLE355_tree = null;
    CommonTree KW_DISABLE357_tree = null;
    RewriteRuleTokenStream stream_KW_DISABLE = new RewriteRuleTokenStream(adaptor, "token KW_DISABLE");
    RewriteRuleTokenStream stream_KW_ENABLE = new RewriteRuleTokenStream(adaptor, "token KW_ENABLE");
    RewriteRuleSubtreeStream stream_alterProtectModeMode =
        new RewriteRuleSubtreeStream(adaptor, "rule alterProtectModeMode");
    pushMsg("protect mode specification enable", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1277:5: ( KW_ENABLE alterProtectModeMode -> ^( TOK_ENABLE alterProtectModeMode ) | KW_DISABLE alterProtectModeMode -> ^( TOK_DISABLE alterProtectModeMode ) )
      int alt99 = 2;
      switch (input.LA(1)) {
        case KW_ENABLE: {
          alt99 = 1;
        }
        break;
        case KW_DISABLE: {
          alt99 = 2;
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 99, 0, input);

          throw nvae;
      }

      switch (alt99) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1277:7: KW_ENABLE alterProtectModeMode
        {
          KW_ENABLE355 = (Token) match(input, KW_ENABLE, FOLLOW_KW_ENABLE_in_alterProtectMode6054);
          stream_KW_ENABLE.add(KW_ENABLE355);

          pushFollow(FOLLOW_alterProtectModeMode_in_alterProtectMode6056);
          alterProtectModeMode356 = alterProtectModeMode();

          state._fsp--;

          stream_alterProtectModeMode.add(alterProtectModeMode356.getTree());

          // AST REWRITE
          // elements: alterProtectModeMode
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1277:39: -> ^( TOK_ENABLE alterProtectModeMode )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1277:42: ^( TOK_ENABLE alterProtectModeMode )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_ENABLE, "TOK_ENABLE"), root_1);

              adaptor.addChild(root_1, stream_alterProtectModeMode.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1278:7: KW_DISABLE alterProtectModeMode
        {
          KW_DISABLE357 = (Token) match(input, KW_DISABLE, FOLLOW_KW_DISABLE_in_alterProtectMode6073);
          stream_KW_DISABLE.add(KW_DISABLE357);

          pushFollow(FOLLOW_alterProtectModeMode_in_alterProtectMode6075);
          alterProtectModeMode358 = alterProtectModeMode();

          state._fsp--;

          stream_alterProtectModeMode.add(alterProtectModeMode358.getTree());

          // AST REWRITE
          // elements: alterProtectModeMode
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1278:40: -> ^( TOK_DISABLE alterProtectModeMode )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1278:43: ^( TOK_DISABLE alterProtectModeMode )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DISABLE, "TOK_DISABLE"), root_1);

              adaptor.addChild(root_1, stream_alterProtectModeMode.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterProtectMode"

  public static class alterProtectModeMode_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterProtectModeMode"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1281:1: alterProtectModeMode : ( KW_OFFLINE -> ^( TOK_OFFLINE ) | KW_NO_DROP ( KW_CASCADE )? -> ^( TOK_NO_DROP ( KW_CASCADE )? ) | KW_READONLY -> ^( TOK_READONLY ) );
  public final HiveParser.alterProtectModeMode_return alterProtectModeMode() throws RecognitionException {
    HiveParser.alterProtectModeMode_return retval = new HiveParser.alterProtectModeMode_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_OFFLINE359 = null;
    Token KW_NO_DROP360 = null;
    Token KW_CASCADE361 = null;
    Token KW_READONLY362 = null;

    CommonTree KW_OFFLINE359_tree = null;
    CommonTree KW_NO_DROP360_tree = null;
    CommonTree KW_CASCADE361_tree = null;
    CommonTree KW_READONLY362_tree = null;
    RewriteRuleTokenStream stream_KW_CASCADE = new RewriteRuleTokenStream(adaptor, "token KW_CASCADE");
    RewriteRuleTokenStream stream_KW_READONLY = new RewriteRuleTokenStream(adaptor, "token KW_READONLY");
    RewriteRuleTokenStream stream_KW_OFFLINE = new RewriteRuleTokenStream(adaptor, "token KW_OFFLINE");
    RewriteRuleTokenStream stream_KW_NO_DROP = new RewriteRuleTokenStream(adaptor, "token KW_NO_DROP");

    pushMsg("protect mode specification enable", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1284:5: ( KW_OFFLINE -> ^( TOK_OFFLINE ) | KW_NO_DROP ( KW_CASCADE )? -> ^( TOK_NO_DROP ( KW_CASCADE )? ) | KW_READONLY -> ^( TOK_READONLY ) )
      int alt101 = 3;
      switch (input.LA(1)) {
        case KW_OFFLINE: {
          alt101 = 1;
        }
        break;
        case KW_NO_DROP: {
          alt101 = 2;
        }
        break;
        case KW_READONLY: {
          alt101 = 3;
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 101, 0, input);

          throw nvae;
      }

      switch (alt101) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1284:7: KW_OFFLINE
        {
          KW_OFFLINE359 = (Token) match(input, KW_OFFLINE, FOLLOW_KW_OFFLINE_in_alterProtectModeMode6111);
          stream_KW_OFFLINE.add(KW_OFFLINE359);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1284:19: -> ^( TOK_OFFLINE )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1284:22: ^( TOK_OFFLINE )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_OFFLINE, "TOK_OFFLINE"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1285:7: KW_NO_DROP ( KW_CASCADE )?
        {
          KW_NO_DROP360 = (Token) match(input, KW_NO_DROP, FOLLOW_KW_NO_DROP_in_alterProtectModeMode6126);
          stream_KW_NO_DROP.add(KW_NO_DROP360);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1285:18: ( KW_CASCADE )?
          int alt100 = 2;
          switch (input.LA(1)) {
            case KW_CASCADE: {
              alt100 = 1;
            }
            break;
          }

          switch (alt100) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1285:18: KW_CASCADE
            {
              KW_CASCADE361 = (Token) match(input, KW_CASCADE, FOLLOW_KW_CASCADE_in_alterProtectModeMode6128);
              stream_KW_CASCADE.add(KW_CASCADE361);
            }
            break;
          }

          // AST REWRITE
          // elements: KW_CASCADE
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1285:30: -> ^( TOK_NO_DROP ( KW_CASCADE )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1285:33: ^( TOK_NO_DROP ( KW_CASCADE )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_NO_DROP, "TOK_NO_DROP"), root_1);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1285:47: ( KW_CASCADE )?
              if (stream_KW_CASCADE.hasNext()) {
                adaptor.addChild(root_1, stream_KW_CASCADE.nextNode());
              }
              stream_KW_CASCADE.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 3:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1286:7: KW_READONLY
        {
          KW_READONLY362 = (Token) match(input, KW_READONLY, FOLLOW_KW_READONLY_in_alterProtectModeMode6146);
          stream_KW_READONLY.add(KW_READONLY362);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1286:20: -> ^( TOK_READONLY )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1286:23: ^( TOK_READONLY )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_READONLY, "TOK_READONLY"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterProtectModeMode"

  public static class alterStatementSuffixBucketNum_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixBucketNum"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1289:1: alterStatementSuffixBucketNum : KW_INTO num= Number KW_BUCKETS -> ^( TOK_ALTERTABLE_BUCKETS $num) ;
  public final HiveParser.alterStatementSuffixBucketNum_return alterStatementSuffixBucketNum()
      throws RecognitionException {
    HiveParser.alterStatementSuffixBucketNum_return retval = new HiveParser.alterStatementSuffixBucketNum_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token num = null;
    Token KW_INTO363 = null;
    Token KW_BUCKETS364 = null;

    CommonTree num_tree = null;
    CommonTree KW_INTO363_tree = null;
    CommonTree KW_BUCKETS364_tree = null;
    RewriteRuleTokenStream stream_Number = new RewriteRuleTokenStream(adaptor, "token Number");
    RewriteRuleTokenStream stream_KW_INTO = new RewriteRuleTokenStream(adaptor, "token KW_INTO");
    RewriteRuleTokenStream stream_KW_BUCKETS = new RewriteRuleTokenStream(adaptor, "token KW_BUCKETS");

    pushMsg("", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1292:5: ( KW_INTO num= Number KW_BUCKETS -> ^( TOK_ALTERTABLE_BUCKETS $num) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1292:7: KW_INTO num= Number KW_BUCKETS
      {
        KW_INTO363 = (Token) match(input, KW_INTO, FOLLOW_KW_INTO_in_alterStatementSuffixBucketNum6180);
        stream_KW_INTO.add(KW_INTO363);

        num = (Token) match(input, Number, FOLLOW_Number_in_alterStatementSuffixBucketNum6184);
        stream_Number.add(num);

        KW_BUCKETS364 = (Token) match(input, KW_BUCKETS, FOLLOW_KW_BUCKETS_in_alterStatementSuffixBucketNum6186);
        stream_KW_BUCKETS.add(KW_BUCKETS364);

        // AST REWRITE
        // elements: num
        // token labels: num
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_num = new RewriteRuleTokenStream(adaptor, "token num", num);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1293:5: -> ^( TOK_ALTERTABLE_BUCKETS $num)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1293:8: ^( TOK_ALTERTABLE_BUCKETS $num)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERTABLE_BUCKETS, "TOK_ALTERTABLE_BUCKETS"), root_1);

            adaptor.addChild(root_1, stream_num.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixBucketNum"

  public static class alterStatementSuffixCompact_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "alterStatementSuffixCompact"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1296:1: alterStatementSuffixCompact : KW_COMPACT compactType= StringLiteral -> ^( TOK_ALTERTABLE_COMPACT $compactType) ;
  public final HiveParser.alterStatementSuffixCompact_return alterStatementSuffixCompact() throws RecognitionException {
    HiveParser.alterStatementSuffixCompact_return retval = new HiveParser.alterStatementSuffixCompact_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token compactType = null;
    Token KW_COMPACT365 = null;

    CommonTree compactType_tree = null;
    CommonTree KW_COMPACT365_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_COMPACT = new RewriteRuleTokenStream(adaptor, "token KW_COMPACT");

    msgs.push("compaction request");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1299:5: ( KW_COMPACT compactType= StringLiteral -> ^( TOK_ALTERTABLE_COMPACT $compactType) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1299:7: KW_COMPACT compactType= StringLiteral
      {
        KW_COMPACT365 = (Token) match(input, KW_COMPACT, FOLLOW_KW_COMPACT_in_alterStatementSuffixCompact6226);
        stream_KW_COMPACT.add(KW_COMPACT365);

        compactType = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_alterStatementSuffixCompact6230);
        stream_StringLiteral.add(compactType);

        // AST REWRITE
        // elements: compactType
        // token labels: compactType
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_compactType =
            new RewriteRuleTokenStream(adaptor, "token compactType", compactType);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1300:5: -> ^( TOK_ALTERTABLE_COMPACT $compactType)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1300:8: ^( TOK_ALTERTABLE_COMPACT $compactType)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERTABLE_COMPACT, "TOK_ALTERTABLE_COMPACT"), root_1);

            adaptor.addChild(root_1, stream_compactType.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      msgs.pop();
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "alterStatementSuffixCompact"

  public static class fileFormat_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "fileFormat"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1304:1: fileFormat : ( KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral KW_SERDE serdeCls= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )? -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt $serdeCls ( $inDriver)? ( $outDriver)? ) |genericSpec= identifier -> ^( TOK_FILEFORMAT_GENERIC $genericSpec) );
  public final HiveParser.fileFormat_return fileFormat() throws RecognitionException {
    HiveParser.fileFormat_return retval = new HiveParser.fileFormat_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token inFmt = null;
    Token outFmt = null;
    Token serdeCls = null;
    Token inDriver = null;
    Token outDriver = null;
    Token KW_INPUTFORMAT366 = null;
    Token KW_OUTPUTFORMAT367 = null;
    Token KW_SERDE368 = null;
    Token KW_INPUTDRIVER369 = null;
    Token KW_OUTPUTDRIVER370 = null;
    HiveParser_IdentifiersParser.identifier_return genericSpec = null;

    CommonTree inFmt_tree = null;
    CommonTree outFmt_tree = null;
    CommonTree serdeCls_tree = null;
    CommonTree inDriver_tree = null;
    CommonTree outDriver_tree = null;
    CommonTree KW_INPUTFORMAT366_tree = null;
    CommonTree KW_OUTPUTFORMAT367_tree = null;
    CommonTree KW_SERDE368_tree = null;
    CommonTree KW_INPUTDRIVER369_tree = null;
    CommonTree KW_OUTPUTDRIVER370_tree = null;
    RewriteRuleTokenStream stream_KW_INPUTFORMAT = new RewriteRuleTokenStream(adaptor, "token KW_INPUTFORMAT");
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_INPUTDRIVER = new RewriteRuleTokenStream(adaptor, "token KW_INPUTDRIVER");
    RewriteRuleTokenStream stream_KW_SERDE = new RewriteRuleTokenStream(adaptor, "token KW_SERDE");
    RewriteRuleTokenStream stream_KW_OUTPUTFORMAT = new RewriteRuleTokenStream(adaptor, "token KW_OUTPUTFORMAT");
    RewriteRuleTokenStream stream_KW_OUTPUTDRIVER = new RewriteRuleTokenStream(adaptor, "token KW_OUTPUTDRIVER");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    pushMsg("file format specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1307:5: ( KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral KW_SERDE serdeCls= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )? -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt $serdeCls ( $inDriver)? ( $outDriver)? ) |genericSpec= identifier -> ^( TOK_FILEFORMAT_GENERIC $genericSpec) )
      int alt103 = 2;
      switch (input.LA(1)) {
        case KW_INPUTFORMAT: {
          switch (input.LA(2)) {
            case StringLiteral: {
              alt103 = 1;
            }
            break;
            case EOF:
            case KW_LOCATION:
            case KW_PARTITION:
            case KW_SERDEPROPERTIES: {
              alt103 = 2;
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 103, 1, input);

              throw nvae;
          }
        }
        break;
        case Identifier:
        case KW_ADD:
        case KW_ADMIN:
        case KW_AFTER:
        case KW_ALL:
        case KW_ALTER:
        case KW_ANALYZE:
        case KW_ARCHIVE:
        case KW_ARRAY:
        case KW_AS:
        case KW_ASC:
        case KW_AUTHORIZATION:
        case KW_BEFORE:
        case KW_BETWEEN:
        case KW_BIGINT:
        case KW_BINARY:
        case KW_BOOLEAN:
        case KW_BOTH:
        case KW_BUCKET:
        case KW_BUCKETS:
        case KW_BY:
        case KW_CASCADE:
        case KW_CHANGE:
        case KW_CLUSTER:
        case KW_CLUSTERED:
        case KW_CLUSTERSTATUS:
        case KW_COLLECTION:
        case KW_COLUMNS:
        case KW_COMMENT:
        case KW_COMPACT:
        case KW_COMPACTIONS:
        case KW_COMPUTE:
        case KW_CONCATENATE:
        case KW_CONTINUE:
        case KW_CREATE:
        case KW_CUBE:
        case KW_CURSOR:
        case KW_DATA:
        case KW_DATABASES:
        case KW_DATE:
        case KW_DATETIME:
        case KW_DBPROPERTIES:
        case KW_DECIMAL:
        case KW_DEFAULT:
        case KW_DEFERRED:
        case KW_DEFINED:
        case KW_DELETE:
        case KW_DELIMITED:
        case KW_DEPENDENCY:
        case KW_DESC:
        case KW_DESCRIBE:
        case KW_DIRECTORIES:
        case KW_DIRECTORY:
        case KW_DISABLE:
        case KW_DISTRIBUTE:
        case KW_DOUBLE:
        case KW_DROP:
        case KW_ELEM_TYPE:
        case KW_ENABLE:
        case KW_ESCAPED:
        case KW_EXCLUSIVE:
        case KW_EXISTS:
        case KW_EXPLAIN:
        case KW_EXPORT:
        case KW_EXTERNAL:
        case KW_FALSE:
        case KW_FETCH:
        case KW_FIELDS:
        case KW_FILE:
        case KW_FILEFORMAT:
        case KW_FIRST:
        case KW_FLOAT:
        case KW_FOR:
        case KW_FORMAT:
        case KW_FORMATTED:
        case KW_FULL:
        case KW_FUNCTIONS:
        case KW_GRANT:
        case KW_GROUP:
        case KW_GROUPING:
        case KW_HOLD_DDLTIME:
        case KW_IDXPROPERTIES:
        case KW_IGNORE:
        case KW_IMPORT:
        case KW_IN:
        case KW_INDEX:
        case KW_INDEXES:
        case KW_INNER:
        case KW_INPATH:
        case KW_INPUTDRIVER:
        case KW_INSERT:
        case KW_INT:
        case KW_INTERSECT:
        case KW_INTO:
        case KW_IS:
        case KW_ITEMS:
        case KW_JAR:
        case KW_KEYS:
        case KW_KEY_TYPE:
        case KW_LATERAL:
        case KW_LEFT:
        case KW_LIKE:
        case KW_LIMIT:
        case KW_LINES:
        case KW_LOAD:
        case KW_LOCAL:
        case KW_LOCATION:
        case KW_LOCK:
        case KW_LOCKS:
        case KW_LOGICAL:
        case KW_LONG:
        case KW_MAPJOIN:
        case KW_MATERIALIZED:
        case KW_METADATA:
        case KW_MINUS:
        case KW_MSCK:
        case KW_NONE:
        case KW_NOSCAN:
        case KW_NO_DROP:
        case KW_NULL:
        case KW_OF:
        case KW_OFFLINE:
        case KW_OPTION:
        case KW_ORDER:
        case KW_OUT:
        case KW_OUTER:
        case KW_OUTPUTDRIVER:
        case KW_OUTPUTFORMAT:
        case KW_OVERWRITE:
        case KW_OWNER:
        case KW_PARTITION:
        case KW_PARTITIONED:
        case KW_PARTITIONS:
        case KW_PERCENT:
        case KW_PLUS:
        case KW_PRETTY:
        case KW_PRINCIPALS:
        case KW_PROCEDURE:
        case KW_PROTECTION:
        case KW_PURGE:
        case KW_RANGE:
        case KW_READ:
        case KW_READONLY:
        case KW_READS:
        case KW_REBUILD:
        case KW_RECORDREADER:
        case KW_RECORDWRITER:
        case KW_REGEXP:
        case KW_RELOAD:
        case KW_RENAME:
        case KW_REPAIR:
        case KW_REPLACE:
        case KW_REPLICATION:
        case KW_RESTRICT:
        case KW_REVOKE:
        case KW_REWRITE:
        case KW_RIGHT:
        case KW_RLIKE:
        case KW_ROLE:
        case KW_ROLES:
        case KW_ROLLUP:
        case KW_ROW:
        case KW_ROWS:
        case KW_SCHEMA:
        case KW_SCHEMAS:
        case KW_SEMI:
        case KW_SERDE:
        case KW_SERDEPROPERTIES:
        case KW_SERVER:
        case KW_SET:
        case KW_SETS:
        case KW_SHARED:
        case KW_SHOW:
        case KW_SHOW_DATABASE:
        case KW_SKEWED:
        case KW_SMALLINT:
        case KW_SORT:
        case KW_SORTED:
        case KW_SSL:
        case KW_STATISTICS:
        case KW_STORED:
        case KW_STREAMTABLE:
        case KW_STRING:
        case KW_STRUCT:
        case KW_TABLE:
        case KW_TABLES:
        case KW_TBLPROPERTIES:
        case KW_TEMPORARY:
        case KW_TERMINATED:
        case KW_TIMESTAMP:
        case KW_TINYINT:
        case KW_TO:
        case KW_TOUCH:
        case KW_TRANSACTIONS:
        case KW_TRIGGER:
        case KW_TRUE:
        case KW_TRUNCATE:
        case KW_UNARCHIVE:
        case KW_UNDO:
        case KW_UNION:
        case KW_UNIONTYPE:
        case KW_UNLOCK:
        case KW_UNSET:
        case KW_UNSIGNED:
        case KW_UPDATE:
        case KW_URI:
        case KW_USE:
        case KW_USER:
        case KW_USING:
        case KW_UTC:
        case KW_UTCTIMESTAMP:
        case KW_VALUES:
        case KW_VALUE_TYPE:
        case KW_VIEW:
        case KW_WHILE:
        case KW_WITH: {
          alt103 = 2;
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 103, 0, input);

          throw nvae;
      }

      switch (alt103) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1307:7: KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral KW_SERDE serdeCls= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )?
        {
          KW_INPUTFORMAT366 = (Token) match(input, KW_INPUTFORMAT, FOLLOW_KW_INPUTFORMAT_in_fileFormat6271);
          stream_KW_INPUTFORMAT.add(KW_INPUTFORMAT366);

          inFmt = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_fileFormat6275);
          stream_StringLiteral.add(inFmt);

          KW_OUTPUTFORMAT367 = (Token) match(input, KW_OUTPUTFORMAT, FOLLOW_KW_OUTPUTFORMAT_in_fileFormat6277);
          stream_KW_OUTPUTFORMAT.add(KW_OUTPUTFORMAT367);

          outFmt = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_fileFormat6281);
          stream_StringLiteral.add(outFmt);

          KW_SERDE368 = (Token) match(input, KW_SERDE, FOLLOW_KW_SERDE_in_fileFormat6283);
          stream_KW_SERDE.add(KW_SERDE368);

          serdeCls = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_fileFormat6287);
          stream_StringLiteral.add(serdeCls);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1307:111: ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )?
          int alt102 = 2;
          switch (input.LA(1)) {
            case KW_INPUTDRIVER: {
              alt102 = 1;
            }
            break;
          }

          switch (alt102) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1307:112: KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral
            {
              KW_INPUTDRIVER369 = (Token) match(input, KW_INPUTDRIVER, FOLLOW_KW_INPUTDRIVER_in_fileFormat6290);
              stream_KW_INPUTDRIVER.add(KW_INPUTDRIVER369);

              inDriver = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_fileFormat6294);
              stream_StringLiteral.add(inDriver);

              KW_OUTPUTDRIVER370 = (Token) match(input, KW_OUTPUTDRIVER, FOLLOW_KW_OUTPUTDRIVER_in_fileFormat6296);
              stream_KW_OUTPUTDRIVER.add(KW_OUTPUTDRIVER370);

              outDriver = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_fileFormat6300);
              stream_StringLiteral.add(outDriver);
            }
            break;
          }

          // AST REWRITE
          // elements: outFmt, inDriver, serdeCls, outDriver, inFmt
          // token labels: inFmt, inDriver, serdeCls, outDriver, outFmt
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleTokenStream stream_inFmt = new RewriteRuleTokenStream(adaptor, "token inFmt", inFmt);
          RewriteRuleTokenStream stream_inDriver = new RewriteRuleTokenStream(adaptor, "token inDriver", inDriver);
          RewriteRuleTokenStream stream_serdeCls = new RewriteRuleTokenStream(adaptor, "token serdeCls", serdeCls);
          RewriteRuleTokenStream stream_outDriver = new RewriteRuleTokenStream(adaptor, "token outDriver", outDriver);
          RewriteRuleTokenStream stream_outFmt = new RewriteRuleTokenStream(adaptor, "token outFmt", outFmt);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1308:7: -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt $serdeCls ( $inDriver)? ( $outDriver)? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1308:10: ^( TOK_TABLEFILEFORMAT $inFmt $outFmt $serdeCls ( $inDriver)? ( $outDriver)? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_TABLEFILEFORMAT, "TOK_TABLEFILEFORMAT"), root_1);

              adaptor.addChild(root_1, stream_inFmt.nextNode());

              adaptor.addChild(root_1, stream_outFmt.nextNode());

              adaptor.addChild(root_1, stream_serdeCls.nextNode());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1308:58: ( $inDriver)?
              if (stream_inDriver.hasNext()) {
                adaptor.addChild(root_1, stream_inDriver.nextNode());
              }
              stream_inDriver.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1308:69: ( $outDriver)?
              if (stream_outDriver.hasNext()) {
                adaptor.addChild(root_1, stream_outDriver.nextNode());
              }
              stream_outDriver.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1309:7: genericSpec= identifier
        {
          pushFollow(FOLLOW_identifier_in_fileFormat6341);
          genericSpec = identifier();

          state._fsp--;

          stream_identifier.add(genericSpec.getTree());

          // AST REWRITE
          // elements: genericSpec
          // token labels:
          // rule labels: genericSpec, retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_genericSpec =
              new RewriteRuleSubtreeStream(adaptor, "rule genericSpec", genericSpec != null ? genericSpec.tree : null);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1309:30: -> ^( TOK_FILEFORMAT_GENERIC $genericSpec)
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1309:33: ^( TOK_FILEFORMAT_GENERIC $genericSpec)
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_FILEFORMAT_GENERIC, "TOK_FILEFORMAT_GENERIC"), root_1);

              adaptor.addChild(root_1, stream_genericSpec.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "fileFormat"

  public static class tabTypeExpr_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "tabTypeExpr"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1312:1: tabTypeExpr : identifier ( DOT ^ ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier ) )* ;
  public final HiveParser.tabTypeExpr_return tabTypeExpr() throws RecognitionException {
    HiveParser.tabTypeExpr_return retval = new HiveParser.tabTypeExpr_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token DOT372 = null;
    Token KW_ELEM_TYPE373 = null;
    Token KW_KEY_TYPE374 = null;
    Token KW_VALUE_TYPE375 = null;
    HiveParser_IdentifiersParser.identifier_return identifier371 = null;

    HiveParser_IdentifiersParser.identifier_return identifier376 = null;

    CommonTree DOT372_tree = null;
    CommonTree KW_ELEM_TYPE373_tree = null;
    CommonTree KW_KEY_TYPE374_tree = null;
    CommonTree KW_VALUE_TYPE375_tree = null;

    pushMsg("specifying table types", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1316:4: ( identifier ( DOT ^ ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier ) )* )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1316:6: identifier ( DOT ^ ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier ) )*
      {
        root_0 = (CommonTree) adaptor.nil();

        pushFollow(FOLLOW_identifier_in_tabTypeExpr6377);
        identifier371 = identifier();

        state._fsp--;

        adaptor.addChild(root_0, identifier371.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1316:17: ( DOT ^ ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier ) )*
        loop105:
        do {
          int alt105 = 2;
          switch (input.LA(1)) {
            case DOT: {
              alt105 = 1;
            }
            break;
          }

          switch (alt105) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1316:18: DOT ^ ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier )
            {
              DOT372 = (Token) match(input, DOT, FOLLOW_DOT_in_tabTypeExpr6380);
              DOT372_tree = (CommonTree) adaptor.create(DOT372);
              root_0 = (CommonTree) adaptor.becomeRoot(DOT372_tree, root_0);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1316:23: ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier )
              int alt104 = 4;
              switch (input.LA(1)) {
                case KW_ELEM_TYPE: {
                  alt104 = 1;
                }
                break;
                case KW_KEY_TYPE: {
                  alt104 = 2;
                }
                break;
                case KW_VALUE_TYPE: {
                  alt104 = 3;
                }
                break;
                case Identifier:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFAULT:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEYS:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_METADATA:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NONE:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITION:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUES:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH: {
                  alt104 = 4;
                }
                break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 104, 0, input);

                  throw nvae;
              }

              switch (alt104) {
                case 1:
                  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1316:24: KW_ELEM_TYPE
                {
                  KW_ELEM_TYPE373 = (Token) match(input, KW_ELEM_TYPE, FOLLOW_KW_ELEM_TYPE_in_tabTypeExpr6384);
                  KW_ELEM_TYPE373_tree = (CommonTree) adaptor.create(KW_ELEM_TYPE373);
                  adaptor.addChild(root_0, KW_ELEM_TYPE373_tree);
                }
                break;
                case 2:
                  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1316:39: KW_KEY_TYPE
                {
                  KW_KEY_TYPE374 = (Token) match(input, KW_KEY_TYPE, FOLLOW_KW_KEY_TYPE_in_tabTypeExpr6388);
                  KW_KEY_TYPE374_tree = (CommonTree) adaptor.create(KW_KEY_TYPE374);
                  adaptor.addChild(root_0, KW_KEY_TYPE374_tree);
                }
                break;
                case 3:
                  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1316:53: KW_VALUE_TYPE
                {
                  KW_VALUE_TYPE375 = (Token) match(input, KW_VALUE_TYPE, FOLLOW_KW_VALUE_TYPE_in_tabTypeExpr6392);
                  KW_VALUE_TYPE375_tree = (CommonTree) adaptor.create(KW_VALUE_TYPE375);
                  adaptor.addChild(root_0, KW_VALUE_TYPE375_tree);
                }
                break;
                case 4:
                  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1316:69: identifier
                {
                  pushFollow(FOLLOW_identifier_in_tabTypeExpr6396);
                  identifier376 = identifier();

                  state._fsp--;

                  adaptor.addChild(root_0, identifier376.getTree());
                }
                break;
              }
            }
            break;

            default:
              break loop105;
          }
        } while (true);
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "tabTypeExpr"

  public static class descTabTypeExpr_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "descTabTypeExpr"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1319:1: descTabTypeExpr : identifier ( DOT ^ ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier ) )* ( identifier )? ;
  public final HiveParser.descTabTypeExpr_return descTabTypeExpr() throws RecognitionException {
    HiveParser.descTabTypeExpr_return retval = new HiveParser.descTabTypeExpr_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token DOT378 = null;
    Token KW_ELEM_TYPE379 = null;
    Token KW_KEY_TYPE380 = null;
    Token KW_VALUE_TYPE381 = null;
    HiveParser_IdentifiersParser.identifier_return identifier377 = null;

    HiveParser_IdentifiersParser.identifier_return identifier382 = null;

    HiveParser_IdentifiersParser.identifier_return identifier383 = null;

    CommonTree DOT378_tree = null;
    CommonTree KW_ELEM_TYPE379_tree = null;
    CommonTree KW_KEY_TYPE380_tree = null;
    CommonTree KW_VALUE_TYPE381_tree = null;

    pushMsg("specifying describe table types", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1323:4: ( identifier ( DOT ^ ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier ) )* ( identifier )? )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1323:6: identifier ( DOT ^ ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier ) )* ( identifier )?
      {
        root_0 = (CommonTree) adaptor.nil();

        pushFollow(FOLLOW_identifier_in_descTabTypeExpr6425);
        identifier377 = identifier();

        state._fsp--;

        adaptor.addChild(root_0, identifier377.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1323:17: ( DOT ^ ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier ) )*
        loop107:
        do {
          int alt107 = 2;
          switch (input.LA(1)) {
            case DOT: {
              alt107 = 1;
            }
            break;
          }

          switch (alt107) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1323:18: DOT ^ ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier )
            {
              DOT378 = (Token) match(input, DOT, FOLLOW_DOT_in_descTabTypeExpr6428);
              DOT378_tree = (CommonTree) adaptor.create(DOT378);
              root_0 = (CommonTree) adaptor.becomeRoot(DOT378_tree, root_0);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1323:23: ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier )
              int alt106 = 4;
              switch (input.LA(1)) {
                case KW_ELEM_TYPE: {
                  alt106 = 1;
                }
                break;
                case KW_KEY_TYPE: {
                  alt106 = 2;
                }
                break;
                case KW_VALUE_TYPE: {
                  alt106 = 3;
                }
                break;
                case Identifier:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFAULT:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEYS:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_METADATA:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NONE:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITION:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUES:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH: {
                  alt106 = 4;
                }
                break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 106, 0, input);

                  throw nvae;
              }

              switch (alt106) {
                case 1:
                  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1323:24: KW_ELEM_TYPE
                {
                  KW_ELEM_TYPE379 = (Token) match(input, KW_ELEM_TYPE, FOLLOW_KW_ELEM_TYPE_in_descTabTypeExpr6432);
                  KW_ELEM_TYPE379_tree = (CommonTree) adaptor.create(KW_ELEM_TYPE379);
                  adaptor.addChild(root_0, KW_ELEM_TYPE379_tree);
                }
                break;
                case 2:
                  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1323:39: KW_KEY_TYPE
                {
                  KW_KEY_TYPE380 = (Token) match(input, KW_KEY_TYPE, FOLLOW_KW_KEY_TYPE_in_descTabTypeExpr6436);
                  KW_KEY_TYPE380_tree = (CommonTree) adaptor.create(KW_KEY_TYPE380);
                  adaptor.addChild(root_0, KW_KEY_TYPE380_tree);
                }
                break;
                case 3:
                  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1323:53: KW_VALUE_TYPE
                {
                  KW_VALUE_TYPE381 = (Token) match(input, KW_VALUE_TYPE, FOLLOW_KW_VALUE_TYPE_in_descTabTypeExpr6440);
                  KW_VALUE_TYPE381_tree = (CommonTree) adaptor.create(KW_VALUE_TYPE381);
                  adaptor.addChild(root_0, KW_VALUE_TYPE381_tree);
                }
                break;
                case 4:
                  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1323:69: identifier
                {
                  pushFollow(FOLLOW_identifier_in_descTabTypeExpr6444);
                  identifier382 = identifier();

                  state._fsp--;

                  adaptor.addChild(root_0, identifier382.getTree());
                }
                break;
              }
            }
            break;

            default:
              break loop107;
          }
        } while (true);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1323:83: ( identifier )?
        int alt108 = 2;
        switch (input.LA(1)) {
          case Identifier:
          case KW_ADD:
          case KW_ADMIN:
          case KW_AFTER:
          case KW_ALL:
          case KW_ALTER:
          case KW_ANALYZE:
          case KW_ARCHIVE:
          case KW_ARRAY:
          case KW_AS:
          case KW_ASC:
          case KW_AUTHORIZATION:
          case KW_BEFORE:
          case KW_BETWEEN:
          case KW_BIGINT:
          case KW_BINARY:
          case KW_BOOLEAN:
          case KW_BOTH:
          case KW_BUCKET:
          case KW_BUCKETS:
          case KW_BY:
          case KW_CASCADE:
          case KW_CHANGE:
          case KW_CLUSTER:
          case KW_CLUSTERED:
          case KW_CLUSTERSTATUS:
          case KW_COLLECTION:
          case KW_COLUMNS:
          case KW_COMMENT:
          case KW_COMPACT:
          case KW_COMPACTIONS:
          case KW_COMPUTE:
          case KW_CONCATENATE:
          case KW_CONTINUE:
          case KW_CREATE:
          case KW_CUBE:
          case KW_CURSOR:
          case KW_DATA:
          case KW_DATABASES:
          case KW_DATE:
          case KW_DATETIME:
          case KW_DBPROPERTIES:
          case KW_DECIMAL:
          case KW_DEFAULT:
          case KW_DEFERRED:
          case KW_DEFINED:
          case KW_DELETE:
          case KW_DELIMITED:
          case KW_DEPENDENCY:
          case KW_DESC:
          case KW_DESCRIBE:
          case KW_DIRECTORIES:
          case KW_DIRECTORY:
          case KW_DISABLE:
          case KW_DISTRIBUTE:
          case KW_DOUBLE:
          case KW_DROP:
          case KW_ELEM_TYPE:
          case KW_ENABLE:
          case KW_ESCAPED:
          case KW_EXCLUSIVE:
          case KW_EXISTS:
          case KW_EXPLAIN:
          case KW_EXPORT:
          case KW_EXTERNAL:
          case KW_FALSE:
          case KW_FETCH:
          case KW_FIELDS:
          case KW_FILE:
          case KW_FILEFORMAT:
          case KW_FIRST:
          case KW_FLOAT:
          case KW_FOR:
          case KW_FORMAT:
          case KW_FORMATTED:
          case KW_FULL:
          case KW_FUNCTIONS:
          case KW_GRANT:
          case KW_GROUP:
          case KW_GROUPING:
          case KW_HOLD_DDLTIME:
          case KW_IDXPROPERTIES:
          case KW_IGNORE:
          case KW_IMPORT:
          case KW_IN:
          case KW_INDEX:
          case KW_INDEXES:
          case KW_INNER:
          case KW_INPATH:
          case KW_INPUTDRIVER:
          case KW_INPUTFORMAT:
          case KW_INSERT:
          case KW_INT:
          case KW_INTERSECT:
          case KW_INTO:
          case KW_IS:
          case KW_ITEMS:
          case KW_JAR:
          case KW_KEYS:
          case KW_KEY_TYPE:
          case KW_LATERAL:
          case KW_LEFT:
          case KW_LIKE:
          case KW_LIMIT:
          case KW_LINES:
          case KW_LOAD:
          case KW_LOCAL:
          case KW_LOCATION:
          case KW_LOCK:
          case KW_LOCKS:
          case KW_LOGICAL:
          case KW_LONG:
          case KW_MAPJOIN:
          case KW_MATERIALIZED:
          case KW_METADATA:
          case KW_MINUS:
          case KW_MSCK:
          case KW_NONE:
          case KW_NOSCAN:
          case KW_NO_DROP:
          case KW_NULL:
          case KW_OF:
          case KW_OFFLINE:
          case KW_OPTION:
          case KW_ORDER:
          case KW_OUT:
          case KW_OUTER:
          case KW_OUTPUTDRIVER:
          case KW_OUTPUTFORMAT:
          case KW_OVERWRITE:
          case KW_OWNER:
          case KW_PARTITIONED:
          case KW_PARTITIONS:
          case KW_PERCENT:
          case KW_PLUS:
          case KW_PRETTY:
          case KW_PRINCIPALS:
          case KW_PROCEDURE:
          case KW_PROTECTION:
          case KW_PURGE:
          case KW_RANGE:
          case KW_READ:
          case KW_READONLY:
          case KW_READS:
          case KW_REBUILD:
          case KW_RECORDREADER:
          case KW_RECORDWRITER:
          case KW_REGEXP:
          case KW_RELOAD:
          case KW_RENAME:
          case KW_REPAIR:
          case KW_REPLACE:
          case KW_REPLICATION:
          case KW_RESTRICT:
          case KW_REVOKE:
          case KW_REWRITE:
          case KW_RIGHT:
          case KW_RLIKE:
          case KW_ROLE:
          case KW_ROLES:
          case KW_ROLLUP:
          case KW_ROW:
          case KW_ROWS:
          case KW_SCHEMA:
          case KW_SCHEMAS:
          case KW_SEMI:
          case KW_SERDE:
          case KW_SERDEPROPERTIES:
          case KW_SERVER:
          case KW_SET:
          case KW_SETS:
          case KW_SHARED:
          case KW_SHOW:
          case KW_SHOW_DATABASE:
          case KW_SKEWED:
          case KW_SMALLINT:
          case KW_SORT:
          case KW_SORTED:
          case KW_SSL:
          case KW_STATISTICS:
          case KW_STORED:
          case KW_STREAMTABLE:
          case KW_STRING:
          case KW_STRUCT:
          case KW_TABLE:
          case KW_TABLES:
          case KW_TBLPROPERTIES:
          case KW_TEMPORARY:
          case KW_TERMINATED:
          case KW_TIMESTAMP:
          case KW_TINYINT:
          case KW_TO:
          case KW_TOUCH:
          case KW_TRANSACTIONS:
          case KW_TRIGGER:
          case KW_TRUE:
          case KW_TRUNCATE:
          case KW_UNARCHIVE:
          case KW_UNDO:
          case KW_UNION:
          case KW_UNIONTYPE:
          case KW_UNLOCK:
          case KW_UNSET:
          case KW_UNSIGNED:
          case KW_UPDATE:
          case KW_URI:
          case KW_USE:
          case KW_USER:
          case KW_USING:
          case KW_UTC:
          case KW_UTCTIMESTAMP:
          case KW_VALUES:
          case KW_VALUE_TYPE:
          case KW_VIEW:
          case KW_WHILE:
          case KW_WITH: {
            alt108 = 1;
          }
          break;
          case KW_PARTITION: {
            switch (input.LA(2)) {
              case EOF:
              case KW_PARTITION: {
                alt108 = 1;
              }
              break;
            }
          }
          break;
        }

        switch (alt108) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1323:83: identifier
          {
            pushFollow(FOLLOW_identifier_in_descTabTypeExpr6449);
            identifier383 = identifier();

            state._fsp--;

            adaptor.addChild(root_0, identifier383.getTree());
          }
          break;
        }
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "descTabTypeExpr"

  public static class partTypeExpr_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "partTypeExpr"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1326:1: partTypeExpr : tabTypeExpr ( partitionSpec )? -> ^( TOK_TABTYPE tabTypeExpr ( partitionSpec )? ) ;
  public final HiveParser.partTypeExpr_return partTypeExpr() throws RecognitionException {
    HiveParser.partTypeExpr_return retval = new HiveParser.partTypeExpr_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.tabTypeExpr_return tabTypeExpr384 = null;

    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec385 = null;

    RewriteRuleSubtreeStream stream_partitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule partitionSpec");
    RewriteRuleSubtreeStream stream_tabTypeExpr = new RewriteRuleSubtreeStream(adaptor, "rule tabTypeExpr");
    pushMsg("specifying table partitions", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1329:5: ( tabTypeExpr ( partitionSpec )? -> ^( TOK_TABTYPE tabTypeExpr ( partitionSpec )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1329:8: tabTypeExpr ( partitionSpec )?
      {
        pushFollow(FOLLOW_tabTypeExpr_in_partTypeExpr6477);
        tabTypeExpr384 = tabTypeExpr();

        state._fsp--;

        stream_tabTypeExpr.add(tabTypeExpr384.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1329:20: ( partitionSpec )?
        int alt109 = 2;
        switch (input.LA(1)) {
          case KW_PARTITION: {
            alt109 = 1;
          }
          break;
        }

        switch (alt109) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1329:20: partitionSpec
          {
            pushFollow(FOLLOW_partitionSpec_in_partTypeExpr6479);
            partitionSpec385 = partitionSpec();

            state._fsp--;

            stream_partitionSpec.add(partitionSpec385.getTree());
          }
          break;
        }

        // AST REWRITE
        // elements: partitionSpec, tabTypeExpr
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1329:35: -> ^( TOK_TABTYPE tabTypeExpr ( partitionSpec )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1329:38: ^( TOK_TABTYPE tabTypeExpr ( partitionSpec )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABTYPE, "TOK_TABTYPE"), root_1);

            adaptor.addChild(root_1, stream_tabTypeExpr.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1329:64: ( partitionSpec )?
            if (stream_partitionSpec.hasNext()) {
              adaptor.addChild(root_1, stream_partitionSpec.nextTree());
            }
            stream_partitionSpec.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "partTypeExpr"

  public static class descPartTypeExpr_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "descPartTypeExpr"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1332:1: descPartTypeExpr : descTabTypeExpr ( partitionSpec )? -> ^( TOK_TABTYPE descTabTypeExpr ( partitionSpec )? ) ;
  public final HiveParser.descPartTypeExpr_return descPartTypeExpr() throws RecognitionException {
    HiveParser.descPartTypeExpr_return retval = new HiveParser.descPartTypeExpr_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.descTabTypeExpr_return descTabTypeExpr386 = null;

    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec387 = null;

    RewriteRuleSubtreeStream stream_descTabTypeExpr = new RewriteRuleSubtreeStream(adaptor, "rule descTabTypeExpr");
    RewriteRuleSubtreeStream stream_partitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule partitionSpec");
    pushMsg("specifying describe table partitions", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1335:5: ( descTabTypeExpr ( partitionSpec )? -> ^( TOK_TABTYPE descTabTypeExpr ( partitionSpec )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1335:8: descTabTypeExpr ( partitionSpec )?
      {
        pushFollow(FOLLOW_descTabTypeExpr_in_descPartTypeExpr6519);
        descTabTypeExpr386 = descTabTypeExpr();

        state._fsp--;

        stream_descTabTypeExpr.add(descTabTypeExpr386.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1335:24: ( partitionSpec )?
        int alt110 = 2;
        switch (input.LA(1)) {
          case KW_PARTITION: {
            alt110 = 1;
          }
          break;
        }

        switch (alt110) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1335:24: partitionSpec
          {
            pushFollow(FOLLOW_partitionSpec_in_descPartTypeExpr6521);
            partitionSpec387 = partitionSpec();

            state._fsp--;

            stream_partitionSpec.add(partitionSpec387.getTree());
          }
          break;
        }

        // AST REWRITE
        // elements: partitionSpec, descTabTypeExpr
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1335:39: -> ^( TOK_TABTYPE descTabTypeExpr ( partitionSpec )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1335:42: ^( TOK_TABTYPE descTabTypeExpr ( partitionSpec )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABTYPE, "TOK_TABTYPE"), root_1);

            adaptor.addChild(root_1, stream_descTabTypeExpr.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1335:72: ( partitionSpec )?
            if (stream_partitionSpec.hasNext()) {
              adaptor.addChild(root_1, stream_partitionSpec.nextTree());
            }
            stream_partitionSpec.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "descPartTypeExpr"

  public static class descStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "descStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1338:1: descStatement : ( ( KW_DESCRIBE | KW_DESC ) ( KW_DATABASE | KW_SCHEMA ) ( KW_EXTENDED )? (dbName= identifier ) -> ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? ) | ( KW_DESCRIBE | KW_DESC ) (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED |descOptions= KW_PRETTY )? (parttype= descPartTypeExpr ) -> ^( TOK_DESCTABLE $parttype ( $descOptions)? ) | ( KW_DESCRIBE | KW_DESC ) KW_FUNCTION ( KW_EXTENDED )? (name= descFuncNames ) -> ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? ) );
  public final HiveParser.descStatement_return descStatement() throws RecognitionException {
    HiveParser.descStatement_return retval = new HiveParser.descStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token descOptions = null;
    Token KW_DESCRIBE388 = null;
    Token KW_DESC389 = null;
    Token KW_DATABASE390 = null;
    Token KW_SCHEMA391 = null;
    Token KW_EXTENDED392 = null;
    Token KW_DESCRIBE393 = null;
    Token KW_DESC394 = null;
    Token KW_DESCRIBE395 = null;
    Token KW_DESC396 = null;
    Token KW_FUNCTION397 = null;
    Token KW_EXTENDED398 = null;
    HiveParser_IdentifiersParser.identifier_return dbName = null;

    HiveParser.descPartTypeExpr_return parttype = null;

    HiveParser_IdentifiersParser.descFuncNames_return name = null;

    CommonTree descOptions_tree = null;
    CommonTree KW_DESCRIBE388_tree = null;
    CommonTree KW_DESC389_tree = null;
    CommonTree KW_DATABASE390_tree = null;
    CommonTree KW_SCHEMA391_tree = null;
    CommonTree KW_EXTENDED392_tree = null;
    CommonTree KW_DESCRIBE393_tree = null;
    CommonTree KW_DESC394_tree = null;
    CommonTree KW_DESCRIBE395_tree = null;
    CommonTree KW_DESC396_tree = null;
    CommonTree KW_FUNCTION397_tree = null;
    CommonTree KW_EXTENDED398_tree = null;
    RewriteRuleTokenStream stream_KW_SCHEMA = new RewriteRuleTokenStream(adaptor, "token KW_SCHEMA");
    RewriteRuleTokenStream stream_KW_PRETTY = new RewriteRuleTokenStream(adaptor, "token KW_PRETTY");
    RewriteRuleTokenStream stream_KW_DATABASE = new RewriteRuleTokenStream(adaptor, "token KW_DATABASE");
    RewriteRuleTokenStream stream_KW_EXTENDED = new RewriteRuleTokenStream(adaptor, "token KW_EXTENDED");
    RewriteRuleTokenStream stream_KW_DESC = new RewriteRuleTokenStream(adaptor, "token KW_DESC");
    RewriteRuleTokenStream stream_KW_FUNCTION = new RewriteRuleTokenStream(adaptor, "token KW_FUNCTION");
    RewriteRuleTokenStream stream_KW_FORMATTED = new RewriteRuleTokenStream(adaptor, "token KW_FORMATTED");
    RewriteRuleTokenStream stream_KW_DESCRIBE = new RewriteRuleTokenStream(adaptor, "token KW_DESCRIBE");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_descPartTypeExpr = new RewriteRuleSubtreeStream(adaptor, "rule descPartTypeExpr");
    RewriteRuleSubtreeStream stream_descFuncNames = new RewriteRuleSubtreeStream(adaptor, "rule descFuncNames");
    pushMsg("describe statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1341:5: ( ( KW_DESCRIBE | KW_DESC ) ( KW_DATABASE | KW_SCHEMA ) ( KW_EXTENDED )? (dbName= identifier ) -> ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? ) | ( KW_DESCRIBE | KW_DESC ) (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED |descOptions= KW_PRETTY )? (parttype= descPartTypeExpr ) -> ^( TOK_DESCTABLE $parttype ( $descOptions)? ) | ( KW_DESCRIBE | KW_DESC ) KW_FUNCTION ( KW_EXTENDED )? (name= descFuncNames ) -> ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? ) )
      int alt118 = 3;
      switch (input.LA(1)) {
        case KW_DESCRIBE: {
          switch (input.LA(2)) {
            case KW_DATABASE: {
              alt118 = 1;
            }
            break;
            case KW_SCHEMA: {
              switch (input.LA(3)) {
                case KW_EXTENDED: {
                  alt118 = 1;
                }
                break;
                case Identifier: {
                  alt118 = 1;
                }
                break;
                case KW_PARTITION: {
                  alt118 = 1;
                }
                break;
                case EOF:
                case DOT: {
                  alt118 = 2;
                }
                break;
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFAULT:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_METADATA:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NONE:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH: {
                  alt118 = 1;
                }
                break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 118, 4, input);

                  throw nvae;
              }
            }
            break;
            case Identifier:
            case KW_ADD:
            case KW_ADMIN:
            case KW_AFTER:
            case KW_ALL:
            case KW_ALTER:
            case KW_ANALYZE:
            case KW_ARCHIVE:
            case KW_ARRAY:
            case KW_AS:
            case KW_ASC:
            case KW_AUTHORIZATION:
            case KW_BEFORE:
            case KW_BETWEEN:
            case KW_BIGINT:
            case KW_BINARY:
            case KW_BOOLEAN:
            case KW_BOTH:
            case KW_BUCKET:
            case KW_BUCKETS:
            case KW_BY:
            case KW_CASCADE:
            case KW_CHANGE:
            case KW_CLUSTER:
            case KW_CLUSTERED:
            case KW_CLUSTERSTATUS:
            case KW_COLLECTION:
            case KW_COLUMNS:
            case KW_COMMENT:
            case KW_COMPACT:
            case KW_COMPACTIONS:
            case KW_COMPUTE:
            case KW_CONCATENATE:
            case KW_CONTINUE:
            case KW_CREATE:
            case KW_CUBE:
            case KW_CURSOR:
            case KW_DATA:
            case KW_DATABASES:
            case KW_DATE:
            case KW_DATETIME:
            case KW_DBPROPERTIES:
            case KW_DECIMAL:
            case KW_DEFAULT:
            case KW_DEFERRED:
            case KW_DEFINED:
            case KW_DELETE:
            case KW_DELIMITED:
            case KW_DEPENDENCY:
            case KW_DESC:
            case KW_DESCRIBE:
            case KW_DIRECTORIES:
            case KW_DIRECTORY:
            case KW_DISABLE:
            case KW_DISTRIBUTE:
            case KW_DOUBLE:
            case KW_DROP:
            case KW_ELEM_TYPE:
            case KW_ENABLE:
            case KW_ESCAPED:
            case KW_EXCLUSIVE:
            case KW_EXISTS:
            case KW_EXPLAIN:
            case KW_EXPORT:
            case KW_EXTENDED:
            case KW_EXTERNAL:
            case KW_FALSE:
            case KW_FETCH:
            case KW_FIELDS:
            case KW_FILE:
            case KW_FILEFORMAT:
            case KW_FIRST:
            case KW_FLOAT:
            case KW_FOR:
            case KW_FORMAT:
            case KW_FORMATTED:
            case KW_FULL:
            case KW_FUNCTIONS:
            case KW_GRANT:
            case KW_GROUP:
            case KW_GROUPING:
            case KW_HOLD_DDLTIME:
            case KW_IDXPROPERTIES:
            case KW_IGNORE:
            case KW_IMPORT:
            case KW_IN:
            case KW_INDEX:
            case KW_INDEXES:
            case KW_INNER:
            case KW_INPATH:
            case KW_INPUTDRIVER:
            case KW_INPUTFORMAT:
            case KW_INSERT:
            case KW_INT:
            case KW_INTERSECT:
            case KW_INTO:
            case KW_IS:
            case KW_ITEMS:
            case KW_JAR:
            case KW_KEYS:
            case KW_KEY_TYPE:
            case KW_LATERAL:
            case KW_LEFT:
            case KW_LIKE:
            case KW_LIMIT:
            case KW_LINES:
            case KW_LOAD:
            case KW_LOCAL:
            case KW_LOCATION:
            case KW_LOCK:
            case KW_LOCKS:
            case KW_LOGICAL:
            case KW_LONG:
            case KW_MAPJOIN:
            case KW_MATERIALIZED:
            case KW_METADATA:
            case KW_MINUS:
            case KW_MSCK:
            case KW_NONE:
            case KW_NOSCAN:
            case KW_NO_DROP:
            case KW_NULL:
            case KW_OF:
            case KW_OFFLINE:
            case KW_OPTION:
            case KW_ORDER:
            case KW_OUT:
            case KW_OUTER:
            case KW_OUTPUTDRIVER:
            case KW_OUTPUTFORMAT:
            case KW_OVERWRITE:
            case KW_OWNER:
            case KW_PARTITION:
            case KW_PARTITIONED:
            case KW_PARTITIONS:
            case KW_PERCENT:
            case KW_PLUS:
            case KW_PRETTY:
            case KW_PRINCIPALS:
            case KW_PROCEDURE:
            case KW_PROTECTION:
            case KW_PURGE:
            case KW_RANGE:
            case KW_READ:
            case KW_READONLY:
            case KW_READS:
            case KW_REBUILD:
            case KW_RECORDREADER:
            case KW_RECORDWRITER:
            case KW_REGEXP:
            case KW_RELOAD:
            case KW_RENAME:
            case KW_REPAIR:
            case KW_REPLACE:
            case KW_REPLICATION:
            case KW_RESTRICT:
            case KW_REVOKE:
            case KW_REWRITE:
            case KW_RIGHT:
            case KW_RLIKE:
            case KW_ROLE:
            case KW_ROLES:
            case KW_ROLLUP:
            case KW_ROW:
            case KW_ROWS:
            case KW_SCHEMAS:
            case KW_SEMI:
            case KW_SERDE:
            case KW_SERDEPROPERTIES:
            case KW_SERVER:
            case KW_SET:
            case KW_SETS:
            case KW_SHARED:
            case KW_SHOW:
            case KW_SHOW_DATABASE:
            case KW_SKEWED:
            case KW_SMALLINT:
            case KW_SORT:
            case KW_SORTED:
            case KW_SSL:
            case KW_STATISTICS:
            case KW_STORED:
            case KW_STREAMTABLE:
            case KW_STRING:
            case KW_STRUCT:
            case KW_TABLE:
            case KW_TABLES:
            case KW_TBLPROPERTIES:
            case KW_TEMPORARY:
            case KW_TERMINATED:
            case KW_TIMESTAMP:
            case KW_TINYINT:
            case KW_TO:
            case KW_TOUCH:
            case KW_TRANSACTIONS:
            case KW_TRIGGER:
            case KW_TRUE:
            case KW_TRUNCATE:
            case KW_UNARCHIVE:
            case KW_UNDO:
            case KW_UNION:
            case KW_UNIONTYPE:
            case KW_UNLOCK:
            case KW_UNSET:
            case KW_UNSIGNED:
            case KW_UPDATE:
            case KW_URI:
            case KW_USE:
            case KW_USER:
            case KW_USING:
            case KW_UTC:
            case KW_UTCTIMESTAMP:
            case KW_VALUES:
            case KW_VALUE_TYPE:
            case KW_VIEW:
            case KW_WHILE:
            case KW_WITH: {
              alt118 = 2;
            }
            break;
            case KW_FUNCTION: {
              alt118 = 3;
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 118, 1, input);

              throw nvae;
          }
        }
        break;
        case KW_DESC: {
          switch (input.LA(2)) {
            case KW_DATABASE: {
              alt118 = 1;
            }
            break;
            case KW_SCHEMA: {
              switch (input.LA(3)) {
                case KW_EXTENDED: {
                  alt118 = 1;
                }
                break;
                case Identifier: {
                  alt118 = 1;
                }
                break;
                case KW_PARTITION: {
                  alt118 = 1;
                }
                break;
                case EOF:
                case DOT: {
                  alt118 = 2;
                }
                break;
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFAULT:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_METADATA:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NONE:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH: {
                  alt118 = 1;
                }
                break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 118, 12, input);

                  throw nvae;
              }
            }
            break;
            case Identifier:
            case KW_ADD:
            case KW_ADMIN:
            case KW_AFTER:
            case KW_ALL:
            case KW_ALTER:
            case KW_ANALYZE:
            case KW_ARCHIVE:
            case KW_ARRAY:
            case KW_AS:
            case KW_ASC:
            case KW_AUTHORIZATION:
            case KW_BEFORE:
            case KW_BETWEEN:
            case KW_BIGINT:
            case KW_BINARY:
            case KW_BOOLEAN:
            case KW_BOTH:
            case KW_BUCKET:
            case KW_BUCKETS:
            case KW_BY:
            case KW_CASCADE:
            case KW_CHANGE:
            case KW_CLUSTER:
            case KW_CLUSTERED:
            case KW_CLUSTERSTATUS:
            case KW_COLLECTION:
            case KW_COLUMNS:
            case KW_COMMENT:
            case KW_COMPACT:
            case KW_COMPACTIONS:
            case KW_COMPUTE:
            case KW_CONCATENATE:
            case KW_CONTINUE:
            case KW_CREATE:
            case KW_CUBE:
            case KW_CURSOR:
            case KW_DATA:
            case KW_DATABASES:
            case KW_DATE:
            case KW_DATETIME:
            case KW_DBPROPERTIES:
            case KW_DECIMAL:
            case KW_DEFAULT:
            case KW_DEFERRED:
            case KW_DEFINED:
            case KW_DELETE:
            case KW_DELIMITED:
            case KW_DEPENDENCY:
            case KW_DESC:
            case KW_DESCRIBE:
            case KW_DIRECTORIES:
            case KW_DIRECTORY:
            case KW_DISABLE:
            case KW_DISTRIBUTE:
            case KW_DOUBLE:
            case KW_DROP:
            case KW_ELEM_TYPE:
            case KW_ENABLE:
            case KW_ESCAPED:
            case KW_EXCLUSIVE:
            case KW_EXISTS:
            case KW_EXPLAIN:
            case KW_EXPORT:
            case KW_EXTENDED:
            case KW_EXTERNAL:
            case KW_FALSE:
            case KW_FETCH:
            case KW_FIELDS:
            case KW_FILE:
            case KW_FILEFORMAT:
            case KW_FIRST:
            case KW_FLOAT:
            case KW_FOR:
            case KW_FORMAT:
            case KW_FORMATTED:
            case KW_FULL:
            case KW_FUNCTIONS:
            case KW_GRANT:
            case KW_GROUP:
            case KW_GROUPING:
            case KW_HOLD_DDLTIME:
            case KW_IDXPROPERTIES:
            case KW_IGNORE:
            case KW_IMPORT:
            case KW_IN:
            case KW_INDEX:
            case KW_INDEXES:
            case KW_INNER:
            case KW_INPATH:
            case KW_INPUTDRIVER:
            case KW_INPUTFORMAT:
            case KW_INSERT:
            case KW_INT:
            case KW_INTERSECT:
            case KW_INTO:
            case KW_IS:
            case KW_ITEMS:
            case KW_JAR:
            case KW_KEYS:
            case KW_KEY_TYPE:
            case KW_LATERAL:
            case KW_LEFT:
            case KW_LIKE:
            case KW_LIMIT:
            case KW_LINES:
            case KW_LOAD:
            case KW_LOCAL:
            case KW_LOCATION:
            case KW_LOCK:
            case KW_LOCKS:
            case KW_LOGICAL:
            case KW_LONG:
            case KW_MAPJOIN:
            case KW_MATERIALIZED:
            case KW_METADATA:
            case KW_MINUS:
            case KW_MSCK:
            case KW_NONE:
            case KW_NOSCAN:
            case KW_NO_DROP:
            case KW_NULL:
            case KW_OF:
            case KW_OFFLINE:
            case KW_OPTION:
            case KW_ORDER:
            case KW_OUT:
            case KW_OUTER:
            case KW_OUTPUTDRIVER:
            case KW_OUTPUTFORMAT:
            case KW_OVERWRITE:
            case KW_OWNER:
            case KW_PARTITION:
            case KW_PARTITIONED:
            case KW_PARTITIONS:
            case KW_PERCENT:
            case KW_PLUS:
            case KW_PRETTY:
            case KW_PRINCIPALS:
            case KW_PROCEDURE:
            case KW_PROTECTION:
            case KW_PURGE:
            case KW_RANGE:
            case KW_READ:
            case KW_READONLY:
            case KW_READS:
            case KW_REBUILD:
            case KW_RECORDREADER:
            case KW_RECORDWRITER:
            case KW_REGEXP:
            case KW_RELOAD:
            case KW_RENAME:
            case KW_REPAIR:
            case KW_REPLACE:
            case KW_REPLICATION:
            case KW_RESTRICT:
            case KW_REVOKE:
            case KW_REWRITE:
            case KW_RIGHT:
            case KW_RLIKE:
            case KW_ROLE:
            case KW_ROLES:
            case KW_ROLLUP:
            case KW_ROW:
            case KW_ROWS:
            case KW_SCHEMAS:
            case KW_SEMI:
            case KW_SERDE:
            case KW_SERDEPROPERTIES:
            case KW_SERVER:
            case KW_SET:
            case KW_SETS:
            case KW_SHARED:
            case KW_SHOW:
            case KW_SHOW_DATABASE:
            case KW_SKEWED:
            case KW_SMALLINT:
            case KW_SORT:
            case KW_SORTED:
            case KW_SSL:
            case KW_STATISTICS:
            case KW_STORED:
            case KW_STREAMTABLE:
            case KW_STRING:
            case KW_STRUCT:
            case KW_TABLE:
            case KW_TABLES:
            case KW_TBLPROPERTIES:
            case KW_TEMPORARY:
            case KW_TERMINATED:
            case KW_TIMESTAMP:
            case KW_TINYINT:
            case KW_TO:
            case KW_TOUCH:
            case KW_TRANSACTIONS:
            case KW_TRIGGER:
            case KW_TRUE:
            case KW_TRUNCATE:
            case KW_UNARCHIVE:
            case KW_UNDO:
            case KW_UNION:
            case KW_UNIONTYPE:
            case KW_UNLOCK:
            case KW_UNSET:
            case KW_UNSIGNED:
            case KW_UPDATE:
            case KW_URI:
            case KW_USE:
            case KW_USER:
            case KW_USING:
            case KW_UTC:
            case KW_UTCTIMESTAMP:
            case KW_VALUES:
            case KW_VALUE_TYPE:
            case KW_VIEW:
            case KW_WHILE:
            case KW_WITH: {
              alt118 = 2;
            }
            break;
            case KW_FUNCTION: {
              alt118 = 3;
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 118, 2, input);

              throw nvae;
          }
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 118, 0, input);

          throw nvae;
      }

      switch (alt118) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1341:7: ( KW_DESCRIBE | KW_DESC ) ( KW_DATABASE | KW_SCHEMA ) ( KW_EXTENDED )? (dbName= identifier )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1341:7: ( KW_DESCRIBE | KW_DESC )
          int alt111 = 2;
          switch (input.LA(1)) {
            case KW_DESCRIBE: {
              alt111 = 1;
            }
            break;
            case KW_DESC: {
              alt111 = 2;
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 111, 0, input);

              throw nvae;
          }

          switch (alt111) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1341:8: KW_DESCRIBE
            {
              KW_DESCRIBE388 = (Token) match(input, KW_DESCRIBE, FOLLOW_KW_DESCRIBE_in_descStatement6561);
              stream_KW_DESCRIBE.add(KW_DESCRIBE388);
            }
            break;
            case 2:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1341:20: KW_DESC
            {
              KW_DESC389 = (Token) match(input, KW_DESC, FOLLOW_KW_DESC_in_descStatement6563);
              stream_KW_DESC.add(KW_DESC389);
            }
            break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1341:29: ( KW_DATABASE | KW_SCHEMA )
          int alt112 = 2;
          switch (input.LA(1)) {
            case KW_DATABASE: {
              alt112 = 1;
            }
            break;
            case KW_SCHEMA: {
              alt112 = 2;
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 112, 0, input);

              throw nvae;
          }

          switch (alt112) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1341:30: KW_DATABASE
            {
              KW_DATABASE390 = (Token) match(input, KW_DATABASE, FOLLOW_KW_DATABASE_in_descStatement6567);
              stream_KW_DATABASE.add(KW_DATABASE390);
            }
            break;
            case 2:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1341:42: KW_SCHEMA
            {
              KW_SCHEMA391 = (Token) match(input, KW_SCHEMA, FOLLOW_KW_SCHEMA_in_descStatement6569);
              stream_KW_SCHEMA.add(KW_SCHEMA391);
            }
            break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1341:53: ( KW_EXTENDED )?
          int alt113 = 2;
          switch (input.LA(1)) {
            case KW_EXTENDED: {
              alt113 = 1;
            }
            break;
          }

          switch (alt113) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1341:53: KW_EXTENDED
            {
              KW_EXTENDED392 = (Token) match(input, KW_EXTENDED, FOLLOW_KW_EXTENDED_in_descStatement6572);
              stream_KW_EXTENDED.add(KW_EXTENDED392);
            }
            break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1341:66: (dbName= identifier )
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1341:67: dbName= identifier
          {
            pushFollow(FOLLOW_identifier_in_descStatement6578);
            dbName = identifier();

            state._fsp--;

            stream_identifier.add(dbName.getTree());
          }

          // AST REWRITE
          // elements: KW_EXTENDED, dbName
          // token labels:
          // rule labels: dbName, retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_dbName =
              new RewriteRuleSubtreeStream(adaptor, "rule dbName", dbName != null ? dbName.tree : null);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1341:86: -> ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1341:89: ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DESCDATABASE, "TOK_DESCDATABASE"),
                      root_1);

              adaptor.addChild(root_1, stream_dbName.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1341:116: ( KW_EXTENDED )?
              if (stream_KW_EXTENDED.hasNext()) {
                adaptor.addChild(root_1, stream_KW_EXTENDED.nextNode());
              }
              stream_KW_EXTENDED.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1342:7: ( KW_DESCRIBE | KW_DESC ) (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED |descOptions= KW_PRETTY )? (parttype= descPartTypeExpr )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1342:7: ( KW_DESCRIBE | KW_DESC )
          int alt114 = 2;
          switch (input.LA(1)) {
            case KW_DESCRIBE: {
              alt114 = 1;
            }
            break;
            case KW_DESC: {
              alt114 = 2;
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 114, 0, input);

              throw nvae;
          }

          switch (alt114) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1342:8: KW_DESCRIBE
            {
              KW_DESCRIBE393 = (Token) match(input, KW_DESCRIBE, FOLLOW_KW_DESCRIBE_in_descStatement6600);
              stream_KW_DESCRIBE.add(KW_DESCRIBE393);
            }
            break;
            case 2:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1342:20: KW_DESC
            {
              KW_DESC394 = (Token) match(input, KW_DESC, FOLLOW_KW_DESC_in_descStatement6602);
              stream_KW_DESC.add(KW_DESC394);
            }
            break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1342:29: (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED |descOptions= KW_PRETTY )?
          int alt115 = 4;
          switch (input.LA(1)) {
            case KW_FORMATTED: {
              switch (input.LA(2)) {
                case Identifier: {
                  alt115 = 1;
                }
                break;
                case KW_PARTITION: {
                  alt115 = 1;
                }
                break;
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFAULT:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_METADATA:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NONE:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH: {
                  alt115 = 1;
                }
                break;
              }
            }
            break;
            case KW_EXTENDED: {
              alt115 = 2;
            }
            break;
            case KW_PRETTY: {
              switch (input.LA(2)) {
                case Identifier: {
                  alt115 = 3;
                }
                break;
                case KW_PARTITION: {
                  alt115 = 3;
                }
                break;
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFAULT:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_METADATA:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NONE:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH: {
                  alt115 = 3;
                }
                break;
              }
            }
            break;
          }

          switch (alt115) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1342:30: descOptions= KW_FORMATTED
            {
              descOptions = (Token) match(input, KW_FORMATTED, FOLLOW_KW_FORMATTED_in_descStatement6608);
              stream_KW_FORMATTED.add(descOptions);
            }
            break;
            case 2:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1342:55: descOptions= KW_EXTENDED
            {
              descOptions = (Token) match(input, KW_EXTENDED, FOLLOW_KW_EXTENDED_in_descStatement6612);
              stream_KW_EXTENDED.add(descOptions);
            }
            break;
            case 3:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1342:79: descOptions= KW_PRETTY
            {
              descOptions = (Token) match(input, KW_PRETTY, FOLLOW_KW_PRETTY_in_descStatement6616);
              stream_KW_PRETTY.add(descOptions);
            }
            break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1342:103: (parttype= descPartTypeExpr )
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1342:104: parttype= descPartTypeExpr
          {
            pushFollow(FOLLOW_descPartTypeExpr_in_descStatement6623);
            parttype = descPartTypeExpr();

            state._fsp--;

            stream_descPartTypeExpr.add(parttype.getTree());
          }

          // AST REWRITE
          // elements: parttype, descOptions
          // token labels: descOptions
          // rule labels: parttype, retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleTokenStream stream_descOptions =
              new RewriteRuleTokenStream(adaptor, "token descOptions", descOptions);
          RewriteRuleSubtreeStream stream_parttype =
              new RewriteRuleSubtreeStream(adaptor, "rule parttype", parttype != null ? parttype.tree : null);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1342:131: -> ^( TOK_DESCTABLE $parttype ( $descOptions)? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1342:134: ^( TOK_DESCTABLE $parttype ( $descOptions)? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DESCTABLE, "TOK_DESCTABLE"), root_1);

              adaptor.addChild(root_1, stream_parttype.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1342:161: ( $descOptions)?
              if (stream_descOptions.hasNext()) {
                adaptor.addChild(root_1, stream_descOptions.nextNode());
              }
              stream_descOptions.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 3:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1343:7: ( KW_DESCRIBE | KW_DESC ) KW_FUNCTION ( KW_EXTENDED )? (name= descFuncNames )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1343:7: ( KW_DESCRIBE | KW_DESC )
          int alt116 = 2;
          switch (input.LA(1)) {
            case KW_DESCRIBE: {
              alt116 = 1;
            }
            break;
            case KW_DESC: {
              alt116 = 2;
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 116, 0, input);

              throw nvae;
          }

          switch (alt116) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1343:8: KW_DESCRIBE
            {
              KW_DESCRIBE395 = (Token) match(input, KW_DESCRIBE, FOLLOW_KW_DESCRIBE_in_descStatement6646);
              stream_KW_DESCRIBE.add(KW_DESCRIBE395);
            }
            break;
            case 2:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1343:20: KW_DESC
            {
              KW_DESC396 = (Token) match(input, KW_DESC, FOLLOW_KW_DESC_in_descStatement6648);
              stream_KW_DESC.add(KW_DESC396);
            }
            break;
          }

          KW_FUNCTION397 = (Token) match(input, KW_FUNCTION, FOLLOW_KW_FUNCTION_in_descStatement6651);
          stream_KW_FUNCTION.add(KW_FUNCTION397);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1343:41: ( KW_EXTENDED )?
          int alt117 = 2;
          switch (input.LA(1)) {
            case KW_EXTENDED: {
              alt117 = 1;
            }
            break;
          }

          switch (alt117) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1343:41: KW_EXTENDED
            {
              KW_EXTENDED398 = (Token) match(input, KW_EXTENDED, FOLLOW_KW_EXTENDED_in_descStatement6653);
              stream_KW_EXTENDED.add(KW_EXTENDED398);
            }
            break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1343:54: (name= descFuncNames )
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1343:55: name= descFuncNames
          {
            pushFollow(FOLLOW_descFuncNames_in_descStatement6659);
            name = descFuncNames();

            state._fsp--;

            stream_descFuncNames.add(name.getTree());
          }

          // AST REWRITE
          // elements: KW_EXTENDED, name
          // token labels:
          // rule labels: name, retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_name =
              new RewriteRuleSubtreeStream(adaptor, "rule name", name != null ? name.tree : null);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1343:75: -> ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1343:78: ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DESCFUNCTION, "TOK_DESCFUNCTION"),
                      root_1);

              adaptor.addChild(root_1, stream_name.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1343:103: ( KW_EXTENDED )?
              if (stream_KW_EXTENDED.hasNext()) {
                adaptor.addChild(root_1, stream_KW_EXTENDED.nextNode());
              }
              stream_KW_EXTENDED.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "descStatement"

  public static class analyzeStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "analyzeStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1347:1: analyzeStatement : KW_ANALYZE KW_TABLE (parttype= tableOrPartition ) KW_COMPUTE KW_STATISTICS ( (noscan= KW_NOSCAN ) | (partialscan= KW_PARTIALSCAN ) | ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? ) )? -> ^( TOK_ANALYZE $parttype ( $noscan)? ( $partialscan)? ( KW_COLUMNS )? ( $statsColumnName)? ) ;
  public final HiveParser.analyzeStatement_return analyzeStatement() throws RecognitionException {
    HiveParser.analyzeStatement_return retval = new HiveParser.analyzeStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token noscan = null;
    Token partialscan = null;
    Token KW_ANALYZE399 = null;
    Token KW_TABLE400 = null;
    Token KW_COMPUTE401 = null;
    Token KW_STATISTICS402 = null;
    Token KW_FOR403 = null;
    Token KW_COLUMNS404 = null;
    HiveParser_IdentifiersParser.tableOrPartition_return parttype = null;

    HiveParser.columnNameList_return statsColumnName = null;

    CommonTree noscan_tree = null;
    CommonTree partialscan_tree = null;
    CommonTree KW_ANALYZE399_tree = null;
    CommonTree KW_TABLE400_tree = null;
    CommonTree KW_COMPUTE401_tree = null;
    CommonTree KW_STATISTICS402_tree = null;
    CommonTree KW_FOR403_tree = null;
    CommonTree KW_COLUMNS404_tree = null;
    RewriteRuleTokenStream stream_KW_STATISTICS = new RewriteRuleTokenStream(adaptor, "token KW_STATISTICS");
    RewriteRuleTokenStream stream_KW_ANALYZE = new RewriteRuleTokenStream(adaptor, "token KW_ANALYZE");
    RewriteRuleTokenStream stream_KW_COLUMNS = new RewriteRuleTokenStream(adaptor, "token KW_COLUMNS");
    RewriteRuleTokenStream stream_KW_FOR = new RewriteRuleTokenStream(adaptor, "token KW_FOR");
    RewriteRuleTokenStream stream_KW_PARTIALSCAN = new RewriteRuleTokenStream(adaptor, "token KW_PARTIALSCAN");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleTokenStream stream_KW_COMPUTE = new RewriteRuleTokenStream(adaptor, "token KW_COMPUTE");
    RewriteRuleTokenStream stream_KW_NOSCAN = new RewriteRuleTokenStream(adaptor, "token KW_NOSCAN");
    RewriteRuleSubtreeStream stream_tableOrPartition = new RewriteRuleSubtreeStream(adaptor, "rule tableOrPartition");
    RewriteRuleSubtreeStream stream_columnNameList = new RewriteRuleSubtreeStream(adaptor, "rule columnNameList");
    pushMsg("analyze statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1350:5: ( KW_ANALYZE KW_TABLE (parttype= tableOrPartition ) KW_COMPUTE KW_STATISTICS ( (noscan= KW_NOSCAN ) | (partialscan= KW_PARTIALSCAN ) | ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? ) )? -> ^( TOK_ANALYZE $parttype ( $noscan)? ( $partialscan)? ( KW_COLUMNS )? ( $statsColumnName)? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1350:7: KW_ANALYZE KW_TABLE (parttype= tableOrPartition ) KW_COMPUTE KW_STATISTICS ( (noscan= KW_NOSCAN ) | (partialscan= KW_PARTIALSCAN ) | ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? ) )?
      {
        KW_ANALYZE399 = (Token) match(input, KW_ANALYZE, FOLLOW_KW_ANALYZE_in_analyzeStatement6700);
        stream_KW_ANALYZE.add(KW_ANALYZE399);

        KW_TABLE400 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_analyzeStatement6702);
        stream_KW_TABLE.add(KW_TABLE400);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1350:27: (parttype= tableOrPartition )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1350:28: parttype= tableOrPartition
        {
          pushFollow(FOLLOW_tableOrPartition_in_analyzeStatement6707);
          parttype = tableOrPartition();

          state._fsp--;

          stream_tableOrPartition.add(parttype.getTree());
        }

        KW_COMPUTE401 = (Token) match(input, KW_COMPUTE, FOLLOW_KW_COMPUTE_in_analyzeStatement6710);
        stream_KW_COMPUTE.add(KW_COMPUTE401);

        KW_STATISTICS402 = (Token) match(input, KW_STATISTICS, FOLLOW_KW_STATISTICS_in_analyzeStatement6712);
        stream_KW_STATISTICS.add(KW_STATISTICS402);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1350:80: ( (noscan= KW_NOSCAN ) | (partialscan= KW_PARTIALSCAN ) | ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? ) )?
        int alt120 = 4;
        switch (input.LA(1)) {
          case KW_NOSCAN: {
            alt120 = 1;
          }
          break;
          case KW_PARTIALSCAN: {
            alt120 = 2;
          }
          break;
          case KW_FOR: {
            alt120 = 3;
          }
          break;
        }

        switch (alt120) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1350:81: (noscan= KW_NOSCAN )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1350:81: (noscan= KW_NOSCAN )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1350:82: noscan= KW_NOSCAN
            {
              noscan = (Token) match(input, KW_NOSCAN, FOLLOW_KW_NOSCAN_in_analyzeStatement6718);
              stream_KW_NOSCAN.add(noscan);
            }
          }
          break;
          case 2:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1350:102: (partialscan= KW_PARTIALSCAN )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1350:102: (partialscan= KW_PARTIALSCAN )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1350:103: partialscan= KW_PARTIALSCAN
            {
              partialscan = (Token) match(input, KW_PARTIALSCAN, FOLLOW_KW_PARTIALSCAN_in_analyzeStatement6726);
              stream_KW_PARTIALSCAN.add(partialscan);
            }
          }
          break;
          case 3:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:57: ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:57: ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? )
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:58: KW_FOR KW_COLUMNS (statsColumnName= columnNameList )?
            {
              KW_FOR403 = (Token) match(input, KW_FOR, FOLLOW_KW_FOR_in_analyzeStatement6787);
              stream_KW_FOR.add(KW_FOR403);

              KW_COLUMNS404 = (Token) match(input, KW_COLUMNS, FOLLOW_KW_COLUMNS_in_analyzeStatement6789);
              stream_KW_COLUMNS.add(KW_COLUMNS404);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:76: (statsColumnName= columnNameList )?
              int alt119 = 2;
              switch (input.LA(1)) {
                case Identifier:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFAULT:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_METADATA:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NONE:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITION:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH: {
                  alt119 = 1;
                }
                break;
              }

              switch (alt119) {
                case 1:
                  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:77: statsColumnName= columnNameList
                {
                  pushFollow(FOLLOW_columnNameList_in_analyzeStatement6794);
                  statsColumnName = columnNameList();

                  state._fsp--;

                  stream_columnNameList.add(statsColumnName.getTree());
                }
                break;
              }
            }
          }
          break;
        }

        // AST REWRITE
        // elements: partialscan, noscan, KW_COLUMNS, statsColumnName, parttype
        // token labels: partialscan, noscan
        // rule labels: statsColumnName, parttype, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_partialscan =
            new RewriteRuleTokenStream(adaptor, "token partialscan", partialscan);
        RewriteRuleTokenStream stream_noscan = new RewriteRuleTokenStream(adaptor, "token noscan", noscan);
        RewriteRuleSubtreeStream stream_statsColumnName = new RewriteRuleSubtreeStream(adaptor, "rule statsColumnName",
            statsColumnName != null ? statsColumnName.tree : null);
        RewriteRuleSubtreeStream stream_parttype =
            new RewriteRuleSubtreeStream(adaptor, "rule parttype", parttype != null ? parttype.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1352:7: -> ^( TOK_ANALYZE $parttype ( $noscan)? ( $partialscan)? ( KW_COLUMNS )? ( $statsColumnName)? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1352:10: ^( TOK_ANALYZE $parttype ( $noscan)? ( $partialscan)? ( KW_COLUMNS )? ( $statsColumnName)? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_ANALYZE, "TOK_ANALYZE"), root_1);

            adaptor.addChild(root_1, stream_parttype.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1352:35: ( $noscan)?
            if (stream_noscan.hasNext()) {
              adaptor.addChild(root_1, stream_noscan.nextNode());
            }
            stream_noscan.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1352:44: ( $partialscan)?
            if (stream_partialscan.hasNext()) {
              adaptor.addChild(root_1, stream_partialscan.nextNode());
            }
            stream_partialscan.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1352:57: ( KW_COLUMNS )?
            if (stream_KW_COLUMNS.hasNext()) {
              adaptor.addChild(root_1, stream_KW_COLUMNS.nextNode());
            }
            stream_KW_COLUMNS.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1352:70: ( $statsColumnName)?
            if (stream_statsColumnName.hasNext()) {
              adaptor.addChild(root_1, stream_statsColumnName.nextTree());
            }
            stream_statsColumnName.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "analyzeStatement"

  public static class showStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "showStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1355:1: showStatement : ( KW_SHOW ( KW_DATABASES | KW_SCHEMAS ) ( KW_LIKE showStmtIdentifier )? -> ^( TOK_SHOWDATABASES ( showStmtIdentifier )? ) | KW_SHOW KW_TABLES ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )? -> ^( TOK_SHOWTABLES ( TOK_FROM $db_name)? ( showStmtIdentifier )? ) | KW_SHOW KW_COLUMNS ( KW_FROM | KW_IN ) tableName ( ( KW_FROM | KW_IN ) db_name= identifier )? -> ^( TOK_SHOWCOLUMNS tableName ( $db_name)? ) | KW_SHOW KW_FUNCTIONS ( KW_LIKE showFunctionIdentifier | showFunctionIdentifier )? -> ^( TOK_SHOWFUNCTIONS ( KW_LIKE )? ( showFunctionIdentifier )? ) | KW_SHOW KW_PARTITIONS tabName= tableName ( partitionSpec )? -> ^( TOK_SHOWPARTITIONS $tabName ( partitionSpec )? ) | KW_SHOW KW_CREATE KW_TABLE tabName= tableName -> ^( TOK_SHOW_CREATETABLE $tabName) | KW_SHOW KW_TABLE KW_EXTENDED ( ( KW_FROM | KW_IN ) db_name= identifier )? KW_LIKE showStmtIdentifier ( partitionSpec )? -> ^( TOK_SHOW_TABLESTATUS showStmtIdentifier ( $db_name)? ( partitionSpec )? ) | KW_SHOW KW_TBLPROPERTIES tableName ( LPAREN prptyName= StringLiteral RPAREN )? -> ^( TOK_SHOW_TBLPROPERTIES tableName ( $prptyName)? ) | KW_SHOW KW_LOCKS (parttype= partTypeExpr )? (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? ) | KW_SHOW KW_LOCKS ( KW_DATABASE | KW_SCHEMA ) (dbName= Identifier ) (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWDBLOCKS $dbName ( $isExtended)? ) | KW_SHOW (showOptions= KW_FORMATTED )? ( KW_INDEX | KW_INDEXES ) KW_ON showStmtIdentifier ( ( KW_FROM | KW_IN ) db_name= identifier )? -> ^( TOK_SHOWINDEXES showStmtIdentifier ( $showOptions)? ( $db_name)? ) | KW_SHOW KW_COMPACTIONS -> ^( TOK_SHOW_COMPACTIONS ) | KW_SHOW KW_TRANSACTIONS -> ^( TOK_SHOW_TRANSACTIONS ) | KW_SHOW KW_CONF StringLiteral -> ^( TOK_SHOWCONF StringLiteral ) );
  public final HiveParser.showStatement_return showStatement() throws RecognitionException {
    HiveParser.showStatement_return retval = new HiveParser.showStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token prptyName = null;
    Token isExtended = null;
    Token dbName = null;
    Token showOptions = null;
    Token KW_SHOW405 = null;
    Token KW_DATABASES406 = null;
    Token KW_SCHEMAS407 = null;
    Token KW_LIKE408 = null;
    Token KW_SHOW410 = null;
    Token KW_TABLES411 = null;
    Token KW_FROM412 = null;
    Token KW_IN413 = null;
    Token KW_LIKE414 = null;
    Token KW_SHOW417 = null;
    Token KW_COLUMNS418 = null;
    Token KW_FROM419 = null;
    Token KW_IN420 = null;
    Token KW_FROM422 = null;
    Token KW_IN423 = null;
    Token KW_SHOW424 = null;
    Token KW_FUNCTIONS425 = null;
    Token KW_LIKE426 = null;
    Token KW_SHOW429 = null;
    Token KW_PARTITIONS430 = null;
    Token KW_SHOW432 = null;
    Token KW_CREATE433 = null;
    Token KW_TABLE434 = null;
    Token KW_SHOW435 = null;
    Token KW_TABLE436 = null;
    Token KW_EXTENDED437 = null;
    Token KW_FROM438 = null;
    Token KW_IN439 = null;
    Token KW_LIKE440 = null;
    Token KW_SHOW443 = null;
    Token KW_TBLPROPERTIES444 = null;
    Token LPAREN446 = null;
    Token RPAREN447 = null;
    Token KW_SHOW448 = null;
    Token KW_LOCKS449 = null;
    Token KW_SHOW450 = null;
    Token KW_LOCKS451 = null;
    Token KW_DATABASE452 = null;
    Token KW_SCHEMA453 = null;
    Token KW_SHOW454 = null;
    Token KW_INDEX455 = null;
    Token KW_INDEXES456 = null;
    Token KW_ON457 = null;
    Token KW_FROM459 = null;
    Token KW_IN460 = null;
    Token KW_SHOW461 = null;
    Token KW_COMPACTIONS462 = null;
    Token KW_SHOW463 = null;
    Token KW_TRANSACTIONS464 = null;
    Token KW_SHOW465 = null;
    Token KW_CONF466 = null;
    Token StringLiteral467 = null;
    HiveParser_IdentifiersParser.identifier_return db_name = null;

    HiveParser_FromClauseParser.tableName_return tabName = null;

    HiveParser.partTypeExpr_return parttype = null;

    HiveParser.showStmtIdentifier_return showStmtIdentifier409 = null;

    HiveParser.showStmtIdentifier_return showStmtIdentifier415 = null;

    HiveParser.showStmtIdentifier_return showStmtIdentifier416 = null;

    HiveParser_FromClauseParser.tableName_return tableName421 = null;

    HiveParser.showFunctionIdentifier_return showFunctionIdentifier427 = null;

    HiveParser.showFunctionIdentifier_return showFunctionIdentifier428 = null;

    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec431 = null;

    HiveParser.showStmtIdentifier_return showStmtIdentifier441 = null;

    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec442 = null;

    HiveParser_FromClauseParser.tableName_return tableName445 = null;

    HiveParser.showStmtIdentifier_return showStmtIdentifier458 = null;

    CommonTree prptyName_tree = null;
    CommonTree isExtended_tree = null;
    CommonTree dbName_tree = null;
    CommonTree showOptions_tree = null;
    CommonTree KW_SHOW405_tree = null;
    CommonTree KW_DATABASES406_tree = null;
    CommonTree KW_SCHEMAS407_tree = null;
    CommonTree KW_LIKE408_tree = null;
    CommonTree KW_SHOW410_tree = null;
    CommonTree KW_TABLES411_tree = null;
    CommonTree KW_FROM412_tree = null;
    CommonTree KW_IN413_tree = null;
    CommonTree KW_LIKE414_tree = null;
    CommonTree KW_SHOW417_tree = null;
    CommonTree KW_COLUMNS418_tree = null;
    CommonTree KW_FROM419_tree = null;
    CommonTree KW_IN420_tree = null;
    CommonTree KW_FROM422_tree = null;
    CommonTree KW_IN423_tree = null;
    CommonTree KW_SHOW424_tree = null;
    CommonTree KW_FUNCTIONS425_tree = null;
    CommonTree KW_LIKE426_tree = null;
    CommonTree KW_SHOW429_tree = null;
    CommonTree KW_PARTITIONS430_tree = null;
    CommonTree KW_SHOW432_tree = null;
    CommonTree KW_CREATE433_tree = null;
    CommonTree KW_TABLE434_tree = null;
    CommonTree KW_SHOW435_tree = null;
    CommonTree KW_TABLE436_tree = null;
    CommonTree KW_EXTENDED437_tree = null;
    CommonTree KW_FROM438_tree = null;
    CommonTree KW_IN439_tree = null;
    CommonTree KW_LIKE440_tree = null;
    CommonTree KW_SHOW443_tree = null;
    CommonTree KW_TBLPROPERTIES444_tree = null;
    CommonTree LPAREN446_tree = null;
    CommonTree RPAREN447_tree = null;
    CommonTree KW_SHOW448_tree = null;
    CommonTree KW_LOCKS449_tree = null;
    CommonTree KW_SHOW450_tree = null;
    CommonTree KW_LOCKS451_tree = null;
    CommonTree KW_DATABASE452_tree = null;
    CommonTree KW_SCHEMA453_tree = null;
    CommonTree KW_SHOW454_tree = null;
    CommonTree KW_INDEX455_tree = null;
    CommonTree KW_INDEXES456_tree = null;
    CommonTree KW_ON457_tree = null;
    CommonTree KW_FROM459_tree = null;
    CommonTree KW_IN460_tree = null;
    CommonTree KW_SHOW461_tree = null;
    CommonTree KW_COMPACTIONS462_tree = null;
    CommonTree KW_SHOW463_tree = null;
    CommonTree KW_TRANSACTIONS464_tree = null;
    CommonTree KW_SHOW465_tree = null;
    CommonTree KW_CONF466_tree = null;
    CommonTree StringLiteral467_tree = null;
    RewriteRuleTokenStream stream_KW_DATABASE = new RewriteRuleTokenStream(adaptor, "token KW_DATABASE");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleTokenStream stream_KW_LIKE = new RewriteRuleTokenStream(adaptor, "token KW_LIKE");
    RewriteRuleTokenStream stream_KW_PARTITIONS = new RewriteRuleTokenStream(adaptor, "token KW_PARTITIONS");
    RewriteRuleTokenStream stream_KW_IN = new RewriteRuleTokenStream(adaptor, "token KW_IN");
    RewriteRuleTokenStream stream_KW_LOCKS = new RewriteRuleTokenStream(adaptor, "token KW_LOCKS");
    RewriteRuleTokenStream stream_Identifier = new RewriteRuleTokenStream(adaptor, "token Identifier");
    RewriteRuleTokenStream stream_KW_TABLES = new RewriteRuleTokenStream(adaptor, "token KW_TABLES");
    RewriteRuleTokenStream stream_KW_FUNCTIONS = new RewriteRuleTokenStream(adaptor, "token KW_FUNCTIONS");
    RewriteRuleTokenStream stream_KW_CREATE = new RewriteRuleTokenStream(adaptor, "token KW_CREATE");
    RewriteRuleTokenStream stream_KW_EXTENDED = new RewriteRuleTokenStream(adaptor, "token KW_EXTENDED");
    RewriteRuleTokenStream stream_KW_CONF = new RewriteRuleTokenStream(adaptor, "token KW_CONF");
    RewriteRuleTokenStream stream_KW_COLUMNS = new RewriteRuleTokenStream(adaptor, "token KW_COLUMNS");
    RewriteRuleTokenStream stream_KW_TRANSACTIONS = new RewriteRuleTokenStream(adaptor, "token KW_TRANSACTIONS");
    RewriteRuleTokenStream stream_KW_SCHEMAS = new RewriteRuleTokenStream(adaptor, "token KW_SCHEMAS");
    RewriteRuleTokenStream stream_KW_FROM = new RewriteRuleTokenStream(adaptor, "token KW_FROM");
    RewriteRuleTokenStream stream_KW_ON = new RewriteRuleTokenStream(adaptor, "token KW_ON");
    RewriteRuleTokenStream stream_KW_FORMATTED = new RewriteRuleTokenStream(adaptor, "token KW_FORMATTED");
    RewriteRuleTokenStream stream_KW_SCHEMA = new RewriteRuleTokenStream(adaptor, "token KW_SCHEMA");
    RewriteRuleTokenStream stream_KW_INDEX = new RewriteRuleTokenStream(adaptor, "token KW_INDEX");
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_KW_COMPACTIONS = new RewriteRuleTokenStream(adaptor, "token KW_COMPACTIONS");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleTokenStream stream_KW_DATABASES = new RewriteRuleTokenStream(adaptor, "token KW_DATABASES");
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_INDEXES = new RewriteRuleTokenStream(adaptor, "token KW_INDEXES");
    RewriteRuleTokenStream stream_KW_SHOW = new RewriteRuleTokenStream(adaptor, "token KW_SHOW");
    RewriteRuleTokenStream stream_KW_TBLPROPERTIES = new RewriteRuleTokenStream(adaptor, "token KW_TBLPROPERTIES");
    RewriteRuleSubtreeStream stream_showStmtIdentifier =
        new RewriteRuleSubtreeStream(adaptor, "rule showStmtIdentifier");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_showFunctionIdentifier =
        new RewriteRuleSubtreeStream(adaptor, "rule showFunctionIdentifier");
    RewriteRuleSubtreeStream stream_partTypeExpr = new RewriteRuleSubtreeStream(adaptor, "rule partTypeExpr");
    RewriteRuleSubtreeStream stream_partitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule partitionSpec");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    pushMsg("show statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1358:5: ( KW_SHOW ( KW_DATABASES | KW_SCHEMAS ) ( KW_LIKE showStmtIdentifier )? -> ^( TOK_SHOWDATABASES ( showStmtIdentifier )? ) | KW_SHOW KW_TABLES ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )? -> ^( TOK_SHOWTABLES ( TOK_FROM $db_name)? ( showStmtIdentifier )? ) | KW_SHOW KW_COLUMNS ( KW_FROM | KW_IN ) tableName ( ( KW_FROM | KW_IN ) db_name= identifier )? -> ^( TOK_SHOWCOLUMNS tableName ( $db_name)? ) | KW_SHOW KW_FUNCTIONS ( KW_LIKE showFunctionIdentifier | showFunctionIdentifier )? -> ^( TOK_SHOWFUNCTIONS ( KW_LIKE )? ( showFunctionIdentifier )? ) | KW_SHOW KW_PARTITIONS tabName= tableName ( partitionSpec )? -> ^( TOK_SHOWPARTITIONS $tabName ( partitionSpec )? ) | KW_SHOW KW_CREATE KW_TABLE tabName= tableName -> ^( TOK_SHOW_CREATETABLE $tabName) | KW_SHOW KW_TABLE KW_EXTENDED ( ( KW_FROM | KW_IN ) db_name= identifier )? KW_LIKE showStmtIdentifier ( partitionSpec )? -> ^( TOK_SHOW_TABLESTATUS showStmtIdentifier ( $db_name)? ( partitionSpec )? ) | KW_SHOW KW_TBLPROPERTIES tableName ( LPAREN prptyName= StringLiteral RPAREN )? -> ^( TOK_SHOW_TBLPROPERTIES tableName ( $prptyName)? ) | KW_SHOW KW_LOCKS (parttype= partTypeExpr )? (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? ) | KW_SHOW KW_LOCKS ( KW_DATABASE | KW_SCHEMA ) (dbName= Identifier ) (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWDBLOCKS $dbName ( $isExtended)? ) | KW_SHOW (showOptions= KW_FORMATTED )? ( KW_INDEX | KW_INDEXES ) KW_ON showStmtIdentifier ( ( KW_FROM | KW_IN ) db_name= identifier )? -> ^( TOK_SHOWINDEXES showStmtIdentifier ( $showOptions)? ( $db_name)? ) | KW_SHOW KW_COMPACTIONS -> ^( TOK_SHOW_COMPACTIONS ) | KW_SHOW KW_TRANSACTIONS -> ^( TOK_SHOW_TRANSACTIONS ) | KW_SHOW KW_CONF StringLiteral -> ^( TOK_SHOWCONF StringLiteral ) )
      int alt143 = 14;
      switch (input.LA(1)) {
        case KW_SHOW: {
          switch (input.LA(2)) {
            case KW_TABLES: {
              alt143 = 2;
            }
            break;
            case KW_COLUMNS: {
              alt143 = 3;
            }
            break;
            case KW_FUNCTIONS: {
              alt143 = 4;
            }
            break;
            case KW_PARTITIONS: {
              alt143 = 5;
            }
            break;
            case KW_CREATE: {
              alt143 = 6;
            }
            break;
            case KW_TABLE: {
              alt143 = 7;
            }
            break;
            case KW_TBLPROPERTIES: {
              alt143 = 8;
            }
            break;
            case KW_LOCKS: {
              switch (input.LA(3)) {
                case EOF:
                case Identifier:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFAULT:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTENDED:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_METADATA:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NONE:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITION:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH: {
                  alt143 = 9;
                }
                break;
                case KW_SCHEMA: {
                  alt143 = 9;
                }
                break;
                case KW_DATABASE: {
                  alt143 = 10;
                }
                break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 143, 9, input);

                  throw nvae;
              }
            }
            break;
            case KW_COMPACTIONS: {
              alt143 = 12;
            }
            break;
            case KW_TRANSACTIONS: {
              alt143 = 13;
            }
            break;
            case KW_CONF: {
              alt143 = 14;
            }
            break;
            case KW_DATABASES:
            case KW_SCHEMAS: {
              alt143 = 1;
            }
            break;
            case KW_FORMATTED:
            case KW_INDEX:
            case KW_INDEXES: {
              alt143 = 11;
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 143, 1, input);

              throw nvae;
          }
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 143, 0, input);

          throw nvae;
      }

      switch (alt143) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1358:7: KW_SHOW ( KW_DATABASES | KW_SCHEMAS ) ( KW_LIKE showStmtIdentifier )?
        {
          KW_SHOW405 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showStatement6856);
          stream_KW_SHOW.add(KW_SHOW405);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1358:15: ( KW_DATABASES | KW_SCHEMAS )
          int alt121 = 2;
          switch (input.LA(1)) {
            case KW_DATABASES: {
              alt121 = 1;
            }
            break;
            case KW_SCHEMAS: {
              alt121 = 2;
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 121, 0, input);

              throw nvae;
          }

          switch (alt121) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1358:16: KW_DATABASES
            {
              KW_DATABASES406 = (Token) match(input, KW_DATABASES, FOLLOW_KW_DATABASES_in_showStatement6859);
              stream_KW_DATABASES.add(KW_DATABASES406);
            }
            break;
            case 2:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1358:29: KW_SCHEMAS
            {
              KW_SCHEMAS407 = (Token) match(input, KW_SCHEMAS, FOLLOW_KW_SCHEMAS_in_showStatement6861);
              stream_KW_SCHEMAS.add(KW_SCHEMAS407);
            }
            break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1358:41: ( KW_LIKE showStmtIdentifier )?
          int alt122 = 2;
          switch (input.LA(1)) {
            case KW_LIKE: {
              alt122 = 1;
            }
            break;
          }

          switch (alt122) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1358:42: KW_LIKE showStmtIdentifier
            {
              KW_LIKE408 = (Token) match(input, KW_LIKE, FOLLOW_KW_LIKE_in_showStatement6865);
              stream_KW_LIKE.add(KW_LIKE408);

              pushFollow(FOLLOW_showStmtIdentifier_in_showStatement6867);
              showStmtIdentifier409 = showStmtIdentifier();

              state._fsp--;

              stream_showStmtIdentifier.add(showStmtIdentifier409.getTree());
            }
            break;
          }

          // AST REWRITE
          // elements: showStmtIdentifier
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1358:71: -> ^( TOK_SHOWDATABASES ( showStmtIdentifier )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1358:74: ^( TOK_SHOWDATABASES ( showStmtIdentifier )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SHOWDATABASES, "TOK_SHOWDATABASES"),
                      root_1);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1358:94: ( showStmtIdentifier )?
              if (stream_showStmtIdentifier.hasNext()) {
                adaptor.addChild(root_1, stream_showStmtIdentifier.nextTree());
              }
              stream_showStmtIdentifier.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1359:7: KW_SHOW KW_TABLES ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )?
        {
          KW_SHOW410 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showStatement6886);
          stream_KW_SHOW.add(KW_SHOW410);

          KW_TABLES411 = (Token) match(input, KW_TABLES, FOLLOW_KW_TABLES_in_showStatement6888);
          stream_KW_TABLES.add(KW_TABLES411);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1359:25: ( ( KW_FROM | KW_IN ) db_name= identifier )?
          int alt124 = 2;
          switch (input.LA(1)) {
            case KW_FROM: {
              alt124 = 1;
            }
            break;
            case KW_IN: {
              switch (input.LA(2)) {
                case Identifier:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFAULT:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_METADATA:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NONE:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITION:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH: {
                  alt124 = 1;
                }
                break;
              }
            }
            break;
          }

          switch (alt124) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1359:26: ( KW_FROM | KW_IN ) db_name= identifier
            {
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1359:26: ( KW_FROM | KW_IN )
              int alt123 = 2;
              switch (input.LA(1)) {
                case KW_FROM: {
                  alt123 = 1;
                }
                break;
                case KW_IN: {
                  alt123 = 2;
                }
                break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 123, 0, input);

                  throw nvae;
              }

              switch (alt123) {
                case 1:
                  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1359:27: KW_FROM
                {
                  KW_FROM412 = (Token) match(input, KW_FROM, FOLLOW_KW_FROM_in_showStatement6892);
                  stream_KW_FROM.add(KW_FROM412);
                }
                break;
                case 2:
                  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1359:35: KW_IN
                {
                  KW_IN413 = (Token) match(input, KW_IN, FOLLOW_KW_IN_in_showStatement6894);
                  stream_KW_IN.add(KW_IN413);
                }
                break;
              }

              pushFollow(FOLLOW_identifier_in_showStatement6899);
              db_name = identifier();

              state._fsp--;

              stream_identifier.add(db_name.getTree());
            }
            break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1359:63: ( KW_LIKE showStmtIdentifier | showStmtIdentifier )?
          int alt125 = 3;
          switch (input.LA(1)) {
            case KW_LIKE: {
              switch (input.LA(2)) {
                case Identifier:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFAULT:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_METADATA:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NONE:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITION:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH:
                case StringLiteral: {
                  alt125 = 1;
                }
                break;
                case EOF: {
                  alt125 = 2;
                }
                break;
              }
            }
            break;
            case Identifier:
            case KW_ADD:
            case KW_ADMIN:
            case KW_AFTER:
            case KW_ALL:
            case KW_ALTER:
            case KW_ANALYZE:
            case KW_ARCHIVE:
            case KW_ARRAY:
            case KW_AS:
            case KW_ASC:
            case KW_AUTHORIZATION:
            case KW_BEFORE:
            case KW_BETWEEN:
            case KW_BIGINT:
            case KW_BINARY:
            case KW_BOOLEAN:
            case KW_BOTH:
            case KW_BUCKET:
            case KW_BUCKETS:
            case KW_BY:
            case KW_CASCADE:
            case KW_CHANGE:
            case KW_CLUSTER:
            case KW_CLUSTERED:
            case KW_CLUSTERSTATUS:
            case KW_COLLECTION:
            case KW_COLUMNS:
            case KW_COMMENT:
            case KW_COMPACT:
            case KW_COMPACTIONS:
            case KW_COMPUTE:
            case KW_CONCATENATE:
            case KW_CONTINUE:
            case KW_CREATE:
            case KW_CUBE:
            case KW_CURSOR:
            case KW_DATA:
            case KW_DATABASES:
            case KW_DATE:
            case KW_DATETIME:
            case KW_DBPROPERTIES:
            case KW_DECIMAL:
            case KW_DEFAULT:
            case KW_DEFERRED:
            case KW_DEFINED:
            case KW_DELETE:
            case KW_DELIMITED:
            case KW_DEPENDENCY:
            case KW_DESC:
            case KW_DESCRIBE:
            case KW_DIRECTORIES:
            case KW_DIRECTORY:
            case KW_DISABLE:
            case KW_DISTRIBUTE:
            case KW_DOUBLE:
            case KW_DROP:
            case KW_ELEM_TYPE:
            case KW_ENABLE:
            case KW_ESCAPED:
            case KW_EXCLUSIVE:
            case KW_EXISTS:
            case KW_EXPLAIN:
            case KW_EXPORT:
            case KW_EXTERNAL:
            case KW_FALSE:
            case KW_FETCH:
            case KW_FIELDS:
            case KW_FILE:
            case KW_FILEFORMAT:
            case KW_FIRST:
            case KW_FLOAT:
            case KW_FOR:
            case KW_FORMAT:
            case KW_FORMATTED:
            case KW_FULL:
            case KW_FUNCTIONS:
            case KW_GRANT:
            case KW_GROUP:
            case KW_GROUPING:
            case KW_HOLD_DDLTIME:
            case KW_IDXPROPERTIES:
            case KW_IGNORE:
            case KW_IMPORT:
            case KW_IN:
            case KW_INDEX:
            case KW_INDEXES:
            case KW_INNER:
            case KW_INPATH:
            case KW_INPUTDRIVER:
            case KW_INPUTFORMAT:
            case KW_INSERT:
            case KW_INT:
            case KW_INTERSECT:
            case KW_INTO:
            case KW_IS:
            case KW_ITEMS:
            case KW_JAR:
            case KW_KEYS:
            case KW_KEY_TYPE:
            case KW_LATERAL:
            case KW_LEFT:
            case KW_LIMIT:
            case KW_LINES:
            case KW_LOAD:
            case KW_LOCAL:
            case KW_LOCATION:
            case KW_LOCK:
            case KW_LOCKS:
            case KW_LOGICAL:
            case KW_LONG:
            case KW_MAPJOIN:
            case KW_MATERIALIZED:
            case KW_METADATA:
            case KW_MINUS:
            case KW_MSCK:
            case KW_NONE:
            case KW_NOSCAN:
            case KW_NO_DROP:
            case KW_NULL:
            case KW_OF:
            case KW_OFFLINE:
            case KW_OPTION:
            case KW_ORDER:
            case KW_OUT:
            case KW_OUTER:
            case KW_OUTPUTDRIVER:
            case KW_OUTPUTFORMAT:
            case KW_OVERWRITE:
            case KW_OWNER:
            case KW_PARTITION:
            case KW_PARTITIONED:
            case KW_PARTITIONS:
            case KW_PERCENT:
            case KW_PLUS:
            case KW_PRETTY:
            case KW_PRINCIPALS:
            case KW_PROCEDURE:
            case KW_PROTECTION:
            case KW_PURGE:
            case KW_RANGE:
            case KW_READ:
            case KW_READONLY:
            case KW_READS:
            case KW_REBUILD:
            case KW_RECORDREADER:
            case KW_RECORDWRITER:
            case KW_REGEXP:
            case KW_RELOAD:
            case KW_RENAME:
            case KW_REPAIR:
            case KW_REPLACE:
            case KW_REPLICATION:
            case KW_RESTRICT:
            case KW_REVOKE:
            case KW_REWRITE:
            case KW_RIGHT:
            case KW_RLIKE:
            case KW_ROLE:
            case KW_ROLES:
            case KW_ROLLUP:
            case KW_ROW:
            case KW_ROWS:
            case KW_SCHEMA:
            case KW_SCHEMAS:
            case KW_SEMI:
            case KW_SERDE:
            case KW_SERDEPROPERTIES:
            case KW_SERVER:
            case KW_SET:
            case KW_SETS:
            case KW_SHARED:
            case KW_SHOW:
            case KW_SHOW_DATABASE:
            case KW_SKEWED:
            case KW_SMALLINT:
            case KW_SORT:
            case KW_SORTED:
            case KW_SSL:
            case KW_STATISTICS:
            case KW_STORED:
            case KW_STREAMTABLE:
            case KW_STRING:
            case KW_STRUCT:
            case KW_TABLE:
            case KW_TABLES:
            case KW_TBLPROPERTIES:
            case KW_TEMPORARY:
            case KW_TERMINATED:
            case KW_TIMESTAMP:
            case KW_TINYINT:
            case KW_TO:
            case KW_TOUCH:
            case KW_TRANSACTIONS:
            case KW_TRIGGER:
            case KW_TRUE:
            case KW_TRUNCATE:
            case KW_UNARCHIVE:
            case KW_UNDO:
            case KW_UNION:
            case KW_UNIONTYPE:
            case KW_UNLOCK:
            case KW_UNSET:
            case KW_UNSIGNED:
            case KW_UPDATE:
            case KW_URI:
            case KW_USE:
            case KW_USER:
            case KW_USING:
            case KW_UTC:
            case KW_UTCTIMESTAMP:
            case KW_VALUES:
            case KW_VALUE_TYPE:
            case KW_VIEW:
            case KW_WHILE:
            case KW_WITH:
            case StringLiteral: {
              alt125 = 2;
            }
            break;
          }

          switch (alt125) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1359:64: KW_LIKE showStmtIdentifier
            {
              KW_LIKE414 = (Token) match(input, KW_LIKE, FOLLOW_KW_LIKE_in_showStatement6904);
              stream_KW_LIKE.add(KW_LIKE414);

              pushFollow(FOLLOW_showStmtIdentifier_in_showStatement6906);
              showStmtIdentifier415 = showStmtIdentifier();

              state._fsp--;

              stream_showStmtIdentifier.add(showStmtIdentifier415.getTree());
            }
            break;
            case 2:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1359:91: showStmtIdentifier
            {
              pushFollow(FOLLOW_showStmtIdentifier_in_showStatement6908);
              showStmtIdentifier416 = showStmtIdentifier();

              state._fsp--;

              stream_showStmtIdentifier.add(showStmtIdentifier416.getTree());
            }
            break;
          }

          // AST REWRITE
          // elements: db_name, showStmtIdentifier
          // token labels:
          // rule labels: db_name, retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_db_name =
              new RewriteRuleSubtreeStream(adaptor, "rule db_name", db_name != null ? db_name.tree : null);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1359:113: -> ^( TOK_SHOWTABLES ( TOK_FROM $db_name)? ( showStmtIdentifier )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1359:116: ^( TOK_SHOWTABLES ( TOK_FROM $db_name)? ( showStmtIdentifier )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SHOWTABLES, "TOK_SHOWTABLES"),
                  root_1);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1359:133: ( TOK_FROM $db_name)?
              if (stream_db_name.hasNext()) {
                adaptor.addChild(root_1, (CommonTree) adaptor.create(TOK_FROM, "TOK_FROM"));

                adaptor.addChild(root_1, stream_db_name.nextTree());
              }
              stream_db_name.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1359:154: ( showStmtIdentifier )?
              if (stream_showStmtIdentifier.hasNext()) {
                adaptor.addChild(root_1, stream_showStmtIdentifier.nextTree());
              }
              stream_showStmtIdentifier.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 3:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:7: KW_SHOW KW_COLUMNS ( KW_FROM | KW_IN ) tableName ( ( KW_FROM | KW_IN ) db_name= identifier )?
        {
          KW_SHOW417 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showStatement6936);
          stream_KW_SHOW.add(KW_SHOW417);

          KW_COLUMNS418 = (Token) match(input, KW_COLUMNS, FOLLOW_KW_COLUMNS_in_showStatement6938);
          stream_KW_COLUMNS.add(KW_COLUMNS418);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:26: ( KW_FROM | KW_IN )
          int alt126 = 2;
          switch (input.LA(1)) {
            case KW_FROM: {
              alt126 = 1;
            }
            break;
            case KW_IN: {
              alt126 = 2;
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 126, 0, input);

              throw nvae;
          }

          switch (alt126) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:27: KW_FROM
            {
              KW_FROM419 = (Token) match(input, KW_FROM, FOLLOW_KW_FROM_in_showStatement6941);
              stream_KW_FROM.add(KW_FROM419);
            }
            break;
            case 2:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:35: KW_IN
            {
              KW_IN420 = (Token) match(input, KW_IN, FOLLOW_KW_IN_in_showStatement6943);
              stream_KW_IN.add(KW_IN420);
            }
            break;
          }

          pushFollow(FOLLOW_tableName_in_showStatement6946);
          tableName421 = tableName();

          state._fsp--;

          stream_tableName.add(tableName421.getTree());

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:52: ( ( KW_FROM | KW_IN ) db_name= identifier )?
          int alt128 = 2;
          switch (input.LA(1)) {
            case KW_FROM:
            case KW_IN: {
              alt128 = 1;
            }
            break;
          }

          switch (alt128) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:53: ( KW_FROM | KW_IN ) db_name= identifier
            {
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:53: ( KW_FROM | KW_IN )
              int alt127 = 2;
              switch (input.LA(1)) {
                case KW_FROM: {
                  alt127 = 1;
                }
                break;
                case KW_IN: {
                  alt127 = 2;
                }
                break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 127, 0, input);

                  throw nvae;
              }

              switch (alt127) {
                case 1:
                  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:54: KW_FROM
                {
                  KW_FROM422 = (Token) match(input, KW_FROM, FOLLOW_KW_FROM_in_showStatement6950);
                  stream_KW_FROM.add(KW_FROM422);
                }
                break;
                case 2:
                  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:62: KW_IN
                {
                  KW_IN423 = (Token) match(input, KW_IN, FOLLOW_KW_IN_in_showStatement6952);
                  stream_KW_IN.add(KW_IN423);
                }
                break;
              }

              pushFollow(FOLLOW_identifier_in_showStatement6957);
              db_name = identifier();

              state._fsp--;

              stream_identifier.add(db_name.getTree());
            }
            break;
          }

          // AST REWRITE
          // elements: db_name, tableName
          // token labels:
          // rule labels: db_name, retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_db_name =
              new RewriteRuleSubtreeStream(adaptor, "rule db_name", db_name != null ? db_name.tree : null);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1361:5: -> ^( TOK_SHOWCOLUMNS tableName ( $db_name)? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1361:8: ^( TOK_SHOWCOLUMNS tableName ( $db_name)? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SHOWCOLUMNS, "TOK_SHOWCOLUMNS"),
                  root_1);

              adaptor.addChild(root_1, stream_tableName.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1361:37: ( $db_name)?
              if (stream_db_name.hasNext()) {
                adaptor.addChild(root_1, stream_db_name.nextTree());
              }
              stream_db_name.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 4:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1362:7: KW_SHOW KW_FUNCTIONS ( KW_LIKE showFunctionIdentifier | showFunctionIdentifier )?
        {
          KW_SHOW424 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showStatement6983);
          stream_KW_SHOW.add(KW_SHOW424);

          KW_FUNCTIONS425 = (Token) match(input, KW_FUNCTIONS, FOLLOW_KW_FUNCTIONS_in_showStatement6985);
          stream_KW_FUNCTIONS.add(KW_FUNCTIONS425);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1362:28: ( KW_LIKE showFunctionIdentifier | showFunctionIdentifier )?
          int alt129 = 3;
          switch (input.LA(1)) {
            case KW_LIKE: {
              switch (input.LA(2)) {
                case Identifier:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFAULT:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_METADATA:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NONE:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITION:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH:
                case StringLiteral: {
                  alt129 = 1;
                }
                break;
                case EOF:
                case DOT: {
                  alt129 = 2;
                }
                break;
              }
            }
            break;
            case Identifier:
            case KW_ADD:
            case KW_ADMIN:
            case KW_AFTER:
            case KW_ALL:
            case KW_ALTER:
            case KW_ANALYZE:
            case KW_ARCHIVE:
            case KW_ARRAY:
            case KW_AS:
            case KW_ASC:
            case KW_AUTHORIZATION:
            case KW_BEFORE:
            case KW_BETWEEN:
            case KW_BIGINT:
            case KW_BINARY:
            case KW_BOOLEAN:
            case KW_BOTH:
            case KW_BUCKET:
            case KW_BUCKETS:
            case KW_BY:
            case KW_CASCADE:
            case KW_CHANGE:
            case KW_CLUSTER:
            case KW_CLUSTERED:
            case KW_CLUSTERSTATUS:
            case KW_COLLECTION:
            case KW_COLUMNS:
            case KW_COMMENT:
            case KW_COMPACT:
            case KW_COMPACTIONS:
            case KW_COMPUTE:
            case KW_CONCATENATE:
            case KW_CONTINUE:
            case KW_CREATE:
            case KW_CUBE:
            case KW_CURSOR:
            case KW_DATA:
            case KW_DATABASES:
            case KW_DATE:
            case KW_DATETIME:
            case KW_DBPROPERTIES:
            case KW_DECIMAL:
            case KW_DEFAULT:
            case KW_DEFERRED:
            case KW_DEFINED:
            case KW_DELETE:
            case KW_DELIMITED:
            case KW_DEPENDENCY:
            case KW_DESC:
            case KW_DESCRIBE:
            case KW_DIRECTORIES:
            case KW_DIRECTORY:
            case KW_DISABLE:
            case KW_DISTRIBUTE:
            case KW_DOUBLE:
            case KW_DROP:
            case KW_ELEM_TYPE:
            case KW_ENABLE:
            case KW_ESCAPED:
            case KW_EXCLUSIVE:
            case KW_EXISTS:
            case KW_EXPLAIN:
            case KW_EXPORT:
            case KW_EXTERNAL:
            case KW_FALSE:
            case KW_FETCH:
            case KW_FIELDS:
            case KW_FILE:
            case KW_FILEFORMAT:
            case KW_FIRST:
            case KW_FLOAT:
            case KW_FOR:
            case KW_FORMAT:
            case KW_FORMATTED:
            case KW_FULL:
            case KW_FUNCTIONS:
            case KW_GRANT:
            case KW_GROUP:
            case KW_GROUPING:
            case KW_HOLD_DDLTIME:
            case KW_IDXPROPERTIES:
            case KW_IGNORE:
            case KW_IMPORT:
            case KW_IN:
            case KW_INDEX:
            case KW_INDEXES:
            case KW_INNER:
            case KW_INPATH:
            case KW_INPUTDRIVER:
            case KW_INPUTFORMAT:
            case KW_INSERT:
            case KW_INT:
            case KW_INTERSECT:
            case KW_INTO:
            case KW_IS:
            case KW_ITEMS:
            case KW_JAR:
            case KW_KEYS:
            case KW_KEY_TYPE:
            case KW_LATERAL:
            case KW_LEFT:
            case KW_LIMIT:
            case KW_LINES:
            case KW_LOAD:
            case KW_LOCAL:
            case KW_LOCATION:
            case KW_LOCK:
            case KW_LOCKS:
            case KW_LOGICAL:
            case KW_LONG:
            case KW_MAPJOIN:
            case KW_MATERIALIZED:
            case KW_METADATA:
            case KW_MINUS:
            case KW_MSCK:
            case KW_NONE:
            case KW_NOSCAN:
            case KW_NO_DROP:
            case KW_NULL:
            case KW_OF:
            case KW_OFFLINE:
            case KW_OPTION:
            case KW_ORDER:
            case KW_OUT:
            case KW_OUTER:
            case KW_OUTPUTDRIVER:
            case KW_OUTPUTFORMAT:
            case KW_OVERWRITE:
            case KW_OWNER:
            case KW_PARTITION:
            case KW_PARTITIONED:
            case KW_PARTITIONS:
            case KW_PERCENT:
            case KW_PLUS:
            case KW_PRETTY:
            case KW_PRINCIPALS:
            case KW_PROCEDURE:
            case KW_PROTECTION:
            case KW_PURGE:
            case KW_RANGE:
            case KW_READ:
            case KW_READONLY:
            case KW_READS:
            case KW_REBUILD:
            case KW_RECORDREADER:
            case KW_RECORDWRITER:
            case KW_REGEXP:
            case KW_RELOAD:
            case KW_RENAME:
            case KW_REPAIR:
            case KW_REPLACE:
            case KW_REPLICATION:
            case KW_RESTRICT:
            case KW_REVOKE:
            case KW_REWRITE:
            case KW_RIGHT:
            case KW_RLIKE:
            case KW_ROLE:
            case KW_ROLES:
            case KW_ROLLUP:
            case KW_ROW:
            case KW_ROWS:
            case KW_SCHEMA:
            case KW_SCHEMAS:
            case KW_SEMI:
            case KW_SERDE:
            case KW_SERDEPROPERTIES:
            case KW_SERVER:
            case KW_SET:
            case KW_SETS:
            case KW_SHARED:
            case KW_SHOW:
            case KW_SHOW_DATABASE:
            case KW_SKEWED:
            case KW_SMALLINT:
            case KW_SORT:
            case KW_SORTED:
            case KW_SSL:
            case KW_STATISTICS:
            case KW_STORED:
            case KW_STREAMTABLE:
            case KW_STRING:
            case KW_STRUCT:
            case KW_TABLE:
            case KW_TABLES:
            case KW_TBLPROPERTIES:
            case KW_TEMPORARY:
            case KW_TERMINATED:
            case KW_TIMESTAMP:
            case KW_TINYINT:
            case KW_TO:
            case KW_TOUCH:
            case KW_TRANSACTIONS:
            case KW_TRIGGER:
            case KW_TRUE:
            case KW_TRUNCATE:
            case KW_UNARCHIVE:
            case KW_UNDO:
            case KW_UNION:
            case KW_UNIONTYPE:
            case KW_UNLOCK:
            case KW_UNSET:
            case KW_UNSIGNED:
            case KW_UPDATE:
            case KW_URI:
            case KW_USE:
            case KW_USER:
            case KW_USING:
            case KW_UTC:
            case KW_UTCTIMESTAMP:
            case KW_VALUES:
            case KW_VALUE_TYPE:
            case KW_VIEW:
            case KW_WHILE:
            case KW_WITH:
            case StringLiteral: {
              alt129 = 2;
            }
            break;
          }

          switch (alt129) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1362:29: KW_LIKE showFunctionIdentifier
            {
              KW_LIKE426 = (Token) match(input, KW_LIKE, FOLLOW_KW_LIKE_in_showStatement6988);
              stream_KW_LIKE.add(KW_LIKE426);

              pushFollow(FOLLOW_showFunctionIdentifier_in_showStatement6990);
              showFunctionIdentifier427 = showFunctionIdentifier();

              state._fsp--;

              stream_showFunctionIdentifier.add(showFunctionIdentifier427.getTree());
            }
            break;
            case 2:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1362:60: showFunctionIdentifier
            {
              pushFollow(FOLLOW_showFunctionIdentifier_in_showStatement6992);
              showFunctionIdentifier428 = showFunctionIdentifier();

              state._fsp--;

              stream_showFunctionIdentifier.add(showFunctionIdentifier428.getTree());
            }
            break;
          }

          // AST REWRITE
          // elements: KW_LIKE, showFunctionIdentifier
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1362:86: -> ^( TOK_SHOWFUNCTIONS ( KW_LIKE )? ( showFunctionIdentifier )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1362:89: ^( TOK_SHOWFUNCTIONS ( KW_LIKE )? ( showFunctionIdentifier )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SHOWFUNCTIONS, "TOK_SHOWFUNCTIONS"),
                      root_1);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1362:109: ( KW_LIKE )?
              if (stream_KW_LIKE.hasNext()) {
                adaptor.addChild(root_1, stream_KW_LIKE.nextNode());
              }
              stream_KW_LIKE.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1362:118: ( showFunctionIdentifier )?
              if (stream_showFunctionIdentifier.hasNext()) {
                adaptor.addChild(root_1, stream_showFunctionIdentifier.nextTree());
              }
              stream_showFunctionIdentifier.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 5:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1363:7: KW_SHOW KW_PARTITIONS tabName= tableName ( partitionSpec )?
        {
          KW_SHOW429 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showStatement7015);
          stream_KW_SHOW.add(KW_SHOW429);

          KW_PARTITIONS430 = (Token) match(input, KW_PARTITIONS, FOLLOW_KW_PARTITIONS_in_showStatement7017);
          stream_KW_PARTITIONS.add(KW_PARTITIONS430);

          pushFollow(FOLLOW_tableName_in_showStatement7021);
          tabName = tableName();

          state._fsp--;

          stream_tableName.add(tabName.getTree());

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1363:47: ( partitionSpec )?
          int alt130 = 2;
          switch (input.LA(1)) {
            case KW_PARTITION: {
              alt130 = 1;
            }
            break;
          }

          switch (alt130) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1363:47: partitionSpec
            {
              pushFollow(FOLLOW_partitionSpec_in_showStatement7023);
              partitionSpec431 = partitionSpec();

              state._fsp--;

              stream_partitionSpec.add(partitionSpec431.getTree());
            }
            break;
          }

          // AST REWRITE
          // elements: partitionSpec, tabName
          // token labels:
          // rule labels: tabName, retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_tabName =
              new RewriteRuleSubtreeStream(adaptor, "rule tabName", tabName != null ? tabName.tree : null);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1363:62: -> ^( TOK_SHOWPARTITIONS $tabName ( partitionSpec )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1363:65: ^( TOK_SHOWPARTITIONS $tabName ( partitionSpec )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SHOWPARTITIONS, "TOK_SHOWPARTITIONS"),
                      root_1);

              adaptor.addChild(root_1, stream_tabName.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1363:95: ( partitionSpec )?
              if (stream_partitionSpec.hasNext()) {
                adaptor.addChild(root_1, stream_partitionSpec.nextTree());
              }
              stream_partitionSpec.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 6:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1364:7: KW_SHOW KW_CREATE KW_TABLE tabName= tableName
        {
          KW_SHOW432 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showStatement7045);
          stream_KW_SHOW.add(KW_SHOW432);

          KW_CREATE433 = (Token) match(input, KW_CREATE, FOLLOW_KW_CREATE_in_showStatement7047);
          stream_KW_CREATE.add(KW_CREATE433);

          KW_TABLE434 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_showStatement7049);
          stream_KW_TABLE.add(KW_TABLE434);

          pushFollow(FOLLOW_tableName_in_showStatement7053);
          tabName = tableName();

          state._fsp--;

          stream_tableName.add(tabName.getTree());

          // AST REWRITE
          // elements: tabName
          // token labels:
          // rule labels: tabName, retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_tabName =
              new RewriteRuleSubtreeStream(adaptor, "rule tabName", tabName != null ? tabName.tree : null);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1364:52: -> ^( TOK_SHOW_CREATETABLE $tabName)
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1364:55: ^( TOK_SHOW_CREATETABLE $tabName)
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_SHOW_CREATETABLE, "TOK_SHOW_CREATETABLE"), root_1);

              adaptor.addChild(root_1, stream_tabName.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 7:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1365:7: KW_SHOW KW_TABLE KW_EXTENDED ( ( KW_FROM | KW_IN ) db_name= identifier )? KW_LIKE showStmtIdentifier ( partitionSpec )?
        {
          KW_SHOW435 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showStatement7070);
          stream_KW_SHOW.add(KW_SHOW435);

          KW_TABLE436 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_showStatement7072);
          stream_KW_TABLE.add(KW_TABLE436);

          KW_EXTENDED437 = (Token) match(input, KW_EXTENDED, FOLLOW_KW_EXTENDED_in_showStatement7074);
          stream_KW_EXTENDED.add(KW_EXTENDED437);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1365:36: ( ( KW_FROM | KW_IN ) db_name= identifier )?
          int alt132 = 2;
          switch (input.LA(1)) {
            case KW_FROM:
            case KW_IN: {
              alt132 = 1;
            }
            break;
          }

          switch (alt132) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1365:37: ( KW_FROM | KW_IN ) db_name= identifier
            {
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1365:37: ( KW_FROM | KW_IN )
              int alt131 = 2;
              switch (input.LA(1)) {
                case KW_FROM: {
                  alt131 = 1;
                }
                break;
                case KW_IN: {
                  alt131 = 2;
                }
                break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 131, 0, input);

                  throw nvae;
              }

              switch (alt131) {
                case 1:
                  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1365:38: KW_FROM
                {
                  KW_FROM438 = (Token) match(input, KW_FROM, FOLLOW_KW_FROM_in_showStatement7078);
                  stream_KW_FROM.add(KW_FROM438);
                }
                break;
                case 2:
                  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1365:46: KW_IN
                {
                  KW_IN439 = (Token) match(input, KW_IN, FOLLOW_KW_IN_in_showStatement7080);
                  stream_KW_IN.add(KW_IN439);
                }
                break;
              }

              pushFollow(FOLLOW_identifier_in_showStatement7085);
              db_name = identifier();

              state._fsp--;

              stream_identifier.add(db_name.getTree());
            }
            break;
          }

          KW_LIKE440 = (Token) match(input, KW_LIKE, FOLLOW_KW_LIKE_in_showStatement7089);
          stream_KW_LIKE.add(KW_LIKE440);

          pushFollow(FOLLOW_showStmtIdentifier_in_showStatement7091);
          showStmtIdentifier441 = showStmtIdentifier();

          state._fsp--;

          stream_showStmtIdentifier.add(showStmtIdentifier441.getTree());

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1365:101: ( partitionSpec )?
          int alt133 = 2;
          switch (input.LA(1)) {
            case KW_PARTITION: {
              alt133 = 1;
            }
            break;
          }

          switch (alt133) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1365:101: partitionSpec
            {
              pushFollow(FOLLOW_partitionSpec_in_showStatement7093);
              partitionSpec442 = partitionSpec();

              state._fsp--;

              stream_partitionSpec.add(partitionSpec442.getTree());
            }
            break;
          }

          // AST REWRITE
          // elements: db_name, showStmtIdentifier, partitionSpec
          // token labels:
          // rule labels: db_name, retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_db_name =
              new RewriteRuleSubtreeStream(adaptor, "rule db_name", db_name != null ? db_name.tree : null);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1366:5: -> ^( TOK_SHOW_TABLESTATUS showStmtIdentifier ( $db_name)? ( partitionSpec )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1366:8: ^( TOK_SHOW_TABLESTATUS showStmtIdentifier ( $db_name)? ( partitionSpec )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_SHOW_TABLESTATUS, "TOK_SHOW_TABLESTATUS"), root_1);

              adaptor.addChild(root_1, stream_showStmtIdentifier.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1366:51: ( $db_name)?
              if (stream_db_name.hasNext()) {
                adaptor.addChild(root_1, stream_db_name.nextTree());
              }
              stream_db_name.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1366:60: ( partitionSpec )?
              if (stream_partitionSpec.hasNext()) {
                adaptor.addChild(root_1, stream_partitionSpec.nextTree());
              }
              stream_partitionSpec.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 8:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1367:7: KW_SHOW KW_TBLPROPERTIES tableName ( LPAREN prptyName= StringLiteral RPAREN )?
        {
          KW_SHOW443 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showStatement7121);
          stream_KW_SHOW.add(KW_SHOW443);

          KW_TBLPROPERTIES444 = (Token) match(input, KW_TBLPROPERTIES, FOLLOW_KW_TBLPROPERTIES_in_showStatement7123);
          stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES444);

          pushFollow(FOLLOW_tableName_in_showStatement7125);
          tableName445 = tableName();

          state._fsp--;

          stream_tableName.add(tableName445.getTree());

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1367:42: ( LPAREN prptyName= StringLiteral RPAREN )?
          int alt134 = 2;
          switch (input.LA(1)) {
            case LPAREN: {
              alt134 = 1;
            }
            break;
          }

          switch (alt134) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1367:43: LPAREN prptyName= StringLiteral RPAREN
            {
              LPAREN446 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_showStatement7128);
              stream_LPAREN.add(LPAREN446);

              prptyName = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_showStatement7132);
              stream_StringLiteral.add(prptyName);

              RPAREN447 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_showStatement7134);
              stream_RPAREN.add(RPAREN447);
            }
            break;
          }

          // AST REWRITE
          // elements: prptyName, tableName
          // token labels: prptyName
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleTokenStream stream_prptyName = new RewriteRuleTokenStream(adaptor, "token prptyName", prptyName);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1367:83: -> ^( TOK_SHOW_TBLPROPERTIES tableName ( $prptyName)? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1367:86: ^( TOK_SHOW_TBLPROPERTIES tableName ( $prptyName)? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_SHOW_TBLPROPERTIES, "TOK_SHOW_TBLPROPERTIES"), root_1);

              adaptor.addChild(root_1, stream_tableName.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1367:122: ( $prptyName)?
              if (stream_prptyName.hasNext()) {
                adaptor.addChild(root_1, stream_prptyName.nextNode());
              }
              stream_prptyName.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 9:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1368:7: KW_SHOW KW_LOCKS (parttype= partTypeExpr )? (isExtended= KW_EXTENDED )?
        {
          KW_SHOW448 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showStatement7156);
          stream_KW_SHOW.add(KW_SHOW448);

          KW_LOCKS449 = (Token) match(input, KW_LOCKS, FOLLOW_KW_LOCKS_in_showStatement7158);
          stream_KW_LOCKS.add(KW_LOCKS449);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1368:24: (parttype= partTypeExpr )?
          int alt135 = 2;
          switch (input.LA(1)) {
            case Identifier:
            case KW_ADD:
            case KW_ADMIN:
            case KW_AFTER:
            case KW_ALL:
            case KW_ALTER:
            case KW_ANALYZE:
            case KW_ARCHIVE:
            case KW_ARRAY:
            case KW_AS:
            case KW_ASC:
            case KW_AUTHORIZATION:
            case KW_BEFORE:
            case KW_BETWEEN:
            case KW_BIGINT:
            case KW_BINARY:
            case KW_BOOLEAN:
            case KW_BOTH:
            case KW_BUCKET:
            case KW_BUCKETS:
            case KW_BY:
            case KW_CASCADE:
            case KW_CHANGE:
            case KW_CLUSTER:
            case KW_CLUSTERED:
            case KW_CLUSTERSTATUS:
            case KW_COLLECTION:
            case KW_COLUMNS:
            case KW_COMMENT:
            case KW_COMPACT:
            case KW_COMPACTIONS:
            case KW_COMPUTE:
            case KW_CONCATENATE:
            case KW_CONTINUE:
            case KW_CREATE:
            case KW_CUBE:
            case KW_CURSOR:
            case KW_DATA:
            case KW_DATABASES:
            case KW_DATE:
            case KW_DATETIME:
            case KW_DBPROPERTIES:
            case KW_DECIMAL:
            case KW_DEFAULT:
            case KW_DEFERRED:
            case KW_DEFINED:
            case KW_DELETE:
            case KW_DELIMITED:
            case KW_DEPENDENCY:
            case KW_DESC:
            case KW_DESCRIBE:
            case KW_DIRECTORIES:
            case KW_DIRECTORY:
            case KW_DISABLE:
            case KW_DISTRIBUTE:
            case KW_DOUBLE:
            case KW_DROP:
            case KW_ELEM_TYPE:
            case KW_ENABLE:
            case KW_ESCAPED:
            case KW_EXCLUSIVE:
            case KW_EXISTS:
            case KW_EXPLAIN:
            case KW_EXPORT:
            case KW_EXTERNAL:
            case KW_FALSE:
            case KW_FETCH:
            case KW_FIELDS:
            case KW_FILE:
            case KW_FILEFORMAT:
            case KW_FIRST:
            case KW_FLOAT:
            case KW_FOR:
            case KW_FORMAT:
            case KW_FORMATTED:
            case KW_FULL:
            case KW_FUNCTIONS:
            case KW_GRANT:
            case KW_GROUP:
            case KW_GROUPING:
            case KW_HOLD_DDLTIME:
            case KW_IDXPROPERTIES:
            case KW_IGNORE:
            case KW_IMPORT:
            case KW_IN:
            case KW_INDEX:
            case KW_INDEXES:
            case KW_INNER:
            case KW_INPATH:
            case KW_INPUTDRIVER:
            case KW_INPUTFORMAT:
            case KW_INSERT:
            case KW_INT:
            case KW_INTERSECT:
            case KW_INTO:
            case KW_IS:
            case KW_ITEMS:
            case KW_JAR:
            case KW_KEYS:
            case KW_KEY_TYPE:
            case KW_LATERAL:
            case KW_LEFT:
            case KW_LIKE:
            case KW_LIMIT:
            case KW_LINES:
            case KW_LOAD:
            case KW_LOCAL:
            case KW_LOCATION:
            case KW_LOCK:
            case KW_LOCKS:
            case KW_LOGICAL:
            case KW_LONG:
            case KW_MAPJOIN:
            case KW_MATERIALIZED:
            case KW_METADATA:
            case KW_MINUS:
            case KW_MSCK:
            case KW_NONE:
            case KW_NOSCAN:
            case KW_NO_DROP:
            case KW_NULL:
            case KW_OF:
            case KW_OFFLINE:
            case KW_OPTION:
            case KW_ORDER:
            case KW_OUT:
            case KW_OUTER:
            case KW_OUTPUTDRIVER:
            case KW_OUTPUTFORMAT:
            case KW_OVERWRITE:
            case KW_OWNER:
            case KW_PARTITION:
            case KW_PARTITIONED:
            case KW_PARTITIONS:
            case KW_PERCENT:
            case KW_PLUS:
            case KW_PRETTY:
            case KW_PRINCIPALS:
            case KW_PROCEDURE:
            case KW_PROTECTION:
            case KW_PURGE:
            case KW_RANGE:
            case KW_READ:
            case KW_READONLY:
            case KW_READS:
            case KW_REBUILD:
            case KW_RECORDREADER:
            case KW_RECORDWRITER:
            case KW_REGEXP:
            case KW_RELOAD:
            case KW_RENAME:
            case KW_REPAIR:
            case KW_REPLACE:
            case KW_REPLICATION:
            case KW_RESTRICT:
            case KW_REVOKE:
            case KW_REWRITE:
            case KW_RIGHT:
            case KW_RLIKE:
            case KW_ROLE:
            case KW_ROLES:
            case KW_ROLLUP:
            case KW_ROW:
            case KW_ROWS:
            case KW_SCHEMA:
            case KW_SCHEMAS:
            case KW_SEMI:
            case KW_SERDE:
            case KW_SERDEPROPERTIES:
            case KW_SERVER:
            case KW_SET:
            case KW_SETS:
            case KW_SHARED:
            case KW_SHOW:
            case KW_SHOW_DATABASE:
            case KW_SKEWED:
            case KW_SMALLINT:
            case KW_SORT:
            case KW_SORTED:
            case KW_SSL:
            case KW_STATISTICS:
            case KW_STORED:
            case KW_STREAMTABLE:
            case KW_STRING:
            case KW_STRUCT:
            case KW_TABLE:
            case KW_TABLES:
            case KW_TBLPROPERTIES:
            case KW_TEMPORARY:
            case KW_TERMINATED:
            case KW_TIMESTAMP:
            case KW_TINYINT:
            case KW_TO:
            case KW_TOUCH:
            case KW_TRANSACTIONS:
            case KW_TRIGGER:
            case KW_TRUE:
            case KW_TRUNCATE:
            case KW_UNARCHIVE:
            case KW_UNDO:
            case KW_UNION:
            case KW_UNIONTYPE:
            case KW_UNLOCK:
            case KW_UNSET:
            case KW_UNSIGNED:
            case KW_UPDATE:
            case KW_URI:
            case KW_USE:
            case KW_USER:
            case KW_USING:
            case KW_UTC:
            case KW_UTCTIMESTAMP:
            case KW_VALUES:
            case KW_VALUE_TYPE:
            case KW_VIEW:
            case KW_WHILE:
            case KW_WITH: {
              alt135 = 1;
            }
            break;
          }

          switch (alt135) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1368:25: parttype= partTypeExpr
            {
              pushFollow(FOLLOW_partTypeExpr_in_showStatement7163);
              parttype = partTypeExpr();

              state._fsp--;

              stream_partTypeExpr.add(parttype.getTree());
            }
            break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1368:49: (isExtended= KW_EXTENDED )?
          int alt136 = 2;
          switch (input.LA(1)) {
            case KW_EXTENDED: {
              alt136 = 1;
            }
            break;
          }

          switch (alt136) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1368:50: isExtended= KW_EXTENDED
            {
              isExtended = (Token) match(input, KW_EXTENDED, FOLLOW_KW_EXTENDED_in_showStatement7170);
              stream_KW_EXTENDED.add(isExtended);
            }
            break;
          }

          // AST REWRITE
          // elements: parttype, isExtended
          // token labels: isExtended
          // rule labels: parttype, retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleTokenStream stream_isExtended =
              new RewriteRuleTokenStream(adaptor, "token isExtended", isExtended);
          RewriteRuleSubtreeStream stream_parttype =
              new RewriteRuleSubtreeStream(adaptor, "rule parttype", parttype != null ? parttype.tree : null);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1368:75: -> ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1368:78: ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SHOWLOCKS, "TOK_SHOWLOCKS"), root_1);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1368:95: ( $parttype)?
              if (stream_parttype.hasNext()) {
                adaptor.addChild(root_1, stream_parttype.nextTree());
              }
              stream_parttype.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1368:106: ( $isExtended)?
              if (stream_isExtended.hasNext()) {
                adaptor.addChild(root_1, stream_isExtended.nextNode());
              }
              stream_isExtended.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 10:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1369:7: KW_SHOW KW_LOCKS ( KW_DATABASE | KW_SCHEMA ) (dbName= Identifier ) (isExtended= KW_EXTENDED )?
        {
          KW_SHOW450 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showStatement7194);
          stream_KW_SHOW.add(KW_SHOW450);

          KW_LOCKS451 = (Token) match(input, KW_LOCKS, FOLLOW_KW_LOCKS_in_showStatement7196);
          stream_KW_LOCKS.add(KW_LOCKS451);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1369:24: ( KW_DATABASE | KW_SCHEMA )
          int alt137 = 2;
          switch (input.LA(1)) {
            case KW_DATABASE: {
              alt137 = 1;
            }
            break;
            case KW_SCHEMA: {
              alt137 = 2;
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 137, 0, input);

              throw nvae;
          }

          switch (alt137) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1369:25: KW_DATABASE
            {
              KW_DATABASE452 = (Token) match(input, KW_DATABASE, FOLLOW_KW_DATABASE_in_showStatement7199);
              stream_KW_DATABASE.add(KW_DATABASE452);
            }
            break;
            case 2:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1369:37: KW_SCHEMA
            {
              KW_SCHEMA453 = (Token) match(input, KW_SCHEMA, FOLLOW_KW_SCHEMA_in_showStatement7201);
              stream_KW_SCHEMA.add(KW_SCHEMA453);
            }
            break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1369:48: (dbName= Identifier )
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1369:49: dbName= Identifier
          {
            dbName = (Token) match(input, Identifier, FOLLOW_Identifier_in_showStatement7207);
            stream_Identifier.add(dbName);
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1369:68: (isExtended= KW_EXTENDED )?
          int alt138 = 2;
          switch (input.LA(1)) {
            case KW_EXTENDED: {
              alt138 = 1;
            }
            break;
          }

          switch (alt138) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1369:69: isExtended= KW_EXTENDED
            {
              isExtended = (Token) match(input, KW_EXTENDED, FOLLOW_KW_EXTENDED_in_showStatement7213);
              stream_KW_EXTENDED.add(isExtended);
            }
            break;
          }

          // AST REWRITE
          // elements: isExtended, dbName
          // token labels: dbName, isExtended
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleTokenStream stream_dbName = new RewriteRuleTokenStream(adaptor, "token dbName", dbName);
          RewriteRuleTokenStream stream_isExtended =
              new RewriteRuleTokenStream(adaptor, "token isExtended", isExtended);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1369:94: -> ^( TOK_SHOWDBLOCKS $dbName ( $isExtended)? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1369:97: ^( TOK_SHOWDBLOCKS $dbName ( $isExtended)? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SHOWDBLOCKS, "TOK_SHOWDBLOCKS"),
                  root_1);

              adaptor.addChild(root_1, stream_dbName.nextNode());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1369:124: ( $isExtended)?
              if (stream_isExtended.hasNext()) {
                adaptor.addChild(root_1, stream_isExtended.nextNode());
              }
              stream_isExtended.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 11:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1370:7: KW_SHOW (showOptions= KW_FORMATTED )? ( KW_INDEX | KW_INDEXES ) KW_ON showStmtIdentifier ( ( KW_FROM | KW_IN ) db_name= identifier )?
        {
          KW_SHOW454 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showStatement7236);
          stream_KW_SHOW.add(KW_SHOW454);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1370:15: (showOptions= KW_FORMATTED )?
          int alt139 = 2;
          switch (input.LA(1)) {
            case KW_FORMATTED: {
              alt139 = 1;
            }
            break;
          }

          switch (alt139) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1370:16: showOptions= KW_FORMATTED
            {
              showOptions = (Token) match(input, KW_FORMATTED, FOLLOW_KW_FORMATTED_in_showStatement7241);
              stream_KW_FORMATTED.add(showOptions);
            }
            break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1370:43: ( KW_INDEX | KW_INDEXES )
          int alt140 = 2;
          switch (input.LA(1)) {
            case KW_INDEX: {
              alt140 = 1;
            }
            break;
            case KW_INDEXES: {
              alt140 = 2;
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 140, 0, input);

              throw nvae;
          }

          switch (alt140) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1370:44: KW_INDEX
            {
              KW_INDEX455 = (Token) match(input, KW_INDEX, FOLLOW_KW_INDEX_in_showStatement7246);
              stream_KW_INDEX.add(KW_INDEX455);
            }
            break;
            case 2:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1370:53: KW_INDEXES
            {
              KW_INDEXES456 = (Token) match(input, KW_INDEXES, FOLLOW_KW_INDEXES_in_showStatement7248);
              stream_KW_INDEXES.add(KW_INDEXES456);
            }
            break;
          }

          KW_ON457 = (Token) match(input, KW_ON, FOLLOW_KW_ON_in_showStatement7251);
          stream_KW_ON.add(KW_ON457);

          pushFollow(FOLLOW_showStmtIdentifier_in_showStatement7253);
          showStmtIdentifier458 = showStmtIdentifier();

          state._fsp--;

          stream_showStmtIdentifier.add(showStmtIdentifier458.getTree());

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1370:90: ( ( KW_FROM | KW_IN ) db_name= identifier )?
          int alt142 = 2;
          switch (input.LA(1)) {
            case KW_FROM:
            case KW_IN: {
              alt142 = 1;
            }
            break;
          }

          switch (alt142) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1370:91: ( KW_FROM | KW_IN ) db_name= identifier
            {
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1370:91: ( KW_FROM | KW_IN )
              int alt141 = 2;
              switch (input.LA(1)) {
                case KW_FROM: {
                  alt141 = 1;
                }
                break;
                case KW_IN: {
                  alt141 = 2;
                }
                break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 141, 0, input);

                  throw nvae;
              }

              switch (alt141) {
                case 1:
                  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1370:92: KW_FROM
                {
                  KW_FROM459 = (Token) match(input, KW_FROM, FOLLOW_KW_FROM_in_showStatement7257);
                  stream_KW_FROM.add(KW_FROM459);
                }
                break;
                case 2:
                  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1370:100: KW_IN
                {
                  KW_IN460 = (Token) match(input, KW_IN, FOLLOW_KW_IN_in_showStatement7259);
                  stream_KW_IN.add(KW_IN460);
                }
                break;
              }

              pushFollow(FOLLOW_identifier_in_showStatement7264);
              db_name = identifier();

              state._fsp--;

              stream_identifier.add(db_name.getTree());
            }
            break;
          }

          // AST REWRITE
          // elements: showOptions, db_name, showStmtIdentifier
          // token labels: showOptions
          // rule labels: db_name, retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleTokenStream stream_showOptions =
              new RewriteRuleTokenStream(adaptor, "token showOptions", showOptions);
          RewriteRuleSubtreeStream stream_db_name =
              new RewriteRuleSubtreeStream(adaptor, "rule db_name", db_name != null ? db_name.tree : null);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1371:5: -> ^( TOK_SHOWINDEXES showStmtIdentifier ( $showOptions)? ( $db_name)? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1371:8: ^( TOK_SHOWINDEXES showStmtIdentifier ( $showOptions)? ( $db_name)? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SHOWINDEXES, "TOK_SHOWINDEXES"),
                  root_1);

              adaptor.addChild(root_1, stream_showStmtIdentifier.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1371:46: ( $showOptions)?
              if (stream_showOptions.hasNext()) {
                adaptor.addChild(root_1, stream_showOptions.nextNode());
              }
              stream_showOptions.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1371:60: ( $db_name)?
              if (stream_db_name.hasNext()) {
                adaptor.addChild(root_1, stream_db_name.nextTree());
              }
              stream_db_name.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 12:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1372:7: KW_SHOW KW_COMPACTIONS
        {
          KW_SHOW461 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showStatement7294);
          stream_KW_SHOW.add(KW_SHOW461);

          KW_COMPACTIONS462 = (Token) match(input, KW_COMPACTIONS, FOLLOW_KW_COMPACTIONS_in_showStatement7296);
          stream_KW_COMPACTIONS.add(KW_COMPACTIONS462);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1372:30: -> ^( TOK_SHOW_COMPACTIONS )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1372:33: ^( TOK_SHOW_COMPACTIONS )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_SHOW_COMPACTIONS, "TOK_SHOW_COMPACTIONS"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 13:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1373:7: KW_SHOW KW_TRANSACTIONS
        {
          KW_SHOW463 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showStatement7310);
          stream_KW_SHOW.add(KW_SHOW463);

          KW_TRANSACTIONS464 = (Token) match(input, KW_TRANSACTIONS, FOLLOW_KW_TRANSACTIONS_in_showStatement7312);
          stream_KW_TRANSACTIONS.add(KW_TRANSACTIONS464);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1373:31: -> ^( TOK_SHOW_TRANSACTIONS )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1373:34: ^( TOK_SHOW_TRANSACTIONS )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_SHOW_TRANSACTIONS, "TOK_SHOW_TRANSACTIONS"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 14:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1374:7: KW_SHOW KW_CONF StringLiteral
        {
          KW_SHOW465 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showStatement7326);
          stream_KW_SHOW.add(KW_SHOW465);

          KW_CONF466 = (Token) match(input, KW_CONF, FOLLOW_KW_CONF_in_showStatement7328);
          stream_KW_CONF.add(KW_CONF466);

          StringLiteral467 = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_showStatement7330);
          stream_StringLiteral.add(StringLiteral467);

          // AST REWRITE
          // elements: StringLiteral
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1374:37: -> ^( TOK_SHOWCONF StringLiteral )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1374:40: ^( TOK_SHOWCONF StringLiteral )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SHOWCONF, "TOK_SHOWCONF"), root_1);

              adaptor.addChild(root_1, stream_StringLiteral.nextNode());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "showStatement"

  public static class lockStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "lockStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1377:1: lockStatement : KW_LOCK KW_TABLE tableName ( partitionSpec )? lockMode -> ^( TOK_LOCKTABLE tableName lockMode ( partitionSpec )? ) ;
  public final HiveParser.lockStatement_return lockStatement() throws RecognitionException {
    HiveParser.lockStatement_return retval = new HiveParser.lockStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_LOCK468 = null;
    Token KW_TABLE469 = null;
    HiveParser_FromClauseParser.tableName_return tableName470 = null;

    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec471 = null;

    HiveParser.lockMode_return lockMode472 = null;

    CommonTree KW_LOCK468_tree = null;
    CommonTree KW_TABLE469_tree = null;
    RewriteRuleTokenStream stream_KW_LOCK = new RewriteRuleTokenStream(adaptor, "token KW_LOCK");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleSubtreeStream stream_lockMode = new RewriteRuleSubtreeStream(adaptor, "rule lockMode");
    RewriteRuleSubtreeStream stream_partitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule partitionSpec");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    pushMsg("lock statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1380:5: ( KW_LOCK KW_TABLE tableName ( partitionSpec )? lockMode -> ^( TOK_LOCKTABLE tableName lockMode ( partitionSpec )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1380:7: KW_LOCK KW_TABLE tableName ( partitionSpec )? lockMode
      {
        KW_LOCK468 = (Token) match(input, KW_LOCK, FOLLOW_KW_LOCK_in_lockStatement7365);
        stream_KW_LOCK.add(KW_LOCK468);

        KW_TABLE469 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_lockStatement7367);
        stream_KW_TABLE.add(KW_TABLE469);

        pushFollow(FOLLOW_tableName_in_lockStatement7369);
        tableName470 = tableName();

        state._fsp--;

        stream_tableName.add(tableName470.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1380:34: ( partitionSpec )?
        int alt144 = 2;
        switch (input.LA(1)) {
          case KW_PARTITION: {
            alt144 = 1;
          }
          break;
        }

        switch (alt144) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1380:34: partitionSpec
          {
            pushFollow(FOLLOW_partitionSpec_in_lockStatement7371);
            partitionSpec471 = partitionSpec();

            state._fsp--;

            stream_partitionSpec.add(partitionSpec471.getTree());
          }
          break;
        }

        pushFollow(FOLLOW_lockMode_in_lockStatement7374);
        lockMode472 = lockMode();

        state._fsp--;

        stream_lockMode.add(lockMode472.getTree());

        // AST REWRITE
        // elements: tableName, partitionSpec, lockMode
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1380:58: -> ^( TOK_LOCKTABLE tableName lockMode ( partitionSpec )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1380:61: ^( TOK_LOCKTABLE tableName lockMode ( partitionSpec )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_LOCKTABLE, "TOK_LOCKTABLE"), root_1);

            adaptor.addChild(root_1, stream_tableName.nextTree());

            adaptor.addChild(root_1, stream_lockMode.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1380:96: ( partitionSpec )?
            if (stream_partitionSpec.hasNext()) {
              adaptor.addChild(root_1, stream_partitionSpec.nextTree());
            }
            stream_partitionSpec.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "lockStatement"

  public static class lockDatabase_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "lockDatabase"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1383:1: lockDatabase : KW_LOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= Identifier ) lockMode -> ^( TOK_LOCKDB $dbName lockMode ) ;
  public final HiveParser.lockDatabase_return lockDatabase() throws RecognitionException {
    HiveParser.lockDatabase_return retval = new HiveParser.lockDatabase_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token dbName = null;
    Token KW_LOCK473 = null;
    Token KW_DATABASE474 = null;
    Token KW_SCHEMA475 = null;
    HiveParser.lockMode_return lockMode476 = null;

    CommonTree dbName_tree = null;
    CommonTree KW_LOCK473_tree = null;
    CommonTree KW_DATABASE474_tree = null;
    CommonTree KW_SCHEMA475_tree = null;
    RewriteRuleTokenStream stream_KW_SCHEMA = new RewriteRuleTokenStream(adaptor, "token KW_SCHEMA");
    RewriteRuleTokenStream stream_Identifier = new RewriteRuleTokenStream(adaptor, "token Identifier");
    RewriteRuleTokenStream stream_KW_DATABASE = new RewriteRuleTokenStream(adaptor, "token KW_DATABASE");
    RewriteRuleTokenStream stream_KW_LOCK = new RewriteRuleTokenStream(adaptor, "token KW_LOCK");
    RewriteRuleSubtreeStream stream_lockMode = new RewriteRuleSubtreeStream(adaptor, "rule lockMode");
    pushMsg("lock database statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1386:5: ( KW_LOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= Identifier ) lockMode -> ^( TOK_LOCKDB $dbName lockMode ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1386:7: KW_LOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= Identifier ) lockMode
      {
        KW_LOCK473 = (Token) match(input, KW_LOCK, FOLLOW_KW_LOCK_in_lockDatabase7414);
        stream_KW_LOCK.add(KW_LOCK473);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1386:15: ( KW_DATABASE | KW_SCHEMA )
        int alt145 = 2;
        switch (input.LA(1)) {
          case KW_DATABASE: {
            alt145 = 1;
          }
          break;
          case KW_SCHEMA: {
            alt145 = 2;
          }
          break;
          default:
            NoViableAltException nvae = new NoViableAltException("", 145, 0, input);

            throw nvae;
        }

        switch (alt145) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1386:16: KW_DATABASE
          {
            KW_DATABASE474 = (Token) match(input, KW_DATABASE, FOLLOW_KW_DATABASE_in_lockDatabase7417);
            stream_KW_DATABASE.add(KW_DATABASE474);
          }
          break;
          case 2:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1386:28: KW_SCHEMA
          {
            KW_SCHEMA475 = (Token) match(input, KW_SCHEMA, FOLLOW_KW_SCHEMA_in_lockDatabase7419);
            stream_KW_SCHEMA.add(KW_SCHEMA475);
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1386:39: (dbName= Identifier )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1386:40: dbName= Identifier
        {
          dbName = (Token) match(input, Identifier, FOLLOW_Identifier_in_lockDatabase7425);
          stream_Identifier.add(dbName);
        }

        pushFollow(FOLLOW_lockMode_in_lockDatabase7428);
        lockMode476 = lockMode();

        state._fsp--;

        stream_lockMode.add(lockMode476.getTree());

        // AST REWRITE
        // elements: lockMode, dbName
        // token labels: dbName
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_dbName = new RewriteRuleTokenStream(adaptor, "token dbName", dbName);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1386:68: -> ^( TOK_LOCKDB $dbName lockMode )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1386:71: ^( TOK_LOCKDB $dbName lockMode )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_LOCKDB, "TOK_LOCKDB"), root_1);

            adaptor.addChild(root_1, stream_dbName.nextNode());

            adaptor.addChild(root_1, stream_lockMode.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "lockDatabase"

  public static class lockMode_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "lockMode"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1389:1: lockMode : ( KW_SHARED | KW_EXCLUSIVE );
  public final HiveParser.lockMode_return lockMode() throws RecognitionException {
    HiveParser.lockMode_return retval = new HiveParser.lockMode_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token set477 = null;

    CommonTree set477_tree = null;

    pushMsg("lock mode", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1392:5: ( KW_SHARED | KW_EXCLUSIVE )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:
      {
        root_0 = (CommonTree) adaptor.nil();

        set477 = (Token) input.LT(1);

        if (input.LA(1) == KW_EXCLUSIVE || input.LA(1) == KW_SHARED) {
          input.consume();
          adaptor.addChild(root_0, (CommonTree) adaptor.create(set477));
          state.errorRecovery = false;
        } else {
          MismatchedSetException mse = new MismatchedSetException(null, input);
          throw mse;
        }
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "lockMode"

  public static class unlockStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "unlockStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1395:1: unlockStatement : KW_UNLOCK KW_TABLE tableName ( partitionSpec )? -> ^( TOK_UNLOCKTABLE tableName ( partitionSpec )? ) ;
  public final HiveParser.unlockStatement_return unlockStatement() throws RecognitionException {
    HiveParser.unlockStatement_return retval = new HiveParser.unlockStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_UNLOCK478 = null;
    Token KW_TABLE479 = null;
    HiveParser_FromClauseParser.tableName_return tableName480 = null;

    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec481 = null;

    CommonTree KW_UNLOCK478_tree = null;
    CommonTree KW_TABLE479_tree = null;
    RewriteRuleTokenStream stream_KW_UNLOCK = new RewriteRuleTokenStream(adaptor, "token KW_UNLOCK");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleSubtreeStream stream_partitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule partitionSpec");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    pushMsg("unlock statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1398:5: ( KW_UNLOCK KW_TABLE tableName ( partitionSpec )? -> ^( TOK_UNLOCKTABLE tableName ( partitionSpec )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1398:7: KW_UNLOCK KW_TABLE tableName ( partitionSpec )?
      {
        KW_UNLOCK478 = (Token) match(input, KW_UNLOCK, FOLLOW_KW_UNLOCK_in_unlockStatement7497);
        stream_KW_UNLOCK.add(KW_UNLOCK478);

        KW_TABLE479 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_unlockStatement7499);
        stream_KW_TABLE.add(KW_TABLE479);

        pushFollow(FOLLOW_tableName_in_unlockStatement7501);
        tableName480 = tableName();

        state._fsp--;

        stream_tableName.add(tableName480.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1398:36: ( partitionSpec )?
        int alt146 = 2;
        switch (input.LA(1)) {
          case KW_PARTITION: {
            alt146 = 1;
          }
          break;
        }

        switch (alt146) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1398:36: partitionSpec
          {
            pushFollow(FOLLOW_partitionSpec_in_unlockStatement7503);
            partitionSpec481 = partitionSpec();

            state._fsp--;

            stream_partitionSpec.add(partitionSpec481.getTree());
          }
          break;
        }

        // AST REWRITE
        // elements: partitionSpec, tableName
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1398:52: -> ^( TOK_UNLOCKTABLE tableName ( partitionSpec )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1398:55: ^( TOK_UNLOCKTABLE tableName ( partitionSpec )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_UNLOCKTABLE, "TOK_UNLOCKTABLE"),
                root_1);

            adaptor.addChild(root_1, stream_tableName.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1398:83: ( partitionSpec )?
            if (stream_partitionSpec.hasNext()) {
              adaptor.addChild(root_1, stream_partitionSpec.nextTree());
            }
            stream_partitionSpec.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "unlockStatement"

  public static class unlockDatabase_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "unlockDatabase"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1401:1: unlockDatabase : KW_UNLOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= Identifier ) -> ^( TOK_UNLOCKDB $dbName) ;
  public final HiveParser.unlockDatabase_return unlockDatabase() throws RecognitionException {
    HiveParser.unlockDatabase_return retval = new HiveParser.unlockDatabase_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token dbName = null;
    Token KW_UNLOCK482 = null;
    Token KW_DATABASE483 = null;
    Token KW_SCHEMA484 = null;

    CommonTree dbName_tree = null;
    CommonTree KW_UNLOCK482_tree = null;
    CommonTree KW_DATABASE483_tree = null;
    CommonTree KW_SCHEMA484_tree = null;
    RewriteRuleTokenStream stream_KW_SCHEMA = new RewriteRuleTokenStream(adaptor, "token KW_SCHEMA");
    RewriteRuleTokenStream stream_Identifier = new RewriteRuleTokenStream(adaptor, "token Identifier");
    RewriteRuleTokenStream stream_KW_DATABASE = new RewriteRuleTokenStream(adaptor, "token KW_DATABASE");
    RewriteRuleTokenStream stream_KW_UNLOCK = new RewriteRuleTokenStream(adaptor, "token KW_UNLOCK");

    pushMsg("unlock database statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1404:5: ( KW_UNLOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= Identifier ) -> ^( TOK_UNLOCKDB $dbName) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1404:7: KW_UNLOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= Identifier )
      {
        KW_UNLOCK482 = (Token) match(input, KW_UNLOCK, FOLLOW_KW_UNLOCK_in_unlockDatabase7543);
        stream_KW_UNLOCK.add(KW_UNLOCK482);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1404:17: ( KW_DATABASE | KW_SCHEMA )
        int alt147 = 2;
        switch (input.LA(1)) {
          case KW_DATABASE: {
            alt147 = 1;
          }
          break;
          case KW_SCHEMA: {
            alt147 = 2;
          }
          break;
          default:
            NoViableAltException nvae = new NoViableAltException("", 147, 0, input);

            throw nvae;
        }

        switch (alt147) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1404:18: KW_DATABASE
          {
            KW_DATABASE483 = (Token) match(input, KW_DATABASE, FOLLOW_KW_DATABASE_in_unlockDatabase7546);
            stream_KW_DATABASE.add(KW_DATABASE483);
          }
          break;
          case 2:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1404:30: KW_SCHEMA
          {
            KW_SCHEMA484 = (Token) match(input, KW_SCHEMA, FOLLOW_KW_SCHEMA_in_unlockDatabase7548);
            stream_KW_SCHEMA.add(KW_SCHEMA484);
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1404:41: (dbName= Identifier )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1404:42: dbName= Identifier
        {
          dbName = (Token) match(input, Identifier, FOLLOW_Identifier_in_unlockDatabase7554);
          stream_Identifier.add(dbName);
        }

        // AST REWRITE
        // elements: dbName
        // token labels: dbName
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_dbName = new RewriteRuleTokenStream(adaptor, "token dbName", dbName);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1404:61: -> ^( TOK_UNLOCKDB $dbName)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1404:64: ^( TOK_UNLOCKDB $dbName)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_UNLOCKDB, "TOK_UNLOCKDB"), root_1);

            adaptor.addChild(root_1, stream_dbName.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "unlockDatabase"

  public static class createRoleStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "createRoleStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1407:1: createRoleStatement : KW_CREATE KW_ROLE roleName= identifier -> ^( TOK_CREATEROLE $roleName) ;
  public final HiveParser.createRoleStatement_return createRoleStatement() throws RecognitionException {
    HiveParser.createRoleStatement_return retval = new HiveParser.createRoleStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_CREATE485 = null;
    Token KW_ROLE486 = null;
    HiveParser_IdentifiersParser.identifier_return roleName = null;

    CommonTree KW_CREATE485_tree = null;
    CommonTree KW_ROLE486_tree = null;
    RewriteRuleTokenStream stream_KW_ROLE = new RewriteRuleTokenStream(adaptor, "token KW_ROLE");
    RewriteRuleTokenStream stream_KW_CREATE = new RewriteRuleTokenStream(adaptor, "token KW_CREATE");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    pushMsg("create role", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1410:5: ( KW_CREATE KW_ROLE roleName= identifier -> ^( TOK_CREATEROLE $roleName) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1410:7: KW_CREATE KW_ROLE roleName= identifier
      {
        KW_CREATE485 = (Token) match(input, KW_CREATE, FOLLOW_KW_CREATE_in_createRoleStatement7591);
        stream_KW_CREATE.add(KW_CREATE485);

        KW_ROLE486 = (Token) match(input, KW_ROLE, FOLLOW_KW_ROLE_in_createRoleStatement7593);
        stream_KW_ROLE.add(KW_ROLE486);

        pushFollow(FOLLOW_identifier_in_createRoleStatement7597);
        roleName = identifier();

        state._fsp--;

        stream_identifier.add(roleName.getTree());

        // AST REWRITE
        // elements: roleName
        // token labels:
        // rule labels: roleName, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_roleName =
            new RewriteRuleSubtreeStream(adaptor, "rule roleName", roleName != null ? roleName.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1411:5: -> ^( TOK_CREATEROLE $roleName)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1411:8: ^( TOK_CREATEROLE $roleName)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_CREATEROLE, "TOK_CREATEROLE"), root_1);

            adaptor.addChild(root_1, stream_roleName.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "createRoleStatement"

  public static class dropRoleStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "dropRoleStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1414:1: dropRoleStatement : KW_DROP KW_ROLE roleName= identifier -> ^( TOK_DROPROLE $roleName) ;
  public final HiveParser.dropRoleStatement_return dropRoleStatement() throws RecognitionException {
    HiveParser.dropRoleStatement_return retval = new HiveParser.dropRoleStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_DROP487 = null;
    Token KW_ROLE488 = null;
    HiveParser_IdentifiersParser.identifier_return roleName = null;

    CommonTree KW_DROP487_tree = null;
    CommonTree KW_ROLE488_tree = null;
    RewriteRuleTokenStream stream_KW_DROP = new RewriteRuleTokenStream(adaptor, "token KW_DROP");
    RewriteRuleTokenStream stream_KW_ROLE = new RewriteRuleTokenStream(adaptor, "token KW_ROLE");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    pushMsg("drop role", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1417:5: ( KW_DROP KW_ROLE roleName= identifier -> ^( TOK_DROPROLE $roleName) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1417:7: KW_DROP KW_ROLE roleName= identifier
      {
        KW_DROP487 = (Token) match(input, KW_DROP, FOLLOW_KW_DROP_in_dropRoleStatement7637);
        stream_KW_DROP.add(KW_DROP487);

        KW_ROLE488 = (Token) match(input, KW_ROLE, FOLLOW_KW_ROLE_in_dropRoleStatement7639);
        stream_KW_ROLE.add(KW_ROLE488);

        pushFollow(FOLLOW_identifier_in_dropRoleStatement7643);
        roleName = identifier();

        state._fsp--;

        stream_identifier.add(roleName.getTree());

        // AST REWRITE
        // elements: roleName
        // token labels:
        // rule labels: roleName, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_roleName =
            new RewriteRuleSubtreeStream(adaptor, "rule roleName", roleName != null ? roleName.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1418:5: -> ^( TOK_DROPROLE $roleName)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1418:8: ^( TOK_DROPROLE $roleName)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DROPROLE, "TOK_DROPROLE"), root_1);

            adaptor.addChild(root_1, stream_roleName.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "dropRoleStatement"

  public static class grantPrivileges_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "grantPrivileges"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1421:1: grantPrivileges : KW_GRANT privList= privilegeList ( privilegeObject )? KW_TO principalSpecification ( withGrantOption )? -> ^( TOK_GRANT $privList principalSpecification ( privilegeObject )? ( withGrantOption )? ) ;
  public final HiveParser.grantPrivileges_return grantPrivileges() throws RecognitionException {
    HiveParser.grantPrivileges_return retval = new HiveParser.grantPrivileges_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_GRANT489 = null;
    Token KW_TO491 = null;
    HiveParser.privilegeList_return privList = null;

    HiveParser.privilegeObject_return privilegeObject490 = null;

    HiveParser.principalSpecification_return principalSpecification492 = null;

    HiveParser.withGrantOption_return withGrantOption493 = null;

    CommonTree KW_GRANT489_tree = null;
    CommonTree KW_TO491_tree = null;
    RewriteRuleTokenStream stream_KW_TO = new RewriteRuleTokenStream(adaptor, "token KW_TO");
    RewriteRuleTokenStream stream_KW_GRANT = new RewriteRuleTokenStream(adaptor, "token KW_GRANT");
    RewriteRuleSubtreeStream stream_withGrantOption = new RewriteRuleSubtreeStream(adaptor, "rule withGrantOption");
    RewriteRuleSubtreeStream stream_privilegeList = new RewriteRuleSubtreeStream(adaptor, "rule privilegeList");
    RewriteRuleSubtreeStream stream_privilegeObject = new RewriteRuleSubtreeStream(adaptor, "rule privilegeObject");
    RewriteRuleSubtreeStream stream_principalSpecification =
        new RewriteRuleSubtreeStream(adaptor, "rule principalSpecification");
    pushMsg("grant privileges", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1424:5: ( KW_GRANT privList= privilegeList ( privilegeObject )? KW_TO principalSpecification ( withGrantOption )? -> ^( TOK_GRANT $privList principalSpecification ( privilegeObject )? ( withGrantOption )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1424:7: KW_GRANT privList= privilegeList ( privilegeObject )? KW_TO principalSpecification ( withGrantOption )?
      {
        KW_GRANT489 = (Token) match(input, KW_GRANT, FOLLOW_KW_GRANT_in_grantPrivileges7683);
        stream_KW_GRANT.add(KW_GRANT489);

        pushFollow(FOLLOW_privilegeList_in_grantPrivileges7687);
        privList = privilegeList();

        state._fsp--;

        stream_privilegeList.add(privList.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1425:7: ( privilegeObject )?
        int alt148 = 2;
        switch (input.LA(1)) {
          case KW_ON: {
            alt148 = 1;
          }
          break;
        }

        switch (alt148) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1425:7: privilegeObject
          {
            pushFollow(FOLLOW_privilegeObject_in_grantPrivileges7695);
            privilegeObject490 = privilegeObject();

            state._fsp--;

            stream_privilegeObject.add(privilegeObject490.getTree());
          }
          break;
        }

        KW_TO491 = (Token) match(input, KW_TO, FOLLOW_KW_TO_in_grantPrivileges7704);
        stream_KW_TO.add(KW_TO491);

        pushFollow(FOLLOW_principalSpecification_in_grantPrivileges7706);
        principalSpecification492 = principalSpecification();

        state._fsp--;

        stream_principalSpecification.add(principalSpecification492.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1427:7: ( withGrantOption )?
        int alt149 = 2;
        switch (input.LA(1)) {
          case KW_WITH: {
            alt149 = 1;
          }
          break;
        }

        switch (alt149) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1427:7: withGrantOption
          {
            pushFollow(FOLLOW_withGrantOption_in_grantPrivileges7714);
            withGrantOption493 = withGrantOption();

            state._fsp--;

            stream_withGrantOption.add(withGrantOption493.getTree());
          }
          break;
        }

        // AST REWRITE
        // elements: withGrantOption, privList, privilegeObject, principalSpecification
        // token labels:
        // rule labels: privList, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_privList =
            new RewriteRuleSubtreeStream(adaptor, "rule privList", privList != null ? privList.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1428:5: -> ^( TOK_GRANT $privList principalSpecification ( privilegeObject )? ( withGrantOption )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1428:8: ^( TOK_GRANT $privList principalSpecification ( privilegeObject )? ( withGrantOption )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_GRANT, "TOK_GRANT"), root_1);

            adaptor.addChild(root_1, stream_privList.nextTree());

            adaptor.addChild(root_1, stream_principalSpecification.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1428:53: ( privilegeObject )?
            if (stream_privilegeObject.hasNext()) {
              adaptor.addChild(root_1, stream_privilegeObject.nextTree());
            }
            stream_privilegeObject.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1428:70: ( withGrantOption )?
            if (stream_withGrantOption.hasNext()) {
              adaptor.addChild(root_1, stream_withGrantOption.nextTree());
            }
            stream_withGrantOption.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "grantPrivileges"

  public static class revokePrivileges_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "revokePrivileges"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1431:1: revokePrivileges : KW_REVOKE ( grantOptionFor )? privilegeList ( privilegeObject )? KW_FROM principalSpecification -> ^( TOK_REVOKE privilegeList principalSpecification ( privilegeObject )? ( grantOptionFor )? ) ;
  public final HiveParser.revokePrivileges_return revokePrivileges() throws RecognitionException {
    HiveParser.revokePrivileges_return retval = new HiveParser.revokePrivileges_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_REVOKE494 = null;
    Token KW_FROM498 = null;
    HiveParser.grantOptionFor_return grantOptionFor495 = null;

    HiveParser.privilegeList_return privilegeList496 = null;

    HiveParser.privilegeObject_return privilegeObject497 = null;

    HiveParser.principalSpecification_return principalSpecification499 = null;

    CommonTree KW_REVOKE494_tree = null;
    CommonTree KW_FROM498_tree = null;
    RewriteRuleTokenStream stream_KW_FROM = new RewriteRuleTokenStream(adaptor, "token KW_FROM");
    RewriteRuleTokenStream stream_KW_REVOKE = new RewriteRuleTokenStream(adaptor, "token KW_REVOKE");
    RewriteRuleSubtreeStream stream_grantOptionFor = new RewriteRuleSubtreeStream(adaptor, "rule grantOptionFor");
    RewriteRuleSubtreeStream stream_privilegeList = new RewriteRuleSubtreeStream(adaptor, "rule privilegeList");
    RewriteRuleSubtreeStream stream_privilegeObject = new RewriteRuleSubtreeStream(adaptor, "rule privilegeObject");
    RewriteRuleSubtreeStream stream_principalSpecification =
        new RewriteRuleSubtreeStream(adaptor, "rule principalSpecification");
    pushMsg("revoke privileges", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1434:5: ( KW_REVOKE ( grantOptionFor )? privilegeList ( privilegeObject )? KW_FROM principalSpecification -> ^( TOK_REVOKE privilegeList principalSpecification ( privilegeObject )? ( grantOptionFor )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1434:7: KW_REVOKE ( grantOptionFor )? privilegeList ( privilegeObject )? KW_FROM principalSpecification
      {
        KW_REVOKE494 = (Token) match(input, KW_REVOKE, FOLLOW_KW_REVOKE_in_revokePrivileges7763);
        stream_KW_REVOKE.add(KW_REVOKE494);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1434:17: ( grantOptionFor )?
        int alt150 = 2;
        switch (input.LA(1)) {
          case KW_GRANT: {
            alt150 = 1;
          }
          break;
        }

        switch (alt150) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1434:17: grantOptionFor
          {
            pushFollow(FOLLOW_grantOptionFor_in_revokePrivileges7765);
            grantOptionFor495 = grantOptionFor();

            state._fsp--;

            stream_grantOptionFor.add(grantOptionFor495.getTree());
          }
          break;
        }

        pushFollow(FOLLOW_privilegeList_in_revokePrivileges7768);
        privilegeList496 = privilegeList();

        state._fsp--;

        stream_privilegeList.add(privilegeList496.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1434:47: ( privilegeObject )?
        int alt151 = 2;
        switch (input.LA(1)) {
          case KW_ON: {
            alt151 = 1;
          }
          break;
        }

        switch (alt151) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1434:47: privilegeObject
          {
            pushFollow(FOLLOW_privilegeObject_in_revokePrivileges7770);
            privilegeObject497 = privilegeObject();

            state._fsp--;

            stream_privilegeObject.add(privilegeObject497.getTree());
          }
          break;
        }

        KW_FROM498 = (Token) match(input, KW_FROM, FOLLOW_KW_FROM_in_revokePrivileges7773);
        stream_KW_FROM.add(KW_FROM498);

        pushFollow(FOLLOW_principalSpecification_in_revokePrivileges7775);
        principalSpecification499 = principalSpecification();

        state._fsp--;

        stream_principalSpecification.add(principalSpecification499.getTree());

        // AST REWRITE
        // elements: grantOptionFor, privilegeObject, privilegeList, principalSpecification
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1435:5: -> ^( TOK_REVOKE privilegeList principalSpecification ( privilegeObject )? ( grantOptionFor )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1435:8: ^( TOK_REVOKE privilegeList principalSpecification ( privilegeObject )? ( grantOptionFor )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_REVOKE, "TOK_REVOKE"), root_1);

            adaptor.addChild(root_1, stream_privilegeList.nextTree());

            adaptor.addChild(root_1, stream_principalSpecification.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1435:58: ( privilegeObject )?
            if (stream_privilegeObject.hasNext()) {
              adaptor.addChild(root_1, stream_privilegeObject.nextTree());
            }
            stream_privilegeObject.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1435:75: ( grantOptionFor )?
            if (stream_grantOptionFor.hasNext()) {
              adaptor.addChild(root_1, stream_grantOptionFor.nextTree());
            }
            stream_grantOptionFor.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "revokePrivileges"

  public static class grantRole_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "grantRole"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1438:1: grantRole : KW_GRANT ( KW_ROLE )? identifier ( COMMA identifier )* KW_TO principalSpecification ( withAdminOption )? -> ^( TOK_GRANT_ROLE principalSpecification ( withAdminOption )? ( identifier )+ ) ;
  public final HiveParser.grantRole_return grantRole() throws RecognitionException {
    HiveParser.grantRole_return retval = new HiveParser.grantRole_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_GRANT500 = null;
    Token KW_ROLE501 = null;
    Token COMMA503 = null;
    Token KW_TO505 = null;
    HiveParser_IdentifiersParser.identifier_return identifier502 = null;

    HiveParser_IdentifiersParser.identifier_return identifier504 = null;

    HiveParser.principalSpecification_return principalSpecification506 = null;

    HiveParser.withAdminOption_return withAdminOption507 = null;

    CommonTree KW_GRANT500_tree = null;
    CommonTree KW_ROLE501_tree = null;
    CommonTree COMMA503_tree = null;
    CommonTree KW_TO505_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleTokenStream stream_KW_ROLE = new RewriteRuleTokenStream(adaptor, "token KW_ROLE");
    RewriteRuleTokenStream stream_KW_TO = new RewriteRuleTokenStream(adaptor, "token KW_TO");
    RewriteRuleTokenStream stream_KW_GRANT = new RewriteRuleTokenStream(adaptor, "token KW_GRANT");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_withAdminOption = new RewriteRuleSubtreeStream(adaptor, "rule withAdminOption");
    RewriteRuleSubtreeStream stream_principalSpecification =
        new RewriteRuleSubtreeStream(adaptor, "rule principalSpecification");
    pushMsg("grant role", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1441:5: ( KW_GRANT ( KW_ROLE )? identifier ( COMMA identifier )* KW_TO principalSpecification ( withAdminOption )? -> ^( TOK_GRANT_ROLE principalSpecification ( withAdminOption )? ( identifier )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1441:7: KW_GRANT ( KW_ROLE )? identifier ( COMMA identifier )* KW_TO principalSpecification ( withAdminOption )?
      {
        KW_GRANT500 = (Token) match(input, KW_GRANT, FOLLOW_KW_GRANT_in_grantRole7822);
        stream_KW_GRANT.add(KW_GRANT500);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1441:16: ( KW_ROLE )?
        int alt152 = 2;
        switch (input.LA(1)) {
          case KW_ROLE: {
            switch (input.LA(2)) {
              case Identifier:
              case KW_ADD:
              case KW_ADMIN:
              case KW_AFTER:
              case KW_ALL:
              case KW_ALTER:
              case KW_ANALYZE:
              case KW_ARCHIVE:
              case KW_ARRAY:
              case KW_AS:
              case KW_ASC:
              case KW_AUTHORIZATION:
              case KW_BEFORE:
              case KW_BETWEEN:
              case KW_BIGINT:
              case KW_BINARY:
              case KW_BOOLEAN:
              case KW_BOTH:
              case KW_BUCKET:
              case KW_BUCKETS:
              case KW_BY:
              case KW_CASCADE:
              case KW_CHANGE:
              case KW_CLUSTER:
              case KW_CLUSTERED:
              case KW_CLUSTERSTATUS:
              case KW_COLLECTION:
              case KW_COLUMNS:
              case KW_COMMENT:
              case KW_COMPACT:
              case KW_COMPACTIONS:
              case KW_COMPUTE:
              case KW_CONCATENATE:
              case KW_CONTINUE:
              case KW_CREATE:
              case KW_CUBE:
              case KW_CURSOR:
              case KW_DATA:
              case KW_DATABASES:
              case KW_DATE:
              case KW_DATETIME:
              case KW_DBPROPERTIES:
              case KW_DECIMAL:
              case KW_DEFAULT:
              case KW_DEFERRED:
              case KW_DEFINED:
              case KW_DELETE:
              case KW_DELIMITED:
              case KW_DEPENDENCY:
              case KW_DESC:
              case KW_DESCRIBE:
              case KW_DIRECTORIES:
              case KW_DIRECTORY:
              case KW_DISABLE:
              case KW_DISTRIBUTE:
              case KW_DOUBLE:
              case KW_DROP:
              case KW_ELEM_TYPE:
              case KW_ENABLE:
              case KW_ESCAPED:
              case KW_EXCLUSIVE:
              case KW_EXISTS:
              case KW_EXPLAIN:
              case KW_EXPORT:
              case KW_EXTERNAL:
              case KW_FALSE:
              case KW_FETCH:
              case KW_FIELDS:
              case KW_FILE:
              case KW_FILEFORMAT:
              case KW_FIRST:
              case KW_FLOAT:
              case KW_FOR:
              case KW_FORMAT:
              case KW_FORMATTED:
              case KW_FULL:
              case KW_FUNCTIONS:
              case KW_GRANT:
              case KW_GROUP:
              case KW_GROUPING:
              case KW_HOLD_DDLTIME:
              case KW_IDXPROPERTIES:
              case KW_IGNORE:
              case KW_IMPORT:
              case KW_IN:
              case KW_INDEX:
              case KW_INDEXES:
              case KW_INNER:
              case KW_INPATH:
              case KW_INPUTDRIVER:
              case KW_INPUTFORMAT:
              case KW_INSERT:
              case KW_INT:
              case KW_INTERSECT:
              case KW_INTO:
              case KW_IS:
              case KW_ITEMS:
              case KW_JAR:
              case KW_KEYS:
              case KW_KEY_TYPE:
              case KW_LATERAL:
              case KW_LEFT:
              case KW_LIKE:
              case KW_LIMIT:
              case KW_LINES:
              case KW_LOAD:
              case KW_LOCAL:
              case KW_LOCATION:
              case KW_LOCK:
              case KW_LOCKS:
              case KW_LOGICAL:
              case KW_LONG:
              case KW_MAPJOIN:
              case KW_MATERIALIZED:
              case KW_METADATA:
              case KW_MINUS:
              case KW_MSCK:
              case KW_NONE:
              case KW_NOSCAN:
              case KW_NO_DROP:
              case KW_NULL:
              case KW_OF:
              case KW_OFFLINE:
              case KW_OPTION:
              case KW_ORDER:
              case KW_OUT:
              case KW_OUTER:
              case KW_OUTPUTDRIVER:
              case KW_OUTPUTFORMAT:
              case KW_OVERWRITE:
              case KW_OWNER:
              case KW_PARTITION:
              case KW_PARTITIONED:
              case KW_PARTITIONS:
              case KW_PERCENT:
              case KW_PLUS:
              case KW_PRETTY:
              case KW_PRINCIPALS:
              case KW_PROCEDURE:
              case KW_PROTECTION:
              case KW_PURGE:
              case KW_RANGE:
              case KW_READ:
              case KW_READONLY:
              case KW_READS:
              case KW_REBUILD:
              case KW_RECORDREADER:
              case KW_RECORDWRITER:
              case KW_REGEXP:
              case KW_RELOAD:
              case KW_RENAME:
              case KW_REPAIR:
              case KW_REPLACE:
              case KW_REPLICATION:
              case KW_RESTRICT:
              case KW_REVOKE:
              case KW_REWRITE:
              case KW_RIGHT:
              case KW_RLIKE:
              case KW_ROLE:
              case KW_ROLES:
              case KW_ROLLUP:
              case KW_ROW:
              case KW_ROWS:
              case KW_SCHEMA:
              case KW_SCHEMAS:
              case KW_SEMI:
              case KW_SERDE:
              case KW_SERDEPROPERTIES:
              case KW_SERVER:
              case KW_SET:
              case KW_SETS:
              case KW_SHARED:
              case KW_SHOW:
              case KW_SHOW_DATABASE:
              case KW_SKEWED:
              case KW_SMALLINT:
              case KW_SORT:
              case KW_SORTED:
              case KW_SSL:
              case KW_STATISTICS:
              case KW_STORED:
              case KW_STREAMTABLE:
              case KW_STRING:
              case KW_STRUCT:
              case KW_TABLE:
              case KW_TABLES:
              case KW_TBLPROPERTIES:
              case KW_TEMPORARY:
              case KW_TERMINATED:
              case KW_TIMESTAMP:
              case KW_TINYINT:
              case KW_TOUCH:
              case KW_TRANSACTIONS:
              case KW_TRIGGER:
              case KW_TRUE:
              case KW_TRUNCATE:
              case KW_UNARCHIVE:
              case KW_UNDO:
              case KW_UNION:
              case KW_UNIONTYPE:
              case KW_UNLOCK:
              case KW_UNSET:
              case KW_UNSIGNED:
              case KW_UPDATE:
              case KW_URI:
              case KW_USE:
              case KW_USER:
              case KW_USING:
              case KW_UTC:
              case KW_UTCTIMESTAMP:
              case KW_VALUES:
              case KW_VALUE_TYPE:
              case KW_VIEW:
              case KW_WHILE:
              case KW_WITH: {
                alt152 = 1;
              }
              break;
              case KW_TO: {
                switch (input.LA(3)) {
                  case COMMA:
                  case KW_TO: {
                    alt152 = 1;
                  }
                  break;
                }
              }
              break;
            }
          }
          break;
        }

        switch (alt152) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1441:16: KW_ROLE
          {
            KW_ROLE501 = (Token) match(input, KW_ROLE, FOLLOW_KW_ROLE_in_grantRole7824);
            stream_KW_ROLE.add(KW_ROLE501);
          }
          break;
        }

        pushFollow(FOLLOW_identifier_in_grantRole7827);
        identifier502 = identifier();

        state._fsp--;

        stream_identifier.add(identifier502.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1441:36: ( COMMA identifier )*
        loop153:
        do {
          int alt153 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt153 = 1;
            }
            break;
          }

          switch (alt153) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1441:37: COMMA identifier
            {
              COMMA503 = (Token) match(input, COMMA, FOLLOW_COMMA_in_grantRole7830);
              stream_COMMA.add(COMMA503);

              pushFollow(FOLLOW_identifier_in_grantRole7832);
              identifier504 = identifier();

              state._fsp--;

              stream_identifier.add(identifier504.getTree());
            }
            break;

            default:
              break loop153;
          }
        } while (true);

        KW_TO505 = (Token) match(input, KW_TO, FOLLOW_KW_TO_in_grantRole7836);
        stream_KW_TO.add(KW_TO505);

        pushFollow(FOLLOW_principalSpecification_in_grantRole7838);
        principalSpecification506 = principalSpecification();

        state._fsp--;

        stream_principalSpecification.add(principalSpecification506.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1441:85: ( withAdminOption )?
        int alt154 = 2;
        switch (input.LA(1)) {
          case KW_WITH: {
            alt154 = 1;
          }
          break;
        }

        switch (alt154) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1441:85: withAdminOption
          {
            pushFollow(FOLLOW_withAdminOption_in_grantRole7840);
            withAdminOption507 = withAdminOption();

            state._fsp--;

            stream_withAdminOption.add(withAdminOption507.getTree());
          }
          break;
        }

        // AST REWRITE
        // elements: principalSpecification, withAdminOption, identifier
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1442:5: -> ^( TOK_GRANT_ROLE principalSpecification ( withAdminOption )? ( identifier )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1442:8: ^( TOK_GRANT_ROLE principalSpecification ( withAdminOption )? ( identifier )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_GRANT_ROLE, "TOK_GRANT_ROLE"), root_1);

            adaptor.addChild(root_1, stream_principalSpecification.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1442:48: ( withAdminOption )?
            if (stream_withAdminOption.hasNext()) {
              adaptor.addChild(root_1, stream_withAdminOption.nextTree());
            }
            stream_withAdminOption.reset();

            if (!(stream_identifier.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_identifier.hasNext()) {
              adaptor.addChild(root_1, stream_identifier.nextTree());
            }
            stream_identifier.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "grantRole"

  public static class revokeRole_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "revokeRole"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1445:1: revokeRole : KW_REVOKE ( adminOptionFor )? ( KW_ROLE )? identifier ( COMMA identifier )* KW_FROM principalSpecification -> ^( TOK_REVOKE_ROLE principalSpecification ( adminOptionFor )? ( identifier )+ ) ;
  public final HiveParser.revokeRole_return revokeRole() throws RecognitionException {
    HiveParser.revokeRole_return retval = new HiveParser.revokeRole_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_REVOKE508 = null;
    Token KW_ROLE510 = null;
    Token COMMA512 = null;
    Token KW_FROM514 = null;
    HiveParser.adminOptionFor_return adminOptionFor509 = null;

    HiveParser_IdentifiersParser.identifier_return identifier511 = null;

    HiveParser_IdentifiersParser.identifier_return identifier513 = null;

    HiveParser.principalSpecification_return principalSpecification515 = null;

    CommonTree KW_REVOKE508_tree = null;
    CommonTree KW_ROLE510_tree = null;
    CommonTree COMMA512_tree = null;
    CommonTree KW_FROM514_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleTokenStream stream_KW_ROLE = new RewriteRuleTokenStream(adaptor, "token KW_ROLE");
    RewriteRuleTokenStream stream_KW_FROM = new RewriteRuleTokenStream(adaptor, "token KW_FROM");
    RewriteRuleTokenStream stream_KW_REVOKE = new RewriteRuleTokenStream(adaptor, "token KW_REVOKE");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_adminOptionFor = new RewriteRuleSubtreeStream(adaptor, "rule adminOptionFor");
    RewriteRuleSubtreeStream stream_principalSpecification =
        new RewriteRuleSubtreeStream(adaptor, "rule principalSpecification");
    pushMsg("revoke role", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1448:5: ( KW_REVOKE ( adminOptionFor )? ( KW_ROLE )? identifier ( COMMA identifier )* KW_FROM principalSpecification -> ^( TOK_REVOKE_ROLE principalSpecification ( adminOptionFor )? ( identifier )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1448:7: KW_REVOKE ( adminOptionFor )? ( KW_ROLE )? identifier ( COMMA identifier )* KW_FROM principalSpecification
      {
        KW_REVOKE508 = (Token) match(input, KW_REVOKE, FOLLOW_KW_REVOKE_in_revokeRole7886);
        stream_KW_REVOKE.add(KW_REVOKE508);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1448:17: ( adminOptionFor )?
        int alt155 = 2;
        switch (input.LA(1)) {
          case KW_ADMIN: {
            switch (input.LA(2)) {
              case KW_OPTION: {
                alt155 = 1;
              }
              break;
            }
          }
          break;
        }

        switch (alt155) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1448:17: adminOptionFor
          {
            pushFollow(FOLLOW_adminOptionFor_in_revokeRole7888);
            adminOptionFor509 = adminOptionFor();

            state._fsp--;

            stream_adminOptionFor.add(adminOptionFor509.getTree());
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1448:33: ( KW_ROLE )?
        int alt156 = 2;
        switch (input.LA(1)) {
          case KW_ROLE: {
            switch (input.LA(2)) {
              case Identifier:
              case KW_ADD:
              case KW_ADMIN:
              case KW_AFTER:
              case KW_ALL:
              case KW_ALTER:
              case KW_ANALYZE:
              case KW_ARCHIVE:
              case KW_ARRAY:
              case KW_AS:
              case KW_ASC:
              case KW_AUTHORIZATION:
              case KW_BEFORE:
              case KW_BETWEEN:
              case KW_BIGINT:
              case KW_BINARY:
              case KW_BOOLEAN:
              case KW_BOTH:
              case KW_BUCKET:
              case KW_BUCKETS:
              case KW_BY:
              case KW_CASCADE:
              case KW_CHANGE:
              case KW_CLUSTER:
              case KW_CLUSTERED:
              case KW_CLUSTERSTATUS:
              case KW_COLLECTION:
              case KW_COLUMNS:
              case KW_COMMENT:
              case KW_COMPACT:
              case KW_COMPACTIONS:
              case KW_COMPUTE:
              case KW_CONCATENATE:
              case KW_CONTINUE:
              case KW_CREATE:
              case KW_CUBE:
              case KW_CURSOR:
              case KW_DATA:
              case KW_DATABASES:
              case KW_DATE:
              case KW_DATETIME:
              case KW_DBPROPERTIES:
              case KW_DECIMAL:
              case KW_DEFAULT:
              case KW_DEFERRED:
              case KW_DEFINED:
              case KW_DELETE:
              case KW_DELIMITED:
              case KW_DEPENDENCY:
              case KW_DESC:
              case KW_DESCRIBE:
              case KW_DIRECTORIES:
              case KW_DIRECTORY:
              case KW_DISABLE:
              case KW_DISTRIBUTE:
              case KW_DOUBLE:
              case KW_DROP:
              case KW_ELEM_TYPE:
              case KW_ENABLE:
              case KW_ESCAPED:
              case KW_EXCLUSIVE:
              case KW_EXISTS:
              case KW_EXPLAIN:
              case KW_EXPORT:
              case KW_EXTERNAL:
              case KW_FALSE:
              case KW_FETCH:
              case KW_FIELDS:
              case KW_FILE:
              case KW_FILEFORMAT:
              case KW_FIRST:
              case KW_FLOAT:
              case KW_FOR:
              case KW_FORMAT:
              case KW_FORMATTED:
              case KW_FULL:
              case KW_FUNCTIONS:
              case KW_GRANT:
              case KW_GROUP:
              case KW_GROUPING:
              case KW_HOLD_DDLTIME:
              case KW_IDXPROPERTIES:
              case KW_IGNORE:
              case KW_IMPORT:
              case KW_IN:
              case KW_INDEX:
              case KW_INDEXES:
              case KW_INNER:
              case KW_INPATH:
              case KW_INPUTDRIVER:
              case KW_INPUTFORMAT:
              case KW_INSERT:
              case KW_INT:
              case KW_INTERSECT:
              case KW_INTO:
              case KW_IS:
              case KW_ITEMS:
              case KW_JAR:
              case KW_KEYS:
              case KW_KEY_TYPE:
              case KW_LATERAL:
              case KW_LEFT:
              case KW_LIKE:
              case KW_LIMIT:
              case KW_LINES:
              case KW_LOAD:
              case KW_LOCAL:
              case KW_LOCATION:
              case KW_LOCK:
              case KW_LOCKS:
              case KW_LOGICAL:
              case KW_LONG:
              case KW_MAPJOIN:
              case KW_MATERIALIZED:
              case KW_METADATA:
              case KW_MINUS:
              case KW_MSCK:
              case KW_NONE:
              case KW_NOSCAN:
              case KW_NO_DROP:
              case KW_NULL:
              case KW_OF:
              case KW_OFFLINE:
              case KW_OPTION:
              case KW_ORDER:
              case KW_OUT:
              case KW_OUTER:
              case KW_OUTPUTDRIVER:
              case KW_OUTPUTFORMAT:
              case KW_OVERWRITE:
              case KW_OWNER:
              case KW_PARTITION:
              case KW_PARTITIONED:
              case KW_PARTITIONS:
              case KW_PERCENT:
              case KW_PLUS:
              case KW_PRETTY:
              case KW_PRINCIPALS:
              case KW_PROCEDURE:
              case KW_PROTECTION:
              case KW_PURGE:
              case KW_RANGE:
              case KW_READ:
              case KW_READONLY:
              case KW_READS:
              case KW_REBUILD:
              case KW_RECORDREADER:
              case KW_RECORDWRITER:
              case KW_REGEXP:
              case KW_RELOAD:
              case KW_RENAME:
              case KW_REPAIR:
              case KW_REPLACE:
              case KW_REPLICATION:
              case KW_RESTRICT:
              case KW_REVOKE:
              case KW_REWRITE:
              case KW_RIGHT:
              case KW_RLIKE:
              case KW_ROLE:
              case KW_ROLES:
              case KW_ROLLUP:
              case KW_ROW:
              case KW_ROWS:
              case KW_SCHEMA:
              case KW_SCHEMAS:
              case KW_SEMI:
              case KW_SERDE:
              case KW_SERDEPROPERTIES:
              case KW_SERVER:
              case KW_SET:
              case KW_SETS:
              case KW_SHARED:
              case KW_SHOW:
              case KW_SHOW_DATABASE:
              case KW_SKEWED:
              case KW_SMALLINT:
              case KW_SORT:
              case KW_SORTED:
              case KW_SSL:
              case KW_STATISTICS:
              case KW_STORED:
              case KW_STREAMTABLE:
              case KW_STRING:
              case KW_STRUCT:
              case KW_TABLE:
              case KW_TABLES:
              case KW_TBLPROPERTIES:
              case KW_TEMPORARY:
              case KW_TERMINATED:
              case KW_TIMESTAMP:
              case KW_TINYINT:
              case KW_TO:
              case KW_TOUCH:
              case KW_TRANSACTIONS:
              case KW_TRIGGER:
              case KW_TRUE:
              case KW_TRUNCATE:
              case KW_UNARCHIVE:
              case KW_UNDO:
              case KW_UNION:
              case KW_UNIONTYPE:
              case KW_UNLOCK:
              case KW_UNSET:
              case KW_UNSIGNED:
              case KW_UPDATE:
              case KW_URI:
              case KW_USE:
              case KW_USER:
              case KW_USING:
              case KW_UTC:
              case KW_UTCTIMESTAMP:
              case KW_VALUES:
              case KW_VALUE_TYPE:
              case KW_VIEW:
              case KW_WHILE:
              case KW_WITH: {
                alt156 = 1;
              }
              break;
            }
          }
          break;
        }

        switch (alt156) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1448:33: KW_ROLE
          {
            KW_ROLE510 = (Token) match(input, KW_ROLE, FOLLOW_KW_ROLE_in_revokeRole7891);
            stream_KW_ROLE.add(KW_ROLE510);
          }
          break;
        }

        pushFollow(FOLLOW_identifier_in_revokeRole7894);
        identifier511 = identifier();

        state._fsp--;

        stream_identifier.add(identifier511.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1448:53: ( COMMA identifier )*
        loop157:
        do {
          int alt157 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt157 = 1;
            }
            break;
          }

          switch (alt157) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1448:54: COMMA identifier
            {
              COMMA512 = (Token) match(input, COMMA, FOLLOW_COMMA_in_revokeRole7897);
              stream_COMMA.add(COMMA512);

              pushFollow(FOLLOW_identifier_in_revokeRole7899);
              identifier513 = identifier();

              state._fsp--;

              stream_identifier.add(identifier513.getTree());
            }
            break;

            default:
              break loop157;
          }
        } while (true);

        KW_FROM514 = (Token) match(input, KW_FROM, FOLLOW_KW_FROM_in_revokeRole7903);
        stream_KW_FROM.add(KW_FROM514);

        pushFollow(FOLLOW_principalSpecification_in_revokeRole7905);
        principalSpecification515 = principalSpecification();

        state._fsp--;

        stream_principalSpecification.add(principalSpecification515.getTree());

        // AST REWRITE
        // elements: adminOptionFor, identifier, principalSpecification
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1449:5: -> ^( TOK_REVOKE_ROLE principalSpecification ( adminOptionFor )? ( identifier )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1449:8: ^( TOK_REVOKE_ROLE principalSpecification ( adminOptionFor )? ( identifier )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_REVOKE_ROLE, "TOK_REVOKE_ROLE"),
                root_1);

            adaptor.addChild(root_1, stream_principalSpecification.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1449:49: ( adminOptionFor )?
            if (stream_adminOptionFor.hasNext()) {
              adaptor.addChild(root_1, stream_adminOptionFor.nextTree());
            }
            stream_adminOptionFor.reset();

            if (!(stream_identifier.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_identifier.hasNext()) {
              adaptor.addChild(root_1, stream_identifier.nextTree());
            }
            stream_identifier.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "revokeRole"

  public static class showRoleGrants_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "showRoleGrants"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1452:1: showRoleGrants : KW_SHOW KW_ROLE KW_GRANT principalName -> ^( TOK_SHOW_ROLE_GRANT principalName ) ;
  public final HiveParser.showRoleGrants_return showRoleGrants() throws RecognitionException {
    HiveParser.showRoleGrants_return retval = new HiveParser.showRoleGrants_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_SHOW516 = null;
    Token KW_ROLE517 = null;
    Token KW_GRANT518 = null;
    HiveParser.principalName_return principalName519 = null;

    CommonTree KW_SHOW516_tree = null;
    CommonTree KW_ROLE517_tree = null;
    CommonTree KW_GRANT518_tree = null;
    RewriteRuleTokenStream stream_KW_ROLE = new RewriteRuleTokenStream(adaptor, "token KW_ROLE");
    RewriteRuleTokenStream stream_KW_GRANT = new RewriteRuleTokenStream(adaptor, "token KW_GRANT");
    RewriteRuleTokenStream stream_KW_SHOW = new RewriteRuleTokenStream(adaptor, "token KW_SHOW");
    RewriteRuleSubtreeStream stream_principalName = new RewriteRuleSubtreeStream(adaptor, "rule principalName");
    pushMsg("show role grants", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1455:5: ( KW_SHOW KW_ROLE KW_GRANT principalName -> ^( TOK_SHOW_ROLE_GRANT principalName ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1455:7: KW_SHOW KW_ROLE KW_GRANT principalName
      {
        KW_SHOW516 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showRoleGrants7950);
        stream_KW_SHOW.add(KW_SHOW516);

        KW_ROLE517 = (Token) match(input, KW_ROLE, FOLLOW_KW_ROLE_in_showRoleGrants7952);
        stream_KW_ROLE.add(KW_ROLE517);

        KW_GRANT518 = (Token) match(input, KW_GRANT, FOLLOW_KW_GRANT_in_showRoleGrants7954);
        stream_KW_GRANT.add(KW_GRANT518);

        pushFollow(FOLLOW_principalName_in_showRoleGrants7956);
        principalName519 = principalName();

        state._fsp--;

        stream_principalName.add(principalName519.getTree());

        // AST REWRITE
        // elements: principalName
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1456:5: -> ^( TOK_SHOW_ROLE_GRANT principalName )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1456:8: ^( TOK_SHOW_ROLE_GRANT principalName )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SHOW_ROLE_GRANT, "TOK_SHOW_ROLE_GRANT"),
                    root_1);

            adaptor.addChild(root_1, stream_principalName.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "showRoleGrants"

  public static class showRoles_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "showRoles"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1460:1: showRoles : KW_SHOW KW_ROLES -> ^( TOK_SHOW_ROLES ) ;
  public final HiveParser.showRoles_return showRoles() throws RecognitionException {
    HiveParser.showRoles_return retval = new HiveParser.showRoles_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_SHOW520 = null;
    Token KW_ROLES521 = null;

    CommonTree KW_SHOW520_tree = null;
    CommonTree KW_ROLES521_tree = null;
    RewriteRuleTokenStream stream_KW_ROLES = new RewriteRuleTokenStream(adaptor, "token KW_ROLES");
    RewriteRuleTokenStream stream_KW_SHOW = new RewriteRuleTokenStream(adaptor, "token KW_SHOW");

    pushMsg("show roles", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1463:5: ( KW_SHOW KW_ROLES -> ^( TOK_SHOW_ROLES ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1463:7: KW_SHOW KW_ROLES
      {
        KW_SHOW520 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showRoles7996);
        stream_KW_SHOW.add(KW_SHOW520);

        KW_ROLES521 = (Token) match(input, KW_ROLES, FOLLOW_KW_ROLES_in_showRoles7998);
        stream_KW_ROLES.add(KW_ROLES521);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1464:5: -> ^( TOK_SHOW_ROLES )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1464:8: ^( TOK_SHOW_ROLES )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SHOW_ROLES, "TOK_SHOW_ROLES"), root_1);

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "showRoles"

  public static class showCurrentRole_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "showCurrentRole"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1467:1: showCurrentRole : KW_SHOW KW_CURRENT KW_ROLES -> ^( TOK_SHOW_SET_ROLE ) ;
  public final HiveParser.showCurrentRole_return showCurrentRole() throws RecognitionException {
    HiveParser.showCurrentRole_return retval = new HiveParser.showCurrentRole_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_SHOW522 = null;
    Token KW_CURRENT523 = null;
    Token KW_ROLES524 = null;

    CommonTree KW_SHOW522_tree = null;
    CommonTree KW_CURRENT523_tree = null;
    CommonTree KW_ROLES524_tree = null;
    RewriteRuleTokenStream stream_KW_ROLES = new RewriteRuleTokenStream(adaptor, "token KW_ROLES");
    RewriteRuleTokenStream stream_KW_SHOW = new RewriteRuleTokenStream(adaptor, "token KW_SHOW");
    RewriteRuleTokenStream stream_KW_CURRENT = new RewriteRuleTokenStream(adaptor, "token KW_CURRENT");

    pushMsg("show current role", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1470:5: ( KW_SHOW KW_CURRENT KW_ROLES -> ^( TOK_SHOW_SET_ROLE ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1470:7: KW_SHOW KW_CURRENT KW_ROLES
      {
        KW_SHOW522 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showCurrentRole8035);
        stream_KW_SHOW.add(KW_SHOW522);

        KW_CURRENT523 = (Token) match(input, KW_CURRENT, FOLLOW_KW_CURRENT_in_showCurrentRole8037);
        stream_KW_CURRENT.add(KW_CURRENT523);

        KW_ROLES524 = (Token) match(input, KW_ROLES, FOLLOW_KW_ROLES_in_showCurrentRole8039);
        stream_KW_ROLES.add(KW_ROLES524);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1471:5: -> ^( TOK_SHOW_SET_ROLE )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1471:8: ^( TOK_SHOW_SET_ROLE )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SHOW_SET_ROLE, "TOK_SHOW_SET_ROLE"),
                    root_1);

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "showCurrentRole"

  public static class setRole_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "setRole"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1474:1: setRole : KW_SET KW_ROLE roleName= identifier -> ^( TOK_SHOW_SET_ROLE $roleName) ;
  public final HiveParser.setRole_return setRole() throws RecognitionException {
    HiveParser.setRole_return retval = new HiveParser.setRole_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_SET525 = null;
    Token KW_ROLE526 = null;
    HiveParser_IdentifiersParser.identifier_return roleName = null;

    CommonTree KW_SET525_tree = null;
    CommonTree KW_ROLE526_tree = null;
    RewriteRuleTokenStream stream_KW_ROLE = new RewriteRuleTokenStream(adaptor, "token KW_ROLE");
    RewriteRuleTokenStream stream_KW_SET = new RewriteRuleTokenStream(adaptor, "token KW_SET");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    pushMsg("set role", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1477:5: ( KW_SET KW_ROLE roleName= identifier -> ^( TOK_SHOW_SET_ROLE $roleName) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1477:7: KW_SET KW_ROLE roleName= identifier
      {
        KW_SET525 = (Token) match(input, KW_SET, FOLLOW_KW_SET_in_setRole8076);
        stream_KW_SET.add(KW_SET525);

        KW_ROLE526 = (Token) match(input, KW_ROLE, FOLLOW_KW_ROLE_in_setRole8078);
        stream_KW_ROLE.add(KW_ROLE526);

        pushFollow(FOLLOW_identifier_in_setRole8082);
        roleName = identifier();

        state._fsp--;

        stream_identifier.add(roleName.getTree());

        // AST REWRITE
        // elements: roleName
        // token labels:
        // rule labels: roleName, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_roleName =
            new RewriteRuleSubtreeStream(adaptor, "rule roleName", roleName != null ? roleName.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1478:5: -> ^( TOK_SHOW_SET_ROLE $roleName)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1478:8: ^( TOK_SHOW_SET_ROLE $roleName)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SHOW_SET_ROLE, "TOK_SHOW_SET_ROLE"),
                    root_1);

            adaptor.addChild(root_1, stream_roleName.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "setRole"

  public static class showGrants_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "showGrants"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1481:1: showGrants : KW_SHOW KW_GRANT ( principalName )? ( KW_ON privilegeIncludeColObject )? -> ^( TOK_SHOW_GRANT ( principalName )? ( privilegeIncludeColObject )? ) ;
  public final HiveParser.showGrants_return showGrants() throws RecognitionException {
    HiveParser.showGrants_return retval = new HiveParser.showGrants_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_SHOW527 = null;
    Token KW_GRANT528 = null;
    Token KW_ON530 = null;
    HiveParser.principalName_return principalName529 = null;

    HiveParser.privilegeIncludeColObject_return privilegeIncludeColObject531 = null;

    CommonTree KW_SHOW527_tree = null;
    CommonTree KW_GRANT528_tree = null;
    CommonTree KW_ON530_tree = null;
    RewriteRuleTokenStream stream_KW_GRANT = new RewriteRuleTokenStream(adaptor, "token KW_GRANT");
    RewriteRuleTokenStream stream_KW_SHOW = new RewriteRuleTokenStream(adaptor, "token KW_SHOW");
    RewriteRuleTokenStream stream_KW_ON = new RewriteRuleTokenStream(adaptor, "token KW_ON");
    RewriteRuleSubtreeStream stream_privilegeIncludeColObject =
        new RewriteRuleSubtreeStream(adaptor, "rule privilegeIncludeColObject");
    RewriteRuleSubtreeStream stream_principalName = new RewriteRuleSubtreeStream(adaptor, "rule principalName");
    pushMsg("show grants", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1484:5: ( KW_SHOW KW_GRANT ( principalName )? ( KW_ON privilegeIncludeColObject )? -> ^( TOK_SHOW_GRANT ( principalName )? ( privilegeIncludeColObject )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1484:7: KW_SHOW KW_GRANT ( principalName )? ( KW_ON privilegeIncludeColObject )?
      {
        KW_SHOW527 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showGrants8122);
        stream_KW_SHOW.add(KW_SHOW527);

        KW_GRANT528 = (Token) match(input, KW_GRANT, FOLLOW_KW_GRANT_in_showGrants8124);
        stream_KW_GRANT.add(KW_GRANT528);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1484:24: ( principalName )?
        int alt158 = 2;
        switch (input.LA(1)) {
          case KW_GROUP:
          case KW_ROLE:
          case KW_USER: {
            alt158 = 1;
          }
          break;
        }

        switch (alt158) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1484:24: principalName
          {
            pushFollow(FOLLOW_principalName_in_showGrants8126);
            principalName529 = principalName();

            state._fsp--;

            stream_principalName.add(principalName529.getTree());
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1484:39: ( KW_ON privilegeIncludeColObject )?
        int alt159 = 2;
        switch (input.LA(1)) {
          case KW_ON: {
            alt159 = 1;
          }
          break;
        }

        switch (alt159) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1484:40: KW_ON privilegeIncludeColObject
          {
            KW_ON530 = (Token) match(input, KW_ON, FOLLOW_KW_ON_in_showGrants8130);
            stream_KW_ON.add(KW_ON530);

            pushFollow(FOLLOW_privilegeIncludeColObject_in_showGrants8132);
            privilegeIncludeColObject531 = privilegeIncludeColObject();

            state._fsp--;

            stream_privilegeIncludeColObject.add(privilegeIncludeColObject531.getTree());
          }
          break;
        }

        // AST REWRITE
        // elements: principalName, privilegeIncludeColObject
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1485:5: -> ^( TOK_SHOW_GRANT ( principalName )? ( privilegeIncludeColObject )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1485:8: ^( TOK_SHOW_GRANT ( principalName )? ( privilegeIncludeColObject )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SHOW_GRANT, "TOK_SHOW_GRANT"), root_1);

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1485:25: ( principalName )?
            if (stream_principalName.hasNext()) {
              adaptor.addChild(root_1, stream_principalName.nextTree());
            }
            stream_principalName.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1485:40: ( privilegeIncludeColObject )?
            if (stream_privilegeIncludeColObject.hasNext()) {
              adaptor.addChild(root_1, stream_privilegeIncludeColObject.nextTree());
            }
            stream_privilegeIncludeColObject.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "showGrants"

  public static class showRolePrincipals_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "showRolePrincipals"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1488:1: showRolePrincipals : KW_SHOW KW_PRINCIPALS roleName= identifier -> ^( TOK_SHOW_ROLE_PRINCIPALS $roleName) ;
  public final HiveParser.showRolePrincipals_return showRolePrincipals() throws RecognitionException {
    HiveParser.showRolePrincipals_return retval = new HiveParser.showRolePrincipals_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_SHOW532 = null;
    Token KW_PRINCIPALS533 = null;
    HiveParser_IdentifiersParser.identifier_return roleName = null;

    CommonTree KW_SHOW532_tree = null;
    CommonTree KW_PRINCIPALS533_tree = null;
    RewriteRuleTokenStream stream_KW_PRINCIPALS = new RewriteRuleTokenStream(adaptor, "token KW_PRINCIPALS");
    RewriteRuleTokenStream stream_KW_SHOW = new RewriteRuleTokenStream(adaptor, "token KW_SHOW");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    pushMsg("show role principals", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1491:5: ( KW_SHOW KW_PRINCIPALS roleName= identifier -> ^( TOK_SHOW_ROLE_PRINCIPALS $roleName) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1491:7: KW_SHOW KW_PRINCIPALS roleName= identifier
      {
        KW_SHOW532 = (Token) match(input, KW_SHOW, FOLLOW_KW_SHOW_in_showRolePrincipals8177);
        stream_KW_SHOW.add(KW_SHOW532);

        KW_PRINCIPALS533 = (Token) match(input, KW_PRINCIPALS, FOLLOW_KW_PRINCIPALS_in_showRolePrincipals8179);
        stream_KW_PRINCIPALS.add(KW_PRINCIPALS533);

        pushFollow(FOLLOW_identifier_in_showRolePrincipals8183);
        roleName = identifier();

        state._fsp--;

        stream_identifier.add(roleName.getTree());

        // AST REWRITE
        // elements: roleName
        // token labels:
        // rule labels: roleName, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_roleName =
            new RewriteRuleSubtreeStream(adaptor, "rule roleName", roleName != null ? roleName.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1492:5: -> ^( TOK_SHOW_ROLE_PRINCIPALS $roleName)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1492:8: ^( TOK_SHOW_ROLE_PRINCIPALS $roleName)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_SHOW_ROLE_PRINCIPALS, "TOK_SHOW_ROLE_PRINCIPALS"), root_1);

            adaptor.addChild(root_1, stream_roleName.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "showRolePrincipals"

  public static class privilegeIncludeColObject_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "privilegeIncludeColObject"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1496:1: privilegeIncludeColObject : ( KW_ALL -> ^( TOK_RESOURCE_ALL ) | privObjectCols -> ^( TOK_PRIV_OBJECT_COL privObjectCols ) );
  public final HiveParser.privilegeIncludeColObject_return privilegeIncludeColObject() throws RecognitionException {
    HiveParser.privilegeIncludeColObject_return retval = new HiveParser.privilegeIncludeColObject_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_ALL534 = null;
    HiveParser.privObjectCols_return privObjectCols535 = null;

    CommonTree KW_ALL534_tree = null;
    RewriteRuleTokenStream stream_KW_ALL = new RewriteRuleTokenStream(adaptor, "token KW_ALL");
    RewriteRuleSubtreeStream stream_privObjectCols = new RewriteRuleSubtreeStream(adaptor, "rule privObjectCols");
    pushMsg("privilege object including columns", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1499:5: ( KW_ALL -> ^( TOK_RESOURCE_ALL ) | privObjectCols -> ^( TOK_PRIV_OBJECT_COL privObjectCols ) )
      int alt160 = 2;
      switch (input.LA(1)) {
        case KW_ALL: {
          alt160 = 1;
        }
        break;
        case Identifier:
        case KW_ADD:
        case KW_ADMIN:
        case KW_AFTER:
        case KW_ALTER:
        case KW_ANALYZE:
        case KW_ARCHIVE:
        case KW_ARRAY:
        case KW_AS:
        case KW_ASC:
        case KW_AUTHORIZATION:
        case KW_BEFORE:
        case KW_BETWEEN:
        case KW_BIGINT:
        case KW_BINARY:
        case KW_BOOLEAN:
        case KW_BOTH:
        case KW_BUCKET:
        case KW_BUCKETS:
        case KW_BY:
        case KW_CASCADE:
        case KW_CHANGE:
        case KW_CLUSTER:
        case KW_CLUSTERED:
        case KW_CLUSTERSTATUS:
        case KW_COLLECTION:
        case KW_COLUMNS:
        case KW_COMMENT:
        case KW_COMPACT:
        case KW_COMPACTIONS:
        case KW_COMPUTE:
        case KW_CONCATENATE:
        case KW_CONTINUE:
        case KW_CREATE:
        case KW_CUBE:
        case KW_CURSOR:
        case KW_DATA:
        case KW_DATABASE:
        case KW_DATABASES:
        case KW_DATE:
        case KW_DATETIME:
        case KW_DBPROPERTIES:
        case KW_DECIMAL:
        case KW_DEFAULT:
        case KW_DEFERRED:
        case KW_DEFINED:
        case KW_DELETE:
        case KW_DELIMITED:
        case KW_DEPENDENCY:
        case KW_DESC:
        case KW_DESCRIBE:
        case KW_DIRECTORIES:
        case KW_DIRECTORY:
        case KW_DISABLE:
        case KW_DISTRIBUTE:
        case KW_DOUBLE:
        case KW_DROP:
        case KW_ELEM_TYPE:
        case KW_ENABLE:
        case KW_ESCAPED:
        case KW_EXCLUSIVE:
        case KW_EXISTS:
        case KW_EXPLAIN:
        case KW_EXPORT:
        case KW_EXTERNAL:
        case KW_FALSE:
        case KW_FETCH:
        case KW_FIELDS:
        case KW_FILE:
        case KW_FILEFORMAT:
        case KW_FIRST:
        case KW_FLOAT:
        case KW_FOR:
        case KW_FORMAT:
        case KW_FORMATTED:
        case KW_FULL:
        case KW_FUNCTIONS:
        case KW_GRANT:
        case KW_GROUP:
        case KW_GROUPING:
        case KW_HOLD_DDLTIME:
        case KW_IDXPROPERTIES:
        case KW_IGNORE:
        case KW_IMPORT:
        case KW_IN:
        case KW_INDEX:
        case KW_INDEXES:
        case KW_INNER:
        case KW_INPATH:
        case KW_INPUTDRIVER:
        case KW_INPUTFORMAT:
        case KW_INSERT:
        case KW_INT:
        case KW_INTERSECT:
        case KW_INTO:
        case KW_IS:
        case KW_ITEMS:
        case KW_JAR:
        case KW_KEYS:
        case KW_KEY_TYPE:
        case KW_LATERAL:
        case KW_LEFT:
        case KW_LIKE:
        case KW_LIMIT:
        case KW_LINES:
        case KW_LOAD:
        case KW_LOCAL:
        case KW_LOCATION:
        case KW_LOCK:
        case KW_LOCKS:
        case KW_LOGICAL:
        case KW_LONG:
        case KW_MAPJOIN:
        case KW_MATERIALIZED:
        case KW_METADATA:
        case KW_MINUS:
        case KW_MSCK:
        case KW_NONE:
        case KW_NOSCAN:
        case KW_NO_DROP:
        case KW_NULL:
        case KW_OF:
        case KW_OFFLINE:
        case KW_OPTION:
        case KW_ORDER:
        case KW_OUT:
        case KW_OUTER:
        case KW_OUTPUTDRIVER:
        case KW_OUTPUTFORMAT:
        case KW_OVERWRITE:
        case KW_OWNER:
        case KW_PARTITION:
        case KW_PARTITIONED:
        case KW_PARTITIONS:
        case KW_PERCENT:
        case KW_PLUS:
        case KW_PRETTY:
        case KW_PRINCIPALS:
        case KW_PROCEDURE:
        case KW_PROTECTION:
        case KW_PURGE:
        case KW_RANGE:
        case KW_READ:
        case KW_READONLY:
        case KW_READS:
        case KW_REBUILD:
        case KW_RECORDREADER:
        case KW_RECORDWRITER:
        case KW_REGEXP:
        case KW_RELOAD:
        case KW_RENAME:
        case KW_REPAIR:
        case KW_REPLACE:
        case KW_REPLICATION:
        case KW_RESTRICT:
        case KW_REVOKE:
        case KW_REWRITE:
        case KW_RIGHT:
        case KW_RLIKE:
        case KW_ROLE:
        case KW_ROLES:
        case KW_ROLLUP:
        case KW_ROW:
        case KW_ROWS:
        case KW_SCHEMA:
        case KW_SCHEMAS:
        case KW_SEMI:
        case KW_SERDE:
        case KW_SERDEPROPERTIES:
        case KW_SERVER:
        case KW_SET:
        case KW_SETS:
        case KW_SHARED:
        case KW_SHOW:
        case KW_SHOW_DATABASE:
        case KW_SKEWED:
        case KW_SMALLINT:
        case KW_SORT:
        case KW_SORTED:
        case KW_SSL:
        case KW_STATISTICS:
        case KW_STORED:
        case KW_STREAMTABLE:
        case KW_STRING:
        case KW_STRUCT:
        case KW_TABLE:
        case KW_TABLES:
        case KW_TBLPROPERTIES:
        case KW_TEMPORARY:
        case KW_TERMINATED:
        case KW_TIMESTAMP:
        case KW_TINYINT:
        case KW_TO:
        case KW_TOUCH:
        case KW_TRANSACTIONS:
        case KW_TRIGGER:
        case KW_TRUE:
        case KW_TRUNCATE:
        case KW_UNARCHIVE:
        case KW_UNDO:
        case KW_UNION:
        case KW_UNIONTYPE:
        case KW_UNLOCK:
        case KW_UNSET:
        case KW_UNSIGNED:
        case KW_UPDATE:
        case KW_URI:
        case KW_USE:
        case KW_USER:
        case KW_USING:
        case KW_UTC:
        case KW_UTCTIMESTAMP:
        case KW_VALUES:
        case KW_VALUE_TYPE:
        case KW_VIEW:
        case KW_WHILE:
        case KW_WITH: {
          alt160 = 2;
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 160, 0, input);

          throw nvae;
      }

      switch (alt160) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1499:7: KW_ALL
        {
          KW_ALL534 = (Token) match(input, KW_ALL, FOLLOW_KW_ALL_in_privilegeIncludeColObject8224);
          stream_KW_ALL.add(KW_ALL534);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1499:14: -> ^( TOK_RESOURCE_ALL )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1499:17: ^( TOK_RESOURCE_ALL )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_RESOURCE_ALL, "TOK_RESOURCE_ALL"),
                      root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1500:7: privObjectCols
        {
          pushFollow(FOLLOW_privObjectCols_in_privilegeIncludeColObject8238);
          privObjectCols535 = privObjectCols();

          state._fsp--;

          stream_privObjectCols.add(privObjectCols535.getTree());

          // AST REWRITE
          // elements: privObjectCols
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1500:22: -> ^( TOK_PRIV_OBJECT_COL privObjectCols )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1500:25: ^( TOK_PRIV_OBJECT_COL privObjectCols )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_PRIV_OBJECT_COL, "TOK_PRIV_OBJECT_COL"), root_1);

              adaptor.addChild(root_1, stream_privObjectCols.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "privilegeIncludeColObject"

  public static class privilegeObject_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "privilegeObject"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1503:1: privilegeObject : KW_ON privObject -> ^( TOK_PRIV_OBJECT privObject ) ;
  public final HiveParser.privilegeObject_return privilegeObject() throws RecognitionException {
    HiveParser.privilegeObject_return retval = new HiveParser.privilegeObject_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_ON536 = null;
    HiveParser.privObject_return privObject537 = null;

    CommonTree KW_ON536_tree = null;
    RewriteRuleTokenStream stream_KW_ON = new RewriteRuleTokenStream(adaptor, "token KW_ON");
    RewriteRuleSubtreeStream stream_privObject = new RewriteRuleSubtreeStream(adaptor, "rule privObject");
    pushMsg("privilege object", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1506:5: ( KW_ON privObject -> ^( TOK_PRIV_OBJECT privObject ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1506:7: KW_ON privObject
      {
        KW_ON536 = (Token) match(input, KW_ON, FOLLOW_KW_ON_in_privilegeObject8273);
        stream_KW_ON.add(KW_ON536);

        pushFollow(FOLLOW_privObject_in_privilegeObject8275);
        privObject537 = privObject();

        state._fsp--;

        stream_privObject.add(privObject537.getTree());

        // AST REWRITE
        // elements: privObject
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1506:24: -> ^( TOK_PRIV_OBJECT privObject )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1506:27: ^( TOK_PRIV_OBJECT privObject )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_PRIV_OBJECT, "TOK_PRIV_OBJECT"),
                root_1);

            adaptor.addChild(root_1, stream_privObject.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "privilegeObject"

  public static class privObject_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "privObject"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1510:1: privObject : ( ( KW_DATABASE | KW_SCHEMA ) identifier -> ^( TOK_DB_TYPE identifier ) | ( KW_TABLE )? tableName ( partitionSpec )? -> ^( TOK_TABLE_TYPE tableName ( partitionSpec )? ) | KW_URI (path= StringLiteral ) -> ^( TOK_URI_TYPE $path) | KW_SERVER identifier -> ^( TOK_SERVER_TYPE identifier ) );
  public final HiveParser.privObject_return privObject() throws RecognitionException {
    HiveParser.privObject_return retval = new HiveParser.privObject_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token path = null;
    Token KW_DATABASE538 = null;
    Token KW_SCHEMA539 = null;
    Token KW_TABLE541 = null;
    Token KW_URI544 = null;
    Token KW_SERVER545 = null;
    HiveParser_IdentifiersParser.identifier_return identifier540 = null;

    HiveParser_FromClauseParser.tableName_return tableName542 = null;

    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec543 = null;

    HiveParser_IdentifiersParser.identifier_return identifier546 = null;

    CommonTree path_tree = null;
    CommonTree KW_DATABASE538_tree = null;
    CommonTree KW_SCHEMA539_tree = null;
    CommonTree KW_TABLE541_tree = null;
    CommonTree KW_URI544_tree = null;
    CommonTree KW_SERVER545_tree = null;
    RewriteRuleTokenStream stream_KW_SERVER = new RewriteRuleTokenStream(adaptor, "token KW_SERVER");
    RewriteRuleTokenStream stream_KW_SCHEMA = new RewriteRuleTokenStream(adaptor, "token KW_SCHEMA");
    RewriteRuleTokenStream stream_KW_DATABASE = new RewriteRuleTokenStream(adaptor, "token KW_DATABASE");
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_URI = new RewriteRuleTokenStream(adaptor, "token KW_URI");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_partitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule partitionSpec");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1511:5: ( ( KW_DATABASE | KW_SCHEMA ) identifier -> ^( TOK_DB_TYPE identifier ) | ( KW_TABLE )? tableName ( partitionSpec )? -> ^( TOK_TABLE_TYPE tableName ( partitionSpec )? ) | KW_URI (path= StringLiteral ) -> ^( TOK_URI_TYPE $path) | KW_SERVER identifier -> ^( TOK_SERVER_TYPE identifier ) )
      int alt164 = 4;
      switch (input.LA(1)) {
        case KW_DATABASE: {
          alt164 = 1;
        }
        break;
        case KW_SCHEMA: {
          switch (input.LA(2)) {
            case Identifier:
            case KW_ADD:
            case KW_ADMIN:
            case KW_AFTER:
            case KW_ALL:
            case KW_ALTER:
            case KW_ANALYZE:
            case KW_ARCHIVE:
            case KW_ARRAY:
            case KW_AS:
            case KW_ASC:
            case KW_AUTHORIZATION:
            case KW_BEFORE:
            case KW_BETWEEN:
            case KW_BIGINT:
            case KW_BINARY:
            case KW_BOOLEAN:
            case KW_BOTH:
            case KW_BUCKET:
            case KW_BUCKETS:
            case KW_BY:
            case KW_CASCADE:
            case KW_CHANGE:
            case KW_CLUSTER:
            case KW_CLUSTERED:
            case KW_CLUSTERSTATUS:
            case KW_COLLECTION:
            case KW_COLUMNS:
            case KW_COMMENT:
            case KW_COMPACT:
            case KW_COMPACTIONS:
            case KW_COMPUTE:
            case KW_CONCATENATE:
            case KW_CONTINUE:
            case KW_CREATE:
            case KW_CUBE:
            case KW_CURSOR:
            case KW_DATA:
            case KW_DATABASES:
            case KW_DATE:
            case KW_DATETIME:
            case KW_DBPROPERTIES:
            case KW_DECIMAL:
            case KW_DEFAULT:
            case KW_DEFERRED:
            case KW_DEFINED:
            case KW_DELETE:
            case KW_DELIMITED:
            case KW_DEPENDENCY:
            case KW_DESC:
            case KW_DESCRIBE:
            case KW_DIRECTORIES:
            case KW_DIRECTORY:
            case KW_DISABLE:
            case KW_DISTRIBUTE:
            case KW_DOUBLE:
            case KW_DROP:
            case KW_ELEM_TYPE:
            case KW_ENABLE:
            case KW_ESCAPED:
            case KW_EXCLUSIVE:
            case KW_EXISTS:
            case KW_EXPLAIN:
            case KW_EXPORT:
            case KW_EXTERNAL:
            case KW_FALSE:
            case KW_FETCH:
            case KW_FIELDS:
            case KW_FILE:
            case KW_FILEFORMAT:
            case KW_FIRST:
            case KW_FLOAT:
            case KW_FOR:
            case KW_FORMAT:
            case KW_FORMATTED:
            case KW_FULL:
            case KW_FUNCTIONS:
            case KW_GRANT:
            case KW_GROUP:
            case KW_GROUPING:
            case KW_HOLD_DDLTIME:
            case KW_IDXPROPERTIES:
            case KW_IGNORE:
            case KW_IMPORT:
            case KW_IN:
            case KW_INDEX:
            case KW_INDEXES:
            case KW_INNER:
            case KW_INPATH:
            case KW_INPUTDRIVER:
            case KW_INPUTFORMAT:
            case KW_INSERT:
            case KW_INT:
            case KW_INTERSECT:
            case KW_INTO:
            case KW_IS:
            case KW_ITEMS:
            case KW_JAR:
            case KW_KEYS:
            case KW_KEY_TYPE:
            case KW_LATERAL:
            case KW_LEFT:
            case KW_LIKE:
            case KW_LIMIT:
            case KW_LINES:
            case KW_LOAD:
            case KW_LOCAL:
            case KW_LOCATION:
            case KW_LOCK:
            case KW_LOCKS:
            case KW_LOGICAL:
            case KW_LONG:
            case KW_MAPJOIN:
            case KW_MATERIALIZED:
            case KW_METADATA:
            case KW_MINUS:
            case KW_MSCK:
            case KW_NONE:
            case KW_NOSCAN:
            case KW_NO_DROP:
            case KW_NULL:
            case KW_OF:
            case KW_OFFLINE:
            case KW_OPTION:
            case KW_ORDER:
            case KW_OUT:
            case KW_OUTER:
            case KW_OUTPUTDRIVER:
            case KW_OUTPUTFORMAT:
            case KW_OVERWRITE:
            case KW_OWNER:
            case KW_PARTITIONED:
            case KW_PARTITIONS:
            case KW_PERCENT:
            case KW_PLUS:
            case KW_PRETTY:
            case KW_PRINCIPALS:
            case KW_PROCEDURE:
            case KW_PROTECTION:
            case KW_PURGE:
            case KW_RANGE:
            case KW_READ:
            case KW_READONLY:
            case KW_READS:
            case KW_REBUILD:
            case KW_RECORDREADER:
            case KW_RECORDWRITER:
            case KW_REGEXP:
            case KW_RELOAD:
            case KW_RENAME:
            case KW_REPAIR:
            case KW_REPLACE:
            case KW_REPLICATION:
            case KW_RESTRICT:
            case KW_REVOKE:
            case KW_REWRITE:
            case KW_RIGHT:
            case KW_RLIKE:
            case KW_ROLE:
            case KW_ROLES:
            case KW_ROLLUP:
            case KW_ROW:
            case KW_ROWS:
            case KW_SCHEMA:
            case KW_SCHEMAS:
            case KW_SEMI:
            case KW_SERDE:
            case KW_SERDEPROPERTIES:
            case KW_SERVER:
            case KW_SET:
            case KW_SETS:
            case KW_SHARED:
            case KW_SHOW:
            case KW_SHOW_DATABASE:
            case KW_SKEWED:
            case KW_SMALLINT:
            case KW_SORT:
            case KW_SORTED:
            case KW_SSL:
            case KW_STATISTICS:
            case KW_STORED:
            case KW_STREAMTABLE:
            case KW_STRING:
            case KW_STRUCT:
            case KW_TABLE:
            case KW_TABLES:
            case KW_TBLPROPERTIES:
            case KW_TEMPORARY:
            case KW_TERMINATED:
            case KW_TIMESTAMP:
            case KW_TINYINT:
            case KW_TOUCH:
            case KW_TRANSACTIONS:
            case KW_TRIGGER:
            case KW_TRUE:
            case KW_TRUNCATE:
            case KW_UNARCHIVE:
            case KW_UNDO:
            case KW_UNION:
            case KW_UNIONTYPE:
            case KW_UNLOCK:
            case KW_UNSET:
            case KW_UNSIGNED:
            case KW_UPDATE:
            case KW_URI:
            case KW_USE:
            case KW_USER:
            case KW_USING:
            case KW_UTC:
            case KW_UTCTIMESTAMP:
            case KW_VALUES:
            case KW_VALUE_TYPE:
            case KW_VIEW:
            case KW_WHILE:
            case KW_WITH: {
              alt164 = 1;
            }
            break;
            case KW_PARTITION: {
              switch (input.LA(3)) {
                case LPAREN: {
                  alt164 = 2;
                }
                break;
                case KW_FROM:
                case KW_TO: {
                  alt164 = 1;
                }
                break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 164, 9, input);

                  throw nvae;
              }
            }
            break;
            case DOT:
            case KW_FROM: {
              alt164 = 2;
            }
            break;
            case KW_TO: {
              switch (input.LA(3)) {
                case KW_FROM:
                case KW_TO: {
                  alt164 = 1;
                }
                break;
                case KW_GROUP:
                case KW_ROLE:
                case KW_USER: {
                  alt164 = 2;
                }
                break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 164, 11, input);

                  throw nvae;
              }
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 164, 2, input);

              throw nvae;
          }
        }
        break;
        case Identifier:
        case KW_ADD:
        case KW_ADMIN:
        case KW_AFTER:
        case KW_ALL:
        case KW_ALTER:
        case KW_ANALYZE:
        case KW_ARCHIVE:
        case KW_ARRAY:
        case KW_AS:
        case KW_ASC:
        case KW_AUTHORIZATION:
        case KW_BEFORE:
        case KW_BETWEEN:
        case KW_BIGINT:
        case KW_BINARY:
        case KW_BOOLEAN:
        case KW_BOTH:
        case KW_BUCKET:
        case KW_BUCKETS:
        case KW_BY:
        case KW_CASCADE:
        case KW_CHANGE:
        case KW_CLUSTER:
        case KW_CLUSTERED:
        case KW_CLUSTERSTATUS:
        case KW_COLLECTION:
        case KW_COLUMNS:
        case KW_COMMENT:
        case KW_COMPACT:
        case KW_COMPACTIONS:
        case KW_COMPUTE:
        case KW_CONCATENATE:
        case KW_CONTINUE:
        case KW_CREATE:
        case KW_CUBE:
        case KW_CURSOR:
        case KW_DATA:
        case KW_DATABASES:
        case KW_DATE:
        case KW_DATETIME:
        case KW_DBPROPERTIES:
        case KW_DECIMAL:
        case KW_DEFAULT:
        case KW_DEFERRED:
        case KW_DEFINED:
        case KW_DELETE:
        case KW_DELIMITED:
        case KW_DEPENDENCY:
        case KW_DESC:
        case KW_DESCRIBE:
        case KW_DIRECTORIES:
        case KW_DIRECTORY:
        case KW_DISABLE:
        case KW_DISTRIBUTE:
        case KW_DOUBLE:
        case KW_DROP:
        case KW_ELEM_TYPE:
        case KW_ENABLE:
        case KW_ESCAPED:
        case KW_EXCLUSIVE:
        case KW_EXISTS:
        case KW_EXPLAIN:
        case KW_EXPORT:
        case KW_EXTERNAL:
        case KW_FALSE:
        case KW_FETCH:
        case KW_FIELDS:
        case KW_FILE:
        case KW_FILEFORMAT:
        case KW_FIRST:
        case KW_FLOAT:
        case KW_FOR:
        case KW_FORMAT:
        case KW_FORMATTED:
        case KW_FULL:
        case KW_FUNCTIONS:
        case KW_GRANT:
        case KW_GROUP:
        case KW_GROUPING:
        case KW_HOLD_DDLTIME:
        case KW_IDXPROPERTIES:
        case KW_IGNORE:
        case KW_IMPORT:
        case KW_IN:
        case KW_INDEX:
        case KW_INDEXES:
        case KW_INNER:
        case KW_INPATH:
        case KW_INPUTDRIVER:
        case KW_INPUTFORMAT:
        case KW_INSERT:
        case KW_INT:
        case KW_INTERSECT:
        case KW_INTO:
        case KW_IS:
        case KW_ITEMS:
        case KW_JAR:
        case KW_KEYS:
        case KW_KEY_TYPE:
        case KW_LATERAL:
        case KW_LEFT:
        case KW_LIKE:
        case KW_LIMIT:
        case KW_LINES:
        case KW_LOAD:
        case KW_LOCAL:
        case KW_LOCATION:
        case KW_LOCK:
        case KW_LOCKS:
        case KW_LOGICAL:
        case KW_LONG:
        case KW_MAPJOIN:
        case KW_MATERIALIZED:
        case KW_METADATA:
        case KW_MINUS:
        case KW_MSCK:
        case KW_NONE:
        case KW_NOSCAN:
        case KW_NO_DROP:
        case KW_NULL:
        case KW_OF:
        case KW_OFFLINE:
        case KW_OPTION:
        case KW_ORDER:
        case KW_OUT:
        case KW_OUTER:
        case KW_OUTPUTDRIVER:
        case KW_OUTPUTFORMAT:
        case KW_OVERWRITE:
        case KW_OWNER:
        case KW_PARTITION:
        case KW_PARTITIONED:
        case KW_PARTITIONS:
        case KW_PERCENT:
        case KW_PLUS:
        case KW_PRETTY:
        case KW_PRINCIPALS:
        case KW_PROCEDURE:
        case KW_PROTECTION:
        case KW_PURGE:
        case KW_RANGE:
        case KW_READ:
        case KW_READONLY:
        case KW_READS:
        case KW_REBUILD:
        case KW_RECORDREADER:
        case KW_RECORDWRITER:
        case KW_REGEXP:
        case KW_RELOAD:
        case KW_RENAME:
        case KW_REPAIR:
        case KW_REPLACE:
        case KW_REPLICATION:
        case KW_RESTRICT:
        case KW_REVOKE:
        case KW_REWRITE:
        case KW_RIGHT:
        case KW_RLIKE:
        case KW_ROLE:
        case KW_ROLES:
        case KW_ROLLUP:
        case KW_ROW:
        case KW_ROWS:
        case KW_SCHEMAS:
        case KW_SEMI:
        case KW_SERDE:
        case KW_SERDEPROPERTIES:
        case KW_SET:
        case KW_SETS:
        case KW_SHARED:
        case KW_SHOW:
        case KW_SHOW_DATABASE:
        case KW_SKEWED:
        case KW_SMALLINT:
        case KW_SORT:
        case KW_SORTED:
        case KW_SSL:
        case KW_STATISTICS:
        case KW_STORED:
        case KW_STREAMTABLE:
        case KW_STRING:
        case KW_STRUCT:
        case KW_TABLE:
        case KW_TABLES:
        case KW_TBLPROPERTIES:
        case KW_TEMPORARY:
        case KW_TERMINATED:
        case KW_TIMESTAMP:
        case KW_TINYINT:
        case KW_TO:
        case KW_TOUCH:
        case KW_TRANSACTIONS:
        case KW_TRIGGER:
        case KW_TRUE:
        case KW_TRUNCATE:
        case KW_UNARCHIVE:
        case KW_UNDO:
        case KW_UNION:
        case KW_UNIONTYPE:
        case KW_UNLOCK:
        case KW_UNSET:
        case KW_UNSIGNED:
        case KW_UPDATE:
        case KW_USE:
        case KW_USER:
        case KW_USING:
        case KW_UTC:
        case KW_UTCTIMESTAMP:
        case KW_VALUES:
        case KW_VALUE_TYPE:
        case KW_VIEW:
        case KW_WHILE:
        case KW_WITH: {
          alt164 = 2;
        }
        break;
        case KW_URI: {
          switch (input.LA(2)) {
            case DOT:
            case KW_FROM:
            case KW_PARTITION:
            case KW_TO: {
              alt164 = 2;
            }
            break;
            case StringLiteral: {
              alt164 = 3;
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 164, 5, input);

              throw nvae;
          }
        }
        break;
        case KW_SERVER: {
          switch (input.LA(2)) {
            case DOT:
            case KW_FROM: {
              alt164 = 2;
            }
            break;
            case KW_PARTITION: {
              switch (input.LA(3)) {
                case LPAREN: {
                  alt164 = 2;
                }
                break;
                case KW_FROM:
                case KW_TO: {
                  alt164 = 4;
                }
                break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 164, 20, input);

                  throw nvae;
              }
            }
            break;
            case KW_TO: {
              switch (input.LA(3)) {
                case KW_GROUP:
                case KW_ROLE:
                case KW_USER: {
                  alt164 = 2;
                }
                break;
                case KW_FROM:
                case KW_TO: {
                  alt164 = 4;
                }
                break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 164, 21, input);

                  throw nvae;
              }
            }
            break;
            case Identifier:
            case KW_ADD:
            case KW_ADMIN:
            case KW_AFTER:
            case KW_ALL:
            case KW_ALTER:
            case KW_ANALYZE:
            case KW_ARCHIVE:
            case KW_ARRAY:
            case KW_AS:
            case KW_ASC:
            case KW_AUTHORIZATION:
            case KW_BEFORE:
            case KW_BETWEEN:
            case KW_BIGINT:
            case KW_BINARY:
            case KW_BOOLEAN:
            case KW_BOTH:
            case KW_BUCKET:
            case KW_BUCKETS:
            case KW_BY:
            case KW_CASCADE:
            case KW_CHANGE:
            case KW_CLUSTER:
            case KW_CLUSTERED:
            case KW_CLUSTERSTATUS:
            case KW_COLLECTION:
            case KW_COLUMNS:
            case KW_COMMENT:
            case KW_COMPACT:
            case KW_COMPACTIONS:
            case KW_COMPUTE:
            case KW_CONCATENATE:
            case KW_CONTINUE:
            case KW_CREATE:
            case KW_CUBE:
            case KW_CURSOR:
            case KW_DATA:
            case KW_DATABASES:
            case KW_DATE:
            case KW_DATETIME:
            case KW_DBPROPERTIES:
            case KW_DECIMAL:
            case KW_DEFAULT:
            case KW_DEFERRED:
            case KW_DEFINED:
            case KW_DELETE:
            case KW_DELIMITED:
            case KW_DEPENDENCY:
            case KW_DESC:
            case KW_DESCRIBE:
            case KW_DIRECTORIES:
            case KW_DIRECTORY:
            case KW_DISABLE:
            case KW_DISTRIBUTE:
            case KW_DOUBLE:
            case KW_DROP:
            case KW_ELEM_TYPE:
            case KW_ENABLE:
            case KW_ESCAPED:
            case KW_EXCLUSIVE:
            case KW_EXISTS:
            case KW_EXPLAIN:
            case KW_EXPORT:
            case KW_EXTERNAL:
            case KW_FALSE:
            case KW_FETCH:
            case KW_FIELDS:
            case KW_FILE:
            case KW_FILEFORMAT:
            case KW_FIRST:
            case KW_FLOAT:
            case KW_FOR:
            case KW_FORMAT:
            case KW_FORMATTED:
            case KW_FULL:
            case KW_FUNCTIONS:
            case KW_GRANT:
            case KW_GROUP:
            case KW_GROUPING:
            case KW_HOLD_DDLTIME:
            case KW_IDXPROPERTIES:
            case KW_IGNORE:
            case KW_IMPORT:
            case KW_IN:
            case KW_INDEX:
            case KW_INDEXES:
            case KW_INNER:
            case KW_INPATH:
            case KW_INPUTDRIVER:
            case KW_INPUTFORMAT:
            case KW_INSERT:
            case KW_INT:
            case KW_INTERSECT:
            case KW_INTO:
            case KW_IS:
            case KW_ITEMS:
            case KW_JAR:
            case KW_KEYS:
            case KW_KEY_TYPE:
            case KW_LATERAL:
            case KW_LEFT:
            case KW_LIKE:
            case KW_LIMIT:
            case KW_LINES:
            case KW_LOAD:
            case KW_LOCAL:
            case KW_LOCATION:
            case KW_LOCK:
            case KW_LOCKS:
            case KW_LOGICAL:
            case KW_LONG:
            case KW_MAPJOIN:
            case KW_MATERIALIZED:
            case KW_METADATA:
            case KW_MINUS:
            case KW_MSCK:
            case KW_NONE:
            case KW_NOSCAN:
            case KW_NO_DROP:
            case KW_NULL:
            case KW_OF:
            case KW_OFFLINE:
            case KW_OPTION:
            case KW_ORDER:
            case KW_OUT:
            case KW_OUTER:
            case KW_OUTPUTDRIVER:
            case KW_OUTPUTFORMAT:
            case KW_OVERWRITE:
            case KW_OWNER:
            case KW_PARTITIONED:
            case KW_PARTITIONS:
            case KW_PERCENT:
            case KW_PLUS:
            case KW_PRETTY:
            case KW_PRINCIPALS:
            case KW_PROCEDURE:
            case KW_PROTECTION:
            case KW_PURGE:
            case KW_RANGE:
            case KW_READ:
            case KW_READONLY:
            case KW_READS:
            case KW_REBUILD:
            case KW_RECORDREADER:
            case KW_RECORDWRITER:
            case KW_REGEXP:
            case KW_RELOAD:
            case KW_RENAME:
            case KW_REPAIR:
            case KW_REPLACE:
            case KW_REPLICATION:
            case KW_RESTRICT:
            case KW_REVOKE:
            case KW_REWRITE:
            case KW_RIGHT:
            case KW_RLIKE:
            case KW_ROLE:
            case KW_ROLES:
            case KW_ROLLUP:
            case KW_ROW:
            case KW_ROWS:
            case KW_SCHEMA:
            case KW_SCHEMAS:
            case KW_SEMI:
            case KW_SERDE:
            case KW_SERDEPROPERTIES:
            case KW_SERVER:
            case KW_SET:
            case KW_SETS:
            case KW_SHARED:
            case KW_SHOW:
            case KW_SHOW_DATABASE:
            case KW_SKEWED:
            case KW_SMALLINT:
            case KW_SORT:
            case KW_SORTED:
            case KW_SSL:
            case KW_STATISTICS:
            case KW_STORED:
            case KW_STREAMTABLE:
            case KW_STRING:
            case KW_STRUCT:
            case KW_TABLE:
            case KW_TABLES:
            case KW_TBLPROPERTIES:
            case KW_TEMPORARY:
            case KW_TERMINATED:
            case KW_TIMESTAMP:
            case KW_TINYINT:
            case KW_TOUCH:
            case KW_TRANSACTIONS:
            case KW_TRIGGER:
            case KW_TRUE:
            case KW_TRUNCATE:
            case KW_UNARCHIVE:
            case KW_UNDO:
            case KW_UNION:
            case KW_UNIONTYPE:
            case KW_UNLOCK:
            case KW_UNSET:
            case KW_UNSIGNED:
            case KW_UPDATE:
            case KW_URI:
            case KW_USE:
            case KW_USER:
            case KW_USING:
            case KW_UTC:
            case KW_UTCTIMESTAMP:
            case KW_VALUES:
            case KW_VALUE_TYPE:
            case KW_VIEW:
            case KW_WHILE:
            case KW_WITH: {
              alt164 = 4;
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 164, 6, input);

              throw nvae;
          }
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 164, 0, input);

          throw nvae;
      }

      switch (alt164) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1511:7: ( KW_DATABASE | KW_SCHEMA ) identifier
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1511:7: ( KW_DATABASE | KW_SCHEMA )
          int alt161 = 2;
          switch (input.LA(1)) {
            case KW_DATABASE: {
              alt161 = 1;
            }
            break;
            case KW_SCHEMA: {
              alt161 = 2;
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 161, 0, input);

              throw nvae;
          }

          switch (alt161) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1511:8: KW_DATABASE
            {
              KW_DATABASE538 = (Token) match(input, KW_DATABASE, FOLLOW_KW_DATABASE_in_privObject8302);
              stream_KW_DATABASE.add(KW_DATABASE538);
            }
            break;
            case 2:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1511:20: KW_SCHEMA
            {
              KW_SCHEMA539 = (Token) match(input, KW_SCHEMA, FOLLOW_KW_SCHEMA_in_privObject8304);
              stream_KW_SCHEMA.add(KW_SCHEMA539);
            }
            break;
          }

          pushFollow(FOLLOW_identifier_in_privObject8307);
          identifier540 = identifier();

          state._fsp--;

          stream_identifier.add(identifier540.getTree());

          // AST REWRITE
          // elements: identifier
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1511:42: -> ^( TOK_DB_TYPE identifier )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1511:45: ^( TOK_DB_TYPE identifier )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DB_TYPE, "TOK_DB_TYPE"), root_1);

              adaptor.addChild(root_1, stream_identifier.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1512:7: ( KW_TABLE )? tableName ( partitionSpec )?
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1512:7: ( KW_TABLE )?
          int alt162 = 2;
          switch (input.LA(1)) {
            case KW_TABLE: {
              switch (input.LA(2)) {
                case Identifier:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFAULT:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_METADATA:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NONE:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TOUCH:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH: {
                  alt162 = 1;
                }
                break;
                case KW_PARTITION: {
                  switch (input.LA(3)) {
                    case DOT:
                    case KW_FROM:
                    case KW_PARTITION:
                    case KW_TO: {
                      alt162 = 1;
                    }
                    break;
                  }
                }
                break;
                case KW_TO: {
                  switch (input.LA(3)) {
                    case DOT:
                    case KW_FROM:
                    case KW_PARTITION:
                    case KW_TO: {
                      alt162 = 1;
                    }
                    break;
                  }
                }
                break;
              }
            }
            break;
          }

          switch (alt162) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1512:7: KW_TABLE
            {
              KW_TABLE541 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_privObject8323);
              stream_KW_TABLE.add(KW_TABLE541);
            }
            break;
          }

          pushFollow(FOLLOW_tableName_in_privObject8326);
          tableName542 = tableName();

          state._fsp--;

          stream_tableName.add(tableName542.getTree());

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1512:27: ( partitionSpec )?
          int alt163 = 2;
          switch (input.LA(1)) {
            case KW_PARTITION: {
              alt163 = 1;
            }
            break;
          }

          switch (alt163) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1512:27: partitionSpec
            {
              pushFollow(FOLLOW_partitionSpec_in_privObject8328);
              partitionSpec543 = partitionSpec();

              state._fsp--;

              stream_partitionSpec.add(partitionSpec543.getTree());
            }
            break;
          }

          // AST REWRITE
          // elements: partitionSpec, tableName
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1512:42: -> ^( TOK_TABLE_TYPE tableName ( partitionSpec )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1512:45: ^( TOK_TABLE_TYPE tableName ( partitionSpec )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABLE_TYPE, "TOK_TABLE_TYPE"),
                  root_1);

              adaptor.addChild(root_1, stream_tableName.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1512:72: ( partitionSpec )?
              if (stream_partitionSpec.hasNext()) {
                adaptor.addChild(root_1, stream_partitionSpec.nextTree());
              }
              stream_partitionSpec.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 3:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1513:7: KW_URI (path= StringLiteral )
        {
          KW_URI544 = (Token) match(input, KW_URI, FOLLOW_KW_URI_in_privObject8348);
          stream_KW_URI.add(KW_URI544);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1513:14: (path= StringLiteral )
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1513:15: path= StringLiteral
          {
            path = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_privObject8353);
            stream_StringLiteral.add(path);
          }

          // AST REWRITE
          // elements: path
          // token labels: path
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleTokenStream stream_path = new RewriteRuleTokenStream(adaptor, "token path", path);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1513:35: -> ^( TOK_URI_TYPE $path)
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1513:39: ^( TOK_URI_TYPE $path)
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_URI_TYPE, "TOK_URI_TYPE"), root_1);

              adaptor.addChild(root_1, stream_path.nextNode());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 4:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1514:7: KW_SERVER identifier
        {
          KW_SERVER545 = (Token) match(input, KW_SERVER, FOLLOW_KW_SERVER_in_privObject8372);
          stream_KW_SERVER.add(KW_SERVER545);

          pushFollow(FOLLOW_identifier_in_privObject8374);
          identifier546 = identifier();

          state._fsp--;

          stream_identifier.add(identifier546.getTree());

          // AST REWRITE
          // elements: identifier
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1514:28: -> ^( TOK_SERVER_TYPE identifier )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1514:31: ^( TOK_SERVER_TYPE identifier )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SERVER_TYPE, "TOK_SERVER_TYPE"),
                  root_1);

              adaptor.addChild(root_1, stream_identifier.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "privObject"

  public static class privObjectCols_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "privObjectCols"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1517:1: privObjectCols : ( ( KW_DATABASE | KW_SCHEMA ) identifier -> ^( TOK_DB_TYPE identifier ) | ( KW_TABLE )? tableName ( LPAREN cols= columnNameList RPAREN )? ( partitionSpec )? -> ^( TOK_TABLE_TYPE tableName ( $cols)? ( partitionSpec )? ) | KW_URI (path= StringLiteral ) -> ^( TOK_URI_TYPE $path) | KW_SERVER identifier -> ^( TOK_SERVER_TYPE identifier ) );
  public final HiveParser.privObjectCols_return privObjectCols() throws RecognitionException {
    HiveParser.privObjectCols_return retval = new HiveParser.privObjectCols_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token path = null;
    Token KW_DATABASE547 = null;
    Token KW_SCHEMA548 = null;
    Token KW_TABLE550 = null;
    Token LPAREN552 = null;
    Token RPAREN553 = null;
    Token KW_URI555 = null;
    Token KW_SERVER556 = null;
    HiveParser.columnNameList_return cols = null;

    HiveParser_IdentifiersParser.identifier_return identifier549 = null;

    HiveParser_FromClauseParser.tableName_return tableName551 = null;

    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec554 = null;

    HiveParser_IdentifiersParser.identifier_return identifier557 = null;

    CommonTree path_tree = null;
    CommonTree KW_DATABASE547_tree = null;
    CommonTree KW_SCHEMA548_tree = null;
    CommonTree KW_TABLE550_tree = null;
    CommonTree LPAREN552_tree = null;
    CommonTree RPAREN553_tree = null;
    CommonTree KW_URI555_tree = null;
    CommonTree KW_SERVER556_tree = null;
    RewriteRuleTokenStream stream_KW_SERVER = new RewriteRuleTokenStream(adaptor, "token KW_SERVER");
    RewriteRuleTokenStream stream_KW_SCHEMA = new RewriteRuleTokenStream(adaptor, "token KW_SCHEMA");
    RewriteRuleTokenStream stream_KW_DATABASE = new RewriteRuleTokenStream(adaptor, "token KW_DATABASE");
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_KW_URI = new RewriteRuleTokenStream(adaptor, "token KW_URI");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_columnNameList = new RewriteRuleSubtreeStream(adaptor, "rule columnNameList");
    RewriteRuleSubtreeStream stream_partitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule partitionSpec");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1518:5: ( ( KW_DATABASE | KW_SCHEMA ) identifier -> ^( TOK_DB_TYPE identifier ) | ( KW_TABLE )? tableName ( LPAREN cols= columnNameList RPAREN )? ( partitionSpec )? -> ^( TOK_TABLE_TYPE tableName ( $cols)? ( partitionSpec )? ) | KW_URI (path= StringLiteral ) -> ^( TOK_URI_TYPE $path) | KW_SERVER identifier -> ^( TOK_SERVER_TYPE identifier ) )
      int alt169 = 4;
      switch (input.LA(1)) {
        case KW_DATABASE: {
          alt169 = 1;
        }
        break;
        case KW_SCHEMA: {
          switch (input.LA(2)) {
            case Identifier:
            case KW_ADD:
            case KW_ADMIN:
            case KW_AFTER:
            case KW_ALL:
            case KW_ALTER:
            case KW_ANALYZE:
            case KW_ARCHIVE:
            case KW_ARRAY:
            case KW_AS:
            case KW_ASC:
            case KW_AUTHORIZATION:
            case KW_BEFORE:
            case KW_BETWEEN:
            case KW_BIGINT:
            case KW_BINARY:
            case KW_BOOLEAN:
            case KW_BOTH:
            case KW_BUCKET:
            case KW_BUCKETS:
            case KW_BY:
            case KW_CASCADE:
            case KW_CHANGE:
            case KW_CLUSTER:
            case KW_CLUSTERED:
            case KW_CLUSTERSTATUS:
            case KW_COLLECTION:
            case KW_COLUMNS:
            case KW_COMMENT:
            case KW_COMPACT:
            case KW_COMPACTIONS:
            case KW_COMPUTE:
            case KW_CONCATENATE:
            case KW_CONTINUE:
            case KW_CREATE:
            case KW_CUBE:
            case KW_CURSOR:
            case KW_DATA:
            case KW_DATABASES:
            case KW_DATE:
            case KW_DATETIME:
            case KW_DBPROPERTIES:
            case KW_DECIMAL:
            case KW_DEFAULT:
            case KW_DEFERRED:
            case KW_DEFINED:
            case KW_DELETE:
            case KW_DELIMITED:
            case KW_DEPENDENCY:
            case KW_DESC:
            case KW_DESCRIBE:
            case KW_DIRECTORIES:
            case KW_DIRECTORY:
            case KW_DISABLE:
            case KW_DISTRIBUTE:
            case KW_DOUBLE:
            case KW_DROP:
            case KW_ELEM_TYPE:
            case KW_ENABLE:
            case KW_ESCAPED:
            case KW_EXCLUSIVE:
            case KW_EXISTS:
            case KW_EXPLAIN:
            case KW_EXPORT:
            case KW_EXTERNAL:
            case KW_FALSE:
            case KW_FETCH:
            case KW_FIELDS:
            case KW_FILE:
            case KW_FILEFORMAT:
            case KW_FIRST:
            case KW_FLOAT:
            case KW_FOR:
            case KW_FORMAT:
            case KW_FORMATTED:
            case KW_FULL:
            case KW_FUNCTIONS:
            case KW_GRANT:
            case KW_GROUP:
            case KW_GROUPING:
            case KW_HOLD_DDLTIME:
            case KW_IDXPROPERTIES:
            case KW_IGNORE:
            case KW_IMPORT:
            case KW_IN:
            case KW_INDEX:
            case KW_INDEXES:
            case KW_INNER:
            case KW_INPATH:
            case KW_INPUTDRIVER:
            case KW_INPUTFORMAT:
            case KW_INSERT:
            case KW_INT:
            case KW_INTERSECT:
            case KW_INTO:
            case KW_IS:
            case KW_ITEMS:
            case KW_JAR:
            case KW_KEYS:
            case KW_KEY_TYPE:
            case KW_LATERAL:
            case KW_LEFT:
            case KW_LIKE:
            case KW_LIMIT:
            case KW_LINES:
            case KW_LOAD:
            case KW_LOCAL:
            case KW_LOCATION:
            case KW_LOCK:
            case KW_LOCKS:
            case KW_LOGICAL:
            case KW_LONG:
            case KW_MAPJOIN:
            case KW_MATERIALIZED:
            case KW_METADATA:
            case KW_MINUS:
            case KW_MSCK:
            case KW_NONE:
            case KW_NOSCAN:
            case KW_NO_DROP:
            case KW_NULL:
            case KW_OF:
            case KW_OFFLINE:
            case KW_OPTION:
            case KW_ORDER:
            case KW_OUT:
            case KW_OUTER:
            case KW_OUTPUTDRIVER:
            case KW_OUTPUTFORMAT:
            case KW_OVERWRITE:
            case KW_OWNER:
            case KW_PARTITIONED:
            case KW_PARTITIONS:
            case KW_PERCENT:
            case KW_PLUS:
            case KW_PRETTY:
            case KW_PRINCIPALS:
            case KW_PROCEDURE:
            case KW_PROTECTION:
            case KW_PURGE:
            case KW_RANGE:
            case KW_READ:
            case KW_READONLY:
            case KW_READS:
            case KW_REBUILD:
            case KW_RECORDREADER:
            case KW_RECORDWRITER:
            case KW_REGEXP:
            case KW_RELOAD:
            case KW_RENAME:
            case KW_REPAIR:
            case KW_REPLACE:
            case KW_REPLICATION:
            case KW_RESTRICT:
            case KW_REVOKE:
            case KW_REWRITE:
            case KW_RIGHT:
            case KW_RLIKE:
            case KW_ROLE:
            case KW_ROLES:
            case KW_ROLLUP:
            case KW_ROW:
            case KW_ROWS:
            case KW_SCHEMA:
            case KW_SCHEMAS:
            case KW_SEMI:
            case KW_SERDE:
            case KW_SERDEPROPERTIES:
            case KW_SERVER:
            case KW_SET:
            case KW_SETS:
            case KW_SHARED:
            case KW_SHOW:
            case KW_SHOW_DATABASE:
            case KW_SKEWED:
            case KW_SMALLINT:
            case KW_SORT:
            case KW_SORTED:
            case KW_SSL:
            case KW_STATISTICS:
            case KW_STORED:
            case KW_STREAMTABLE:
            case KW_STRING:
            case KW_STRUCT:
            case KW_TABLE:
            case KW_TABLES:
            case KW_TBLPROPERTIES:
            case KW_TEMPORARY:
            case KW_TERMINATED:
            case KW_TIMESTAMP:
            case KW_TINYINT:
            case KW_TO:
            case KW_TOUCH:
            case KW_TRANSACTIONS:
            case KW_TRIGGER:
            case KW_TRUE:
            case KW_TRUNCATE:
            case KW_UNARCHIVE:
            case KW_UNDO:
            case KW_UNION:
            case KW_UNIONTYPE:
            case KW_UNLOCK:
            case KW_UNSET:
            case KW_UNSIGNED:
            case KW_UPDATE:
            case KW_URI:
            case KW_USE:
            case KW_USER:
            case KW_USING:
            case KW_UTC:
            case KW_UTCTIMESTAMP:
            case KW_VALUES:
            case KW_VALUE_TYPE:
            case KW_VIEW:
            case KW_WHILE:
            case KW_WITH: {
              alt169 = 1;
            }
            break;
            case KW_PARTITION: {
              switch (input.LA(3)) {
                case LPAREN: {
                  alt169 = 2;
                }
                break;
                case EOF: {
                  alt169 = 1;
                }
                break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 169, 9, input);

                  throw nvae;
              }
            }
            break;
            case EOF:
            case DOT:
            case LPAREN: {
              alt169 = 2;
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 169, 2, input);

              throw nvae;
          }
        }
        break;
        case Identifier:
        case KW_ADD:
        case KW_ADMIN:
        case KW_AFTER:
        case KW_ALL:
        case KW_ALTER:
        case KW_ANALYZE:
        case KW_ARCHIVE:
        case KW_ARRAY:
        case KW_AS:
        case KW_ASC:
        case KW_AUTHORIZATION:
        case KW_BEFORE:
        case KW_BETWEEN:
        case KW_BIGINT:
        case KW_BINARY:
        case KW_BOOLEAN:
        case KW_BOTH:
        case KW_BUCKET:
        case KW_BUCKETS:
        case KW_BY:
        case KW_CASCADE:
        case KW_CHANGE:
        case KW_CLUSTER:
        case KW_CLUSTERED:
        case KW_CLUSTERSTATUS:
        case KW_COLLECTION:
        case KW_COLUMNS:
        case KW_COMMENT:
        case KW_COMPACT:
        case KW_COMPACTIONS:
        case KW_COMPUTE:
        case KW_CONCATENATE:
        case KW_CONTINUE:
        case KW_CREATE:
        case KW_CUBE:
        case KW_CURSOR:
        case KW_DATA:
        case KW_DATABASES:
        case KW_DATE:
        case KW_DATETIME:
        case KW_DBPROPERTIES:
        case KW_DECIMAL:
        case KW_DEFAULT:
        case KW_DEFERRED:
        case KW_DEFINED:
        case KW_DELETE:
        case KW_DELIMITED:
        case KW_DEPENDENCY:
        case KW_DESC:
        case KW_DESCRIBE:
        case KW_DIRECTORIES:
        case KW_DIRECTORY:
        case KW_DISABLE:
        case KW_DISTRIBUTE:
        case KW_DOUBLE:
        case KW_DROP:
        case KW_ELEM_TYPE:
        case KW_ENABLE:
        case KW_ESCAPED:
        case KW_EXCLUSIVE:
        case KW_EXISTS:
        case KW_EXPLAIN:
        case KW_EXPORT:
        case KW_EXTERNAL:
        case KW_FALSE:
        case KW_FETCH:
        case KW_FIELDS:
        case KW_FILE:
        case KW_FILEFORMAT:
        case KW_FIRST:
        case KW_FLOAT:
        case KW_FOR:
        case KW_FORMAT:
        case KW_FORMATTED:
        case KW_FULL:
        case KW_FUNCTIONS:
        case KW_GRANT:
        case KW_GROUP:
        case KW_GROUPING:
        case KW_HOLD_DDLTIME:
        case KW_IDXPROPERTIES:
        case KW_IGNORE:
        case KW_IMPORT:
        case KW_IN:
        case KW_INDEX:
        case KW_INDEXES:
        case KW_INNER:
        case KW_INPATH:
        case KW_INPUTDRIVER:
        case KW_INPUTFORMAT:
        case KW_INSERT:
        case KW_INT:
        case KW_INTERSECT:
        case KW_INTO:
        case KW_IS:
        case KW_ITEMS:
        case KW_JAR:
        case KW_KEYS:
        case KW_KEY_TYPE:
        case KW_LATERAL:
        case KW_LEFT:
        case KW_LIKE:
        case KW_LIMIT:
        case KW_LINES:
        case KW_LOAD:
        case KW_LOCAL:
        case KW_LOCATION:
        case KW_LOCK:
        case KW_LOCKS:
        case KW_LOGICAL:
        case KW_LONG:
        case KW_MAPJOIN:
        case KW_MATERIALIZED:
        case KW_METADATA:
        case KW_MINUS:
        case KW_MSCK:
        case KW_NONE:
        case KW_NOSCAN:
        case KW_NO_DROP:
        case KW_NULL:
        case KW_OF:
        case KW_OFFLINE:
        case KW_OPTION:
        case KW_ORDER:
        case KW_OUT:
        case KW_OUTER:
        case KW_OUTPUTDRIVER:
        case KW_OUTPUTFORMAT:
        case KW_OVERWRITE:
        case KW_OWNER:
        case KW_PARTITION:
        case KW_PARTITIONED:
        case KW_PARTITIONS:
        case KW_PERCENT:
        case KW_PLUS:
        case KW_PRETTY:
        case KW_PRINCIPALS:
        case KW_PROCEDURE:
        case KW_PROTECTION:
        case KW_PURGE:
        case KW_RANGE:
        case KW_READ:
        case KW_READONLY:
        case KW_READS:
        case KW_REBUILD:
        case KW_RECORDREADER:
        case KW_RECORDWRITER:
        case KW_REGEXP:
        case KW_RELOAD:
        case KW_RENAME:
        case KW_REPAIR:
        case KW_REPLACE:
        case KW_REPLICATION:
        case KW_RESTRICT:
        case KW_REVOKE:
        case KW_REWRITE:
        case KW_RIGHT:
        case KW_RLIKE:
        case KW_ROLE:
        case KW_ROLES:
        case KW_ROLLUP:
        case KW_ROW:
        case KW_ROWS:
        case KW_SCHEMAS:
        case KW_SEMI:
        case KW_SERDE:
        case KW_SERDEPROPERTIES:
        case KW_SET:
        case KW_SETS:
        case KW_SHARED:
        case KW_SHOW:
        case KW_SHOW_DATABASE:
        case KW_SKEWED:
        case KW_SMALLINT:
        case KW_SORT:
        case KW_SORTED:
        case KW_SSL:
        case KW_STATISTICS:
        case KW_STORED:
        case KW_STREAMTABLE:
        case KW_STRING:
        case KW_STRUCT:
        case KW_TABLE:
        case KW_TABLES:
        case KW_TBLPROPERTIES:
        case KW_TEMPORARY:
        case KW_TERMINATED:
        case KW_TIMESTAMP:
        case KW_TINYINT:
        case KW_TO:
        case KW_TOUCH:
        case KW_TRANSACTIONS:
        case KW_TRIGGER:
        case KW_TRUE:
        case KW_TRUNCATE:
        case KW_UNARCHIVE:
        case KW_UNDO:
        case KW_UNION:
        case KW_UNIONTYPE:
        case KW_UNLOCK:
        case KW_UNSET:
        case KW_UNSIGNED:
        case KW_UPDATE:
        case KW_USE:
        case KW_USER:
        case KW_USING:
        case KW_UTC:
        case KW_UTCTIMESTAMP:
        case KW_VALUES:
        case KW_VALUE_TYPE:
        case KW_VIEW:
        case KW_WHILE:
        case KW_WITH: {
          alt169 = 2;
        }
        break;
        case KW_URI: {
          switch (input.LA(2)) {
            case EOF:
            case DOT:
            case KW_PARTITION:
            case LPAREN: {
              alt169 = 2;
            }
            break;
            case StringLiteral: {
              alt169 = 3;
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 169, 5, input);

              throw nvae;
          }
        }
        break;
        case KW_SERVER: {
          switch (input.LA(2)) {
            case EOF:
            case DOT:
            case LPAREN: {
              alt169 = 2;
            }
            break;
            case KW_PARTITION: {
              switch (input.LA(3)) {
                case LPAREN: {
                  alt169 = 2;
                }
                break;
                case EOF: {
                  alt169 = 4;
                }
                break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 169, 21, input);

                  throw nvae;
              }
            }
            break;
            case Identifier:
            case KW_ADD:
            case KW_ADMIN:
            case KW_AFTER:
            case KW_ALL:
            case KW_ALTER:
            case KW_ANALYZE:
            case KW_ARCHIVE:
            case KW_ARRAY:
            case KW_AS:
            case KW_ASC:
            case KW_AUTHORIZATION:
            case KW_BEFORE:
            case KW_BETWEEN:
            case KW_BIGINT:
            case KW_BINARY:
            case KW_BOOLEAN:
            case KW_BOTH:
            case KW_BUCKET:
            case KW_BUCKETS:
            case KW_BY:
            case KW_CASCADE:
            case KW_CHANGE:
            case KW_CLUSTER:
            case KW_CLUSTERED:
            case KW_CLUSTERSTATUS:
            case KW_COLLECTION:
            case KW_COLUMNS:
            case KW_COMMENT:
            case KW_COMPACT:
            case KW_COMPACTIONS:
            case KW_COMPUTE:
            case KW_CONCATENATE:
            case KW_CONTINUE:
            case KW_CREATE:
            case KW_CUBE:
            case KW_CURSOR:
            case KW_DATA:
            case KW_DATABASES:
            case KW_DATE:
            case KW_DATETIME:
            case KW_DBPROPERTIES:
            case KW_DECIMAL:
            case KW_DEFAULT:
            case KW_DEFERRED:
            case KW_DEFINED:
            case KW_DELETE:
            case KW_DELIMITED:
            case KW_DEPENDENCY:
            case KW_DESC:
            case KW_DESCRIBE:
            case KW_DIRECTORIES:
            case KW_DIRECTORY:
            case KW_DISABLE:
            case KW_DISTRIBUTE:
            case KW_DOUBLE:
            case KW_DROP:
            case KW_ELEM_TYPE:
            case KW_ENABLE:
            case KW_ESCAPED:
            case KW_EXCLUSIVE:
            case KW_EXISTS:
            case KW_EXPLAIN:
            case KW_EXPORT:
            case KW_EXTERNAL:
            case KW_FALSE:
            case KW_FETCH:
            case KW_FIELDS:
            case KW_FILE:
            case KW_FILEFORMAT:
            case KW_FIRST:
            case KW_FLOAT:
            case KW_FOR:
            case KW_FORMAT:
            case KW_FORMATTED:
            case KW_FULL:
            case KW_FUNCTIONS:
            case KW_GRANT:
            case KW_GROUP:
            case KW_GROUPING:
            case KW_HOLD_DDLTIME:
            case KW_IDXPROPERTIES:
            case KW_IGNORE:
            case KW_IMPORT:
            case KW_IN:
            case KW_INDEX:
            case KW_INDEXES:
            case KW_INNER:
            case KW_INPATH:
            case KW_INPUTDRIVER:
            case KW_INPUTFORMAT:
            case KW_INSERT:
            case KW_INT:
            case KW_INTERSECT:
            case KW_INTO:
            case KW_IS:
            case KW_ITEMS:
            case KW_JAR:
            case KW_KEYS:
            case KW_KEY_TYPE:
            case KW_LATERAL:
            case KW_LEFT:
            case KW_LIKE:
            case KW_LIMIT:
            case KW_LINES:
            case KW_LOAD:
            case KW_LOCAL:
            case KW_LOCATION:
            case KW_LOCK:
            case KW_LOCKS:
            case KW_LOGICAL:
            case KW_LONG:
            case KW_MAPJOIN:
            case KW_MATERIALIZED:
            case KW_METADATA:
            case KW_MINUS:
            case KW_MSCK:
            case KW_NONE:
            case KW_NOSCAN:
            case KW_NO_DROP:
            case KW_NULL:
            case KW_OF:
            case KW_OFFLINE:
            case KW_OPTION:
            case KW_ORDER:
            case KW_OUT:
            case KW_OUTER:
            case KW_OUTPUTDRIVER:
            case KW_OUTPUTFORMAT:
            case KW_OVERWRITE:
            case KW_OWNER:
            case KW_PARTITIONED:
            case KW_PARTITIONS:
            case KW_PERCENT:
            case KW_PLUS:
            case KW_PRETTY:
            case KW_PRINCIPALS:
            case KW_PROCEDURE:
            case KW_PROTECTION:
            case KW_PURGE:
            case KW_RANGE:
            case KW_READ:
            case KW_READONLY:
            case KW_READS:
            case KW_REBUILD:
            case KW_RECORDREADER:
            case KW_RECORDWRITER:
            case KW_REGEXP:
            case KW_RELOAD:
            case KW_RENAME:
            case KW_REPAIR:
            case KW_REPLACE:
            case KW_REPLICATION:
            case KW_RESTRICT:
            case KW_REVOKE:
            case KW_REWRITE:
            case KW_RIGHT:
            case KW_RLIKE:
            case KW_ROLE:
            case KW_ROLES:
            case KW_ROLLUP:
            case KW_ROW:
            case KW_ROWS:
            case KW_SCHEMA:
            case KW_SCHEMAS:
            case KW_SEMI:
            case KW_SERDE:
            case KW_SERDEPROPERTIES:
            case KW_SERVER:
            case KW_SET:
            case KW_SETS:
            case KW_SHARED:
            case KW_SHOW:
            case KW_SHOW_DATABASE:
            case KW_SKEWED:
            case KW_SMALLINT:
            case KW_SORT:
            case KW_SORTED:
            case KW_SSL:
            case KW_STATISTICS:
            case KW_STORED:
            case KW_STREAMTABLE:
            case KW_STRING:
            case KW_STRUCT:
            case KW_TABLE:
            case KW_TABLES:
            case KW_TBLPROPERTIES:
            case KW_TEMPORARY:
            case KW_TERMINATED:
            case KW_TIMESTAMP:
            case KW_TINYINT:
            case KW_TO:
            case KW_TOUCH:
            case KW_TRANSACTIONS:
            case KW_TRIGGER:
            case KW_TRUE:
            case KW_TRUNCATE:
            case KW_UNARCHIVE:
            case KW_UNDO:
            case KW_UNION:
            case KW_UNIONTYPE:
            case KW_UNLOCK:
            case KW_UNSET:
            case KW_UNSIGNED:
            case KW_UPDATE:
            case KW_URI:
            case KW_USE:
            case KW_USER:
            case KW_USING:
            case KW_UTC:
            case KW_UTCTIMESTAMP:
            case KW_VALUES:
            case KW_VALUE_TYPE:
            case KW_VIEW:
            case KW_WHILE:
            case KW_WITH: {
              alt169 = 4;
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 169, 6, input);

              throw nvae;
          }
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 169, 0, input);

          throw nvae;
      }

      switch (alt169) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1518:7: ( KW_DATABASE | KW_SCHEMA ) identifier
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1518:7: ( KW_DATABASE | KW_SCHEMA )
          int alt165 = 2;
          switch (input.LA(1)) {
            case KW_DATABASE: {
              alt165 = 1;
            }
            break;
            case KW_SCHEMA: {
              alt165 = 2;
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 165, 0, input);

              throw nvae;
          }

          switch (alt165) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1518:8: KW_DATABASE
            {
              KW_DATABASE547 = (Token) match(input, KW_DATABASE, FOLLOW_KW_DATABASE_in_privObjectCols8400);
              stream_KW_DATABASE.add(KW_DATABASE547);
            }
            break;
            case 2:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1518:20: KW_SCHEMA
            {
              KW_SCHEMA548 = (Token) match(input, KW_SCHEMA, FOLLOW_KW_SCHEMA_in_privObjectCols8402);
              stream_KW_SCHEMA.add(KW_SCHEMA548);
            }
            break;
          }

          pushFollow(FOLLOW_identifier_in_privObjectCols8405);
          identifier549 = identifier();

          state._fsp--;

          stream_identifier.add(identifier549.getTree());

          // AST REWRITE
          // elements: identifier
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1518:42: -> ^( TOK_DB_TYPE identifier )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1518:45: ^( TOK_DB_TYPE identifier )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DB_TYPE, "TOK_DB_TYPE"), root_1);

              adaptor.addChild(root_1, stream_identifier.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1519:7: ( KW_TABLE )? tableName ( LPAREN cols= columnNameList RPAREN )? ( partitionSpec )?
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1519:7: ( KW_TABLE )?
          int alt166 = 2;
          switch (input.LA(1)) {
            case KW_TABLE: {
              switch (input.LA(2)) {
                case Identifier:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFAULT:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_METADATA:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NONE:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH: {
                  alt166 = 1;
                }
                break;
                case KW_PARTITION: {
                  switch (input.LA(3)) {
                    case LPAREN: {
                      alt166 = 1;
                    }
                    break;
                    case EOF:
                    case DOT:
                    case KW_PARTITION: {
                      alt166 = 1;
                    }
                    break;
                  }
                }
                break;
              }
            }
            break;
          }

          switch (alt166) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1519:7: KW_TABLE
            {
              KW_TABLE550 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_privObjectCols8421);
              stream_KW_TABLE.add(KW_TABLE550);
            }
            break;
          }

          pushFollow(FOLLOW_tableName_in_privObjectCols8424);
          tableName551 = tableName();

          state._fsp--;

          stream_tableName.add(tableName551.getTree());

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1519:27: ( LPAREN cols= columnNameList RPAREN )?
          int alt167 = 2;
          switch (input.LA(1)) {
            case LPAREN: {
              alt167 = 1;
            }
            break;
          }

          switch (alt167) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1519:28: LPAREN cols= columnNameList RPAREN
            {
              LPAREN552 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_privObjectCols8427);
              stream_LPAREN.add(LPAREN552);

              pushFollow(FOLLOW_columnNameList_in_privObjectCols8431);
              cols = columnNameList();

              state._fsp--;

              stream_columnNameList.add(cols.getTree());

              RPAREN553 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_privObjectCols8433);
              stream_RPAREN.add(RPAREN553);
            }
            break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1519:64: ( partitionSpec )?
          int alt168 = 2;
          switch (input.LA(1)) {
            case KW_PARTITION: {
              alt168 = 1;
            }
            break;
          }

          switch (alt168) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1519:64: partitionSpec
            {
              pushFollow(FOLLOW_partitionSpec_in_privObjectCols8437);
              partitionSpec554 = partitionSpec();

              state._fsp--;

              stream_partitionSpec.add(partitionSpec554.getTree());
            }
            break;
          }

          // AST REWRITE
          // elements: tableName, cols, partitionSpec
          // token labels:
          // rule labels: cols, retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_cols =
              new RewriteRuleSubtreeStream(adaptor, "rule cols", cols != null ? cols.tree : null);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1519:79: -> ^( TOK_TABLE_TYPE tableName ( $cols)? ( partitionSpec )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1519:82: ^( TOK_TABLE_TYPE tableName ( $cols)? ( partitionSpec )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABLE_TYPE, "TOK_TABLE_TYPE"),
                  root_1);

              adaptor.addChild(root_1, stream_tableName.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1519:110: ( $cols)?
              if (stream_cols.hasNext()) {
                adaptor.addChild(root_1, stream_cols.nextTree());
              }
              stream_cols.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1519:116: ( partitionSpec )?
              if (stream_partitionSpec.hasNext()) {
                adaptor.addChild(root_1, stream_partitionSpec.nextTree());
              }
              stream_partitionSpec.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 3:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1520:7: KW_URI (path= StringLiteral )
        {
          KW_URI555 = (Token) match(input, KW_URI, FOLLOW_KW_URI_in_privObjectCols8461);
          stream_KW_URI.add(KW_URI555);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1520:14: (path= StringLiteral )
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1520:15: path= StringLiteral
          {
            path = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_privObjectCols8466);
            stream_StringLiteral.add(path);
          }

          // AST REWRITE
          // elements: path
          // token labels: path
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleTokenStream stream_path = new RewriteRuleTokenStream(adaptor, "token path", path);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1520:35: -> ^( TOK_URI_TYPE $path)
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1520:39: ^( TOK_URI_TYPE $path)
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_URI_TYPE, "TOK_URI_TYPE"), root_1);

              adaptor.addChild(root_1, stream_path.nextNode());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 4:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1521:7: KW_SERVER identifier
        {
          KW_SERVER556 = (Token) match(input, KW_SERVER, FOLLOW_KW_SERVER_in_privObjectCols8485);
          stream_KW_SERVER.add(KW_SERVER556);

          pushFollow(FOLLOW_identifier_in_privObjectCols8487);
          identifier557 = identifier();

          state._fsp--;

          stream_identifier.add(identifier557.getTree());

          // AST REWRITE
          // elements: identifier
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1521:28: -> ^( TOK_SERVER_TYPE identifier )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1521:31: ^( TOK_SERVER_TYPE identifier )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SERVER_TYPE, "TOK_SERVER_TYPE"),
                  root_1);

              adaptor.addChild(root_1, stream_identifier.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "privObjectCols"

  public static class privilegeList_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "privilegeList"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1524:1: privilegeList : privlegeDef ( COMMA privlegeDef )* -> ^( TOK_PRIVILEGE_LIST ( privlegeDef )+ ) ;
  public final HiveParser.privilegeList_return privilegeList() throws RecognitionException {
    HiveParser.privilegeList_return retval = new HiveParser.privilegeList_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token COMMA559 = null;
    HiveParser.privlegeDef_return privlegeDef558 = null;

    HiveParser.privlegeDef_return privlegeDef560 = null;

    CommonTree COMMA559_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleSubtreeStream stream_privlegeDef = new RewriteRuleSubtreeStream(adaptor, "rule privlegeDef");
    pushMsg("grant privilege list", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1527:5: ( privlegeDef ( COMMA privlegeDef )* -> ^( TOK_PRIVILEGE_LIST ( privlegeDef )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1527:7: privlegeDef ( COMMA privlegeDef )*
      {
        pushFollow(FOLLOW_privlegeDef_in_privilegeList8522);
        privlegeDef558 = privlegeDef();

        state._fsp--;

        stream_privlegeDef.add(privlegeDef558.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1527:19: ( COMMA privlegeDef )*
        loop170:
        do {
          int alt170 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt170 = 1;
            }
            break;
          }

          switch (alt170) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1527:20: COMMA privlegeDef
            {
              COMMA559 = (Token) match(input, COMMA, FOLLOW_COMMA_in_privilegeList8525);
              stream_COMMA.add(COMMA559);

              pushFollow(FOLLOW_privlegeDef_in_privilegeList8527);
              privlegeDef560 = privlegeDef();

              state._fsp--;

              stream_privlegeDef.add(privlegeDef560.getTree());
            }
            break;

            default:
              break loop170;
          }
        } while (true);

        // AST REWRITE
        // elements: privlegeDef
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1528:5: -> ^( TOK_PRIVILEGE_LIST ( privlegeDef )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1528:8: ^( TOK_PRIVILEGE_LIST ( privlegeDef )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_PRIVILEGE_LIST, "TOK_PRIVILEGE_LIST"),
                    root_1);

            if (!(stream_privlegeDef.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_privlegeDef.hasNext()) {
              adaptor.addChild(root_1, stream_privlegeDef.nextTree());
            }
            stream_privlegeDef.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "privilegeList"

  public static class privlegeDef_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "privlegeDef"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1531:1: privlegeDef : privilegeType ( LPAREN cols= columnNameList RPAREN )? -> ^( TOK_PRIVILEGE privilegeType ( $cols)? ) ;
  public final HiveParser.privlegeDef_return privlegeDef() throws RecognitionException {
    HiveParser.privlegeDef_return retval = new HiveParser.privlegeDef_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token LPAREN562 = null;
    Token RPAREN563 = null;
    HiveParser.columnNameList_return cols = null;

    HiveParser.privilegeType_return privilegeType561 = null;

    CommonTree LPAREN562_tree = null;
    CommonTree RPAREN563_tree = null;
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleSubtreeStream stream_columnNameList = new RewriteRuleSubtreeStream(adaptor, "rule columnNameList");
    RewriteRuleSubtreeStream stream_privilegeType = new RewriteRuleSubtreeStream(adaptor, "rule privilegeType");
    pushMsg("grant privilege", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1534:5: ( privilegeType ( LPAREN cols= columnNameList RPAREN )? -> ^( TOK_PRIVILEGE privilegeType ( $cols)? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1534:7: privilegeType ( LPAREN cols= columnNameList RPAREN )?
      {
        pushFollow(FOLLOW_privilegeType_in_privlegeDef8569);
        privilegeType561 = privilegeType();

        state._fsp--;

        stream_privilegeType.add(privilegeType561.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1534:21: ( LPAREN cols= columnNameList RPAREN )?
        int alt171 = 2;
        switch (input.LA(1)) {
          case LPAREN: {
            alt171 = 1;
          }
          break;
        }

        switch (alt171) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1534:22: LPAREN cols= columnNameList RPAREN
          {
            LPAREN562 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_privlegeDef8572);
            stream_LPAREN.add(LPAREN562);

            pushFollow(FOLLOW_columnNameList_in_privlegeDef8576);
            cols = columnNameList();

            state._fsp--;

            stream_columnNameList.add(cols.getTree());

            RPAREN563 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_privlegeDef8578);
            stream_RPAREN.add(RPAREN563);
          }
          break;
        }

        // AST REWRITE
        // elements: privilegeType, cols
        // token labels:
        // rule labels: cols, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_cols =
            new RewriteRuleSubtreeStream(adaptor, "rule cols", cols != null ? cols.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1535:5: -> ^( TOK_PRIVILEGE privilegeType ( $cols)? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1535:8: ^( TOK_PRIVILEGE privilegeType ( $cols)? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_PRIVILEGE, "TOK_PRIVILEGE"), root_1);

            adaptor.addChild(root_1, stream_privilegeType.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1535:39: ( $cols)?
            if (stream_cols.hasNext()) {
              adaptor.addChild(root_1, stream_cols.nextTree());
            }
            stream_cols.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "privlegeDef"

  public static class privilegeType_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "privilegeType"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1538:1: privilegeType : ( KW_ALL -> ^( TOK_PRIV_ALL ) | KW_ALTER -> ^( TOK_PRIV_ALTER_METADATA ) | KW_UPDATE -> ^( TOK_PRIV_ALTER_DATA ) | KW_CREATE -> ^( TOK_PRIV_CREATE ) | KW_DROP -> ^( TOK_PRIV_DROP ) | KW_INDEX -> ^( TOK_PRIV_INDEX ) | KW_LOCK -> ^( TOK_PRIV_LOCK ) | KW_SELECT -> ^( TOK_PRIV_SELECT ) | KW_SHOW_DATABASE -> ^( TOK_PRIV_SHOW_DATABASE ) | KW_INSERT -> ^( TOK_PRIV_INSERT ) | KW_DELETE -> ^( TOK_PRIV_DELETE ) );
  public final HiveParser.privilegeType_return privilegeType() throws RecognitionException {
    HiveParser.privilegeType_return retval = new HiveParser.privilegeType_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_ALL564 = null;
    Token KW_ALTER565 = null;
    Token KW_UPDATE566 = null;
    Token KW_CREATE567 = null;
    Token KW_DROP568 = null;
    Token KW_INDEX569 = null;
    Token KW_LOCK570 = null;
    Token KW_SELECT571 = null;
    Token KW_SHOW_DATABASE572 = null;
    Token KW_INSERT573 = null;
    Token KW_DELETE574 = null;

    CommonTree KW_ALL564_tree = null;
    CommonTree KW_ALTER565_tree = null;
    CommonTree KW_UPDATE566_tree = null;
    CommonTree KW_CREATE567_tree = null;
    CommonTree KW_DROP568_tree = null;
    CommonTree KW_INDEX569_tree = null;
    CommonTree KW_LOCK570_tree = null;
    CommonTree KW_SELECT571_tree = null;
    CommonTree KW_SHOW_DATABASE572_tree = null;
    CommonTree KW_INSERT573_tree = null;
    CommonTree KW_DELETE574_tree = null;
    RewriteRuleTokenStream stream_KW_DROP = new RewriteRuleTokenStream(adaptor, "token KW_DROP");
    RewriteRuleTokenStream stream_KW_DELETE = new RewriteRuleTokenStream(adaptor, "token KW_DELETE");
    RewriteRuleTokenStream stream_KW_SHOW_DATABASE = new RewriteRuleTokenStream(adaptor, "token KW_SHOW_DATABASE");
    RewriteRuleTokenStream stream_KW_CREATE = new RewriteRuleTokenStream(adaptor, "token KW_CREATE");
    RewriteRuleTokenStream stream_KW_INDEX = new RewriteRuleTokenStream(adaptor, "token KW_INDEX");
    RewriteRuleTokenStream stream_KW_ALTER = new RewriteRuleTokenStream(adaptor, "token KW_ALTER");
    RewriteRuleTokenStream stream_KW_UPDATE = new RewriteRuleTokenStream(adaptor, "token KW_UPDATE");
    RewriteRuleTokenStream stream_KW_LOCK = new RewriteRuleTokenStream(adaptor, "token KW_LOCK");
    RewriteRuleTokenStream stream_KW_INSERT = new RewriteRuleTokenStream(adaptor, "token KW_INSERT");
    RewriteRuleTokenStream stream_KW_SELECT = new RewriteRuleTokenStream(adaptor, "token KW_SELECT");
    RewriteRuleTokenStream stream_KW_ALL = new RewriteRuleTokenStream(adaptor, "token KW_ALL");

    pushMsg("privilege type", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1541:5: ( KW_ALL -> ^( TOK_PRIV_ALL ) | KW_ALTER -> ^( TOK_PRIV_ALTER_METADATA ) | KW_UPDATE -> ^( TOK_PRIV_ALTER_DATA ) | KW_CREATE -> ^( TOK_PRIV_CREATE ) | KW_DROP -> ^( TOK_PRIV_DROP ) | KW_INDEX -> ^( TOK_PRIV_INDEX ) | KW_LOCK -> ^( TOK_PRIV_LOCK ) | KW_SELECT -> ^( TOK_PRIV_SELECT ) | KW_SHOW_DATABASE -> ^( TOK_PRIV_SHOW_DATABASE ) | KW_INSERT -> ^( TOK_PRIV_INSERT ) | KW_DELETE -> ^( TOK_PRIV_DELETE ) )
      int alt172 = 11;
      switch (input.LA(1)) {
        case KW_ALL: {
          alt172 = 1;
        }
        break;
        case KW_ALTER: {
          alt172 = 2;
        }
        break;
        case KW_UPDATE: {
          alt172 = 3;
        }
        break;
        case KW_CREATE: {
          alt172 = 4;
        }
        break;
        case KW_DROP: {
          alt172 = 5;
        }
        break;
        case KW_INDEX: {
          alt172 = 6;
        }
        break;
        case KW_LOCK: {
          alt172 = 7;
        }
        break;
        case KW_SELECT: {
          alt172 = 8;
        }
        break;
        case KW_SHOW_DATABASE: {
          alt172 = 9;
        }
        break;
        case KW_INSERT: {
          alt172 = 10;
        }
        break;
        case KW_DELETE: {
          alt172 = 11;
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 172, 0, input);

          throw nvae;
      }

      switch (alt172) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1541:7: KW_ALL
        {
          KW_ALL564 = (Token) match(input, KW_ALL, FOLLOW_KW_ALL_in_privilegeType8623);
          stream_KW_ALL.add(KW_ALL564);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1541:14: -> ^( TOK_PRIV_ALL )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1541:17: ^( TOK_PRIV_ALL )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_PRIV_ALL, "TOK_PRIV_ALL"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1542:7: KW_ALTER
        {
          KW_ALTER565 = (Token) match(input, KW_ALTER, FOLLOW_KW_ALTER_in_privilegeType8637);
          stream_KW_ALTER.add(KW_ALTER565);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1542:16: -> ^( TOK_PRIV_ALTER_METADATA )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1542:19: ^( TOK_PRIV_ALTER_METADATA )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_PRIV_ALTER_METADATA, "TOK_PRIV_ALTER_METADATA"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 3:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1543:7: KW_UPDATE
        {
          KW_UPDATE566 = (Token) match(input, KW_UPDATE, FOLLOW_KW_UPDATE_in_privilegeType8651);
          stream_KW_UPDATE.add(KW_UPDATE566);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1543:17: -> ^( TOK_PRIV_ALTER_DATA )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1543:20: ^( TOK_PRIV_ALTER_DATA )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_PRIV_ALTER_DATA, "TOK_PRIV_ALTER_DATA"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 4:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1544:7: KW_CREATE
        {
          KW_CREATE567 = (Token) match(input, KW_CREATE, FOLLOW_KW_CREATE_in_privilegeType8665);
          stream_KW_CREATE.add(KW_CREATE567);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1544:17: -> ^( TOK_PRIV_CREATE )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1544:20: ^( TOK_PRIV_CREATE )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_PRIV_CREATE, "TOK_PRIV_CREATE"),
                  root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 5:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1545:7: KW_DROP
        {
          KW_DROP568 = (Token) match(input, KW_DROP, FOLLOW_KW_DROP_in_privilegeType8679);
          stream_KW_DROP.add(KW_DROP568);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1545:15: -> ^( TOK_PRIV_DROP )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1545:18: ^( TOK_PRIV_DROP )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_PRIV_DROP, "TOK_PRIV_DROP"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 6:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1546:7: KW_INDEX
        {
          KW_INDEX569 = (Token) match(input, KW_INDEX, FOLLOW_KW_INDEX_in_privilegeType8693);
          stream_KW_INDEX.add(KW_INDEX569);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1546:16: -> ^( TOK_PRIV_INDEX )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1546:19: ^( TOK_PRIV_INDEX )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_PRIV_INDEX, "TOK_PRIV_INDEX"),
                  root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 7:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1547:7: KW_LOCK
        {
          KW_LOCK570 = (Token) match(input, KW_LOCK, FOLLOW_KW_LOCK_in_privilegeType8707);
          stream_KW_LOCK.add(KW_LOCK570);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1547:15: -> ^( TOK_PRIV_LOCK )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1547:18: ^( TOK_PRIV_LOCK )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_PRIV_LOCK, "TOK_PRIV_LOCK"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 8:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1548:7: KW_SELECT
        {
          KW_SELECT571 = (Token) match(input, KW_SELECT, FOLLOW_KW_SELECT_in_privilegeType8721);
          stream_KW_SELECT.add(KW_SELECT571);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1548:17: -> ^( TOK_PRIV_SELECT )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1548:20: ^( TOK_PRIV_SELECT )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_PRIV_SELECT, "TOK_PRIV_SELECT"),
                  root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 9:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1549:7: KW_SHOW_DATABASE
        {
          KW_SHOW_DATABASE572 = (Token) match(input, KW_SHOW_DATABASE, FOLLOW_KW_SHOW_DATABASE_in_privilegeType8735);
          stream_KW_SHOW_DATABASE.add(KW_SHOW_DATABASE572);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1549:24: -> ^( TOK_PRIV_SHOW_DATABASE )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1549:27: ^( TOK_PRIV_SHOW_DATABASE )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_PRIV_SHOW_DATABASE, "TOK_PRIV_SHOW_DATABASE"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 10:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1550:7: KW_INSERT
        {
          KW_INSERT573 = (Token) match(input, KW_INSERT, FOLLOW_KW_INSERT_in_privilegeType8749);
          stream_KW_INSERT.add(KW_INSERT573);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1550:17: -> ^( TOK_PRIV_INSERT )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1550:20: ^( TOK_PRIV_INSERT )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_PRIV_INSERT, "TOK_PRIV_INSERT"),
                  root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 11:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1551:7: KW_DELETE
        {
          KW_DELETE574 = (Token) match(input, KW_DELETE, FOLLOW_KW_DELETE_in_privilegeType8763);
          stream_KW_DELETE.add(KW_DELETE574);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1551:17: -> ^( TOK_PRIV_DELETE )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1551:20: ^( TOK_PRIV_DELETE )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_PRIV_DELETE, "TOK_PRIV_DELETE"),
                  root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "privilegeType"

  public static class principalSpecification_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "principalSpecification"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1554:1: principalSpecification : principalName ( COMMA principalName )* -> ^( TOK_PRINCIPAL_NAME ( principalName )+ ) ;
  public final HiveParser.principalSpecification_return principalSpecification() throws RecognitionException {
    HiveParser.principalSpecification_return retval = new HiveParser.principalSpecification_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token COMMA576 = null;
    HiveParser.principalName_return principalName575 = null;

    HiveParser.principalName_return principalName577 = null;

    CommonTree COMMA576_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleSubtreeStream stream_principalName = new RewriteRuleSubtreeStream(adaptor, "rule principalName");
    pushMsg("user/group/role name list", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1557:5: ( principalName ( COMMA principalName )* -> ^( TOK_PRINCIPAL_NAME ( principalName )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1557:7: principalName ( COMMA principalName )*
      {
        pushFollow(FOLLOW_principalName_in_principalSpecification8796);
        principalName575 = principalName();

        state._fsp--;

        stream_principalName.add(principalName575.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1557:21: ( COMMA principalName )*
        loop173:
        do {
          int alt173 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt173 = 1;
            }
            break;
          }

          switch (alt173) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1557:22: COMMA principalName
            {
              COMMA576 = (Token) match(input, COMMA, FOLLOW_COMMA_in_principalSpecification8799);
              stream_COMMA.add(COMMA576);

              pushFollow(FOLLOW_principalName_in_principalSpecification8801);
              principalName577 = principalName();

              state._fsp--;

              stream_principalName.add(principalName577.getTree());
            }
            break;

            default:
              break loop173;
          }
        } while (true);

        // AST REWRITE
        // elements: principalName
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1557:44: -> ^( TOK_PRINCIPAL_NAME ( principalName )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1557:47: ^( TOK_PRINCIPAL_NAME ( principalName )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_PRINCIPAL_NAME, "TOK_PRINCIPAL_NAME"),
                    root_1);

            if (!(stream_principalName.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_principalName.hasNext()) {
              adaptor.addChild(root_1, stream_principalName.nextTree());
            }
            stream_principalName.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "principalSpecification"

  public static class principalName_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "principalName"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1560:1: principalName : ( KW_USER principalIdentifier -> ^( TOK_USER principalIdentifier ) | KW_GROUP principalIdentifier -> ^( TOK_GROUP principalIdentifier ) | KW_ROLE identifier -> ^( TOK_ROLE identifier ) );
  public final HiveParser.principalName_return principalName() throws RecognitionException {
    HiveParser.principalName_return retval = new HiveParser.principalName_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_USER578 = null;
    Token KW_GROUP580 = null;
    Token KW_ROLE582 = null;
    HiveParser_IdentifiersParser.principalIdentifier_return principalIdentifier579 = null;

    HiveParser_IdentifiersParser.principalIdentifier_return principalIdentifier581 = null;

    HiveParser_IdentifiersParser.identifier_return identifier583 = null;

    CommonTree KW_USER578_tree = null;
    CommonTree KW_GROUP580_tree = null;
    CommonTree KW_ROLE582_tree = null;
    RewriteRuleTokenStream stream_KW_ROLE = new RewriteRuleTokenStream(adaptor, "token KW_ROLE");
    RewriteRuleTokenStream stream_KW_USER = new RewriteRuleTokenStream(adaptor, "token KW_USER");
    RewriteRuleTokenStream stream_KW_GROUP = new RewriteRuleTokenStream(adaptor, "token KW_GROUP");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_principalIdentifier =
        new RewriteRuleSubtreeStream(adaptor, "rule principalIdentifier");
    pushMsg("user|group|role name", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1563:5: ( KW_USER principalIdentifier -> ^( TOK_USER principalIdentifier ) | KW_GROUP principalIdentifier -> ^( TOK_GROUP principalIdentifier ) | KW_ROLE identifier -> ^( TOK_ROLE identifier ) )
      int alt174 = 3;
      switch (input.LA(1)) {
        case KW_USER: {
          alt174 = 1;
        }
        break;
        case KW_GROUP: {
          alt174 = 2;
        }
        break;
        case KW_ROLE: {
          alt174 = 3;
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 174, 0, input);

          throw nvae;
      }

      switch (alt174) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1563:7: KW_USER principalIdentifier
        {
          KW_USER578 = (Token) match(input, KW_USER, FOLLOW_KW_USER_in_principalName8839);
          stream_KW_USER.add(KW_USER578);

          pushFollow(FOLLOW_principalIdentifier_in_principalName8841);
          principalIdentifier579 = principalIdentifier();

          state._fsp--;

          stream_principalIdentifier.add(principalIdentifier579.getTree());

          // AST REWRITE
          // elements: principalIdentifier
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1563:35: -> ^( TOK_USER principalIdentifier )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1563:38: ^( TOK_USER principalIdentifier )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_USER, "TOK_USER"), root_1);

              adaptor.addChild(root_1, stream_principalIdentifier.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1564:7: KW_GROUP principalIdentifier
        {
          KW_GROUP580 = (Token) match(input, KW_GROUP, FOLLOW_KW_GROUP_in_principalName8857);
          stream_KW_GROUP.add(KW_GROUP580);

          pushFollow(FOLLOW_principalIdentifier_in_principalName8859);
          principalIdentifier581 = principalIdentifier();

          state._fsp--;

          stream_principalIdentifier.add(principalIdentifier581.getTree());

          // AST REWRITE
          // elements: principalIdentifier
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1564:36: -> ^( TOK_GROUP principalIdentifier )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1564:39: ^( TOK_GROUP principalIdentifier )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_GROUP, "TOK_GROUP"), root_1);

              adaptor.addChild(root_1, stream_principalIdentifier.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 3:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1565:7: KW_ROLE identifier
        {
          KW_ROLE582 = (Token) match(input, KW_ROLE, FOLLOW_KW_ROLE_in_principalName8875);
          stream_KW_ROLE.add(KW_ROLE582);

          pushFollow(FOLLOW_identifier_in_principalName8877);
          identifier583 = identifier();

          state._fsp--;

          stream_identifier.add(identifier583.getTree());

          // AST REWRITE
          // elements: identifier
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1565:26: -> ^( TOK_ROLE identifier )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1565:29: ^( TOK_ROLE identifier )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_ROLE, "TOK_ROLE"), root_1);

              adaptor.addChild(root_1, stream_identifier.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "principalName"

  public static class withGrantOption_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "withGrantOption"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1568:1: withGrantOption : KW_WITH KW_GRANT KW_OPTION -> ^( TOK_GRANT_WITH_OPTION ) ;
  public final HiveParser.withGrantOption_return withGrantOption() throws RecognitionException {
    HiveParser.withGrantOption_return retval = new HiveParser.withGrantOption_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_WITH584 = null;
    Token KW_GRANT585 = null;
    Token KW_OPTION586 = null;

    CommonTree KW_WITH584_tree = null;
    CommonTree KW_GRANT585_tree = null;
    CommonTree KW_OPTION586_tree = null;
    RewriteRuleTokenStream stream_KW_WITH = new RewriteRuleTokenStream(adaptor, "token KW_WITH");
    RewriteRuleTokenStream stream_KW_GRANT = new RewriteRuleTokenStream(adaptor, "token KW_GRANT");
    RewriteRuleTokenStream stream_KW_OPTION = new RewriteRuleTokenStream(adaptor, "token KW_OPTION");

    pushMsg("with grant option", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1571:5: ( KW_WITH KW_GRANT KW_OPTION -> ^( TOK_GRANT_WITH_OPTION ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1571:7: KW_WITH KW_GRANT KW_OPTION
      {
        KW_WITH584 = (Token) match(input, KW_WITH, FOLLOW_KW_WITH_in_withGrantOption8912);
        stream_KW_WITH.add(KW_WITH584);

        KW_GRANT585 = (Token) match(input, KW_GRANT, FOLLOW_KW_GRANT_in_withGrantOption8914);
        stream_KW_GRANT.add(KW_GRANT585);

        KW_OPTION586 = (Token) match(input, KW_OPTION, FOLLOW_KW_OPTION_in_withGrantOption8916);
        stream_KW_OPTION.add(KW_OPTION586);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1572:5: -> ^( TOK_GRANT_WITH_OPTION )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1572:8: ^( TOK_GRANT_WITH_OPTION )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_GRANT_WITH_OPTION, "TOK_GRANT_WITH_OPTION"), root_1);

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "withGrantOption"

  public static class grantOptionFor_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "grantOptionFor"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1575:1: grantOptionFor : KW_GRANT KW_OPTION KW_FOR -> ^( TOK_GRANT_OPTION_FOR ) ;
  public final HiveParser.grantOptionFor_return grantOptionFor() throws RecognitionException {
    HiveParser.grantOptionFor_return retval = new HiveParser.grantOptionFor_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_GRANT587 = null;
    Token KW_OPTION588 = null;
    Token KW_FOR589 = null;

    CommonTree KW_GRANT587_tree = null;
    CommonTree KW_OPTION588_tree = null;
    CommonTree KW_FOR589_tree = null;
    RewriteRuleTokenStream stream_KW_FOR = new RewriteRuleTokenStream(adaptor, "token KW_FOR");
    RewriteRuleTokenStream stream_KW_GRANT = new RewriteRuleTokenStream(adaptor, "token KW_GRANT");
    RewriteRuleTokenStream stream_KW_OPTION = new RewriteRuleTokenStream(adaptor, "token KW_OPTION");

    pushMsg("grant option for", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1578:5: ( KW_GRANT KW_OPTION KW_FOR -> ^( TOK_GRANT_OPTION_FOR ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1578:7: KW_GRANT KW_OPTION KW_FOR
      {
        KW_GRANT587 = (Token) match(input, KW_GRANT, FOLLOW_KW_GRANT_in_grantOptionFor8953);
        stream_KW_GRANT.add(KW_GRANT587);

        KW_OPTION588 = (Token) match(input, KW_OPTION, FOLLOW_KW_OPTION_in_grantOptionFor8955);
        stream_KW_OPTION.add(KW_OPTION588);

        KW_FOR589 = (Token) match(input, KW_FOR, FOLLOW_KW_FOR_in_grantOptionFor8957);
        stream_KW_FOR.add(KW_FOR589);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1579:5: -> ^( TOK_GRANT_OPTION_FOR )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1579:8: ^( TOK_GRANT_OPTION_FOR )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_GRANT_OPTION_FOR, "TOK_GRANT_OPTION_FOR"), root_1);

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "grantOptionFor"

  public static class adminOptionFor_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "adminOptionFor"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1582:1: adminOptionFor : KW_ADMIN KW_OPTION KW_FOR -> ^( TOK_ADMIN_OPTION_FOR ) ;
  public final HiveParser.adminOptionFor_return adminOptionFor() throws RecognitionException {
    HiveParser.adminOptionFor_return retval = new HiveParser.adminOptionFor_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_ADMIN590 = null;
    Token KW_OPTION591 = null;
    Token KW_FOR592 = null;

    CommonTree KW_ADMIN590_tree = null;
    CommonTree KW_OPTION591_tree = null;
    CommonTree KW_FOR592_tree = null;
    RewriteRuleTokenStream stream_KW_FOR = new RewriteRuleTokenStream(adaptor, "token KW_FOR");
    RewriteRuleTokenStream stream_KW_OPTION = new RewriteRuleTokenStream(adaptor, "token KW_OPTION");
    RewriteRuleTokenStream stream_KW_ADMIN = new RewriteRuleTokenStream(adaptor, "token KW_ADMIN");

    pushMsg("admin option for", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1585:5: ( KW_ADMIN KW_OPTION KW_FOR -> ^( TOK_ADMIN_OPTION_FOR ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1585:7: KW_ADMIN KW_OPTION KW_FOR
      {
        KW_ADMIN590 = (Token) match(input, KW_ADMIN, FOLLOW_KW_ADMIN_in_adminOptionFor8990);
        stream_KW_ADMIN.add(KW_ADMIN590);

        KW_OPTION591 = (Token) match(input, KW_OPTION, FOLLOW_KW_OPTION_in_adminOptionFor8992);
        stream_KW_OPTION.add(KW_OPTION591);

        KW_FOR592 = (Token) match(input, KW_FOR, FOLLOW_KW_FOR_in_adminOptionFor8994);
        stream_KW_FOR.add(KW_FOR592);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1586:5: -> ^( TOK_ADMIN_OPTION_FOR )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1586:8: ^( TOK_ADMIN_OPTION_FOR )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ADMIN_OPTION_FOR, "TOK_ADMIN_OPTION_FOR"), root_1);

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "adminOptionFor"

  public static class withAdminOption_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "withAdminOption"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1589:1: withAdminOption : KW_WITH KW_ADMIN KW_OPTION -> ^( TOK_GRANT_WITH_ADMIN_OPTION ) ;
  public final HiveParser.withAdminOption_return withAdminOption() throws RecognitionException {
    HiveParser.withAdminOption_return retval = new HiveParser.withAdminOption_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_WITH593 = null;
    Token KW_ADMIN594 = null;
    Token KW_OPTION595 = null;

    CommonTree KW_WITH593_tree = null;
    CommonTree KW_ADMIN594_tree = null;
    CommonTree KW_OPTION595_tree = null;
    RewriteRuleTokenStream stream_KW_WITH = new RewriteRuleTokenStream(adaptor, "token KW_WITH");
    RewriteRuleTokenStream stream_KW_OPTION = new RewriteRuleTokenStream(adaptor, "token KW_OPTION");
    RewriteRuleTokenStream stream_KW_ADMIN = new RewriteRuleTokenStream(adaptor, "token KW_ADMIN");

    pushMsg("with admin option", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1592:5: ( KW_WITH KW_ADMIN KW_OPTION -> ^( TOK_GRANT_WITH_ADMIN_OPTION ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1592:7: KW_WITH KW_ADMIN KW_OPTION
      {
        KW_WITH593 = (Token) match(input, KW_WITH, FOLLOW_KW_WITH_in_withAdminOption9027);
        stream_KW_WITH.add(KW_WITH593);

        KW_ADMIN594 = (Token) match(input, KW_ADMIN, FOLLOW_KW_ADMIN_in_withAdminOption9029);
        stream_KW_ADMIN.add(KW_ADMIN594);

        KW_OPTION595 = (Token) match(input, KW_OPTION, FOLLOW_KW_OPTION_in_withAdminOption9031);
        stream_KW_OPTION.add(KW_OPTION595);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1593:5: -> ^( TOK_GRANT_WITH_ADMIN_OPTION )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1593:8: ^( TOK_GRANT_WITH_ADMIN_OPTION )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_GRANT_WITH_ADMIN_OPTION, "TOK_GRANT_WITH_ADMIN_OPTION"), root_1);

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "withAdminOption"

  public static class metastoreCheck_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "metastoreCheck"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1596:1: metastoreCheck : KW_MSCK (repair= KW_REPAIR )? ( KW_TABLE tableName ( partitionSpec )? ( COMMA partitionSpec )* )? -> ^( TOK_MSCK ( $repair)? ( tableName ( partitionSpec )* )? ) ;
  public final HiveParser.metastoreCheck_return metastoreCheck() throws RecognitionException {
    HiveParser.metastoreCheck_return retval = new HiveParser.metastoreCheck_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token repair = null;
    Token KW_MSCK596 = null;
    Token KW_TABLE597 = null;
    Token COMMA600 = null;
    HiveParser_FromClauseParser.tableName_return tableName598 = null;

    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec599 = null;

    HiveParser_IdentifiersParser.partitionSpec_return partitionSpec601 = null;

    CommonTree repair_tree = null;
    CommonTree KW_MSCK596_tree = null;
    CommonTree KW_TABLE597_tree = null;
    CommonTree COMMA600_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleTokenStream stream_KW_REPAIR = new RewriteRuleTokenStream(adaptor, "token KW_REPAIR");
    RewriteRuleTokenStream stream_KW_MSCK = new RewriteRuleTokenStream(adaptor, "token KW_MSCK");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleSubtreeStream stream_partitionSpec = new RewriteRuleSubtreeStream(adaptor, "rule partitionSpec");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    pushMsg("metastore check statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:5: ( KW_MSCK (repair= KW_REPAIR )? ( KW_TABLE tableName ( partitionSpec )? ( COMMA partitionSpec )* )? -> ^( TOK_MSCK ( $repair)? ( tableName ( partitionSpec )* )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:7: KW_MSCK (repair= KW_REPAIR )? ( KW_TABLE tableName ( partitionSpec )? ( COMMA partitionSpec )* )?
      {
        KW_MSCK596 = (Token) match(input, KW_MSCK, FOLLOW_KW_MSCK_in_metastoreCheck9068);
        stream_KW_MSCK.add(KW_MSCK596);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:15: (repair= KW_REPAIR )?
        int alt175 = 2;
        switch (input.LA(1)) {
          case KW_REPAIR: {
            alt175 = 1;
          }
          break;
        }

        switch (alt175) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:16: repair= KW_REPAIR
          {
            repair = (Token) match(input, KW_REPAIR, FOLLOW_KW_REPAIR_in_metastoreCheck9073);
            stream_KW_REPAIR.add(repair);
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:35: ( KW_TABLE tableName ( partitionSpec )? ( COMMA partitionSpec )* )?
        int alt178 = 2;
        switch (input.LA(1)) {
          case KW_TABLE: {
            alt178 = 1;
          }
          break;
        }

        switch (alt178) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:36: KW_TABLE tableName ( partitionSpec )? ( COMMA partitionSpec )*
          {
            KW_TABLE597 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_metastoreCheck9078);
            stream_KW_TABLE.add(KW_TABLE597);

            pushFollow(FOLLOW_tableName_in_metastoreCheck9080);
            tableName598 = tableName();

            state._fsp--;

            stream_tableName.add(tableName598.getTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:55: ( partitionSpec )?
            int alt176 = 2;
            switch (input.LA(1)) {
              case KW_PARTITION: {
                alt176 = 1;
              }
              break;
            }

            switch (alt176) {
              case 1:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:55: partitionSpec
              {
                pushFollow(FOLLOW_partitionSpec_in_metastoreCheck9082);
                partitionSpec599 = partitionSpec();

                state._fsp--;

                stream_partitionSpec.add(partitionSpec599.getTree());
              }
              break;
            }

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:70: ( COMMA partitionSpec )*
            loop177:
            do {
              int alt177 = 2;
              switch (input.LA(1)) {
                case COMMA: {
                  alt177 = 1;
                }
                break;
              }

              switch (alt177) {
                case 1:
                  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1599:71: COMMA partitionSpec
                {
                  COMMA600 = (Token) match(input, COMMA, FOLLOW_COMMA_in_metastoreCheck9086);
                  stream_COMMA.add(COMMA600);

                  pushFollow(FOLLOW_partitionSpec_in_metastoreCheck9088);
                  partitionSpec601 = partitionSpec();

                  state._fsp--;

                  stream_partitionSpec.add(partitionSpec601.getTree());
                }
                break;

                default:
                  break loop177;
              }
            } while (true);
          }
          break;
        }

        // AST REWRITE
        // elements: partitionSpec, repair, tableName
        // token labels: repair
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_repair = new RewriteRuleTokenStream(adaptor, "token repair", repair);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1600:5: -> ^( TOK_MSCK ( $repair)? ( tableName ( partitionSpec )* )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1600:8: ^( TOK_MSCK ( $repair)? ( tableName ( partitionSpec )* )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_MSCK, "TOK_MSCK"), root_1);

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1600:20: ( $repair)?
            if (stream_repair.hasNext()) {
              adaptor.addChild(root_1, stream_repair.nextNode());
            }
            stream_repair.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1600:28: ( tableName ( partitionSpec )* )?
            if (stream_partitionSpec.hasNext() || stream_tableName.hasNext()) {
              adaptor.addChild(root_1, stream_tableName.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1600:39: ( partitionSpec )*
              while (stream_partitionSpec.hasNext()) {
                adaptor.addChild(root_1, stream_partitionSpec.nextTree());
              }
              stream_partitionSpec.reset();
            }
            stream_partitionSpec.reset();
            stream_tableName.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "metastoreCheck"

  public static class resourceList_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "resourceList"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1603:1: resourceList : resource ( COMMA resource )* -> ^( TOK_RESOURCE_LIST ( resource )+ ) ;
  public final HiveParser.resourceList_return resourceList() throws RecognitionException {
    HiveParser.resourceList_return retval = new HiveParser.resourceList_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token COMMA603 = null;
    HiveParser.resource_return resource602 = null;

    HiveParser.resource_return resource604 = null;

    CommonTree COMMA603_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleSubtreeStream stream_resource = new RewriteRuleSubtreeStream(adaptor, "rule resource");
    pushMsg("resource list", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1606:3: ( resource ( COMMA resource )* -> ^( TOK_RESOURCE_LIST ( resource )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1607:3: resource ( COMMA resource )*
      {
        pushFollow(FOLLOW_resource_in_resourceList9141);
        resource602 = resource();

        state._fsp--;

        stream_resource.add(resource602.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1607:12: ( COMMA resource )*
        loop179:
        do {
          int alt179 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt179 = 1;
            }
            break;
          }

          switch (alt179) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1607:13: COMMA resource
            {
              COMMA603 = (Token) match(input, COMMA, FOLLOW_COMMA_in_resourceList9144);
              stream_COMMA.add(COMMA603);

              pushFollow(FOLLOW_resource_in_resourceList9146);
              resource604 = resource();

              state._fsp--;

              stream_resource.add(resource604.getTree());
            }
            break;

            default:
              break loop179;
          }
        } while (true);

        // AST REWRITE
        // elements: resource
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1607:30: -> ^( TOK_RESOURCE_LIST ( resource )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1607:33: ^( TOK_RESOURCE_LIST ( resource )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_RESOURCE_LIST, "TOK_RESOURCE_LIST"),
                    root_1);

            if (!(stream_resource.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_resource.hasNext()) {
              adaptor.addChild(root_1, stream_resource.nextTree());
            }
            stream_resource.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "resourceList"

  public static class resource_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "resource"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1610:1: resource : resType= resourceType resPath= StringLiteral -> ^( TOK_RESOURCE_URI $resType $resPath) ;
  public final HiveParser.resource_return resource() throws RecognitionException {
    HiveParser.resource_return retval = new HiveParser.resource_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token resPath = null;
    HiveParser.resourceType_return resType = null;

    CommonTree resPath_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleSubtreeStream stream_resourceType = new RewriteRuleSubtreeStream(adaptor, "rule resourceType");
    pushMsg("resource", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1613:3: (resType= resourceType resPath= StringLiteral -> ^( TOK_RESOURCE_URI $resType $resPath) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1614:3: resType= resourceType resPath= StringLiteral
      {
        pushFollow(FOLLOW_resourceType_in_resource9184);
        resType = resourceType();

        state._fsp--;

        stream_resourceType.add(resType.getTree());

        resPath = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_resource9188);
        stream_StringLiteral.add(resPath);

        // AST REWRITE
        // elements: resType, resPath
        // token labels: resPath
        // rule labels: resType, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_resPath = new RewriteRuleTokenStream(adaptor, "token resPath", resPath);
        RewriteRuleSubtreeStream stream_resType =
            new RewriteRuleSubtreeStream(adaptor, "rule resType", resType != null ? resType.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1614:46: -> ^( TOK_RESOURCE_URI $resType $resPath)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1614:49: ^( TOK_RESOURCE_URI $resType $resPath)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_RESOURCE_URI, "TOK_RESOURCE_URI"),
                root_1);

            adaptor.addChild(root_1, stream_resType.nextTree());

            adaptor.addChild(root_1, stream_resPath.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "resource"

  public static class resourceType_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "resourceType"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1617:1: resourceType : ( KW_JAR -> ^( TOK_JAR ) | KW_FILE -> ^( TOK_FILE ) | KW_ARCHIVE -> ^( TOK_ARCHIVE ) );
  public final HiveParser.resourceType_return resourceType() throws RecognitionException {
    HiveParser.resourceType_return retval = new HiveParser.resourceType_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_JAR605 = null;
    Token KW_FILE606 = null;
    Token KW_ARCHIVE607 = null;

    CommonTree KW_JAR605_tree = null;
    CommonTree KW_FILE606_tree = null;
    CommonTree KW_ARCHIVE607_tree = null;
    RewriteRuleTokenStream stream_KW_ARCHIVE = new RewriteRuleTokenStream(adaptor, "token KW_ARCHIVE");
    RewriteRuleTokenStream stream_KW_JAR = new RewriteRuleTokenStream(adaptor, "token KW_JAR");
    RewriteRuleTokenStream stream_KW_FILE = new RewriteRuleTokenStream(adaptor, "token KW_FILE");

    pushMsg("resource type", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1620:3: ( KW_JAR -> ^( TOK_JAR ) | KW_FILE -> ^( TOK_FILE ) | KW_ARCHIVE -> ^( TOK_ARCHIVE ) )
      int alt180 = 3;
      switch (input.LA(1)) {
        case KW_JAR: {
          alt180 = 1;
        }
        break;
        case KW_FILE: {
          alt180 = 2;
        }
        break;
        case KW_ARCHIVE: {
          alt180 = 3;
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 180, 0, input);

          throw nvae;
      }

      switch (alt180) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1621:3: KW_JAR
        {
          KW_JAR605 = (Token) match(input, KW_JAR, FOLLOW_KW_JAR_in_resourceType9225);
          stream_KW_JAR.add(KW_JAR605);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1621:10: -> ^( TOK_JAR )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1621:13: ^( TOK_JAR )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_JAR, "TOK_JAR"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1623:3: KW_FILE
        {
          KW_FILE606 = (Token) match(input, KW_FILE, FOLLOW_KW_FILE_in_resourceType9239);
          stream_KW_FILE.add(KW_FILE606);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1623:11: -> ^( TOK_FILE )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1623:14: ^( TOK_FILE )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_FILE, "TOK_FILE"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 3:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1625:3: KW_ARCHIVE
        {
          KW_ARCHIVE607 = (Token) match(input, KW_ARCHIVE, FOLLOW_KW_ARCHIVE_in_resourceType9253);
          stream_KW_ARCHIVE.add(KW_ARCHIVE607);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1625:14: -> ^( TOK_ARCHIVE )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1625:17: ^( TOK_ARCHIVE )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_ARCHIVE, "TOK_ARCHIVE"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "resourceType"

  public static class createFunctionStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "createFunctionStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1628:1: createFunctionStatement : KW_CREATE (temp= KW_TEMPORARY )? KW_FUNCTION functionIdentifier KW_AS StringLiteral ( KW_USING rList= resourceList )? -> {$temp != null}? ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? TOK_TEMPORARY ) -> ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? ) ;
  public final HiveParser.createFunctionStatement_return createFunctionStatement() throws RecognitionException {
    HiveParser.createFunctionStatement_return retval = new HiveParser.createFunctionStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token temp = null;
    Token KW_CREATE608 = null;
    Token KW_FUNCTION609 = null;
    Token KW_AS611 = null;
    Token StringLiteral612 = null;
    Token KW_USING613 = null;
    HiveParser.resourceList_return rList = null;

    HiveParser_IdentifiersParser.functionIdentifier_return functionIdentifier610 = null;

    CommonTree temp_tree = null;
    CommonTree KW_CREATE608_tree = null;
    CommonTree KW_FUNCTION609_tree = null;
    CommonTree KW_AS611_tree = null;
    CommonTree StringLiteral612_tree = null;
    CommonTree KW_USING613_tree = null;
    RewriteRuleTokenStream stream_KW_TEMPORARY = new RewriteRuleTokenStream(adaptor, "token KW_TEMPORARY");
    RewriteRuleTokenStream stream_KW_CREATE = new RewriteRuleTokenStream(adaptor, "token KW_CREATE");
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_USING = new RewriteRuleTokenStream(adaptor, "token KW_USING");
    RewriteRuleTokenStream stream_KW_FUNCTION = new RewriteRuleTokenStream(adaptor, "token KW_FUNCTION");
    RewriteRuleTokenStream stream_KW_AS = new RewriteRuleTokenStream(adaptor, "token KW_AS");
    RewriteRuleSubtreeStream stream_functionIdentifier =
        new RewriteRuleSubtreeStream(adaptor, "rule functionIdentifier");
    RewriteRuleSubtreeStream stream_resourceList = new RewriteRuleSubtreeStream(adaptor, "rule resourceList");
    pushMsg("create function statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1631:5: ( KW_CREATE (temp= KW_TEMPORARY )? KW_FUNCTION functionIdentifier KW_AS StringLiteral ( KW_USING rList= resourceList )? -> {$temp != null}? ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? TOK_TEMPORARY ) -> ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1631:7: KW_CREATE (temp= KW_TEMPORARY )? KW_FUNCTION functionIdentifier KW_AS StringLiteral ( KW_USING rList= resourceList )?
      {
        KW_CREATE608 = (Token) match(input, KW_CREATE, FOLLOW_KW_CREATE_in_createFunctionStatement9284);
        stream_KW_CREATE.add(KW_CREATE608);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1631:17: (temp= KW_TEMPORARY )?
        int alt181 = 2;
        switch (input.LA(1)) {
          case KW_TEMPORARY: {
            alt181 = 1;
          }
          break;
        }

        switch (alt181) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1631:18: temp= KW_TEMPORARY
          {
            temp = (Token) match(input, KW_TEMPORARY, FOLLOW_KW_TEMPORARY_in_createFunctionStatement9289);
            stream_KW_TEMPORARY.add(temp);
          }
          break;
        }

        KW_FUNCTION609 = (Token) match(input, KW_FUNCTION, FOLLOW_KW_FUNCTION_in_createFunctionStatement9293);
        stream_KW_FUNCTION.add(KW_FUNCTION609);

        pushFollow(FOLLOW_functionIdentifier_in_createFunctionStatement9295);
        functionIdentifier610 = functionIdentifier();

        state._fsp--;

        stream_functionIdentifier.add(functionIdentifier610.getTree());

        KW_AS611 = (Token) match(input, KW_AS, FOLLOW_KW_AS_in_createFunctionStatement9297);
        stream_KW_AS.add(KW_AS611);

        StringLiteral612 = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_createFunctionStatement9299);
        stream_StringLiteral.add(StringLiteral612);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1632:7: ( KW_USING rList= resourceList )?
        int alt182 = 2;
        switch (input.LA(1)) {
          case KW_USING: {
            alt182 = 1;
          }
          break;
        }

        switch (alt182) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1632:8: KW_USING rList= resourceList
          {
            KW_USING613 = (Token) match(input, KW_USING, FOLLOW_KW_USING_in_createFunctionStatement9308);
            stream_KW_USING.add(KW_USING613);

            pushFollow(FOLLOW_resourceList_in_createFunctionStatement9312);
            rList = resourceList();

            state._fsp--;

            stream_resourceList.add(rList.getTree());
          }
          break;
        }

        // AST REWRITE
        // elements: functionIdentifier, StringLiteral, rList, functionIdentifier, StringLiteral, rList
        // token labels:
        // rule labels: rList, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_rList =
            new RewriteRuleSubtreeStream(adaptor, "rule rList", rList != null ? rList.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1633:5: -> {$temp != null}? ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? TOK_TEMPORARY )
        if (temp != null) {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1633:25: ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? TOK_TEMPORARY )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_CREATEFUNCTION, "TOK_CREATEFUNCTION"),
                    root_1);

            adaptor.addChild(root_1, stream_functionIdentifier.nextTree());

            adaptor.addChild(root_1, stream_StringLiteral.nextNode());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1633:80: ( $rList)?
            if (stream_rList.hasNext()) {
              adaptor.addChild(root_1, stream_rList.nextTree());
            }
            stream_rList.reset();

            adaptor.addChild(root_1, (CommonTree) adaptor.create(TOK_TEMPORARY, "TOK_TEMPORARY"));

            adaptor.addChild(root_0, root_1);
          }
        } else // 1634:5: -> ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1634:25: ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_CREATEFUNCTION, "TOK_CREATEFUNCTION"),
                    root_1);

            adaptor.addChild(root_1, stream_functionIdentifier.nextTree());

            adaptor.addChild(root_1, stream_StringLiteral.nextNode());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1634:80: ( $rList)?
            if (stream_rList.hasNext()) {
              adaptor.addChild(root_1, stream_rList.nextTree());
            }
            stream_rList.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "createFunctionStatement"

  public static class dropFunctionStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "dropFunctionStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1637:1: dropFunctionStatement : KW_DROP (temp= KW_TEMPORARY )? KW_FUNCTION ( ifExists )? functionIdentifier -> {$temp != null}? ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? TOK_TEMPORARY ) -> ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? ) ;
  public final HiveParser.dropFunctionStatement_return dropFunctionStatement() throws RecognitionException {
    HiveParser.dropFunctionStatement_return retval = new HiveParser.dropFunctionStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token temp = null;
    Token KW_DROP614 = null;
    Token KW_FUNCTION615 = null;
    HiveParser.ifExists_return ifExists616 = null;

    HiveParser_IdentifiersParser.functionIdentifier_return functionIdentifier617 = null;

    CommonTree temp_tree = null;
    CommonTree KW_DROP614_tree = null;
    CommonTree KW_FUNCTION615_tree = null;
    RewriteRuleTokenStream stream_KW_DROP = new RewriteRuleTokenStream(adaptor, "token KW_DROP");
    RewriteRuleTokenStream stream_KW_TEMPORARY = new RewriteRuleTokenStream(adaptor, "token KW_TEMPORARY");
    RewriteRuleTokenStream stream_KW_FUNCTION = new RewriteRuleTokenStream(adaptor, "token KW_FUNCTION");
    RewriteRuleSubtreeStream stream_ifExists = new RewriteRuleSubtreeStream(adaptor, "rule ifExists");
    RewriteRuleSubtreeStream stream_functionIdentifier =
        new RewriteRuleSubtreeStream(adaptor, "rule functionIdentifier");
    pushMsg("drop function statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1640:5: ( KW_DROP (temp= KW_TEMPORARY )? KW_FUNCTION ( ifExists )? functionIdentifier -> {$temp != null}? ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? TOK_TEMPORARY ) -> ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1640:7: KW_DROP (temp= KW_TEMPORARY )? KW_FUNCTION ( ifExists )? functionIdentifier
      {
        KW_DROP614 = (Token) match(input, KW_DROP, FOLLOW_KW_DROP_in_dropFunctionStatement9398);
        stream_KW_DROP.add(KW_DROP614);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1640:15: (temp= KW_TEMPORARY )?
        int alt183 = 2;
        switch (input.LA(1)) {
          case KW_TEMPORARY: {
            alt183 = 1;
          }
          break;
        }

        switch (alt183) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1640:16: temp= KW_TEMPORARY
          {
            temp = (Token) match(input, KW_TEMPORARY, FOLLOW_KW_TEMPORARY_in_dropFunctionStatement9403);
            stream_KW_TEMPORARY.add(temp);
          }
          break;
        }

        KW_FUNCTION615 = (Token) match(input, KW_FUNCTION, FOLLOW_KW_FUNCTION_in_dropFunctionStatement9407);
        stream_KW_FUNCTION.add(KW_FUNCTION615);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1640:48: ( ifExists )?
        int alt184 = 2;
        switch (input.LA(1)) {
          case KW_IF: {
            alt184 = 1;
          }
          break;
        }

        switch (alt184) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1640:48: ifExists
          {
            pushFollow(FOLLOW_ifExists_in_dropFunctionStatement9409);
            ifExists616 = ifExists();

            state._fsp--;

            stream_ifExists.add(ifExists616.getTree());
          }
          break;
        }

        pushFollow(FOLLOW_functionIdentifier_in_dropFunctionStatement9412);
        functionIdentifier617 = functionIdentifier();

        state._fsp--;

        stream_functionIdentifier.add(functionIdentifier617.getTree());

        // AST REWRITE
        // elements: functionIdentifier, ifExists, functionIdentifier, ifExists
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1641:5: -> {$temp != null}? ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? TOK_TEMPORARY )
        if (temp != null) {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1641:25: ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? TOK_TEMPORARY )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DROPFUNCTION, "TOK_DROPFUNCTION"),
                root_1);

            adaptor.addChild(root_1, stream_functionIdentifier.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1641:63: ( ifExists )?
            if (stream_ifExists.hasNext()) {
              adaptor.addChild(root_1, stream_ifExists.nextTree());
            }
            stream_ifExists.reset();

            adaptor.addChild(root_1, (CommonTree) adaptor.create(TOK_TEMPORARY, "TOK_TEMPORARY"));

            adaptor.addChild(root_0, root_1);
          }
        } else // 1642:5: -> ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1642:25: ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DROPFUNCTION, "TOK_DROPFUNCTION"),
                root_1);

            adaptor.addChild(root_1, stream_functionIdentifier.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1642:63: ( ifExists )?
            if (stream_ifExists.hasNext()) {
              adaptor.addChild(root_1, stream_ifExists.nextTree());
            }
            stream_ifExists.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "dropFunctionStatement"

  public static class reloadFunctionStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "reloadFunctionStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1645:1: reloadFunctionStatement : KW_RELOAD KW_FUNCTION -> ^( TOK_RELOADFUNCTION ) ;
  public final HiveParser.reloadFunctionStatement_return reloadFunctionStatement() throws RecognitionException {
    HiveParser.reloadFunctionStatement_return retval = new HiveParser.reloadFunctionStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_RELOAD618 = null;
    Token KW_FUNCTION619 = null;

    CommonTree KW_RELOAD618_tree = null;
    CommonTree KW_FUNCTION619_tree = null;
    RewriteRuleTokenStream stream_KW_FUNCTION = new RewriteRuleTokenStream(adaptor, "token KW_FUNCTION");
    RewriteRuleTokenStream stream_KW_RELOAD = new RewriteRuleTokenStream(adaptor, "token KW_RELOAD");

    pushMsg("reload function statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1648:5: ( KW_RELOAD KW_FUNCTION -> ^( TOK_RELOADFUNCTION ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1648:7: KW_RELOAD KW_FUNCTION
      {
        KW_RELOAD618 = (Token) match(input, KW_RELOAD, FOLLOW_KW_RELOAD_in_reloadFunctionStatement9490);
        stream_KW_RELOAD.add(KW_RELOAD618);

        KW_FUNCTION619 = (Token) match(input, KW_FUNCTION, FOLLOW_KW_FUNCTION_in_reloadFunctionStatement9492);
        stream_KW_FUNCTION.add(KW_FUNCTION619);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1648:29: -> ^( TOK_RELOADFUNCTION )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1648:32: ^( TOK_RELOADFUNCTION )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_RELOADFUNCTION, "TOK_RELOADFUNCTION"),
                    root_1);

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "reloadFunctionStatement"

  public static class createMacroStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "createMacroStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1650:1: createMacroStatement : KW_CREATE KW_TEMPORARY KW_MACRO Identifier LPAREN ( columnNameTypeList )? RPAREN expression -> ^( TOK_CREATEMACRO Identifier ( columnNameTypeList )? expression ) ;
  public final HiveParser.createMacroStatement_return createMacroStatement() throws RecognitionException {
    HiveParser.createMacroStatement_return retval = new HiveParser.createMacroStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_CREATE620 = null;
    Token KW_TEMPORARY621 = null;
    Token KW_MACRO622 = null;
    Token Identifier623 = null;
    Token LPAREN624 = null;
    Token RPAREN626 = null;
    HiveParser.columnNameTypeList_return columnNameTypeList625 = null;

    HiveParser_IdentifiersParser.expression_return expression627 = null;

    CommonTree KW_CREATE620_tree = null;
    CommonTree KW_TEMPORARY621_tree = null;
    CommonTree KW_MACRO622_tree = null;
    CommonTree Identifier623_tree = null;
    CommonTree LPAREN624_tree = null;
    CommonTree RPAREN626_tree = null;
    RewriteRuleTokenStream stream_KW_TEMPORARY = new RewriteRuleTokenStream(adaptor, "token KW_TEMPORARY");
    RewriteRuleTokenStream stream_Identifier = new RewriteRuleTokenStream(adaptor, "token Identifier");
    RewriteRuleTokenStream stream_KW_CREATE = new RewriteRuleTokenStream(adaptor, "token KW_CREATE");
    RewriteRuleTokenStream stream_KW_MACRO = new RewriteRuleTokenStream(adaptor, "token KW_MACRO");
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleSubtreeStream stream_expression = new RewriteRuleSubtreeStream(adaptor, "rule expression");
    RewriteRuleSubtreeStream stream_columnNameTypeList =
        new RewriteRuleSubtreeStream(adaptor, "rule columnNameTypeList");
    pushMsg("create macro statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1653:5: ( KW_CREATE KW_TEMPORARY KW_MACRO Identifier LPAREN ( columnNameTypeList )? RPAREN expression -> ^( TOK_CREATEMACRO Identifier ( columnNameTypeList )? expression ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1653:7: KW_CREATE KW_TEMPORARY KW_MACRO Identifier LPAREN ( columnNameTypeList )? RPAREN expression
      {
        KW_CREATE620 = (Token) match(input, KW_CREATE, FOLLOW_KW_CREATE_in_createMacroStatement9520);
        stream_KW_CREATE.add(KW_CREATE620);

        KW_TEMPORARY621 = (Token) match(input, KW_TEMPORARY, FOLLOW_KW_TEMPORARY_in_createMacroStatement9522);
        stream_KW_TEMPORARY.add(KW_TEMPORARY621);

        KW_MACRO622 = (Token) match(input, KW_MACRO, FOLLOW_KW_MACRO_in_createMacroStatement9524);
        stream_KW_MACRO.add(KW_MACRO622);

        Identifier623 = (Token) match(input, Identifier, FOLLOW_Identifier_in_createMacroStatement9526);
        stream_Identifier.add(Identifier623);

        LPAREN624 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_createMacroStatement9534);
        stream_LPAREN.add(LPAREN624);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1654:14: ( columnNameTypeList )?
        int alt185 = 2;
        switch (input.LA(1)) {
          case Identifier:
          case KW_ADD:
          case KW_ADMIN:
          case KW_AFTER:
          case KW_ALL:
          case KW_ALTER:
          case KW_ANALYZE:
          case KW_ARCHIVE:
          case KW_ARRAY:
          case KW_AS:
          case KW_ASC:
          case KW_AUTHORIZATION:
          case KW_BEFORE:
          case KW_BETWEEN:
          case KW_BIGINT:
          case KW_BINARY:
          case KW_BOOLEAN:
          case KW_BOTH:
          case KW_BUCKET:
          case KW_BUCKETS:
          case KW_BY:
          case KW_CASCADE:
          case KW_CHANGE:
          case KW_CLUSTER:
          case KW_CLUSTERED:
          case KW_CLUSTERSTATUS:
          case KW_COLLECTION:
          case KW_COLUMNS:
          case KW_COMMENT:
          case KW_COMPACT:
          case KW_COMPACTIONS:
          case KW_COMPUTE:
          case KW_CONCATENATE:
          case KW_CONTINUE:
          case KW_CREATE:
          case KW_CUBE:
          case KW_CURSOR:
          case KW_DATA:
          case KW_DATABASES:
          case KW_DATE:
          case KW_DATETIME:
          case KW_DBPROPERTIES:
          case KW_DECIMAL:
          case KW_DEFAULT:
          case KW_DEFERRED:
          case KW_DEFINED:
          case KW_DELETE:
          case KW_DELIMITED:
          case KW_DEPENDENCY:
          case KW_DESC:
          case KW_DESCRIBE:
          case KW_DIRECTORIES:
          case KW_DIRECTORY:
          case KW_DISABLE:
          case KW_DISTRIBUTE:
          case KW_DOUBLE:
          case KW_DROP:
          case KW_ELEM_TYPE:
          case KW_ENABLE:
          case KW_ESCAPED:
          case KW_EXCLUSIVE:
          case KW_EXISTS:
          case KW_EXPLAIN:
          case KW_EXPORT:
          case KW_EXTERNAL:
          case KW_FALSE:
          case KW_FETCH:
          case KW_FIELDS:
          case KW_FILE:
          case KW_FILEFORMAT:
          case KW_FIRST:
          case KW_FLOAT:
          case KW_FOR:
          case KW_FORMAT:
          case KW_FORMATTED:
          case KW_FULL:
          case KW_FUNCTIONS:
          case KW_GRANT:
          case KW_GROUP:
          case KW_GROUPING:
          case KW_HOLD_DDLTIME:
          case KW_IDXPROPERTIES:
          case KW_IGNORE:
          case KW_IMPORT:
          case KW_IN:
          case KW_INDEX:
          case KW_INDEXES:
          case KW_INNER:
          case KW_INPATH:
          case KW_INPUTDRIVER:
          case KW_INPUTFORMAT:
          case KW_INSERT:
          case KW_INT:
          case KW_INTERSECT:
          case KW_INTO:
          case KW_IS:
          case KW_ITEMS:
          case KW_JAR:
          case KW_KEYS:
          case KW_KEY_TYPE:
          case KW_LATERAL:
          case KW_LEFT:
          case KW_LIKE:
          case KW_LIMIT:
          case KW_LINES:
          case KW_LOAD:
          case KW_LOCAL:
          case KW_LOCATION:
          case KW_LOCK:
          case KW_LOCKS:
          case KW_LOGICAL:
          case KW_LONG:
          case KW_MAPJOIN:
          case KW_MATERIALIZED:
          case KW_METADATA:
          case KW_MINUS:
          case KW_MSCK:
          case KW_NONE:
          case KW_NOSCAN:
          case KW_NO_DROP:
          case KW_NULL:
          case KW_OF:
          case KW_OFFLINE:
          case KW_OPTION:
          case KW_ORDER:
          case KW_OUT:
          case KW_OUTER:
          case KW_OUTPUTDRIVER:
          case KW_OUTPUTFORMAT:
          case KW_OVERWRITE:
          case KW_OWNER:
          case KW_PARTITION:
          case KW_PARTITIONED:
          case KW_PARTITIONS:
          case KW_PERCENT:
          case KW_PLUS:
          case KW_PRETTY:
          case KW_PRINCIPALS:
          case KW_PROCEDURE:
          case KW_PROTECTION:
          case KW_PURGE:
          case KW_RANGE:
          case KW_READ:
          case KW_READONLY:
          case KW_READS:
          case KW_REBUILD:
          case KW_RECORDREADER:
          case KW_RECORDWRITER:
          case KW_REGEXP:
          case KW_RELOAD:
          case KW_RENAME:
          case KW_REPAIR:
          case KW_REPLACE:
          case KW_REPLICATION:
          case KW_RESTRICT:
          case KW_REVOKE:
          case KW_REWRITE:
          case KW_RIGHT:
          case KW_RLIKE:
          case KW_ROLE:
          case KW_ROLES:
          case KW_ROLLUP:
          case KW_ROW:
          case KW_ROWS:
          case KW_SCHEMA:
          case KW_SCHEMAS:
          case KW_SEMI:
          case KW_SERDE:
          case KW_SERDEPROPERTIES:
          case KW_SERVER:
          case KW_SET:
          case KW_SETS:
          case KW_SHARED:
          case KW_SHOW:
          case KW_SHOW_DATABASE:
          case KW_SKEWED:
          case KW_SMALLINT:
          case KW_SORT:
          case KW_SORTED:
          case KW_SSL:
          case KW_STATISTICS:
          case KW_STORED:
          case KW_STREAMTABLE:
          case KW_STRING:
          case KW_STRUCT:
          case KW_TABLE:
          case KW_TABLES:
          case KW_TBLPROPERTIES:
          case KW_TEMPORARY:
          case KW_TERMINATED:
          case KW_TIMESTAMP:
          case KW_TINYINT:
          case KW_TO:
          case KW_TOUCH:
          case KW_TRANSACTIONS:
          case KW_TRIGGER:
          case KW_TRUE:
          case KW_TRUNCATE:
          case KW_UNARCHIVE:
          case KW_UNDO:
          case KW_UNION:
          case KW_UNIONTYPE:
          case KW_UNLOCK:
          case KW_UNSET:
          case KW_UNSIGNED:
          case KW_UPDATE:
          case KW_URI:
          case KW_USE:
          case KW_USER:
          case KW_USING:
          case KW_UTC:
          case KW_UTCTIMESTAMP:
          case KW_VALUES:
          case KW_VALUE_TYPE:
          case KW_VIEW:
          case KW_WHILE:
          case KW_WITH: {
            alt185 = 1;
          }
          break;
        }

        switch (alt185) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1654:14: columnNameTypeList
          {
            pushFollow(FOLLOW_columnNameTypeList_in_createMacroStatement9536);
            columnNameTypeList625 = columnNameTypeList();

            state._fsp--;

            stream_columnNameTypeList.add(columnNameTypeList625.getTree());
          }
          break;
        }

        RPAREN626 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_createMacroStatement9539);
        stream_RPAREN.add(RPAREN626);

        pushFollow(FOLLOW_expression_in_createMacroStatement9541);
        expression627 = expression();

        state._fsp--;

        stream_expression.add(expression627.getTree());

        // AST REWRITE
        // elements: columnNameTypeList, expression, Identifier
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1655:5: -> ^( TOK_CREATEMACRO Identifier ( columnNameTypeList )? expression )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1655:8: ^( TOK_CREATEMACRO Identifier ( columnNameTypeList )? expression )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_CREATEMACRO, "TOK_CREATEMACRO"),
                root_1);

            adaptor.addChild(root_1, stream_Identifier.nextNode());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1655:37: ( columnNameTypeList )?
            if (stream_columnNameTypeList.hasNext()) {
              adaptor.addChild(root_1, stream_columnNameTypeList.nextTree());
            }
            stream_columnNameTypeList.reset();

            adaptor.addChild(root_1, stream_expression.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "createMacroStatement"

  public static class dropMacroStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "dropMacroStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1658:1: dropMacroStatement : KW_DROP KW_TEMPORARY KW_MACRO ( ifExists )? Identifier -> ^( TOK_DROPMACRO Identifier ( ifExists )? ) ;
  public final HiveParser.dropMacroStatement_return dropMacroStatement() throws RecognitionException {
    HiveParser.dropMacroStatement_return retval = new HiveParser.dropMacroStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_DROP628 = null;
    Token KW_TEMPORARY629 = null;
    Token KW_MACRO630 = null;
    Token Identifier632 = null;
    HiveParser.ifExists_return ifExists631 = null;

    CommonTree KW_DROP628_tree = null;
    CommonTree KW_TEMPORARY629_tree = null;
    CommonTree KW_MACRO630_tree = null;
    CommonTree Identifier632_tree = null;
    RewriteRuleTokenStream stream_KW_DROP = new RewriteRuleTokenStream(adaptor, "token KW_DROP");
    RewriteRuleTokenStream stream_KW_TEMPORARY = new RewriteRuleTokenStream(adaptor, "token KW_TEMPORARY");
    RewriteRuleTokenStream stream_Identifier = new RewriteRuleTokenStream(adaptor, "token Identifier");
    RewriteRuleTokenStream stream_KW_MACRO = new RewriteRuleTokenStream(adaptor, "token KW_MACRO");
    RewriteRuleSubtreeStream stream_ifExists = new RewriteRuleSubtreeStream(adaptor, "rule ifExists");
    pushMsg("drop macro statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1661:5: ( KW_DROP KW_TEMPORARY KW_MACRO ( ifExists )? Identifier -> ^( TOK_DROPMACRO Identifier ( ifExists )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1661:7: KW_DROP KW_TEMPORARY KW_MACRO ( ifExists )? Identifier
      {
        KW_DROP628 = (Token) match(input, KW_DROP, FOLLOW_KW_DROP_in_dropMacroStatement9585);
        stream_KW_DROP.add(KW_DROP628);

        KW_TEMPORARY629 = (Token) match(input, KW_TEMPORARY, FOLLOW_KW_TEMPORARY_in_dropMacroStatement9587);
        stream_KW_TEMPORARY.add(KW_TEMPORARY629);

        KW_MACRO630 = (Token) match(input, KW_MACRO, FOLLOW_KW_MACRO_in_dropMacroStatement9589);
        stream_KW_MACRO.add(KW_MACRO630);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1661:37: ( ifExists )?
        int alt186 = 2;
        switch (input.LA(1)) {
          case KW_IF: {
            alt186 = 1;
          }
          break;
        }

        switch (alt186) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1661:37: ifExists
          {
            pushFollow(FOLLOW_ifExists_in_dropMacroStatement9591);
            ifExists631 = ifExists();

            state._fsp--;

            stream_ifExists.add(ifExists631.getTree());
          }
          break;
        }

        Identifier632 = (Token) match(input, Identifier, FOLLOW_Identifier_in_dropMacroStatement9594);
        stream_Identifier.add(Identifier632);

        // AST REWRITE
        // elements: ifExists, Identifier
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1662:5: -> ^( TOK_DROPMACRO Identifier ( ifExists )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1662:8: ^( TOK_DROPMACRO Identifier ( ifExists )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DROPMACRO, "TOK_DROPMACRO"), root_1);

            adaptor.addChild(root_1, stream_Identifier.nextNode());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1662:35: ( ifExists )?
            if (stream_ifExists.hasNext()) {
              adaptor.addChild(root_1, stream_ifExists.nextTree());
            }
            stream_ifExists.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "dropMacroStatement"

  public static class createViewStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "createViewStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1665:1: createViewStatement : KW_CREATE ( orReplace )? KW_VIEW ( ifNotExists )? name= tableName ( LPAREN columnNameCommentList RPAREN )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? KW_AS selectStatementWithCTE -> ^( TOK_CREATEVIEW $name ( orReplace )? ( ifNotExists )? ( columnNameCommentList )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? selectStatementWithCTE ) ;
  public final HiveParser.createViewStatement_return createViewStatement() throws RecognitionException {
    HiveParser.createViewStatement_return retval = new HiveParser.createViewStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_CREATE633 = null;
    Token KW_VIEW635 = null;
    Token LPAREN637 = null;
    Token RPAREN639 = null;
    Token KW_AS643 = null;
    HiveParser_FromClauseParser.tableName_return name = null;

    HiveParser.orReplace_return orReplace634 = null;

    HiveParser.ifNotExists_return ifNotExists636 = null;

    HiveParser.columnNameCommentList_return columnNameCommentList638 = null;

    HiveParser.tableComment_return tableComment640 = null;

    HiveParser.viewPartition_return viewPartition641 = null;

    HiveParser.tablePropertiesPrefixed_return tablePropertiesPrefixed642 = null;

    HiveParser.selectStatementWithCTE_return selectStatementWithCTE644 = null;

    CommonTree KW_CREATE633_tree = null;
    CommonTree KW_VIEW635_tree = null;
    CommonTree LPAREN637_tree = null;
    CommonTree RPAREN639_tree = null;
    CommonTree KW_AS643_tree = null;
    RewriteRuleTokenStream stream_KW_VIEW = new RewriteRuleTokenStream(adaptor, "token KW_VIEW");
    RewriteRuleTokenStream stream_KW_CREATE = new RewriteRuleTokenStream(adaptor, "token KW_CREATE");
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleTokenStream stream_KW_AS = new RewriteRuleTokenStream(adaptor, "token KW_AS");
    RewriteRuleSubtreeStream stream_columnNameCommentList =
        new RewriteRuleSubtreeStream(adaptor, "rule columnNameCommentList");
    RewriteRuleSubtreeStream stream_selectStatementWithCTE =
        new RewriteRuleSubtreeStream(adaptor, "rule selectStatementWithCTE");
    RewriteRuleSubtreeStream stream_orReplace = new RewriteRuleSubtreeStream(adaptor, "rule orReplace");
    RewriteRuleSubtreeStream stream_tablePropertiesPrefixed =
        new RewriteRuleSubtreeStream(adaptor, "rule tablePropertiesPrefixed");
    RewriteRuleSubtreeStream stream_ifNotExists = new RewriteRuleSubtreeStream(adaptor, "rule ifNotExists");
    RewriteRuleSubtreeStream stream_tableComment = new RewriteRuleSubtreeStream(adaptor, "rule tableComment");
    RewriteRuleSubtreeStream stream_viewPartition = new RewriteRuleSubtreeStream(adaptor, "rule viewPartition");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");

    pushMsg("create view statement", state);

    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1670:5: ( KW_CREATE ( orReplace )? KW_VIEW ( ifNotExists )? name= tableName ( LPAREN columnNameCommentList RPAREN )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? KW_AS selectStatementWithCTE -> ^( TOK_CREATEVIEW $name ( orReplace )? ( ifNotExists )? ( columnNameCommentList )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? selectStatementWithCTE ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1670:7: KW_CREATE ( orReplace )? KW_VIEW ( ifNotExists )? name= tableName ( LPAREN columnNameCommentList RPAREN )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? KW_AS selectStatementWithCTE
      {
        KW_CREATE633 = (Token) match(input, KW_CREATE, FOLLOW_KW_CREATE_in_createViewStatement9636);
        stream_KW_CREATE.add(KW_CREATE633);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1670:17: ( orReplace )?
        int alt187 = 2;
        switch (input.LA(1)) {
          case KW_OR: {
            alt187 = 1;
          }
          break;
        }

        switch (alt187) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1670:18: orReplace
          {
            pushFollow(FOLLOW_orReplace_in_createViewStatement9639);
            orReplace634 = orReplace();

            state._fsp--;

            stream_orReplace.add(orReplace634.getTree());
          }
          break;
        }

        KW_VIEW635 = (Token) match(input, KW_VIEW, FOLLOW_KW_VIEW_in_createViewStatement9643);
        stream_KW_VIEW.add(KW_VIEW635);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1670:38: ( ifNotExists )?
        int alt188 = 2;
        switch (input.LA(1)) {
          case KW_IF: {
            alt188 = 1;
          }
          break;
        }

        switch (alt188) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1670:39: ifNotExists
          {
            pushFollow(FOLLOW_ifNotExists_in_createViewStatement9646);
            ifNotExists636 = ifNotExists();

            state._fsp--;

            stream_ifNotExists.add(ifNotExists636.getTree());
          }
          break;
        }

        pushFollow(FOLLOW_tableName_in_createViewStatement9652);
        name = tableName();

        state._fsp--;

        stream_tableName.add(name.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1671:9: ( LPAREN columnNameCommentList RPAREN )?
        int alt189 = 2;
        switch (input.LA(1)) {
          case LPAREN: {
            alt189 = 1;
          }
          break;
        }

        switch (alt189) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1671:10: LPAREN columnNameCommentList RPAREN
          {
            LPAREN637 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_createViewStatement9663);
            stream_LPAREN.add(LPAREN637);

            pushFollow(FOLLOW_columnNameCommentList_in_createViewStatement9665);
            columnNameCommentList638 = columnNameCommentList();

            state._fsp--;

            stream_columnNameCommentList.add(columnNameCommentList638.getTree());

            RPAREN639 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_createViewStatement9667);
            stream_RPAREN.add(RPAREN639);
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1671:48: ( tableComment )?
        int alt190 = 2;
        switch (input.LA(1)) {
          case KW_COMMENT: {
            alt190 = 1;
          }
          break;
        }

        switch (alt190) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1671:48: tableComment
          {
            pushFollow(FOLLOW_tableComment_in_createViewStatement9671);
            tableComment640 = tableComment();

            state._fsp--;

            stream_tableComment.add(tableComment640.getTree());
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1671:62: ( viewPartition )?
        int alt191 = 2;
        switch (input.LA(1)) {
          case KW_PARTITIONED: {
            alt191 = 1;
          }
          break;
        }

        switch (alt191) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1671:62: viewPartition
          {
            pushFollow(FOLLOW_viewPartition_in_createViewStatement9674);
            viewPartition641 = viewPartition();

            state._fsp--;

            stream_viewPartition.add(viewPartition641.getTree());
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1672:9: ( tablePropertiesPrefixed )?
        int alt192 = 2;
        switch (input.LA(1)) {
          case KW_TBLPROPERTIES: {
            alt192 = 1;
          }
          break;
        }

        switch (alt192) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1672:9: tablePropertiesPrefixed
          {
            pushFollow(FOLLOW_tablePropertiesPrefixed_in_createViewStatement9685);
            tablePropertiesPrefixed642 = tablePropertiesPrefixed();

            state._fsp--;

            stream_tablePropertiesPrefixed.add(tablePropertiesPrefixed642.getTree());
          }
          break;
        }

        KW_AS643 = (Token) match(input, KW_AS, FOLLOW_KW_AS_in_createViewStatement9696);
        stream_KW_AS.add(KW_AS643);

        pushFollow(FOLLOW_selectStatementWithCTE_in_createViewStatement9706);
        selectStatementWithCTE644 = selectStatementWithCTE();

        state._fsp--;

        stream_selectStatementWithCTE.add(selectStatementWithCTE644.getTree());

        // AST REWRITE
        // elements: tablePropertiesPrefixed, ifNotExists, columnNameCommentList, orReplace, viewPartition, name, tableComment, selectStatementWithCTE
        // token labels:
        // rule labels: name, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_name =
            new RewriteRuleSubtreeStream(adaptor, "rule name", name != null ? name.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1675:5: -> ^( TOK_CREATEVIEW $name ( orReplace )? ( ifNotExists )? ( columnNameCommentList )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? selectStatementWithCTE )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1675:8: ^( TOK_CREATEVIEW $name ( orReplace )? ( ifNotExists )? ( columnNameCommentList )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? selectStatementWithCTE )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_CREATEVIEW, "TOK_CREATEVIEW"), root_1);

            adaptor.addChild(root_1, stream_name.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1675:31: ( orReplace )?
            if (stream_orReplace.hasNext()) {
              adaptor.addChild(root_1, stream_orReplace.nextTree());
            }
            stream_orReplace.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1676:10: ( ifNotExists )?
            if (stream_ifNotExists.hasNext()) {
              adaptor.addChild(root_1, stream_ifNotExists.nextTree());
            }
            stream_ifNotExists.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1677:10: ( columnNameCommentList )?
            if (stream_columnNameCommentList.hasNext()) {
              adaptor.addChild(root_1, stream_columnNameCommentList.nextTree());
            }
            stream_columnNameCommentList.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1678:10: ( tableComment )?
            if (stream_tableComment.hasNext()) {
              adaptor.addChild(root_1, stream_tableComment.nextTree());
            }
            stream_tableComment.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1679:10: ( viewPartition )?
            if (stream_viewPartition.hasNext()) {
              adaptor.addChild(root_1, stream_viewPartition.nextTree());
            }
            stream_viewPartition.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1680:10: ( tablePropertiesPrefixed )?
            if (stream_tablePropertiesPrefixed.hasNext()) {
              adaptor.addChild(root_1, stream_tablePropertiesPrefixed.nextTree());
            }
            stream_tablePropertiesPrefixed.reset();

            adaptor.addChild(root_1, stream_selectStatementWithCTE.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "createViewStatement"

  public static class viewPartition_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "viewPartition"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1685:1: viewPartition : KW_PARTITIONED KW_ON LPAREN columnNameList RPAREN -> ^( TOK_VIEWPARTCOLS columnNameList ) ;
  public final HiveParser.viewPartition_return viewPartition() throws RecognitionException {
    HiveParser.viewPartition_return retval = new HiveParser.viewPartition_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_PARTITIONED645 = null;
    Token KW_ON646 = null;
    Token LPAREN647 = null;
    Token RPAREN649 = null;
    HiveParser.columnNameList_return columnNameList648 = null;

    CommonTree KW_PARTITIONED645_tree = null;
    CommonTree KW_ON646_tree = null;
    CommonTree LPAREN647_tree = null;
    CommonTree RPAREN649_tree = null;
    RewriteRuleTokenStream stream_KW_PARTITIONED = new RewriteRuleTokenStream(adaptor, "token KW_PARTITIONED");
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_KW_ON = new RewriteRuleTokenStream(adaptor, "token KW_ON");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleSubtreeStream stream_columnNameList = new RewriteRuleSubtreeStream(adaptor, "rule columnNameList");
    pushMsg("view partition specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1688:5: ( KW_PARTITIONED KW_ON LPAREN columnNameList RPAREN -> ^( TOK_VIEWPARTCOLS columnNameList ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1688:7: KW_PARTITIONED KW_ON LPAREN columnNameList RPAREN
      {
        KW_PARTITIONED645 = (Token) match(input, KW_PARTITIONED, FOLLOW_KW_PARTITIONED_in_viewPartition9829);
        stream_KW_PARTITIONED.add(KW_PARTITIONED645);

        KW_ON646 = (Token) match(input, KW_ON, FOLLOW_KW_ON_in_viewPartition9831);
        stream_KW_ON.add(KW_ON646);

        LPAREN647 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_viewPartition9833);
        stream_LPAREN.add(LPAREN647);

        pushFollow(FOLLOW_columnNameList_in_viewPartition9835);
        columnNameList648 = columnNameList();

        state._fsp--;

        stream_columnNameList.add(columnNameList648.getTree());

        RPAREN649 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_viewPartition9837);
        stream_RPAREN.add(RPAREN649);

        // AST REWRITE
        // elements: columnNameList
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1689:5: -> ^( TOK_VIEWPARTCOLS columnNameList )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1689:8: ^( TOK_VIEWPARTCOLS columnNameList )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_VIEWPARTCOLS, "TOK_VIEWPARTCOLS"),
                root_1);

            adaptor.addChild(root_1, stream_columnNameList.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "viewPartition"

  public static class dropViewStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "dropViewStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1692:1: dropViewStatement : KW_DROP KW_VIEW ( ifExists )? viewName -> ^( TOK_DROPVIEW viewName ( ifExists )? ) ;
  public final HiveParser.dropViewStatement_return dropViewStatement() throws RecognitionException {
    HiveParser.dropViewStatement_return retval = new HiveParser.dropViewStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_DROP650 = null;
    Token KW_VIEW651 = null;
    HiveParser.ifExists_return ifExists652 = null;

    HiveParser_FromClauseParser.viewName_return viewName653 = null;

    CommonTree KW_DROP650_tree = null;
    CommonTree KW_VIEW651_tree = null;
    RewriteRuleTokenStream stream_KW_DROP = new RewriteRuleTokenStream(adaptor, "token KW_DROP");
    RewriteRuleTokenStream stream_KW_VIEW = new RewriteRuleTokenStream(adaptor, "token KW_VIEW");
    RewriteRuleSubtreeStream stream_viewName = new RewriteRuleSubtreeStream(adaptor, "rule viewName");
    RewriteRuleSubtreeStream stream_ifExists = new RewriteRuleSubtreeStream(adaptor, "rule ifExists");
    pushMsg("drop view statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1695:5: ( KW_DROP KW_VIEW ( ifExists )? viewName -> ^( TOK_DROPVIEW viewName ( ifExists )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1695:7: KW_DROP KW_VIEW ( ifExists )? viewName
      {
        KW_DROP650 = (Token) match(input, KW_DROP, FOLLOW_KW_DROP_in_dropViewStatement9876);
        stream_KW_DROP.add(KW_DROP650);

        KW_VIEW651 = (Token) match(input, KW_VIEW, FOLLOW_KW_VIEW_in_dropViewStatement9878);
        stream_KW_VIEW.add(KW_VIEW651);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1695:23: ( ifExists )?
        int alt193 = 2;
        switch (input.LA(1)) {
          case KW_IF: {
            alt193 = 1;
          }
          break;
        }

        switch (alt193) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1695:23: ifExists
          {
            pushFollow(FOLLOW_ifExists_in_dropViewStatement9880);
            ifExists652 = ifExists();

            state._fsp--;

            stream_ifExists.add(ifExists652.getTree());
          }
          break;
        }

        pushFollow(FOLLOW_viewName_in_dropViewStatement9883);
        viewName653 = viewName();

        state._fsp--;

        stream_viewName.add(viewName653.getTree());

        // AST REWRITE
        // elements: viewName, ifExists
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1695:42: -> ^( TOK_DROPVIEW viewName ( ifExists )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1695:45: ^( TOK_DROPVIEW viewName ( ifExists )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DROPVIEW, "TOK_DROPVIEW"), root_1);

            adaptor.addChild(root_1, stream_viewName.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1695:69: ( ifExists )?
            if (stream_ifExists.hasNext()) {
              adaptor.addChild(root_1, stream_ifExists.nextTree());
            }
            stream_ifExists.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "dropViewStatement"

  public static class showFunctionIdentifier_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "showFunctionIdentifier"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1698:1: showFunctionIdentifier : ( functionIdentifier | StringLiteral );
  public final HiveParser.showFunctionIdentifier_return showFunctionIdentifier() throws RecognitionException {
    HiveParser.showFunctionIdentifier_return retval = new HiveParser.showFunctionIdentifier_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token StringLiteral655 = null;
    HiveParser_IdentifiersParser.functionIdentifier_return functionIdentifier654 = null;

    CommonTree StringLiteral655_tree = null;

    pushMsg("identifier for show function statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1701:5: ( functionIdentifier | StringLiteral )
      int alt194 = 2;
      switch (input.LA(1)) {
        case Identifier:
        case KW_ADD:
        case KW_ADMIN:
        case KW_AFTER:
        case KW_ALL:
        case KW_ALTER:
        case KW_ANALYZE:
        case KW_ARCHIVE:
        case KW_ARRAY:
        case KW_AS:
        case KW_ASC:
        case KW_AUTHORIZATION:
        case KW_BEFORE:
        case KW_BETWEEN:
        case KW_BIGINT:
        case KW_BINARY:
        case KW_BOOLEAN:
        case KW_BOTH:
        case KW_BUCKET:
        case KW_BUCKETS:
        case KW_BY:
        case KW_CASCADE:
        case KW_CHANGE:
        case KW_CLUSTER:
        case KW_CLUSTERED:
        case KW_CLUSTERSTATUS:
        case KW_COLLECTION:
        case KW_COLUMNS:
        case KW_COMMENT:
        case KW_COMPACT:
        case KW_COMPACTIONS:
        case KW_COMPUTE:
        case KW_CONCATENATE:
        case KW_CONTINUE:
        case KW_CREATE:
        case KW_CUBE:
        case KW_CURSOR:
        case KW_DATA:
        case KW_DATABASES:
        case KW_DATE:
        case KW_DATETIME:
        case KW_DBPROPERTIES:
        case KW_DECIMAL:
        case KW_DEFAULT:
        case KW_DEFERRED:
        case KW_DEFINED:
        case KW_DELETE:
        case KW_DELIMITED:
        case KW_DEPENDENCY:
        case KW_DESC:
        case KW_DESCRIBE:
        case KW_DIRECTORIES:
        case KW_DIRECTORY:
        case KW_DISABLE:
        case KW_DISTRIBUTE:
        case KW_DOUBLE:
        case KW_DROP:
        case KW_ELEM_TYPE:
        case KW_ENABLE:
        case KW_ESCAPED:
        case KW_EXCLUSIVE:
        case KW_EXISTS:
        case KW_EXPLAIN:
        case KW_EXPORT:
        case KW_EXTERNAL:
        case KW_FALSE:
        case KW_FETCH:
        case KW_FIELDS:
        case KW_FILE:
        case KW_FILEFORMAT:
        case KW_FIRST:
        case KW_FLOAT:
        case KW_FOR:
        case KW_FORMAT:
        case KW_FORMATTED:
        case KW_FULL:
        case KW_FUNCTIONS:
        case KW_GRANT:
        case KW_GROUP:
        case KW_GROUPING:
        case KW_HOLD_DDLTIME:
        case KW_IDXPROPERTIES:
        case KW_IGNORE:
        case KW_IMPORT:
        case KW_IN:
        case KW_INDEX:
        case KW_INDEXES:
        case KW_INNER:
        case KW_INPATH:
        case KW_INPUTDRIVER:
        case KW_INPUTFORMAT:
        case KW_INSERT:
        case KW_INT:
        case KW_INTERSECT:
        case KW_INTO:
        case KW_IS:
        case KW_ITEMS:
        case KW_JAR:
        case KW_KEYS:
        case KW_KEY_TYPE:
        case KW_LATERAL:
        case KW_LEFT:
        case KW_LIKE:
        case KW_LIMIT:
        case KW_LINES:
        case KW_LOAD:
        case KW_LOCAL:
        case KW_LOCATION:
        case KW_LOCK:
        case KW_LOCKS:
        case KW_LOGICAL:
        case KW_LONG:
        case KW_MAPJOIN:
        case KW_MATERIALIZED:
        case KW_METADATA:
        case KW_MINUS:
        case KW_MSCK:
        case KW_NONE:
        case KW_NOSCAN:
        case KW_NO_DROP:
        case KW_NULL:
        case KW_OF:
        case KW_OFFLINE:
        case KW_OPTION:
        case KW_ORDER:
        case KW_OUT:
        case KW_OUTER:
        case KW_OUTPUTDRIVER:
        case KW_OUTPUTFORMAT:
        case KW_OVERWRITE:
        case KW_OWNER:
        case KW_PARTITION:
        case KW_PARTITIONED:
        case KW_PARTITIONS:
        case KW_PERCENT:
        case KW_PLUS:
        case KW_PRETTY:
        case KW_PRINCIPALS:
        case KW_PROCEDURE:
        case KW_PROTECTION:
        case KW_PURGE:
        case KW_RANGE:
        case KW_READ:
        case KW_READONLY:
        case KW_READS:
        case KW_REBUILD:
        case KW_RECORDREADER:
        case KW_RECORDWRITER:
        case KW_REGEXP:
        case KW_RELOAD:
        case KW_RENAME:
        case KW_REPAIR:
        case KW_REPLACE:
        case KW_REPLICATION:
        case KW_RESTRICT:
        case KW_REVOKE:
        case KW_REWRITE:
        case KW_RIGHT:
        case KW_RLIKE:
        case KW_ROLE:
        case KW_ROLES:
        case KW_ROLLUP:
        case KW_ROW:
        case KW_ROWS:
        case KW_SCHEMA:
        case KW_SCHEMAS:
        case KW_SEMI:
        case KW_SERDE:
        case KW_SERDEPROPERTIES:
        case KW_SERVER:
        case KW_SET:
        case KW_SETS:
        case KW_SHARED:
        case KW_SHOW:
        case KW_SHOW_DATABASE:
        case KW_SKEWED:
        case KW_SMALLINT:
        case KW_SORT:
        case KW_SORTED:
        case KW_SSL:
        case KW_STATISTICS:
        case KW_STORED:
        case KW_STREAMTABLE:
        case KW_STRING:
        case KW_STRUCT:
        case KW_TABLE:
        case KW_TABLES:
        case KW_TBLPROPERTIES:
        case KW_TEMPORARY:
        case KW_TERMINATED:
        case KW_TIMESTAMP:
        case KW_TINYINT:
        case KW_TO:
        case KW_TOUCH:
        case KW_TRANSACTIONS:
        case KW_TRIGGER:
        case KW_TRUE:
        case KW_TRUNCATE:
        case KW_UNARCHIVE:
        case KW_UNDO:
        case KW_UNION:
        case KW_UNIONTYPE:
        case KW_UNLOCK:
        case KW_UNSET:
        case KW_UNSIGNED:
        case KW_UPDATE:
        case KW_URI:
        case KW_USE:
        case KW_USER:
        case KW_USING:
        case KW_UTC:
        case KW_UTCTIMESTAMP:
        case KW_VALUES:
        case KW_VALUE_TYPE:
        case KW_VIEW:
        case KW_WHILE:
        case KW_WITH: {
          alt194 = 1;
        }
        break;
        case StringLiteral: {
          alt194 = 2;
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 194, 0, input);

          throw nvae;
      }

      switch (alt194) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1701:7: functionIdentifier
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_functionIdentifier_in_showFunctionIdentifier9921);
          functionIdentifier654 = functionIdentifier();

          state._fsp--;

          adaptor.addChild(root_0, functionIdentifier654.getTree());
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1702:7: StringLiteral
        {
          root_0 = (CommonTree) adaptor.nil();

          StringLiteral655 = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_showFunctionIdentifier9929);
          StringLiteral655_tree = (CommonTree) adaptor.create(StringLiteral655);
          adaptor.addChild(root_0, StringLiteral655_tree);
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "showFunctionIdentifier"

  public static class showStmtIdentifier_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "showStmtIdentifier"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1705:1: showStmtIdentifier : ( identifier | StringLiteral );
  public final HiveParser.showStmtIdentifier_return showStmtIdentifier() throws RecognitionException {
    HiveParser.showStmtIdentifier_return retval = new HiveParser.showStmtIdentifier_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token StringLiteral657 = null;
    HiveParser_IdentifiersParser.identifier_return identifier656 = null;

    CommonTree StringLiteral657_tree = null;

    pushMsg("identifier for show statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1708:5: ( identifier | StringLiteral )
      int alt195 = 2;
      switch (input.LA(1)) {
        case Identifier:
        case KW_ADD:
        case KW_ADMIN:
        case KW_AFTER:
        case KW_ALL:
        case KW_ALTER:
        case KW_ANALYZE:
        case KW_ARCHIVE:
        case KW_ARRAY:
        case KW_AS:
        case KW_ASC:
        case KW_AUTHORIZATION:
        case KW_BEFORE:
        case KW_BETWEEN:
        case KW_BIGINT:
        case KW_BINARY:
        case KW_BOOLEAN:
        case KW_BOTH:
        case KW_BUCKET:
        case KW_BUCKETS:
        case KW_BY:
        case KW_CASCADE:
        case KW_CHANGE:
        case KW_CLUSTER:
        case KW_CLUSTERED:
        case KW_CLUSTERSTATUS:
        case KW_COLLECTION:
        case KW_COLUMNS:
        case KW_COMMENT:
        case KW_COMPACT:
        case KW_COMPACTIONS:
        case KW_COMPUTE:
        case KW_CONCATENATE:
        case KW_CONTINUE:
        case KW_CREATE:
        case KW_CUBE:
        case KW_CURSOR:
        case KW_DATA:
        case KW_DATABASES:
        case KW_DATE:
        case KW_DATETIME:
        case KW_DBPROPERTIES:
        case KW_DECIMAL:
        case KW_DEFAULT:
        case KW_DEFERRED:
        case KW_DEFINED:
        case KW_DELETE:
        case KW_DELIMITED:
        case KW_DEPENDENCY:
        case KW_DESC:
        case KW_DESCRIBE:
        case KW_DIRECTORIES:
        case KW_DIRECTORY:
        case KW_DISABLE:
        case KW_DISTRIBUTE:
        case KW_DOUBLE:
        case KW_DROP:
        case KW_ELEM_TYPE:
        case KW_ENABLE:
        case KW_ESCAPED:
        case KW_EXCLUSIVE:
        case KW_EXISTS:
        case KW_EXPLAIN:
        case KW_EXPORT:
        case KW_EXTERNAL:
        case KW_FALSE:
        case KW_FETCH:
        case KW_FIELDS:
        case KW_FILE:
        case KW_FILEFORMAT:
        case KW_FIRST:
        case KW_FLOAT:
        case KW_FOR:
        case KW_FORMAT:
        case KW_FORMATTED:
        case KW_FULL:
        case KW_FUNCTIONS:
        case KW_GRANT:
        case KW_GROUP:
        case KW_GROUPING:
        case KW_HOLD_DDLTIME:
        case KW_IDXPROPERTIES:
        case KW_IGNORE:
        case KW_IMPORT:
        case KW_IN:
        case KW_INDEX:
        case KW_INDEXES:
        case KW_INNER:
        case KW_INPATH:
        case KW_INPUTDRIVER:
        case KW_INPUTFORMAT:
        case KW_INSERT:
        case KW_INT:
        case KW_INTERSECT:
        case KW_INTO:
        case KW_IS:
        case KW_ITEMS:
        case KW_JAR:
        case KW_KEYS:
        case KW_KEY_TYPE:
        case KW_LATERAL:
        case KW_LEFT:
        case KW_LIKE:
        case KW_LIMIT:
        case KW_LINES:
        case KW_LOAD:
        case KW_LOCAL:
        case KW_LOCATION:
        case KW_LOCK:
        case KW_LOCKS:
        case KW_LOGICAL:
        case KW_LONG:
        case KW_MAPJOIN:
        case KW_MATERIALIZED:
        case KW_METADATA:
        case KW_MINUS:
        case KW_MSCK:
        case KW_NONE:
        case KW_NOSCAN:
        case KW_NO_DROP:
        case KW_NULL:
        case KW_OF:
        case KW_OFFLINE:
        case KW_OPTION:
        case KW_ORDER:
        case KW_OUT:
        case KW_OUTER:
        case KW_OUTPUTDRIVER:
        case KW_OUTPUTFORMAT:
        case KW_OVERWRITE:
        case KW_OWNER:
        case KW_PARTITION:
        case KW_PARTITIONED:
        case KW_PARTITIONS:
        case KW_PERCENT:
        case KW_PLUS:
        case KW_PRETTY:
        case KW_PRINCIPALS:
        case KW_PROCEDURE:
        case KW_PROTECTION:
        case KW_PURGE:
        case KW_RANGE:
        case KW_READ:
        case KW_READONLY:
        case KW_READS:
        case KW_REBUILD:
        case KW_RECORDREADER:
        case KW_RECORDWRITER:
        case KW_REGEXP:
        case KW_RELOAD:
        case KW_RENAME:
        case KW_REPAIR:
        case KW_REPLACE:
        case KW_REPLICATION:
        case KW_RESTRICT:
        case KW_REVOKE:
        case KW_REWRITE:
        case KW_RIGHT:
        case KW_RLIKE:
        case KW_ROLE:
        case KW_ROLES:
        case KW_ROLLUP:
        case KW_ROW:
        case KW_ROWS:
        case KW_SCHEMA:
        case KW_SCHEMAS:
        case KW_SEMI:
        case KW_SERDE:
        case KW_SERDEPROPERTIES:
        case KW_SERVER:
        case KW_SET:
        case KW_SETS:
        case KW_SHARED:
        case KW_SHOW:
        case KW_SHOW_DATABASE:
        case KW_SKEWED:
        case KW_SMALLINT:
        case KW_SORT:
        case KW_SORTED:
        case KW_SSL:
        case KW_STATISTICS:
        case KW_STORED:
        case KW_STREAMTABLE:
        case KW_STRING:
        case KW_STRUCT:
        case KW_TABLE:
        case KW_TABLES:
        case KW_TBLPROPERTIES:
        case KW_TEMPORARY:
        case KW_TERMINATED:
        case KW_TIMESTAMP:
        case KW_TINYINT:
        case KW_TO:
        case KW_TOUCH:
        case KW_TRANSACTIONS:
        case KW_TRIGGER:
        case KW_TRUE:
        case KW_TRUNCATE:
        case KW_UNARCHIVE:
        case KW_UNDO:
        case KW_UNION:
        case KW_UNIONTYPE:
        case KW_UNLOCK:
        case KW_UNSET:
        case KW_UNSIGNED:
        case KW_UPDATE:
        case KW_URI:
        case KW_USE:
        case KW_USER:
        case KW_USING:
        case KW_UTC:
        case KW_UTCTIMESTAMP:
        case KW_VALUES:
        case KW_VALUE_TYPE:
        case KW_VIEW:
        case KW_WHILE:
        case KW_WITH: {
          alt195 = 1;
        }
        break;
        case StringLiteral: {
          alt195 = 2;
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 195, 0, input);

          throw nvae;
      }

      switch (alt195) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1708:7: identifier
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_identifier_in_showStmtIdentifier9956);
          identifier656 = identifier();

          state._fsp--;

          adaptor.addChild(root_0, identifier656.getTree());
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1709:7: StringLiteral
        {
          root_0 = (CommonTree) adaptor.nil();

          StringLiteral657 = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_showStmtIdentifier9964);
          StringLiteral657_tree = (CommonTree) adaptor.create(StringLiteral657);
          adaptor.addChild(root_0, StringLiteral657_tree);
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "showStmtIdentifier"

  public static class tableComment_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "tableComment"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1712:1: tableComment : KW_COMMENT comment= StringLiteral -> ^( TOK_TABLECOMMENT $comment) ;
  public final HiveParser.tableComment_return tableComment() throws RecognitionException {
    HiveParser.tableComment_return retval = new HiveParser.tableComment_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token comment = null;
    Token KW_COMMENT658 = null;

    CommonTree comment_tree = null;
    CommonTree KW_COMMENT658_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_COMMENT = new RewriteRuleTokenStream(adaptor, "token KW_COMMENT");

    pushMsg("table's comment", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1715:5: ( KW_COMMENT comment= StringLiteral -> ^( TOK_TABLECOMMENT $comment) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1716:7: KW_COMMENT comment= StringLiteral
      {
        KW_COMMENT658 = (Token) match(input, KW_COMMENT, FOLLOW_KW_COMMENT_in_tableComment9997);
        stream_KW_COMMENT.add(KW_COMMENT658);

        comment = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_tableComment10001);
        stream_StringLiteral.add(comment);

        // AST REWRITE
        // elements: comment
        // token labels: comment
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_comment = new RewriteRuleTokenStream(adaptor, "token comment", comment);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1716:41: -> ^( TOK_TABLECOMMENT $comment)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1716:44: ^( TOK_TABLECOMMENT $comment)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABLECOMMENT, "TOK_TABLECOMMENT"),
                root_1);

            adaptor.addChild(root_1, stream_comment.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "tableComment"

  public static class tablePartition_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "tablePartition"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1719:1: tablePartition : KW_PARTITIONED KW_BY LPAREN columnNameTypeList RPAREN -> ^( TOK_TABLEPARTCOLS columnNameTypeList ) ;
  public final HiveParser.tablePartition_return tablePartition() throws RecognitionException {
    HiveParser.tablePartition_return retval = new HiveParser.tablePartition_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_PARTITIONED659 = null;
    Token KW_BY660 = null;
    Token LPAREN661 = null;
    Token RPAREN663 = null;
    HiveParser.columnNameTypeList_return columnNameTypeList662 = null;

    CommonTree KW_PARTITIONED659_tree = null;
    CommonTree KW_BY660_tree = null;
    CommonTree LPAREN661_tree = null;
    CommonTree RPAREN663_tree = null;
    RewriteRuleTokenStream stream_KW_BY = new RewriteRuleTokenStream(adaptor, "token KW_BY");
    RewriteRuleTokenStream stream_KW_PARTITIONED = new RewriteRuleTokenStream(adaptor, "token KW_PARTITIONED");
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleSubtreeStream stream_columnNameTypeList =
        new RewriteRuleSubtreeStream(adaptor, "rule columnNameTypeList");
    pushMsg("table partition specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1722:5: ( KW_PARTITIONED KW_BY LPAREN columnNameTypeList RPAREN -> ^( TOK_TABLEPARTCOLS columnNameTypeList ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1722:7: KW_PARTITIONED KW_BY LPAREN columnNameTypeList RPAREN
      {
        KW_PARTITIONED659 = (Token) match(input, KW_PARTITIONED, FOLLOW_KW_PARTITIONED_in_tablePartition10038);
        stream_KW_PARTITIONED.add(KW_PARTITIONED659);

        KW_BY660 = (Token) match(input, KW_BY, FOLLOW_KW_BY_in_tablePartition10040);
        stream_KW_BY.add(KW_BY660);

        LPAREN661 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_tablePartition10042);
        stream_LPAREN.add(LPAREN661);

        pushFollow(FOLLOW_columnNameTypeList_in_tablePartition10044);
        columnNameTypeList662 = columnNameTypeList();

        state._fsp--;

        stream_columnNameTypeList.add(columnNameTypeList662.getTree());

        RPAREN663 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_tablePartition10046);
        stream_RPAREN.add(RPAREN663);

        // AST REWRITE
        // elements: columnNameTypeList
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1723:5: -> ^( TOK_TABLEPARTCOLS columnNameTypeList )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1723:8: ^( TOK_TABLEPARTCOLS columnNameTypeList )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABLEPARTCOLS, "TOK_TABLEPARTCOLS"),
                    root_1);

            adaptor.addChild(root_1, stream_columnNameTypeList.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "tablePartition"

  public static class tableBuckets_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "tableBuckets"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1726:1: tableBuckets : KW_CLUSTERED KW_BY LPAREN bucketCols= columnNameList RPAREN ( KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN )? KW_INTO num= Number KW_BUCKETS -> ^( TOK_ALTERTABLE_BUCKETS $bucketCols ( $sortCols)? $num) ;
  public final HiveParser.tableBuckets_return tableBuckets() throws RecognitionException {
    HiveParser.tableBuckets_return retval = new HiveParser.tableBuckets_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token num = null;
    Token KW_CLUSTERED664 = null;
    Token KW_BY665 = null;
    Token LPAREN666 = null;
    Token RPAREN667 = null;
    Token KW_SORTED668 = null;
    Token KW_BY669 = null;
    Token LPAREN670 = null;
    Token RPAREN671 = null;
    Token KW_INTO672 = null;
    Token KW_BUCKETS673 = null;
    HiveParser.columnNameList_return bucketCols = null;

    HiveParser.columnNameOrderList_return sortCols = null;

    CommonTree num_tree = null;
    CommonTree KW_CLUSTERED664_tree = null;
    CommonTree KW_BY665_tree = null;
    CommonTree LPAREN666_tree = null;
    CommonTree RPAREN667_tree = null;
    CommonTree KW_SORTED668_tree = null;
    CommonTree KW_BY669_tree = null;
    CommonTree LPAREN670_tree = null;
    CommonTree RPAREN671_tree = null;
    CommonTree KW_INTO672_tree = null;
    CommonTree KW_BUCKETS673_tree = null;
    RewriteRuleTokenStream stream_KW_BY = new RewriteRuleTokenStream(adaptor, "token KW_BY");
    RewriteRuleTokenStream stream_KW_SORTED = new RewriteRuleTokenStream(adaptor, "token KW_SORTED");
    RewriteRuleTokenStream stream_Number = new RewriteRuleTokenStream(adaptor, "token Number");
    RewriteRuleTokenStream stream_KW_INTO = new RewriteRuleTokenStream(adaptor, "token KW_INTO");
    RewriteRuleTokenStream stream_KW_BUCKETS = new RewriteRuleTokenStream(adaptor, "token KW_BUCKETS");
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleTokenStream stream_KW_CLUSTERED = new RewriteRuleTokenStream(adaptor, "token KW_CLUSTERED");
    RewriteRuleSubtreeStream stream_columnNameOrderList =
        new RewriteRuleSubtreeStream(adaptor, "rule columnNameOrderList");
    RewriteRuleSubtreeStream stream_columnNameList = new RewriteRuleSubtreeStream(adaptor, "rule columnNameList");
    pushMsg("table buckets specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1729:5: ( KW_CLUSTERED KW_BY LPAREN bucketCols= columnNameList RPAREN ( KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN )? KW_INTO num= Number KW_BUCKETS -> ^( TOK_ALTERTABLE_BUCKETS $bucketCols ( $sortCols)? $num) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1730:7: KW_CLUSTERED KW_BY LPAREN bucketCols= columnNameList RPAREN ( KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN )? KW_INTO num= Number KW_BUCKETS
      {
        KW_CLUSTERED664 = (Token) match(input, KW_CLUSTERED, FOLLOW_KW_CLUSTERED_in_tableBuckets10091);
        stream_KW_CLUSTERED.add(KW_CLUSTERED664);

        KW_BY665 = (Token) match(input, KW_BY, FOLLOW_KW_BY_in_tableBuckets10093);
        stream_KW_BY.add(KW_BY665);

        LPAREN666 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_tableBuckets10095);
        stream_LPAREN.add(LPAREN666);

        pushFollow(FOLLOW_columnNameList_in_tableBuckets10099);
        bucketCols = columnNameList();

        state._fsp--;

        stream_columnNameList.add(bucketCols.getTree());

        RPAREN667 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_tableBuckets10101);
        stream_RPAREN.add(RPAREN667);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1730:66: ( KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN )?
        int alt196 = 2;
        switch (input.LA(1)) {
          case KW_SORTED: {
            alt196 = 1;
          }
          break;
        }

        switch (alt196) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1730:67: KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN
          {
            KW_SORTED668 = (Token) match(input, KW_SORTED, FOLLOW_KW_SORTED_in_tableBuckets10104);
            stream_KW_SORTED.add(KW_SORTED668);

            KW_BY669 = (Token) match(input, KW_BY, FOLLOW_KW_BY_in_tableBuckets10106);
            stream_KW_BY.add(KW_BY669);

            LPAREN670 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_tableBuckets10108);
            stream_LPAREN.add(LPAREN670);

            pushFollow(FOLLOW_columnNameOrderList_in_tableBuckets10112);
            sortCols = columnNameOrderList();

            state._fsp--;

            stream_columnNameOrderList.add(sortCols.getTree());

            RPAREN671 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_tableBuckets10114);
            stream_RPAREN.add(RPAREN671);
          }
          break;
        }

        KW_INTO672 = (Token) match(input, KW_INTO, FOLLOW_KW_INTO_in_tableBuckets10118);
        stream_KW_INTO.add(KW_INTO672);

        num = (Token) match(input, Number, FOLLOW_Number_in_tableBuckets10122);
        stream_Number.add(num);

        KW_BUCKETS673 = (Token) match(input, KW_BUCKETS, FOLLOW_KW_BUCKETS_in_tableBuckets10124);
        stream_KW_BUCKETS.add(KW_BUCKETS673);

        // AST REWRITE
        // elements: bucketCols, num, sortCols
        // token labels: num
        // rule labels: bucketCols, sortCols, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_num = new RewriteRuleTokenStream(adaptor, "token num", num);
        RewriteRuleSubtreeStream stream_bucketCols =
            new RewriteRuleSubtreeStream(adaptor, "rule bucketCols", bucketCols != null ? bucketCols.tree : null);
        RewriteRuleSubtreeStream stream_sortCols =
            new RewriteRuleSubtreeStream(adaptor, "rule sortCols", sortCols != null ? sortCols.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1731:5: -> ^( TOK_ALTERTABLE_BUCKETS $bucketCols ( $sortCols)? $num)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1731:8: ^( TOK_ALTERTABLE_BUCKETS $bucketCols ( $sortCols)? $num)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_ALTERTABLE_BUCKETS, "TOK_ALTERTABLE_BUCKETS"), root_1);

            adaptor.addChild(root_1, stream_bucketCols.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1731:46: ( $sortCols)?
            if (stream_sortCols.hasNext()) {
              adaptor.addChild(root_1, stream_sortCols.nextTree());
            }
            stream_sortCols.reset();

            adaptor.addChild(root_1, stream_num.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "tableBuckets"

  public static class tableSkewed_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "tableSkewed"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1734:1: tableSkewed : KW_SKEWED KW_BY LPAREN skewedCols= columnNameList RPAREN KW_ON LPAREN (skewedValues= skewedValueElement ) RPAREN ( storedAsDirs )? -> ^( TOK_TABLESKEWED $skewedCols $skewedValues ( storedAsDirs )? ) ;
  public final HiveParser.tableSkewed_return tableSkewed() throws RecognitionException {
    HiveParser.tableSkewed_return retval = new HiveParser.tableSkewed_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_SKEWED674 = null;
    Token KW_BY675 = null;
    Token LPAREN676 = null;
    Token RPAREN677 = null;
    Token KW_ON678 = null;
    Token LPAREN679 = null;
    Token RPAREN680 = null;
    HiveParser.columnNameList_return skewedCols = null;

    HiveParser.skewedValueElement_return skewedValues = null;

    HiveParser.storedAsDirs_return storedAsDirs681 = null;

    CommonTree KW_SKEWED674_tree = null;
    CommonTree KW_BY675_tree = null;
    CommonTree LPAREN676_tree = null;
    CommonTree RPAREN677_tree = null;
    CommonTree KW_ON678_tree = null;
    CommonTree LPAREN679_tree = null;
    CommonTree RPAREN680_tree = null;
    RewriteRuleTokenStream stream_KW_BY = new RewriteRuleTokenStream(adaptor, "token KW_BY");
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_KW_SKEWED = new RewriteRuleTokenStream(adaptor, "token KW_SKEWED");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleTokenStream stream_KW_ON = new RewriteRuleTokenStream(adaptor, "token KW_ON");
    RewriteRuleSubtreeStream stream_skewedValueElement =
        new RewriteRuleSubtreeStream(adaptor, "rule skewedValueElement");
    RewriteRuleSubtreeStream stream_columnNameList = new RewriteRuleSubtreeStream(adaptor, "rule columnNameList");
    RewriteRuleSubtreeStream stream_storedAsDirs = new RewriteRuleSubtreeStream(adaptor, "rule storedAsDirs");
    pushMsg("table skewed specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1737:5: ( KW_SKEWED KW_BY LPAREN skewedCols= columnNameList RPAREN KW_ON LPAREN (skewedValues= skewedValueElement ) RPAREN ( storedAsDirs )? -> ^( TOK_TABLESKEWED $skewedCols $skewedValues ( storedAsDirs )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1738:6: KW_SKEWED KW_BY LPAREN skewedCols= columnNameList RPAREN KW_ON LPAREN (skewedValues= skewedValueElement ) RPAREN ( storedAsDirs )?
      {
        KW_SKEWED674 = (Token) match(input, KW_SKEWED, FOLLOW_KW_SKEWED_in_tableSkewed10176);
        stream_KW_SKEWED.add(KW_SKEWED674);

        KW_BY675 = (Token) match(input, KW_BY, FOLLOW_KW_BY_in_tableSkewed10178);
        stream_KW_BY.add(KW_BY675);

        LPAREN676 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_tableSkewed10180);
        stream_LPAREN.add(LPAREN676);

        pushFollow(FOLLOW_columnNameList_in_tableSkewed10184);
        skewedCols = columnNameList();

        state._fsp--;

        stream_columnNameList.add(skewedCols.getTree());

        RPAREN677 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_tableSkewed10186);
        stream_RPAREN.add(RPAREN677);

        KW_ON678 = (Token) match(input, KW_ON, FOLLOW_KW_ON_in_tableSkewed10188);
        stream_KW_ON.add(KW_ON678);

        LPAREN679 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_tableSkewed10190);
        stream_LPAREN.add(LPAREN679);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1738:75: (skewedValues= skewedValueElement )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1738:76: skewedValues= skewedValueElement
        {
          pushFollow(FOLLOW_skewedValueElement_in_tableSkewed10195);
          skewedValues = skewedValueElement();

          state._fsp--;

          stream_skewedValueElement.add(skewedValues.getTree());
        }

        RPAREN680 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_tableSkewed10198);
        stream_RPAREN.add(RPAREN680);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1738:116: ( storedAsDirs )?
        int alt197 = 2;
        switch (input.LA(1)) {
          case KW_STORED: {
            switch (input.LA(2)) {
              case KW_AS: {
                switch (input.LA(3)) {
                  case KW_DIRECTORIES: {
                    alt197 = 1;
                  }
                  break;
                }
              }
              break;
            }
          }
          break;
        }

        switch (alt197) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1738:117: storedAsDirs
          {
            pushFollow(FOLLOW_storedAsDirs_in_tableSkewed10201);
            storedAsDirs681 = storedAsDirs();

            state._fsp--;

            stream_storedAsDirs.add(storedAsDirs681.getTree());
          }
          break;
        }

        // AST REWRITE
        // elements: skewedValues, storedAsDirs, skewedCols
        // token labels:
        // rule labels: skewedCols, skewedValues, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_skewedCols =
            new RewriteRuleSubtreeStream(adaptor, "rule skewedCols", skewedCols != null ? skewedCols.tree : null);
        RewriteRuleSubtreeStream stream_skewedValues =
            new RewriteRuleSubtreeStream(adaptor, "rule skewedValues", skewedValues != null ? skewedValues.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1739:5: -> ^( TOK_TABLESKEWED $skewedCols $skewedValues ( storedAsDirs )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1739:8: ^( TOK_TABLESKEWED $skewedCols $skewedValues ( storedAsDirs )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABLESKEWED, "TOK_TABLESKEWED"),
                root_1);

            adaptor.addChild(root_1, stream_skewedCols.nextTree());

            adaptor.addChild(root_1, stream_skewedValues.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1739:52: ( storedAsDirs )?
            if (stream_storedAsDirs.hasNext()) {
              adaptor.addChild(root_1, stream_storedAsDirs.nextTree());
            }
            stream_storedAsDirs.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "tableSkewed"

  public static class rowFormat_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "rowFormat"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1742:1: rowFormat : ( rowFormatSerde -> ^( TOK_SERDE rowFormatSerde ) | rowFormatDelimited -> ^( TOK_SERDE rowFormatDelimited ) | -> ^( TOK_SERDE ) );
  public final HiveParser.rowFormat_return rowFormat() throws RecognitionException {
    HiveParser.rowFormat_return retval = new HiveParser.rowFormat_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.rowFormatSerde_return rowFormatSerde682 = null;

    HiveParser.rowFormatDelimited_return rowFormatDelimited683 = null;

    RewriteRuleSubtreeStream stream_rowFormatSerde = new RewriteRuleSubtreeStream(adaptor, "rule rowFormatSerde");
    RewriteRuleSubtreeStream stream_rowFormatDelimited =
        new RewriteRuleSubtreeStream(adaptor, "rule rowFormatDelimited");
    pushMsg("serde specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1745:5: ( rowFormatSerde -> ^( TOK_SERDE rowFormatSerde ) | rowFormatDelimited -> ^( TOK_SERDE rowFormatDelimited ) | -> ^( TOK_SERDE ) )
      int alt198 = 3;
      switch (input.LA(1)) {
        case KW_ROW: {
          switch (input.LA(2)) {
            case KW_FORMAT: {
              switch (input.LA(3)) {
                case KW_SERDE: {
                  alt198 = 1;
                }
                break;
                case KW_DELIMITED: {
                  alt198 = 2;
                }
                break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 198, 23, input);

                  throw nvae;
              }
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 198, 1, input);

              throw nvae;
          }
        }
        break;
        case EOF:
        case KW_CLUSTER:
        case KW_DISTRIBUTE:
        case KW_FROM:
        case KW_GROUP:
        case KW_HAVING:
        case KW_INSERT:
        case KW_LATERAL:
        case KW_LIMIT:
        case KW_MAP:
        case KW_ORDER:
        case KW_RECORDREADER:
        case KW_RECORDWRITER:
        case KW_REDUCE:
        case KW_SELECT:
        case KW_SORT:
        case KW_UNION:
        case KW_USING:
        case KW_WHERE:
        case KW_WINDOW:
        case RPAREN: {
          alt198 = 3;
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 198, 0, input);

          throw nvae;
      }

      switch (alt198) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1745:7: rowFormatSerde
        {
          pushFollow(FOLLOW_rowFormatSerde_in_rowFormat10249);
          rowFormatSerde682 = rowFormatSerde();

          state._fsp--;

          stream_rowFormatSerde.add(rowFormatSerde682.getTree());

          // AST REWRITE
          // elements: rowFormatSerde
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1745:22: -> ^( TOK_SERDE rowFormatSerde )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1745:25: ^( TOK_SERDE rowFormatSerde )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SERDE, "TOK_SERDE"), root_1);

              adaptor.addChild(root_1, stream_rowFormatSerde.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1746:7: rowFormatDelimited
        {
          pushFollow(FOLLOW_rowFormatDelimited_in_rowFormat10265);
          rowFormatDelimited683 = rowFormatDelimited();

          state._fsp--;

          stream_rowFormatDelimited.add(rowFormatDelimited683.getTree());

          // AST REWRITE
          // elements: rowFormatDelimited
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1746:26: -> ^( TOK_SERDE rowFormatDelimited )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1746:29: ^( TOK_SERDE rowFormatDelimited )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SERDE, "TOK_SERDE"), root_1);

              adaptor.addChild(root_1, stream_rowFormatDelimited.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 3:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1747:9:
        {
          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1747:9: -> ^( TOK_SERDE )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1747:12: ^( TOK_SERDE )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SERDE, "TOK_SERDE"), root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "rowFormat"

  public static class recordReader_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "recordReader"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1750:1: recordReader : ( KW_RECORDREADER StringLiteral -> ^( TOK_RECORDREADER StringLiteral ) | -> ^( TOK_RECORDREADER ) );
  public final HiveParser.recordReader_return recordReader() throws RecognitionException {
    HiveParser.recordReader_return retval = new HiveParser.recordReader_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_RECORDREADER684 = null;
    Token StringLiteral685 = null;

    CommonTree KW_RECORDREADER684_tree = null;
    CommonTree StringLiteral685_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_RECORDREADER = new RewriteRuleTokenStream(adaptor, "token KW_RECORDREADER");

    pushMsg("record reader specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1753:5: ( KW_RECORDREADER StringLiteral -> ^( TOK_RECORDREADER StringLiteral ) | -> ^( TOK_RECORDREADER ) )
      int alt199 = 2;
      switch (input.LA(1)) {
        case KW_RECORDREADER: {
          alt199 = 1;
        }
        break;
        case EOF:
        case KW_CLUSTER:
        case KW_DISTRIBUTE:
        case KW_FROM:
        case KW_GROUP:
        case KW_HAVING:
        case KW_INSERT:
        case KW_LATERAL:
        case KW_LIMIT:
        case KW_MAP:
        case KW_ORDER:
        case KW_REDUCE:
        case KW_SELECT:
        case KW_SORT:
        case KW_UNION:
        case KW_WHERE:
        case KW_WINDOW:
        case RPAREN: {
          alt199 = 2;
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 199, 0, input);

          throw nvae;
      }

      switch (alt199) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1753:7: KW_RECORDREADER StringLiteral
        {
          KW_RECORDREADER684 = (Token) match(input, KW_RECORDREADER, FOLLOW_KW_RECORDREADER_in_recordReader10314);
          stream_KW_RECORDREADER.add(KW_RECORDREADER684);

          StringLiteral685 = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_recordReader10316);
          stream_StringLiteral.add(StringLiteral685);

          // AST REWRITE
          // elements: StringLiteral
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1753:37: -> ^( TOK_RECORDREADER StringLiteral )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1753:40: ^( TOK_RECORDREADER StringLiteral )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_RECORDREADER, "TOK_RECORDREADER"),
                      root_1);

              adaptor.addChild(root_1, stream_StringLiteral.nextNode());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1754:9:
        {
          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1754:9: -> ^( TOK_RECORDREADER )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1754:12: ^( TOK_RECORDREADER )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_RECORDREADER, "TOK_RECORDREADER"),
                      root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "recordReader"

  public static class recordWriter_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "recordWriter"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1757:1: recordWriter : ( KW_RECORDWRITER StringLiteral -> ^( TOK_RECORDWRITER StringLiteral ) | -> ^( TOK_RECORDWRITER ) );
  public final HiveParser.recordWriter_return recordWriter() throws RecognitionException {
    HiveParser.recordWriter_return retval = new HiveParser.recordWriter_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_RECORDWRITER686 = null;
    Token StringLiteral687 = null;

    CommonTree KW_RECORDWRITER686_tree = null;
    CommonTree StringLiteral687_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_RECORDWRITER = new RewriteRuleTokenStream(adaptor, "token KW_RECORDWRITER");

    pushMsg("record writer specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1760:5: ( KW_RECORDWRITER StringLiteral -> ^( TOK_RECORDWRITER StringLiteral ) | -> ^( TOK_RECORDWRITER ) )
      int alt200 = 2;
      switch (input.LA(1)) {
        case KW_RECORDWRITER: {
          alt200 = 1;
        }
        break;
        case KW_USING: {
          alt200 = 2;
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 200, 0, input);

          throw nvae;
      }

      switch (alt200) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1760:7: KW_RECORDWRITER StringLiteral
        {
          KW_RECORDWRITER686 = (Token) match(input, KW_RECORDWRITER, FOLLOW_KW_RECORDWRITER_in_recordWriter10365);
          stream_KW_RECORDWRITER.add(KW_RECORDWRITER686);

          StringLiteral687 = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_recordWriter10367);
          stream_StringLiteral.add(StringLiteral687);

          // AST REWRITE
          // elements: StringLiteral
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1760:37: -> ^( TOK_RECORDWRITER StringLiteral )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1760:40: ^( TOK_RECORDWRITER StringLiteral )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_RECORDWRITER, "TOK_RECORDWRITER"),
                      root_1);

              adaptor.addChild(root_1, stream_StringLiteral.nextNode());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1761:9:
        {
          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1761:9: -> ^( TOK_RECORDWRITER )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1761:12: ^( TOK_RECORDWRITER )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_RECORDWRITER, "TOK_RECORDWRITER"),
                      root_1);

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "recordWriter"

  public static class rowFormatSerde_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "rowFormatSerde"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1764:1: rowFormatSerde : KW_ROW KW_FORMAT KW_SERDE name= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )? -> ^( TOK_SERDENAME $name ( $serdeprops)? ) ;
  public final HiveParser.rowFormatSerde_return rowFormatSerde() throws RecognitionException {
    HiveParser.rowFormatSerde_return retval = new HiveParser.rowFormatSerde_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token name = null;
    Token KW_ROW688 = null;
    Token KW_FORMAT689 = null;
    Token KW_SERDE690 = null;
    Token KW_WITH691 = null;
    Token KW_SERDEPROPERTIES692 = null;
    HiveParser.tableProperties_return serdeprops = null;

    CommonTree name_tree = null;
    CommonTree KW_ROW688_tree = null;
    CommonTree KW_FORMAT689_tree = null;
    CommonTree KW_SERDE690_tree = null;
    CommonTree KW_WITH691_tree = null;
    CommonTree KW_SERDEPROPERTIES692_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_WITH = new RewriteRuleTokenStream(adaptor, "token KW_WITH");
    RewriteRuleTokenStream stream_KW_ROW = new RewriteRuleTokenStream(adaptor, "token KW_ROW");
    RewriteRuleTokenStream stream_KW_SERDEPROPERTIES = new RewriteRuleTokenStream(adaptor, "token KW_SERDEPROPERTIES");
    RewriteRuleTokenStream stream_KW_SERDE = new RewriteRuleTokenStream(adaptor, "token KW_SERDE");
    RewriteRuleTokenStream stream_KW_FORMAT = new RewriteRuleTokenStream(adaptor, "token KW_FORMAT");
    RewriteRuleSubtreeStream stream_tableProperties = new RewriteRuleSubtreeStream(adaptor, "rule tableProperties");
    pushMsg("serde format specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1767:5: ( KW_ROW KW_FORMAT KW_SERDE name= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )? -> ^( TOK_SERDENAME $name ( $serdeprops)? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1767:7: KW_ROW KW_FORMAT KW_SERDE name= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )?
      {
        KW_ROW688 = (Token) match(input, KW_ROW, FOLLOW_KW_ROW_in_rowFormatSerde10416);
        stream_KW_ROW.add(KW_ROW688);

        KW_FORMAT689 = (Token) match(input, KW_FORMAT, FOLLOW_KW_FORMAT_in_rowFormatSerde10418);
        stream_KW_FORMAT.add(KW_FORMAT689);

        KW_SERDE690 = (Token) match(input, KW_SERDE, FOLLOW_KW_SERDE_in_rowFormatSerde10420);
        stream_KW_SERDE.add(KW_SERDE690);

        name = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_rowFormatSerde10424);
        stream_StringLiteral.add(name);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1767:52: ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )?
        int alt201 = 2;
        switch (input.LA(1)) {
          case KW_WITH: {
            alt201 = 1;
          }
          break;
        }

        switch (alt201) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1767:53: KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties
          {
            KW_WITH691 = (Token) match(input, KW_WITH, FOLLOW_KW_WITH_in_rowFormatSerde10427);
            stream_KW_WITH.add(KW_WITH691);

            KW_SERDEPROPERTIES692 =
                (Token) match(input, KW_SERDEPROPERTIES, FOLLOW_KW_SERDEPROPERTIES_in_rowFormatSerde10429);
            stream_KW_SERDEPROPERTIES.add(KW_SERDEPROPERTIES692);

            pushFollow(FOLLOW_tableProperties_in_rowFormatSerde10433);
            serdeprops = tableProperties();

            state._fsp--;

            stream_tableProperties.add(serdeprops.getTree());
          }
          break;
        }

        // AST REWRITE
        // elements: serdeprops, name
        // token labels: name
        // rule labels: serdeprops, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_name = new RewriteRuleTokenStream(adaptor, "token name", name);
        RewriteRuleSubtreeStream stream_serdeprops =
            new RewriteRuleSubtreeStream(adaptor, "rule serdeprops", serdeprops != null ? serdeprops.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1768:5: -> ^( TOK_SERDENAME $name ( $serdeprops)? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1768:8: ^( TOK_SERDENAME $name ( $serdeprops)? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SERDENAME, "TOK_SERDENAME"), root_1);

            adaptor.addChild(root_1, stream_name.nextNode());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1768:31: ( $serdeprops)?
            if (stream_serdeprops.hasNext()) {
              adaptor.addChild(root_1, stream_serdeprops.nextTree());
            }
            stream_serdeprops.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "rowFormatSerde"

  public static class rowFormatDelimited_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "rowFormatDelimited"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1771:1: rowFormatDelimited : KW_ROW KW_FORMAT KW_DELIMITED ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? -> ^( TOK_SERDEPROPS ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? ) ;
  public final HiveParser.rowFormatDelimited_return rowFormatDelimited() throws RecognitionException {
    HiveParser.rowFormatDelimited_return retval = new HiveParser.rowFormatDelimited_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_ROW693 = null;
    Token KW_FORMAT694 = null;
    Token KW_DELIMITED695 = null;
    HiveParser.tableRowFormatFieldIdentifier_return tableRowFormatFieldIdentifier696 = null;

    HiveParser.tableRowFormatCollItemsIdentifier_return tableRowFormatCollItemsIdentifier697 = null;

    HiveParser.tableRowFormatMapKeysIdentifier_return tableRowFormatMapKeysIdentifier698 = null;

    HiveParser.tableRowFormatLinesIdentifier_return tableRowFormatLinesIdentifier699 = null;

    HiveParser.tableRowNullFormat_return tableRowNullFormat700 = null;

    CommonTree KW_ROW693_tree = null;
    CommonTree KW_FORMAT694_tree = null;
    CommonTree KW_DELIMITED695_tree = null;
    RewriteRuleTokenStream stream_KW_ROW = new RewriteRuleTokenStream(adaptor, "token KW_ROW");
    RewriteRuleTokenStream stream_KW_DELIMITED = new RewriteRuleTokenStream(adaptor, "token KW_DELIMITED");
    RewriteRuleTokenStream stream_KW_FORMAT = new RewriteRuleTokenStream(adaptor, "token KW_FORMAT");
    RewriteRuleSubtreeStream stream_tableRowNullFormat =
        new RewriteRuleSubtreeStream(adaptor, "rule tableRowNullFormat");
    RewriteRuleSubtreeStream stream_tableRowFormatFieldIdentifier =
        new RewriteRuleSubtreeStream(adaptor, "rule tableRowFormatFieldIdentifier");
    RewriteRuleSubtreeStream stream_tableRowFormatCollItemsIdentifier =
        new RewriteRuleSubtreeStream(adaptor, "rule tableRowFormatCollItemsIdentifier");
    RewriteRuleSubtreeStream stream_tableRowFormatMapKeysIdentifier =
        new RewriteRuleSubtreeStream(adaptor, "rule tableRowFormatMapKeysIdentifier");
    RewriteRuleSubtreeStream stream_tableRowFormatLinesIdentifier =
        new RewriteRuleSubtreeStream(adaptor, "rule tableRowFormatLinesIdentifier");
    pushMsg("serde properties specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1774:5: ( KW_ROW KW_FORMAT KW_DELIMITED ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? -> ^( TOK_SERDEPROPS ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1775:7: KW_ROW KW_FORMAT KW_DELIMITED ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )?
      {
        KW_ROW693 = (Token) match(input, KW_ROW, FOLLOW_KW_ROW_in_rowFormatDelimited10485);
        stream_KW_ROW.add(KW_ROW693);

        KW_FORMAT694 = (Token) match(input, KW_FORMAT, FOLLOW_KW_FORMAT_in_rowFormatDelimited10487);
        stream_KW_FORMAT.add(KW_FORMAT694);

        KW_DELIMITED695 = (Token) match(input, KW_DELIMITED, FOLLOW_KW_DELIMITED_in_rowFormatDelimited10489);
        stream_KW_DELIMITED.add(KW_DELIMITED695);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1775:37: ( tableRowFormatFieldIdentifier )?
        int alt202 = 2;
        switch (input.LA(1)) {
          case KW_FIELDS: {
            alt202 = 1;
          }
          break;
        }

        switch (alt202) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1775:37: tableRowFormatFieldIdentifier
          {
            pushFollow(FOLLOW_tableRowFormatFieldIdentifier_in_rowFormatDelimited10491);
            tableRowFormatFieldIdentifier696 = tableRowFormatFieldIdentifier();

            state._fsp--;

            stream_tableRowFormatFieldIdentifier.add(tableRowFormatFieldIdentifier696.getTree());
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1775:68: ( tableRowFormatCollItemsIdentifier )?
        int alt203 = 2;
        switch (input.LA(1)) {
          case KW_COLLECTION: {
            alt203 = 1;
          }
          break;
        }

        switch (alt203) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1775:68: tableRowFormatCollItemsIdentifier
          {
            pushFollow(FOLLOW_tableRowFormatCollItemsIdentifier_in_rowFormatDelimited10494);
            tableRowFormatCollItemsIdentifier697 = tableRowFormatCollItemsIdentifier();

            state._fsp--;

            stream_tableRowFormatCollItemsIdentifier.add(tableRowFormatCollItemsIdentifier697.getTree());
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1775:103: ( tableRowFormatMapKeysIdentifier )?
        int alt204 = 2;
        alt204 = dfa204.predict(input);
        switch (alt204) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1775:103: tableRowFormatMapKeysIdentifier
          {
            pushFollow(FOLLOW_tableRowFormatMapKeysIdentifier_in_rowFormatDelimited10497);
            tableRowFormatMapKeysIdentifier698 = tableRowFormatMapKeysIdentifier();

            state._fsp--;

            stream_tableRowFormatMapKeysIdentifier.add(tableRowFormatMapKeysIdentifier698.getTree());
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1775:136: ( tableRowFormatLinesIdentifier )?
        int alt205 = 2;
        switch (input.LA(1)) {
          case KW_LINES: {
            alt205 = 1;
          }
          break;
        }

        switch (alt205) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1775:136: tableRowFormatLinesIdentifier
          {
            pushFollow(FOLLOW_tableRowFormatLinesIdentifier_in_rowFormatDelimited10500);
            tableRowFormatLinesIdentifier699 = tableRowFormatLinesIdentifier();

            state._fsp--;

            stream_tableRowFormatLinesIdentifier.add(tableRowFormatLinesIdentifier699.getTree());
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1775:167: ( tableRowNullFormat )?
        int alt206 = 2;
        switch (input.LA(1)) {
          case KW_NULL: {
            alt206 = 1;
          }
          break;
        }

        switch (alt206) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1775:167: tableRowNullFormat
          {
            pushFollow(FOLLOW_tableRowNullFormat_in_rowFormatDelimited10503);
            tableRowNullFormat700 = tableRowNullFormat();

            state._fsp--;

            stream_tableRowNullFormat.add(tableRowNullFormat700.getTree());
          }
          break;
        }

        // AST REWRITE
        // elements: tableRowFormatCollItemsIdentifier, tableRowFormatLinesIdentifier, tableRowNullFormat, tableRowFormatFieldIdentifier, tableRowFormatMapKeysIdentifier
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1776:5: -> ^( TOK_SERDEPROPS ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1776:8: ^( TOK_SERDEPROPS ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SERDEPROPS, "TOK_SERDEPROPS"), root_1);

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1776:25: ( tableRowFormatFieldIdentifier )?
            if (stream_tableRowFormatFieldIdentifier.hasNext()) {
              adaptor.addChild(root_1, stream_tableRowFormatFieldIdentifier.nextTree());
            }
            stream_tableRowFormatFieldIdentifier.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1776:56: ( tableRowFormatCollItemsIdentifier )?
            if (stream_tableRowFormatCollItemsIdentifier.hasNext()) {
              adaptor.addChild(root_1, stream_tableRowFormatCollItemsIdentifier.nextTree());
            }
            stream_tableRowFormatCollItemsIdentifier.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1776:91: ( tableRowFormatMapKeysIdentifier )?
            if (stream_tableRowFormatMapKeysIdentifier.hasNext()) {
              adaptor.addChild(root_1, stream_tableRowFormatMapKeysIdentifier.nextTree());
            }
            stream_tableRowFormatMapKeysIdentifier.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1776:124: ( tableRowFormatLinesIdentifier )?
            if (stream_tableRowFormatLinesIdentifier.hasNext()) {
              adaptor.addChild(root_1, stream_tableRowFormatLinesIdentifier.nextTree());
            }
            stream_tableRowFormatLinesIdentifier.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1776:155: ( tableRowNullFormat )?
            if (stream_tableRowNullFormat.hasNext()) {
              adaptor.addChild(root_1, stream_tableRowNullFormat.nextTree());
            }
            stream_tableRowNullFormat.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "rowFormatDelimited"

  public static class tableRowFormat_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "tableRowFormat"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1779:1: tableRowFormat : ( rowFormatDelimited -> ^( TOK_TABLEROWFORMAT rowFormatDelimited ) | rowFormatSerde -> ^( TOK_TABLESERIALIZER rowFormatSerde ) );
  public final HiveParser.tableRowFormat_return tableRowFormat() throws RecognitionException {
    HiveParser.tableRowFormat_return retval = new HiveParser.tableRowFormat_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.rowFormatDelimited_return rowFormatDelimited701 = null;

    HiveParser.rowFormatSerde_return rowFormatSerde702 = null;

    RewriteRuleSubtreeStream stream_rowFormatSerde = new RewriteRuleSubtreeStream(adaptor, "rule rowFormatSerde");
    RewriteRuleSubtreeStream stream_rowFormatDelimited =
        new RewriteRuleSubtreeStream(adaptor, "rule rowFormatDelimited");
    pushMsg("table row format specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1782:5: ( rowFormatDelimited -> ^( TOK_TABLEROWFORMAT rowFormatDelimited ) | rowFormatSerde -> ^( TOK_TABLESERIALIZER rowFormatSerde ) )
      int alt207 = 2;
      switch (input.LA(1)) {
        case KW_ROW: {
          switch (input.LA(2)) {
            case KW_FORMAT: {
              switch (input.LA(3)) {
                case KW_DELIMITED: {
                  alt207 = 1;
                }
                break;
                case KW_SERDE: {
                  alt207 = 2;
                }
                break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 207, 2, input);

                  throw nvae;
              }
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 207, 1, input);

              throw nvae;
          }
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 207, 0, input);

          throw nvae;
      }

      switch (alt207) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1783:7: rowFormatDelimited
        {
          pushFollow(FOLLOW_rowFormatDelimited_in_tableRowFormat10562);
          rowFormatDelimited701 = rowFormatDelimited();

          state._fsp--;

          stream_rowFormatDelimited.add(rowFormatDelimited701.getTree());

          // AST REWRITE
          // elements: rowFormatDelimited
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1784:5: -> ^( TOK_TABLEROWFORMAT rowFormatDelimited )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1784:8: ^( TOK_TABLEROWFORMAT rowFormatDelimited )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABLEROWFORMAT, "TOK_TABLEROWFORMAT"),
                      root_1);

              adaptor.addChild(root_1, stream_rowFormatDelimited.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1785:7: rowFormatSerde
        {
          pushFollow(FOLLOW_rowFormatSerde_in_tableRowFormat10582);
          rowFormatSerde702 = rowFormatSerde();

          state._fsp--;

          stream_rowFormatSerde.add(rowFormatSerde702.getTree());

          // AST REWRITE
          // elements: rowFormatSerde
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1786:5: -> ^( TOK_TABLESERIALIZER rowFormatSerde )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1786:8: ^( TOK_TABLESERIALIZER rowFormatSerde )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_TABLESERIALIZER, "TOK_TABLESERIALIZER"), root_1);

              adaptor.addChild(root_1, stream_rowFormatSerde.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "tableRowFormat"

  public static class tablePropertiesPrefixed_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "tablePropertiesPrefixed"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1789:1: tablePropertiesPrefixed : KW_TBLPROPERTIES ! tableProperties ;
  public final HiveParser.tablePropertiesPrefixed_return tablePropertiesPrefixed() throws RecognitionException {
    HiveParser.tablePropertiesPrefixed_return retval = new HiveParser.tablePropertiesPrefixed_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_TBLPROPERTIES703 = null;
    HiveParser.tableProperties_return tableProperties704 = null;

    CommonTree KW_TBLPROPERTIES703_tree = null;

    pushMsg("table properties with prefix", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1792:5: ( KW_TBLPROPERTIES ! tableProperties )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1793:9: KW_TBLPROPERTIES ! tableProperties
      {
        root_0 = (CommonTree) adaptor.nil();

        KW_TBLPROPERTIES703 =
            (Token) match(input, KW_TBLPROPERTIES, FOLLOW_KW_TBLPROPERTIES_in_tablePropertiesPrefixed10629);

        pushFollow(FOLLOW_tableProperties_in_tablePropertiesPrefixed10632);
        tableProperties704 = tableProperties();

        state._fsp--;

        adaptor.addChild(root_0, tableProperties704.getTree());
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "tablePropertiesPrefixed"

  public static class tableProperties_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "tableProperties"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1796:1: tableProperties : LPAREN tablePropertiesList RPAREN -> ^( TOK_TABLEPROPERTIES tablePropertiesList ) ;
  public final HiveParser.tableProperties_return tableProperties() throws RecognitionException {
    HiveParser.tableProperties_return retval = new HiveParser.tableProperties_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token LPAREN705 = null;
    Token RPAREN707 = null;
    HiveParser.tablePropertiesList_return tablePropertiesList706 = null;

    CommonTree LPAREN705_tree = null;
    CommonTree RPAREN707_tree = null;
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleSubtreeStream stream_tablePropertiesList =
        new RewriteRuleSubtreeStream(adaptor, "rule tablePropertiesList");
    pushMsg("table properties", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1799:5: ( LPAREN tablePropertiesList RPAREN -> ^( TOK_TABLEPROPERTIES tablePropertiesList ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1800:7: LPAREN tablePropertiesList RPAREN
      {
        LPAREN705 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_tableProperties10665);
        stream_LPAREN.add(LPAREN705);

        pushFollow(FOLLOW_tablePropertiesList_in_tableProperties10667);
        tablePropertiesList706 = tablePropertiesList();

        state._fsp--;

        stream_tablePropertiesList.add(tablePropertiesList706.getTree());

        RPAREN707 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_tableProperties10669);
        stream_RPAREN.add(RPAREN707);

        // AST REWRITE
        // elements: tablePropertiesList
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1800:41: -> ^( TOK_TABLEPROPERTIES tablePropertiesList )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1800:44: ^( TOK_TABLEPROPERTIES tablePropertiesList )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABLEPROPERTIES, "TOK_TABLEPROPERTIES"),
                    root_1);

            adaptor.addChild(root_1, stream_tablePropertiesList.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "tableProperties"

  public static class tablePropertiesList_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "tablePropertiesList"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1803:1: tablePropertiesList : ( keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_TABLEPROPLIST ( keyValueProperty )+ ) | keyProperty ( COMMA keyProperty )* -> ^( TOK_TABLEPROPLIST ( keyProperty )+ ) );
  public final HiveParser.tablePropertiesList_return tablePropertiesList() throws RecognitionException {
    HiveParser.tablePropertiesList_return retval = new HiveParser.tablePropertiesList_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token COMMA709 = null;
    Token COMMA712 = null;
    HiveParser.keyValueProperty_return keyValueProperty708 = null;

    HiveParser.keyValueProperty_return keyValueProperty710 = null;

    HiveParser.keyProperty_return keyProperty711 = null;

    HiveParser.keyProperty_return keyProperty713 = null;

    CommonTree COMMA709_tree = null;
    CommonTree COMMA712_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleSubtreeStream stream_keyValueProperty = new RewriteRuleSubtreeStream(adaptor, "rule keyValueProperty");
    RewriteRuleSubtreeStream stream_keyProperty = new RewriteRuleSubtreeStream(adaptor, "rule keyProperty");
    pushMsg("table properties list", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1806:5: ( keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_TABLEPROPLIST ( keyValueProperty )+ ) | keyProperty ( COMMA keyProperty )* -> ^( TOK_TABLEPROPLIST ( keyProperty )+ ) )
      int alt210 = 2;
      switch (input.LA(1)) {
        case StringLiteral: {
          switch (input.LA(2)) {
            case EQUAL: {
              alt210 = 1;
            }
            break;
            case COMMA:
            case RPAREN: {
              alt210 = 2;
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 210, 1, input);

              throw nvae;
          }
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 210, 0, input);

          throw nvae;
      }

      switch (alt210) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1807:7: keyValueProperty ( COMMA keyValueProperty )*
        {
          pushFollow(FOLLOW_keyValueProperty_in_tablePropertiesList10710);
          keyValueProperty708 = keyValueProperty();

          state._fsp--;

          stream_keyValueProperty.add(keyValueProperty708.getTree());

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1807:24: ( COMMA keyValueProperty )*
          loop208:
          do {
            int alt208 = 2;
            switch (input.LA(1)) {
              case COMMA: {
                alt208 = 1;
              }
              break;
            }

            switch (alt208) {
              case 1:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1807:25: COMMA keyValueProperty
              {
                COMMA709 = (Token) match(input, COMMA, FOLLOW_COMMA_in_tablePropertiesList10713);
                stream_COMMA.add(COMMA709);

                pushFollow(FOLLOW_keyValueProperty_in_tablePropertiesList10715);
                keyValueProperty710 = keyValueProperty();

                state._fsp--;

                stream_keyValueProperty.add(keyValueProperty710.getTree());
              }
              break;

              default:
                break loop208;
            }
          } while (true);

          // AST REWRITE
          // elements: keyValueProperty
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1807:50: -> ^( TOK_TABLEPROPLIST ( keyValueProperty )+ )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1807:53: ^( TOK_TABLEPROPLIST ( keyValueProperty )+ )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABLEPROPLIST, "TOK_TABLEPROPLIST"),
                      root_1);

              if (!(stream_keyValueProperty.hasNext())) {
                throw new RewriteEarlyExitException();
              }
              while (stream_keyValueProperty.hasNext()) {
                adaptor.addChild(root_1, stream_keyValueProperty.nextTree());
              }
              stream_keyValueProperty.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1809:7: keyProperty ( COMMA keyProperty )*
        {
          pushFollow(FOLLOW_keyProperty_in_tablePropertiesList10740);
          keyProperty711 = keyProperty();

          state._fsp--;

          stream_keyProperty.add(keyProperty711.getTree());

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1809:19: ( COMMA keyProperty )*
          loop209:
          do {
            int alt209 = 2;
            switch (input.LA(1)) {
              case COMMA: {
                alt209 = 1;
              }
              break;
            }

            switch (alt209) {
              case 1:
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:1809:20: COMMA keyProperty
              {
                COMMA712 = (Token) match(input, COMMA, FOLLOW_COMMA_in_tablePropertiesList10743);
                stream_COMMA.add(COMMA712);

                pushFollow(FOLLOW_keyProperty_in_tablePropertiesList10745);
                keyProperty713 = keyProperty();

                state._fsp--;

                stream_keyProperty.add(keyProperty713.getTree());
              }
              break;

              default:
                break loop209;
            }
          } while (true);

          // AST REWRITE
          // elements: keyProperty
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1809:40: -> ^( TOK_TABLEPROPLIST ( keyProperty )+ )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1809:43: ^( TOK_TABLEPROPLIST ( keyProperty )+ )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABLEPROPLIST, "TOK_TABLEPROPLIST"),
                      root_1);

              if (!(stream_keyProperty.hasNext())) {
                throw new RewriteEarlyExitException();
              }
              while (stream_keyProperty.hasNext()) {
                adaptor.addChild(root_1, stream_keyProperty.nextTree());
              }
              stream_keyProperty.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "tablePropertiesList"

  public static class keyValueProperty_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "keyValueProperty"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1812:1: keyValueProperty : key= StringLiteral EQUAL value= StringLiteral -> ^( TOK_TABLEPROPERTY $key $value) ;
  public final HiveParser.keyValueProperty_return keyValueProperty() throws RecognitionException {
    HiveParser.keyValueProperty_return retval = new HiveParser.keyValueProperty_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token key = null;
    Token value = null;
    Token EQUAL714 = null;

    CommonTree key_tree = null;
    CommonTree value_tree = null;
    CommonTree EQUAL714_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_EQUAL = new RewriteRuleTokenStream(adaptor, "token EQUAL");

    pushMsg("specifying key/value property", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1815:5: (key= StringLiteral EQUAL value= StringLiteral -> ^( TOK_TABLEPROPERTY $key $value) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1816:7: key= StringLiteral EQUAL value= StringLiteral
      {
        key = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_keyValueProperty10791);
        stream_StringLiteral.add(key);

        EQUAL714 = (Token) match(input, EQUAL, FOLLOW_EQUAL_in_keyValueProperty10793);
        stream_EQUAL.add(EQUAL714);

        value = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_keyValueProperty10797);
        stream_StringLiteral.add(value);

        // AST REWRITE
        // elements: value, key
        // token labels: value, key
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_value = new RewriteRuleTokenStream(adaptor, "token value", value);
        RewriteRuleTokenStream stream_key = new RewriteRuleTokenStream(adaptor, "token key", key);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1816:51: -> ^( TOK_TABLEPROPERTY $key $value)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1816:54: ^( TOK_TABLEPROPERTY $key $value)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABLEPROPERTY, "TOK_TABLEPROPERTY"),
                    root_1);

            adaptor.addChild(root_1, stream_key.nextNode());

            adaptor.addChild(root_1, stream_value.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "keyValueProperty"

  public static class keyProperty_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "keyProperty"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1819:1: keyProperty : key= StringLiteral -> ^( TOK_TABLEPROPERTY $key TOK_NULL ) ;
  public final HiveParser.keyProperty_return keyProperty() throws RecognitionException {
    HiveParser.keyProperty_return retval = new HiveParser.keyProperty_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token key = null;

    CommonTree key_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");

    pushMsg("specifying key property", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1822:5: (key= StringLiteral -> ^( TOK_TABLEPROPERTY $key TOK_NULL ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1823:7: key= StringLiteral
      {
        key = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_keyProperty10844);
        stream_StringLiteral.add(key);

        // AST REWRITE
        // elements: key
        // token labels: key
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_key = new RewriteRuleTokenStream(adaptor, "token key", key);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1823:25: -> ^( TOK_TABLEPROPERTY $key TOK_NULL )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1823:28: ^( TOK_TABLEPROPERTY $key TOK_NULL )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABLEPROPERTY, "TOK_TABLEPROPERTY"),
                    root_1);

            adaptor.addChild(root_1, stream_key.nextNode());

            adaptor.addChild(root_1, (CommonTree) adaptor.create(TOK_NULL, "TOK_NULL"));

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "keyProperty"

  public static class tableRowFormatFieldIdentifier_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "tableRowFormatFieldIdentifier"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1826:1: tableRowFormatFieldIdentifier : KW_FIELDS KW_TERMINATED KW_BY fldIdnt= StringLiteral ( KW_ESCAPED KW_BY fldEscape= StringLiteral )? -> ^( TOK_TABLEROWFORMATFIELD $fldIdnt ( $fldEscape)? ) ;
  public final HiveParser.tableRowFormatFieldIdentifier_return tableRowFormatFieldIdentifier()
      throws RecognitionException {
    HiveParser.tableRowFormatFieldIdentifier_return retval = new HiveParser.tableRowFormatFieldIdentifier_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token fldIdnt = null;
    Token fldEscape = null;
    Token KW_FIELDS715 = null;
    Token KW_TERMINATED716 = null;
    Token KW_BY717 = null;
    Token KW_ESCAPED718 = null;
    Token KW_BY719 = null;

    CommonTree fldIdnt_tree = null;
    CommonTree fldEscape_tree = null;
    CommonTree KW_FIELDS715_tree = null;
    CommonTree KW_TERMINATED716_tree = null;
    CommonTree KW_BY717_tree = null;
    CommonTree KW_ESCAPED718_tree = null;
    CommonTree KW_BY719_tree = null;
    RewriteRuleTokenStream stream_KW_TERMINATED = new RewriteRuleTokenStream(adaptor, "token KW_TERMINATED");
    RewriteRuleTokenStream stream_KW_BY = new RewriteRuleTokenStream(adaptor, "token KW_BY");
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_ESCAPED = new RewriteRuleTokenStream(adaptor, "token KW_ESCAPED");
    RewriteRuleTokenStream stream_KW_FIELDS = new RewriteRuleTokenStream(adaptor, "token KW_FIELDS");

    pushMsg("table row format's field separator", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1829:5: ( KW_FIELDS KW_TERMINATED KW_BY fldIdnt= StringLiteral ( KW_ESCAPED KW_BY fldEscape= StringLiteral )? -> ^( TOK_TABLEROWFORMATFIELD $fldIdnt ( $fldEscape)? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1830:7: KW_FIELDS KW_TERMINATED KW_BY fldIdnt= StringLiteral ( KW_ESCAPED KW_BY fldEscape= StringLiteral )?
      {
        KW_FIELDS715 = (Token) match(input, KW_FIELDS, FOLLOW_KW_FIELDS_in_tableRowFormatFieldIdentifier10888);
        stream_KW_FIELDS.add(KW_FIELDS715);

        KW_TERMINATED716 =
            (Token) match(input, KW_TERMINATED, FOLLOW_KW_TERMINATED_in_tableRowFormatFieldIdentifier10890);
        stream_KW_TERMINATED.add(KW_TERMINATED716);

        KW_BY717 = (Token) match(input, KW_BY, FOLLOW_KW_BY_in_tableRowFormatFieldIdentifier10892);
        stream_KW_BY.add(KW_BY717);

        fldIdnt = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_tableRowFormatFieldIdentifier10896);
        stream_StringLiteral.add(fldIdnt);

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1830:59: ( KW_ESCAPED KW_BY fldEscape= StringLiteral )?
        int alt211 = 2;
        switch (input.LA(1)) {
          case KW_ESCAPED: {
            alt211 = 1;
          }
          break;
        }

        switch (alt211) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1830:60: KW_ESCAPED KW_BY fldEscape= StringLiteral
          {
            KW_ESCAPED718 = (Token) match(input, KW_ESCAPED, FOLLOW_KW_ESCAPED_in_tableRowFormatFieldIdentifier10899);
            stream_KW_ESCAPED.add(KW_ESCAPED718);

            KW_BY719 = (Token) match(input, KW_BY, FOLLOW_KW_BY_in_tableRowFormatFieldIdentifier10901);
            stream_KW_BY.add(KW_BY719);

            fldEscape = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_tableRowFormatFieldIdentifier10905);
            stream_StringLiteral.add(fldEscape);
          }
          break;
        }

        // AST REWRITE
        // elements: fldEscape, fldIdnt
        // token labels: fldIdnt, fldEscape
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_fldIdnt = new RewriteRuleTokenStream(adaptor, "token fldIdnt", fldIdnt);
        RewriteRuleTokenStream stream_fldEscape = new RewriteRuleTokenStream(adaptor, "token fldEscape", fldEscape);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1831:5: -> ^( TOK_TABLEROWFORMATFIELD $fldIdnt ( $fldEscape)? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1831:8: ^( TOK_TABLEROWFORMATFIELD $fldIdnt ( $fldEscape)? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_TABLEROWFORMATFIELD, "TOK_TABLEROWFORMATFIELD"), root_1);

            adaptor.addChild(root_1, stream_fldIdnt.nextNode());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1831:44: ( $fldEscape)?
            if (stream_fldEscape.hasNext()) {
              adaptor.addChild(root_1, stream_fldEscape.nextNode());
            }
            stream_fldEscape.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "tableRowFormatFieldIdentifier"

  public static class tableRowFormatCollItemsIdentifier_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "tableRowFormatCollItemsIdentifier"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1834:1: tableRowFormatCollItemsIdentifier : KW_COLLECTION KW_ITEMS KW_TERMINATED KW_BY collIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATCOLLITEMS $collIdnt) ;
  public final HiveParser.tableRowFormatCollItemsIdentifier_return tableRowFormatCollItemsIdentifier()
      throws RecognitionException {
    HiveParser.tableRowFormatCollItemsIdentifier_return retval =
        new HiveParser.tableRowFormatCollItemsIdentifier_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token collIdnt = null;
    Token KW_COLLECTION720 = null;
    Token KW_ITEMS721 = null;
    Token KW_TERMINATED722 = null;
    Token KW_BY723 = null;

    CommonTree collIdnt_tree = null;
    CommonTree KW_COLLECTION720_tree = null;
    CommonTree KW_ITEMS721_tree = null;
    CommonTree KW_TERMINATED722_tree = null;
    CommonTree KW_BY723_tree = null;
    RewriteRuleTokenStream stream_KW_COLLECTION = new RewriteRuleTokenStream(adaptor, "token KW_COLLECTION");
    RewriteRuleTokenStream stream_KW_TERMINATED = new RewriteRuleTokenStream(adaptor, "token KW_TERMINATED");
    RewriteRuleTokenStream stream_KW_ITEMS = new RewriteRuleTokenStream(adaptor, "token KW_ITEMS");
    RewriteRuleTokenStream stream_KW_BY = new RewriteRuleTokenStream(adaptor, "token KW_BY");
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");

    pushMsg("table row format's column separator", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1837:5: ( KW_COLLECTION KW_ITEMS KW_TERMINATED KW_BY collIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATCOLLITEMS $collIdnt) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1838:7: KW_COLLECTION KW_ITEMS KW_TERMINATED KW_BY collIdnt= StringLiteral
      {
        KW_COLLECTION720 =
            (Token) match(input, KW_COLLECTION, FOLLOW_KW_COLLECTION_in_tableRowFormatCollItemsIdentifier10957);
        stream_KW_COLLECTION.add(KW_COLLECTION720);

        KW_ITEMS721 = (Token) match(input, KW_ITEMS, FOLLOW_KW_ITEMS_in_tableRowFormatCollItemsIdentifier10959);
        stream_KW_ITEMS.add(KW_ITEMS721);

        KW_TERMINATED722 =
            (Token) match(input, KW_TERMINATED, FOLLOW_KW_TERMINATED_in_tableRowFormatCollItemsIdentifier10961);
        stream_KW_TERMINATED.add(KW_TERMINATED722);

        KW_BY723 = (Token) match(input, KW_BY, FOLLOW_KW_BY_in_tableRowFormatCollItemsIdentifier10963);
        stream_KW_BY.add(KW_BY723);

        collIdnt = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_tableRowFormatCollItemsIdentifier10967);
        stream_StringLiteral.add(collIdnt);

        // AST REWRITE
        // elements: collIdnt
        // token labels: collIdnt
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_collIdnt = new RewriteRuleTokenStream(adaptor, "token collIdnt", collIdnt);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1839:5: -> ^( TOK_TABLEROWFORMATCOLLITEMS $collIdnt)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1839:8: ^( TOK_TABLEROWFORMATCOLLITEMS $collIdnt)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_TABLEROWFORMATCOLLITEMS, "TOK_TABLEROWFORMATCOLLITEMS"), root_1);

            adaptor.addChild(root_1, stream_collIdnt.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "tableRowFormatCollItemsIdentifier"

  public static class tableRowFormatMapKeysIdentifier_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "tableRowFormatMapKeysIdentifier"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1842:1: tableRowFormatMapKeysIdentifier : KW_MAP KW_KEYS KW_TERMINATED KW_BY mapKeysIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATMAPKEYS $mapKeysIdnt) ;
  public final HiveParser.tableRowFormatMapKeysIdentifier_return tableRowFormatMapKeysIdentifier()
      throws RecognitionException {
    HiveParser.tableRowFormatMapKeysIdentifier_return retval = new HiveParser.tableRowFormatMapKeysIdentifier_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token mapKeysIdnt = null;
    Token KW_MAP724 = null;
    Token KW_KEYS725 = null;
    Token KW_TERMINATED726 = null;
    Token KW_BY727 = null;

    CommonTree mapKeysIdnt_tree = null;
    CommonTree KW_MAP724_tree = null;
    CommonTree KW_KEYS725_tree = null;
    CommonTree KW_TERMINATED726_tree = null;
    CommonTree KW_BY727_tree = null;
    RewriteRuleTokenStream stream_KW_KEYS = new RewriteRuleTokenStream(adaptor, "token KW_KEYS");
    RewriteRuleTokenStream stream_KW_TERMINATED = new RewriteRuleTokenStream(adaptor, "token KW_TERMINATED");
    RewriteRuleTokenStream stream_KW_BY = new RewriteRuleTokenStream(adaptor, "token KW_BY");
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_MAP = new RewriteRuleTokenStream(adaptor, "token KW_MAP");

    pushMsg("table row format's map key separator", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1845:5: ( KW_MAP KW_KEYS KW_TERMINATED KW_BY mapKeysIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATMAPKEYS $mapKeysIdnt) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1846:7: KW_MAP KW_KEYS KW_TERMINATED KW_BY mapKeysIdnt= StringLiteral
      {
        KW_MAP724 = (Token) match(input, KW_MAP, FOLLOW_KW_MAP_in_tableRowFormatMapKeysIdentifier11013);
        stream_KW_MAP.add(KW_MAP724);

        KW_KEYS725 = (Token) match(input, KW_KEYS, FOLLOW_KW_KEYS_in_tableRowFormatMapKeysIdentifier11015);
        stream_KW_KEYS.add(KW_KEYS725);

        KW_TERMINATED726 =
            (Token) match(input, KW_TERMINATED, FOLLOW_KW_TERMINATED_in_tableRowFormatMapKeysIdentifier11017);
        stream_KW_TERMINATED.add(KW_TERMINATED726);

        KW_BY727 = (Token) match(input, KW_BY, FOLLOW_KW_BY_in_tableRowFormatMapKeysIdentifier11019);
        stream_KW_BY.add(KW_BY727);

        mapKeysIdnt = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_tableRowFormatMapKeysIdentifier11023);
        stream_StringLiteral.add(mapKeysIdnt);

        // AST REWRITE
        // elements: mapKeysIdnt
        // token labels: mapKeysIdnt
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_mapKeysIdnt =
            new RewriteRuleTokenStream(adaptor, "token mapKeysIdnt", mapKeysIdnt);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1847:5: -> ^( TOK_TABLEROWFORMATMAPKEYS $mapKeysIdnt)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1847:8: ^( TOK_TABLEROWFORMATMAPKEYS $mapKeysIdnt)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_TABLEROWFORMATMAPKEYS, "TOK_TABLEROWFORMATMAPKEYS"), root_1);

            adaptor.addChild(root_1, stream_mapKeysIdnt.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "tableRowFormatMapKeysIdentifier"

  public static class tableRowFormatLinesIdentifier_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "tableRowFormatLinesIdentifier"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1850:1: tableRowFormatLinesIdentifier : KW_LINES KW_TERMINATED KW_BY linesIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATLINES $linesIdnt) ;
  public final HiveParser.tableRowFormatLinesIdentifier_return tableRowFormatLinesIdentifier()
      throws RecognitionException {
    HiveParser.tableRowFormatLinesIdentifier_return retval = new HiveParser.tableRowFormatLinesIdentifier_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token linesIdnt = null;
    Token KW_LINES728 = null;
    Token KW_TERMINATED729 = null;
    Token KW_BY730 = null;

    CommonTree linesIdnt_tree = null;
    CommonTree KW_LINES728_tree = null;
    CommonTree KW_TERMINATED729_tree = null;
    CommonTree KW_BY730_tree = null;
    RewriteRuleTokenStream stream_KW_TERMINATED = new RewriteRuleTokenStream(adaptor, "token KW_TERMINATED");
    RewriteRuleTokenStream stream_KW_BY = new RewriteRuleTokenStream(adaptor, "token KW_BY");
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_LINES = new RewriteRuleTokenStream(adaptor, "token KW_LINES");

    pushMsg("table row format's line separator", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1853:5: ( KW_LINES KW_TERMINATED KW_BY linesIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATLINES $linesIdnt) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1854:7: KW_LINES KW_TERMINATED KW_BY linesIdnt= StringLiteral
      {
        KW_LINES728 = (Token) match(input, KW_LINES, FOLLOW_KW_LINES_in_tableRowFormatLinesIdentifier11069);
        stream_KW_LINES.add(KW_LINES728);

        KW_TERMINATED729 =
            (Token) match(input, KW_TERMINATED, FOLLOW_KW_TERMINATED_in_tableRowFormatLinesIdentifier11071);
        stream_KW_TERMINATED.add(KW_TERMINATED729);

        KW_BY730 = (Token) match(input, KW_BY, FOLLOW_KW_BY_in_tableRowFormatLinesIdentifier11073);
        stream_KW_BY.add(KW_BY730);

        linesIdnt = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_tableRowFormatLinesIdentifier11077);
        stream_StringLiteral.add(linesIdnt);

        // AST REWRITE
        // elements: linesIdnt
        // token labels: linesIdnt
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_linesIdnt = new RewriteRuleTokenStream(adaptor, "token linesIdnt", linesIdnt);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1855:5: -> ^( TOK_TABLEROWFORMATLINES $linesIdnt)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1855:8: ^( TOK_TABLEROWFORMATLINES $linesIdnt)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_TABLEROWFORMATLINES, "TOK_TABLEROWFORMATLINES"), root_1);

            adaptor.addChild(root_1, stream_linesIdnt.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "tableRowFormatLinesIdentifier"

  public static class tableRowNullFormat_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "tableRowNullFormat"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1858:1: tableRowNullFormat : KW_NULL KW_DEFINED KW_AS nullIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATNULL $nullIdnt) ;
  public final HiveParser.tableRowNullFormat_return tableRowNullFormat() throws RecognitionException {
    HiveParser.tableRowNullFormat_return retval = new HiveParser.tableRowNullFormat_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token nullIdnt = null;
    Token KW_NULL731 = null;
    Token KW_DEFINED732 = null;
    Token KW_AS733 = null;

    CommonTree nullIdnt_tree = null;
    CommonTree KW_NULL731_tree = null;
    CommonTree KW_DEFINED732_tree = null;
    CommonTree KW_AS733_tree = null;
    RewriteRuleTokenStream stream_KW_NULL = new RewriteRuleTokenStream(adaptor, "token KW_NULL");
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_AS = new RewriteRuleTokenStream(adaptor, "token KW_AS");
    RewriteRuleTokenStream stream_KW_DEFINED = new RewriteRuleTokenStream(adaptor, "token KW_DEFINED");

    pushMsg("table row format's null specifier", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1861:5: ( KW_NULL KW_DEFINED KW_AS nullIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATNULL $nullIdnt) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1862:7: KW_NULL KW_DEFINED KW_AS nullIdnt= StringLiteral
      {
        KW_NULL731 = (Token) match(input, KW_NULL, FOLLOW_KW_NULL_in_tableRowNullFormat11123);
        stream_KW_NULL.add(KW_NULL731);

        KW_DEFINED732 = (Token) match(input, KW_DEFINED, FOLLOW_KW_DEFINED_in_tableRowNullFormat11125);
        stream_KW_DEFINED.add(KW_DEFINED732);

        KW_AS733 = (Token) match(input, KW_AS, FOLLOW_KW_AS_in_tableRowNullFormat11127);
        stream_KW_AS.add(KW_AS733);

        nullIdnt = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_tableRowNullFormat11131);
        stream_StringLiteral.add(nullIdnt);

        // AST REWRITE
        // elements: nullIdnt
        // token labels: nullIdnt
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_nullIdnt = new RewriteRuleTokenStream(adaptor, "token nullIdnt", nullIdnt);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1863:5: -> ^( TOK_TABLEROWFORMATNULL $nullIdnt)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1863:8: ^( TOK_TABLEROWFORMATNULL $nullIdnt)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_TABLEROWFORMATNULL, "TOK_TABLEROWFORMATNULL"), root_1);

            adaptor.addChild(root_1, stream_nullIdnt.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "tableRowNullFormat"

  public static class tableFileFormat_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "tableFileFormat"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1865:1: tableFileFormat : ( KW_STORED KW_AS KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )? -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt ( $inDriver)? ( $outDriver)? ) | KW_STORED KW_BY storageHandler= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )? -> ^( TOK_STORAGEHANDLER $storageHandler ( $serdeprops)? ) | KW_STORED KW_AS genericSpec= identifier -> ^( TOK_FILEFORMAT_GENERIC $genericSpec) );
  public final HiveParser.tableFileFormat_return tableFileFormat() throws RecognitionException {
    HiveParser.tableFileFormat_return retval = new HiveParser.tableFileFormat_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token inFmt = null;
    Token outFmt = null;
    Token inDriver = null;
    Token outDriver = null;
    Token storageHandler = null;
    Token KW_STORED734 = null;
    Token KW_AS735 = null;
    Token KW_INPUTFORMAT736 = null;
    Token KW_OUTPUTFORMAT737 = null;
    Token KW_INPUTDRIVER738 = null;
    Token KW_OUTPUTDRIVER739 = null;
    Token KW_STORED740 = null;
    Token KW_BY741 = null;
    Token KW_WITH742 = null;
    Token KW_SERDEPROPERTIES743 = null;
    Token KW_STORED744 = null;
    Token KW_AS745 = null;
    HiveParser.tableProperties_return serdeprops = null;

    HiveParser_IdentifiersParser.identifier_return genericSpec = null;

    CommonTree inFmt_tree = null;
    CommonTree outFmt_tree = null;
    CommonTree inDriver_tree = null;
    CommonTree outDriver_tree = null;
    CommonTree storageHandler_tree = null;
    CommonTree KW_STORED734_tree = null;
    CommonTree KW_AS735_tree = null;
    CommonTree KW_INPUTFORMAT736_tree = null;
    CommonTree KW_OUTPUTFORMAT737_tree = null;
    CommonTree KW_INPUTDRIVER738_tree = null;
    CommonTree KW_OUTPUTDRIVER739_tree = null;
    CommonTree KW_STORED740_tree = null;
    CommonTree KW_BY741_tree = null;
    CommonTree KW_WITH742_tree = null;
    CommonTree KW_SERDEPROPERTIES743_tree = null;
    CommonTree KW_STORED744_tree = null;
    CommonTree KW_AS745_tree = null;
    RewriteRuleTokenStream stream_KW_BY = new RewriteRuleTokenStream(adaptor, "token KW_BY");
    RewriteRuleTokenStream stream_KW_INPUTFORMAT = new RewriteRuleTokenStream(adaptor, "token KW_INPUTFORMAT");
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_WITH = new RewriteRuleTokenStream(adaptor, "token KW_WITH");
    RewriteRuleTokenStream stream_KW_SERDEPROPERTIES = new RewriteRuleTokenStream(adaptor, "token KW_SERDEPROPERTIES");
    RewriteRuleTokenStream stream_KW_INPUTDRIVER = new RewriteRuleTokenStream(adaptor, "token KW_INPUTDRIVER");
    RewriteRuleTokenStream stream_KW_AS = new RewriteRuleTokenStream(adaptor, "token KW_AS");
    RewriteRuleTokenStream stream_KW_OUTPUTFORMAT = new RewriteRuleTokenStream(adaptor, "token KW_OUTPUTFORMAT");
    RewriteRuleTokenStream stream_KW_STORED = new RewriteRuleTokenStream(adaptor, "token KW_STORED");
    RewriteRuleTokenStream stream_KW_OUTPUTDRIVER = new RewriteRuleTokenStream(adaptor, "token KW_OUTPUTDRIVER");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_tableProperties = new RewriteRuleSubtreeStream(adaptor, "rule tableProperties");
    pushMsg("table file format specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1868:5: ( KW_STORED KW_AS KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )? -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt ( $inDriver)? ( $outDriver)? ) | KW_STORED KW_BY storageHandler= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )? -> ^( TOK_STORAGEHANDLER $storageHandler ( $serdeprops)? ) | KW_STORED KW_AS genericSpec= identifier -> ^( TOK_FILEFORMAT_GENERIC $genericSpec) )
      int alt214 = 3;
      switch (input.LA(1)) {
        case KW_STORED: {
          switch (input.LA(2)) {
            case KW_AS: {
              switch (input.LA(3)) {
                case KW_INPUTFORMAT: {
                  alt214 = 1;
                }
                break;
                case Identifier:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFAULT:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_METADATA:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NONE:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITION:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUES:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH: {
                  alt214 = 3;
                }
                break;
                default:
                  NoViableAltException nvae = new NoViableAltException("", 214, 2, input);

                  throw nvae;
              }
            }
            break;
            case KW_BY: {
              alt214 = 2;
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 214, 1, input);

              throw nvae;
          }
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 214, 0, input);

          throw nvae;
      }

      switch (alt214) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1869:7: KW_STORED KW_AS KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )?
        {
          KW_STORED734 = (Token) match(input, KW_STORED, FOLLOW_KW_STORED_in_tableFileFormat11176);
          stream_KW_STORED.add(KW_STORED734);

          KW_AS735 = (Token) match(input, KW_AS, FOLLOW_KW_AS_in_tableFileFormat11178);
          stream_KW_AS.add(KW_AS735);

          KW_INPUTFORMAT736 = (Token) match(input, KW_INPUTFORMAT, FOLLOW_KW_INPUTFORMAT_in_tableFileFormat11180);
          stream_KW_INPUTFORMAT.add(KW_INPUTFORMAT736);

          inFmt = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_tableFileFormat11184);
          stream_StringLiteral.add(inFmt);

          KW_OUTPUTFORMAT737 = (Token) match(input, KW_OUTPUTFORMAT, FOLLOW_KW_OUTPUTFORMAT_in_tableFileFormat11186);
          stream_KW_OUTPUTFORMAT.add(KW_OUTPUTFORMAT737);

          outFmt = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_tableFileFormat11190);
          stream_StringLiteral.add(outFmt);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1869:95: ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )?
          int alt212 = 2;
          switch (input.LA(1)) {
            case KW_INPUTDRIVER: {
              alt212 = 1;
            }
            break;
          }

          switch (alt212) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1869:96: KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral
            {
              KW_INPUTDRIVER738 = (Token) match(input, KW_INPUTDRIVER, FOLLOW_KW_INPUTDRIVER_in_tableFileFormat11193);
              stream_KW_INPUTDRIVER.add(KW_INPUTDRIVER738);

              inDriver = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_tableFileFormat11197);
              stream_StringLiteral.add(inDriver);

              KW_OUTPUTDRIVER739 =
                  (Token) match(input, KW_OUTPUTDRIVER, FOLLOW_KW_OUTPUTDRIVER_in_tableFileFormat11199);
              stream_KW_OUTPUTDRIVER.add(KW_OUTPUTDRIVER739);

              outDriver = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_tableFileFormat11203);
              stream_StringLiteral.add(outDriver);
            }
            break;
          }

          // AST REWRITE
          // elements: outFmt, inDriver, inFmt, outDriver
          // token labels: inFmt, inDriver, outDriver, outFmt
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleTokenStream stream_inFmt = new RewriteRuleTokenStream(adaptor, "token inFmt", inFmt);
          RewriteRuleTokenStream stream_inDriver = new RewriteRuleTokenStream(adaptor, "token inDriver", inDriver);
          RewriteRuleTokenStream stream_outDriver = new RewriteRuleTokenStream(adaptor, "token outDriver", outDriver);
          RewriteRuleTokenStream stream_outFmt = new RewriteRuleTokenStream(adaptor, "token outFmt", outFmt);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1870:7: -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt ( $inDriver)? ( $outDriver)? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1870:10: ^( TOK_TABLEFILEFORMAT $inFmt $outFmt ( $inDriver)? ( $outDriver)? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_TABLEFILEFORMAT, "TOK_TABLEFILEFORMAT"), root_1);

              adaptor.addChild(root_1, stream_inFmt.nextNode());

              adaptor.addChild(root_1, stream_outFmt.nextNode());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1870:48: ( $inDriver)?
              if (stream_inDriver.hasNext()) {
                adaptor.addChild(root_1, stream_inDriver.nextNode());
              }
              stream_inDriver.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1870:59: ( $outDriver)?
              if (stream_outDriver.hasNext()) {
                adaptor.addChild(root_1, stream_outDriver.nextNode());
              }
              stream_outDriver.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1871:9: KW_STORED KW_BY storageHandler= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )?
        {
          KW_STORED740 = (Token) match(input, KW_STORED, FOLLOW_KW_STORED_in_tableFileFormat11241);
          stream_KW_STORED.add(KW_STORED740);

          KW_BY741 = (Token) match(input, KW_BY, FOLLOW_KW_BY_in_tableFileFormat11243);
          stream_KW_BY.add(KW_BY741);

          storageHandler = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_tableFileFormat11247);
          stream_StringLiteral.add(storageHandler);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1872:10: ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )?
          int alt213 = 2;
          switch (input.LA(1)) {
            case KW_WITH: {
              alt213 = 1;
            }
            break;
          }

          switch (alt213) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1872:11: KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties
            {
              KW_WITH742 = (Token) match(input, KW_WITH, FOLLOW_KW_WITH_in_tableFileFormat11259);
              stream_KW_WITH.add(KW_WITH742);

              KW_SERDEPROPERTIES743 =
                  (Token) match(input, KW_SERDEPROPERTIES, FOLLOW_KW_SERDEPROPERTIES_in_tableFileFormat11261);
              stream_KW_SERDEPROPERTIES.add(KW_SERDEPROPERTIES743);

              pushFollow(FOLLOW_tableProperties_in_tableFileFormat11265);
              serdeprops = tableProperties();

              state._fsp--;

              stream_tableProperties.add(serdeprops.getTree());
            }
            break;
          }

          // AST REWRITE
          // elements: serdeprops, storageHandler
          // token labels: storageHandler
          // rule labels: serdeprops, retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleTokenStream stream_storageHandler =
              new RewriteRuleTokenStream(adaptor, "token storageHandler", storageHandler);
          RewriteRuleSubtreeStream stream_serdeprops =
              new RewriteRuleSubtreeStream(adaptor, "rule serdeprops", serdeprops != null ? serdeprops.tree : null);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1873:7: -> ^( TOK_STORAGEHANDLER $storageHandler ( $serdeprops)? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1873:10: ^( TOK_STORAGEHANDLER $storageHandler ( $serdeprops)? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 =
                  (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_STORAGEHANDLER, "TOK_STORAGEHANDLER"),
                      root_1);

              adaptor.addChild(root_1, stream_storageHandler.nextNode());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1873:48: ( $serdeprops)?
              if (stream_serdeprops.hasNext()) {
                adaptor.addChild(root_1, stream_serdeprops.nextTree());
              }
              stream_serdeprops.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 3:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1874:9: KW_STORED KW_AS genericSpec= identifier
        {
          KW_STORED744 = (Token) match(input, KW_STORED, FOLLOW_KW_STORED_in_tableFileFormat11296);
          stream_KW_STORED.add(KW_STORED744);

          KW_AS745 = (Token) match(input, KW_AS, FOLLOW_KW_AS_in_tableFileFormat11298);
          stream_KW_AS.add(KW_AS745);

          pushFollow(FOLLOW_identifier_in_tableFileFormat11302);
          genericSpec = identifier();

          state._fsp--;

          stream_identifier.add(genericSpec.getTree());

          // AST REWRITE
          // elements: genericSpec
          // token labels:
          // rule labels: genericSpec, retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_genericSpec =
              new RewriteRuleSubtreeStream(adaptor, "rule genericSpec", genericSpec != null ? genericSpec.tree : null);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 1875:7: -> ^( TOK_FILEFORMAT_GENERIC $genericSpec)
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1875:10: ^( TOK_FILEFORMAT_GENERIC $genericSpec)
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot(
                  (CommonTree) adaptor.create(TOK_FILEFORMAT_GENERIC, "TOK_FILEFORMAT_GENERIC"), root_1);

              adaptor.addChild(root_1, stream_genericSpec.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "tableFileFormat"

  public static class columnNameTypeList_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "columnNameTypeList"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1878:1: columnNameTypeList : columnNameType ( COMMA columnNameType )* -> ^( TOK_TABCOLLIST ( columnNameType )+ ) ;
  public final HiveParser.columnNameTypeList_return columnNameTypeList() throws RecognitionException {
    HiveParser.columnNameTypeList_return retval = new HiveParser.columnNameTypeList_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token COMMA747 = null;
    HiveParser.columnNameType_return columnNameType746 = null;

    HiveParser.columnNameType_return columnNameType748 = null;

    CommonTree COMMA747_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleSubtreeStream stream_columnNameType = new RewriteRuleSubtreeStream(adaptor, "rule columnNameType");
    pushMsg("column name type list", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1881:5: ( columnNameType ( COMMA columnNameType )* -> ^( TOK_TABCOLLIST ( columnNameType )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1881:7: columnNameType ( COMMA columnNameType )*
      {
        pushFollow(FOLLOW_columnNameType_in_columnNameTypeList11344);
        columnNameType746 = columnNameType();

        state._fsp--;

        stream_columnNameType.add(columnNameType746.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1881:22: ( COMMA columnNameType )*
        loop215:
        do {
          int alt215 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt215 = 1;
            }
            break;
          }

          switch (alt215) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1881:23: COMMA columnNameType
            {
              COMMA747 = (Token) match(input, COMMA, FOLLOW_COMMA_in_columnNameTypeList11347);
              stream_COMMA.add(COMMA747);

              pushFollow(FOLLOW_columnNameType_in_columnNameTypeList11349);
              columnNameType748 = columnNameType();

              state._fsp--;

              stream_columnNameType.add(columnNameType748.getTree());
            }
            break;

            default:
              break loop215;
          }
        } while (true);

        // AST REWRITE
        // elements: columnNameType
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1881:46: -> ^( TOK_TABCOLLIST ( columnNameType )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1881:49: ^( TOK_TABCOLLIST ( columnNameType )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABCOLLIST, "TOK_TABCOLLIST"), root_1);

            if (!(stream_columnNameType.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_columnNameType.hasNext()) {
              adaptor.addChild(root_1, stream_columnNameType.nextTree());
            }
            stream_columnNameType.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "columnNameTypeList"

  public static class columnNameColonTypeList_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "columnNameColonTypeList"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1884:1: columnNameColonTypeList : columnNameColonType ( COMMA columnNameColonType )* -> ^( TOK_TABCOLLIST ( columnNameColonType )+ ) ;
  public final HiveParser.columnNameColonTypeList_return columnNameColonTypeList() throws RecognitionException {
    HiveParser.columnNameColonTypeList_return retval = new HiveParser.columnNameColonTypeList_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token COMMA750 = null;
    HiveParser.columnNameColonType_return columnNameColonType749 = null;

    HiveParser.columnNameColonType_return columnNameColonType751 = null;

    CommonTree COMMA750_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleSubtreeStream stream_columnNameColonType =
        new RewriteRuleSubtreeStream(adaptor, "rule columnNameColonType");
    pushMsg("column name type list", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1887:5: ( columnNameColonType ( COMMA columnNameColonType )* -> ^( TOK_TABCOLLIST ( columnNameColonType )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1887:7: columnNameColonType ( COMMA columnNameColonType )*
      {
        pushFollow(FOLLOW_columnNameColonType_in_columnNameColonTypeList11387);
        columnNameColonType749 = columnNameColonType();

        state._fsp--;

        stream_columnNameColonType.add(columnNameColonType749.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1887:27: ( COMMA columnNameColonType )*
        loop216:
        do {
          int alt216 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt216 = 1;
            }
            break;
          }

          switch (alt216) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1887:28: COMMA columnNameColonType
            {
              COMMA750 = (Token) match(input, COMMA, FOLLOW_COMMA_in_columnNameColonTypeList11390);
              stream_COMMA.add(COMMA750);

              pushFollow(FOLLOW_columnNameColonType_in_columnNameColonTypeList11392);
              columnNameColonType751 = columnNameColonType();

              state._fsp--;

              stream_columnNameColonType.add(columnNameColonType751.getTree());
            }
            break;

            default:
              break loop216;
          }
        } while (true);

        // AST REWRITE
        // elements: columnNameColonType
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1887:56: -> ^( TOK_TABCOLLIST ( columnNameColonType )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1887:59: ^( TOK_TABCOLLIST ( columnNameColonType )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABCOLLIST, "TOK_TABCOLLIST"), root_1);

            if (!(stream_columnNameColonType.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_columnNameColonType.hasNext()) {
              adaptor.addChild(root_1, stream_columnNameColonType.nextTree());
            }
            stream_columnNameColonType.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "columnNameColonTypeList"

  public static class columnNameList_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "columnNameList"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1890:1: columnNameList : columnName ( COMMA columnName )* -> ^( TOK_TABCOLNAME ( columnName )+ ) ;
  public final HiveParser.columnNameList_return columnNameList() throws RecognitionException {
    HiveParser.columnNameList_return retval = new HiveParser.columnNameList_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token COMMA753 = null;
    HiveParser.columnName_return columnName752 = null;

    HiveParser.columnName_return columnName754 = null;

    CommonTree COMMA753_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleSubtreeStream stream_columnName = new RewriteRuleSubtreeStream(adaptor, "rule columnName");
    pushMsg("column name list", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1893:5: ( columnName ( COMMA columnName )* -> ^( TOK_TABCOLNAME ( columnName )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1893:7: columnName ( COMMA columnName )*
      {
        pushFollow(FOLLOW_columnName_in_columnNameList11430);
        columnName752 = columnName();

        state._fsp--;

        stream_columnName.add(columnName752.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1893:18: ( COMMA columnName )*
        loop217:
        do {
          int alt217 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt217 = 1;
            }
            break;
          }

          switch (alt217) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1893:19: COMMA columnName
            {
              COMMA753 = (Token) match(input, COMMA, FOLLOW_COMMA_in_columnNameList11433);
              stream_COMMA.add(COMMA753);

              pushFollow(FOLLOW_columnName_in_columnNameList11435);
              columnName754 = columnName();

              state._fsp--;

              stream_columnName.add(columnName754.getTree());
            }
            break;

            default:
              break loop217;
          }
        } while (true);

        // AST REWRITE
        // elements: columnName
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1893:38: -> ^( TOK_TABCOLNAME ( columnName )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1893:41: ^( TOK_TABCOLNAME ( columnName )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_1);

            if (!(stream_columnName.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_columnName.hasNext()) {
              adaptor.addChild(root_1, stream_columnName.nextTree());
            }
            stream_columnName.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "columnNameList"

  public static class columnName_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "columnName"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1896:1: columnName : identifier ;
  public final HiveParser.columnName_return columnName() throws RecognitionException {
    HiveParser.columnName_return retval = new HiveParser.columnName_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser_IdentifiersParser.identifier_return identifier755 = null;

    pushMsg("column name", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1899:5: ( identifier )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1900:7: identifier
      {
        root_0 = (CommonTree) adaptor.nil();

        pushFollow(FOLLOW_identifier_in_columnName11479);
        identifier755 = identifier();

        state._fsp--;

        adaptor.addChild(root_0, identifier755.getTree());
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "columnName"

  public static class columnNameOrderList_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "columnNameOrderList"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1903:1: columnNameOrderList : columnNameOrder ( COMMA columnNameOrder )* -> ^( TOK_TABCOLNAME ( columnNameOrder )+ ) ;
  public final HiveParser.columnNameOrderList_return columnNameOrderList() throws RecognitionException {
    HiveParser.columnNameOrderList_return retval = new HiveParser.columnNameOrderList_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token COMMA757 = null;
    HiveParser.columnNameOrder_return columnNameOrder756 = null;

    HiveParser.columnNameOrder_return columnNameOrder758 = null;

    CommonTree COMMA757_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleSubtreeStream stream_columnNameOrder = new RewriteRuleSubtreeStream(adaptor, "rule columnNameOrder");
    pushMsg("column name order list", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1906:5: ( columnNameOrder ( COMMA columnNameOrder )* -> ^( TOK_TABCOLNAME ( columnNameOrder )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1906:7: columnNameOrder ( COMMA columnNameOrder )*
      {
        pushFollow(FOLLOW_columnNameOrder_in_columnNameOrderList11506);
        columnNameOrder756 = columnNameOrder();

        state._fsp--;

        stream_columnNameOrder.add(columnNameOrder756.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1906:23: ( COMMA columnNameOrder )*
        loop218:
        do {
          int alt218 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt218 = 1;
            }
            break;
          }

          switch (alt218) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1906:24: COMMA columnNameOrder
            {
              COMMA757 = (Token) match(input, COMMA, FOLLOW_COMMA_in_columnNameOrderList11509);
              stream_COMMA.add(COMMA757);

              pushFollow(FOLLOW_columnNameOrder_in_columnNameOrderList11511);
              columnNameOrder758 = columnNameOrder();

              state._fsp--;

              stream_columnNameOrder.add(columnNameOrder758.getTree());
            }
            break;

            default:
              break loop218;
          }
        } while (true);

        // AST REWRITE
        // elements: columnNameOrder
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1906:48: -> ^( TOK_TABCOLNAME ( columnNameOrder )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1906:51: ^( TOK_TABCOLNAME ( columnNameOrder )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_1);

            if (!(stream_columnNameOrder.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_columnNameOrder.hasNext()) {
              adaptor.addChild(root_1, stream_columnNameOrder.nextTree());
            }
            stream_columnNameOrder.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "columnNameOrderList"

  public static class skewedValueElement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "skewedValueElement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1909:1: skewedValueElement : ( skewedColumnValues | skewedColumnValuePairList );
  public final HiveParser.skewedValueElement_return skewedValueElement() throws RecognitionException {
    HiveParser.skewedValueElement_return retval = new HiveParser.skewedValueElement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.skewedColumnValues_return skewedColumnValues759 = null;

    HiveParser.skewedColumnValuePairList_return skewedColumnValuePairList760 = null;

    pushMsg("skewed value element", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1912:5: ( skewedColumnValues | skewedColumnValuePairList )
      int alt219 = 2;
      switch (input.LA(1)) {
        case BigintLiteral:
        case CharSetName:
        case DecimalLiteral:
        case KW_DATE:
        case KW_FALSE:
        case KW_TIMESTAMP:
        case KW_TRUE:
        case Number:
        case SmallintLiteral:
        case StringLiteral:
        case TinyintLiteral: {
          alt219 = 1;
        }
        break;
        case LPAREN: {
          alt219 = 2;
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 219, 0, input);

          throw nvae;
      }

      switch (alt219) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1913:7: skewedColumnValues
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_skewedColumnValues_in_skewedValueElement11556);
          skewedColumnValues759 = skewedColumnValues();

          state._fsp--;

          adaptor.addChild(root_0, skewedColumnValues759.getTree());
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1914:8: skewedColumnValuePairList
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_skewedColumnValuePairList_in_skewedValueElement11565);
          skewedColumnValuePairList760 = skewedColumnValuePairList();

          state._fsp--;

          adaptor.addChild(root_0, skewedColumnValuePairList760.getTree());
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "skewedValueElement"

  public static class skewedColumnValuePairList_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "skewedColumnValuePairList"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1917:1: skewedColumnValuePairList : skewedColumnValuePair ( COMMA skewedColumnValuePair )* -> ^( TOK_TABCOLVALUE_PAIR ( skewedColumnValuePair )+ ) ;
  public final HiveParser.skewedColumnValuePairList_return skewedColumnValuePairList() throws RecognitionException {
    HiveParser.skewedColumnValuePairList_return retval = new HiveParser.skewedColumnValuePairList_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token COMMA762 = null;
    HiveParser.skewedColumnValuePair_return skewedColumnValuePair761 = null;

    HiveParser.skewedColumnValuePair_return skewedColumnValuePair763 = null;

    CommonTree COMMA762_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleSubtreeStream stream_skewedColumnValuePair =
        new RewriteRuleSubtreeStream(adaptor, "rule skewedColumnValuePair");
    pushMsg("column value pair list", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1920:5: ( skewedColumnValuePair ( COMMA skewedColumnValuePair )* -> ^( TOK_TABCOLVALUE_PAIR ( skewedColumnValuePair )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1920:7: skewedColumnValuePair ( COMMA skewedColumnValuePair )*
      {
        pushFollow(FOLLOW_skewedColumnValuePair_in_skewedColumnValuePairList11592);
        skewedColumnValuePair761 = skewedColumnValuePair();

        state._fsp--;

        stream_skewedColumnValuePair.add(skewedColumnValuePair761.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1920:29: ( COMMA skewedColumnValuePair )*
        loop220:
        do {
          int alt220 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt220 = 1;
            }
            break;
          }

          switch (alt220) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1920:30: COMMA skewedColumnValuePair
            {
              COMMA762 = (Token) match(input, COMMA, FOLLOW_COMMA_in_skewedColumnValuePairList11595);
              stream_COMMA.add(COMMA762);

              pushFollow(FOLLOW_skewedColumnValuePair_in_skewedColumnValuePairList11597);
              skewedColumnValuePair763 = skewedColumnValuePair();

              state._fsp--;

              stream_skewedColumnValuePair.add(skewedColumnValuePair763.getTree());
            }
            break;

            default:
              break loop220;
          }
        } while (true);

        // AST REWRITE
        // elements: skewedColumnValuePair
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1920:60: -> ^( TOK_TABCOLVALUE_PAIR ( skewedColumnValuePair )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1920:63: ^( TOK_TABCOLVALUE_PAIR ( skewedColumnValuePair )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_TABCOLVALUE_PAIR, "TOK_TABCOLVALUE_PAIR"), root_1);

            if (!(stream_skewedColumnValuePair.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_skewedColumnValuePair.hasNext()) {
              adaptor.addChild(root_1, stream_skewedColumnValuePair.nextTree());
            }
            stream_skewedColumnValuePair.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "skewedColumnValuePairList"

  public static class skewedColumnValuePair_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "skewedColumnValuePair"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1923:1: skewedColumnValuePair : LPAREN colValues= skewedColumnValues RPAREN -> ^( TOK_TABCOLVALUES $colValues) ;
  public final HiveParser.skewedColumnValuePair_return skewedColumnValuePair() throws RecognitionException {
    HiveParser.skewedColumnValuePair_return retval = new HiveParser.skewedColumnValuePair_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token LPAREN764 = null;
    Token RPAREN765 = null;
    HiveParser.skewedColumnValues_return colValues = null;

    CommonTree LPAREN764_tree = null;
    CommonTree RPAREN765_tree = null;
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleSubtreeStream stream_skewedColumnValues =
        new RewriteRuleSubtreeStream(adaptor, "rule skewedColumnValues");
    pushMsg("column value pair", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1926:5: ( LPAREN colValues= skewedColumnValues RPAREN -> ^( TOK_TABCOLVALUES $colValues) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1927:7: LPAREN colValues= skewedColumnValues RPAREN
      {
        LPAREN764 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_skewedColumnValuePair11642);
        stream_LPAREN.add(LPAREN764);

        pushFollow(FOLLOW_skewedColumnValues_in_skewedColumnValuePair11646);
        colValues = skewedColumnValues();

        state._fsp--;

        stream_skewedColumnValues.add(colValues.getTree());

        RPAREN765 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_skewedColumnValuePair11648);
        stream_RPAREN.add(RPAREN765);

        // AST REWRITE
        // elements: colValues
        // token labels:
        // rule labels: colValues, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_colValues =
            new RewriteRuleSubtreeStream(adaptor, "rule colValues", colValues != null ? colValues.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1928:7: -> ^( TOK_TABCOLVALUES $colValues)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1928:10: ^( TOK_TABCOLVALUES $colValues)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABCOLVALUES, "TOK_TABCOLVALUES"),
                root_1);

            adaptor.addChild(root_1, stream_colValues.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "skewedColumnValuePair"

  public static class skewedColumnValues_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "skewedColumnValues"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1931:1: skewedColumnValues : skewedColumnValue ( COMMA skewedColumnValue )* -> ^( TOK_TABCOLVALUE ( skewedColumnValue )+ ) ;
  public final HiveParser.skewedColumnValues_return skewedColumnValues() throws RecognitionException {
    HiveParser.skewedColumnValues_return retval = new HiveParser.skewedColumnValues_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token COMMA767 = null;
    HiveParser.skewedColumnValue_return skewedColumnValue766 = null;

    HiveParser.skewedColumnValue_return skewedColumnValue768 = null;

    CommonTree COMMA767_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleSubtreeStream stream_skewedColumnValue = new RewriteRuleSubtreeStream(adaptor, "rule skewedColumnValue");
    pushMsg("column values", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1934:5: ( skewedColumnValue ( COMMA skewedColumnValue )* -> ^( TOK_TABCOLVALUE ( skewedColumnValue )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1934:7: skewedColumnValue ( COMMA skewedColumnValue )*
      {
        pushFollow(FOLLOW_skewedColumnValue_in_skewedColumnValues11691);
        skewedColumnValue766 = skewedColumnValue();

        state._fsp--;

        stream_skewedColumnValue.add(skewedColumnValue766.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1934:25: ( COMMA skewedColumnValue )*
        loop221:
        do {
          int alt221 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt221 = 1;
            }
            break;
          }

          switch (alt221) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1934:26: COMMA skewedColumnValue
            {
              COMMA767 = (Token) match(input, COMMA, FOLLOW_COMMA_in_skewedColumnValues11694);
              stream_COMMA.add(COMMA767);

              pushFollow(FOLLOW_skewedColumnValue_in_skewedColumnValues11696);
              skewedColumnValue768 = skewedColumnValue();

              state._fsp--;

              stream_skewedColumnValue.add(skewedColumnValue768.getTree());
            }
            break;

            default:
              break loop221;
          }
        } while (true);

        // AST REWRITE
        // elements: skewedColumnValue
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1934:52: -> ^( TOK_TABCOLVALUE ( skewedColumnValue )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1934:55: ^( TOK_TABCOLVALUE ( skewedColumnValue )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABCOLVALUE, "TOK_TABCOLVALUE"),
                root_1);

            if (!(stream_skewedColumnValue.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_skewedColumnValue.hasNext()) {
              adaptor.addChild(root_1, stream_skewedColumnValue.nextTree());
            }
            stream_skewedColumnValue.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "skewedColumnValues"

  public static class skewedColumnValue_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "skewedColumnValue"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1937:1: skewedColumnValue : constant ;
  public final HiveParser.skewedColumnValue_return skewedColumnValue() throws RecognitionException {
    HiveParser.skewedColumnValue_return retval = new HiveParser.skewedColumnValue_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser_IdentifiersParser.constant_return constant769 = null;

    pushMsg("column value", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1940:5: ( constant )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1941:7: constant
      {
        root_0 = (CommonTree) adaptor.nil();

        pushFollow(FOLLOW_constant_in_skewedColumnValue11740);
        constant769 = constant();

        state._fsp--;

        adaptor.addChild(root_0, constant769.getTree());
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "skewedColumnValue"

  public static class skewedValueLocationElement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "skewedValueLocationElement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1944:1: skewedValueLocationElement : ( skewedColumnValue | skewedColumnValuePair );
  public final HiveParser.skewedValueLocationElement_return skewedValueLocationElement() throws RecognitionException {
    HiveParser.skewedValueLocationElement_return retval = new HiveParser.skewedValueLocationElement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.skewedColumnValue_return skewedColumnValue770 = null;

    HiveParser.skewedColumnValuePair_return skewedColumnValuePair771 = null;

    pushMsg("skewed value location element", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1947:5: ( skewedColumnValue | skewedColumnValuePair )
      int alt222 = 2;
      switch (input.LA(1)) {
        case BigintLiteral:
        case CharSetName:
        case DecimalLiteral:
        case KW_DATE:
        case KW_FALSE:
        case KW_TIMESTAMP:
        case KW_TRUE:
        case Number:
        case SmallintLiteral:
        case StringLiteral:
        case TinyintLiteral: {
          alt222 = 1;
        }
        break;
        case LPAREN: {
          alt222 = 2;
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 222, 0, input);

          throw nvae;
      }

      switch (alt222) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1948:7: skewedColumnValue
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_skewedColumnValue_in_skewedValueLocationElement11774);
          skewedColumnValue770 = skewedColumnValue();

          state._fsp--;

          adaptor.addChild(root_0, skewedColumnValue770.getTree());
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1949:8: skewedColumnValuePair
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_skewedColumnValuePair_in_skewedValueLocationElement11783);
          skewedColumnValuePair771 = skewedColumnValuePair();

          state._fsp--;

          adaptor.addChild(root_0, skewedColumnValuePair771.getTree());
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "skewedValueLocationElement"

  public static class columnNameOrder_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "columnNameOrder"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1952:1: columnNameOrder : identifier (asc= KW_ASC |desc= KW_DESC )? -> {$desc == null}? ^( TOK_TABSORTCOLNAMEASC identifier ) -> ^( TOK_TABSORTCOLNAMEDESC identifier ) ;
  public final HiveParser.columnNameOrder_return columnNameOrder() throws RecognitionException {
    HiveParser.columnNameOrder_return retval = new HiveParser.columnNameOrder_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token asc = null;
    Token desc = null;
    HiveParser_IdentifiersParser.identifier_return identifier772 = null;

    CommonTree asc_tree = null;
    CommonTree desc_tree = null;
    RewriteRuleTokenStream stream_KW_DESC = new RewriteRuleTokenStream(adaptor, "token KW_DESC");
    RewriteRuleTokenStream stream_KW_ASC = new RewriteRuleTokenStream(adaptor, "token KW_ASC");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    pushMsg("column name order", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1955:5: ( identifier (asc= KW_ASC |desc= KW_DESC )? -> {$desc == null}? ^( TOK_TABSORTCOLNAMEASC identifier ) -> ^( TOK_TABSORTCOLNAMEDESC identifier ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1955:7: identifier (asc= KW_ASC |desc= KW_DESC )?
      {
        pushFollow(FOLLOW_identifier_in_columnNameOrder11814);
        identifier772 = identifier();

        state._fsp--;

        stream_identifier.add(identifier772.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1955:18: (asc= KW_ASC |desc= KW_DESC )?
        int alt223 = 3;
        switch (input.LA(1)) {
          case KW_ASC: {
            alt223 = 1;
          }
          break;
          case KW_DESC: {
            alt223 = 2;
          }
          break;
        }

        switch (alt223) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1955:19: asc= KW_ASC
          {
            asc = (Token) match(input, KW_ASC, FOLLOW_KW_ASC_in_columnNameOrder11819);
            stream_KW_ASC.add(asc);
          }
          break;
          case 2:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1955:32: desc= KW_DESC
          {
            desc = (Token) match(input, KW_DESC, FOLLOW_KW_DESC_in_columnNameOrder11825);
            stream_KW_DESC.add(desc);
          }
          break;
        }

        // AST REWRITE
        // elements: identifier, identifier
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1956:5: -> {$desc == null}? ^( TOK_TABSORTCOLNAMEASC identifier )
        if (desc == null) {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1956:25: ^( TOK_TABSORTCOLNAMEASC identifier )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC"), root_1);

            adaptor.addChild(root_1, stream_identifier.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        } else // 1957:5: -> ^( TOK_TABSORTCOLNAMEDESC identifier )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1957:25: ^( TOK_TABSORTCOLNAMEDESC identifier )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_TABSORTCOLNAMEDESC, "TOK_TABSORTCOLNAMEDESC"), root_1);

            adaptor.addChild(root_1, stream_identifier.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "columnNameOrder"

  public static class columnNameCommentList_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "columnNameCommentList"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1960:1: columnNameCommentList : columnNameComment ( COMMA columnNameComment )* -> ^( TOK_TABCOLNAME ( columnNameComment )+ ) ;
  public final HiveParser.columnNameCommentList_return columnNameCommentList() throws RecognitionException {
    HiveParser.columnNameCommentList_return retval = new HiveParser.columnNameCommentList_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token COMMA774 = null;
    HiveParser.columnNameComment_return columnNameComment773 = null;

    HiveParser.columnNameComment_return columnNameComment775 = null;

    CommonTree COMMA774_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleSubtreeStream stream_columnNameComment = new RewriteRuleSubtreeStream(adaptor, "rule columnNameComment");
    pushMsg("column name comment list", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1963:5: ( columnNameComment ( COMMA columnNameComment )* -> ^( TOK_TABCOLNAME ( columnNameComment )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1963:7: columnNameComment ( COMMA columnNameComment )*
      {
        pushFollow(FOLLOW_columnNameComment_in_columnNameCommentList11897);
        columnNameComment773 = columnNameComment();

        state._fsp--;

        stream_columnNameComment.add(columnNameComment773.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1963:25: ( COMMA columnNameComment )*
        loop224:
        do {
          int alt224 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt224 = 1;
            }
            break;
          }

          switch (alt224) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:1963:26: COMMA columnNameComment
            {
              COMMA774 = (Token) match(input, COMMA, FOLLOW_COMMA_in_columnNameCommentList11900);
              stream_COMMA.add(COMMA774);

              pushFollow(FOLLOW_columnNameComment_in_columnNameCommentList11902);
              columnNameComment775 = columnNameComment();

              state._fsp--;

              stream_columnNameComment.add(columnNameComment775.getTree());
            }
            break;

            default:
              break loop224;
          }
        } while (true);

        // AST REWRITE
        // elements: columnNameComment
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1963:52: -> ^( TOK_TABCOLNAME ( columnNameComment )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1963:55: ^( TOK_TABCOLNAME ( columnNameComment )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_1);

            if (!(stream_columnNameComment.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_columnNameComment.hasNext()) {
              adaptor.addChild(root_1, stream_columnNameComment.nextTree());
            }
            stream_columnNameComment.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "columnNameCommentList"

  public static class columnNameComment_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "columnNameComment"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1966:1: columnNameComment : colName= identifier ( KW_COMMENT comment= StringLiteral )? -> ^( TOK_TABCOL $colName TOK_NULL ( $comment)? ) ;
  public final HiveParser.columnNameComment_return columnNameComment() throws RecognitionException {
    HiveParser.columnNameComment_return retval = new HiveParser.columnNameComment_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token comment = null;
    Token KW_COMMENT776 = null;
    HiveParser_IdentifiersParser.identifier_return colName = null;

    CommonTree comment_tree = null;
    CommonTree KW_COMMENT776_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_COMMENT = new RewriteRuleTokenStream(adaptor, "token KW_COMMENT");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    pushMsg("column name comment", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1969:5: (colName= identifier ( KW_COMMENT comment= StringLiteral )? -> ^( TOK_TABCOL $colName TOK_NULL ( $comment)? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1969:7: colName= identifier ( KW_COMMENT comment= StringLiteral )?
      {
        pushFollow(FOLLOW_identifier_in_columnNameComment11942);
        colName = identifier();

        state._fsp--;

        stream_identifier.add(colName.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1969:26: ( KW_COMMENT comment= StringLiteral )?
        int alt225 = 2;
        switch (input.LA(1)) {
          case KW_COMMENT: {
            alt225 = 1;
          }
          break;
        }

        switch (alt225) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1969:27: KW_COMMENT comment= StringLiteral
          {
            KW_COMMENT776 = (Token) match(input, KW_COMMENT, FOLLOW_KW_COMMENT_in_columnNameComment11945);
            stream_KW_COMMENT.add(KW_COMMENT776);

            comment = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_columnNameComment11949);
            stream_StringLiteral.add(comment);
          }
          break;
        }

        // AST REWRITE
        // elements: colName, comment
        // token labels: comment
        // rule labels: colName, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_comment = new RewriteRuleTokenStream(adaptor, "token comment", comment);
        RewriteRuleSubtreeStream stream_colName =
            new RewriteRuleSubtreeStream(adaptor, "rule colName", colName != null ? colName.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1970:5: -> ^( TOK_TABCOL $colName TOK_NULL ( $comment)? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1970:8: ^( TOK_TABCOL $colName TOK_NULL ( $comment)? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABCOL, "TOK_TABCOL"), root_1);

            adaptor.addChild(root_1, stream_colName.nextTree());

            adaptor.addChild(root_1, (CommonTree) adaptor.create(TOK_NULL, "TOK_NULL"));

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1970:40: ( $comment)?
            if (stream_comment.hasNext()) {
              adaptor.addChild(root_1, stream_comment.nextNode());
            }
            stream_comment.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "columnNameComment"

  public static class columnRefOrder_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "columnRefOrder"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1973:1: columnRefOrder : expression (asc= KW_ASC |desc= KW_DESC )? -> {$desc == null}? ^( TOK_TABSORTCOLNAMEASC expression ) -> ^( TOK_TABSORTCOLNAMEDESC expression ) ;
  public final HiveParser.columnRefOrder_return columnRefOrder() throws RecognitionException {
    HiveParser.columnRefOrder_return retval = new HiveParser.columnRefOrder_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token asc = null;
    Token desc = null;
    HiveParser_IdentifiersParser.expression_return expression777 = null;

    CommonTree asc_tree = null;
    CommonTree desc_tree = null;
    RewriteRuleTokenStream stream_KW_DESC = new RewriteRuleTokenStream(adaptor, "token KW_DESC");
    RewriteRuleTokenStream stream_KW_ASC = new RewriteRuleTokenStream(adaptor, "token KW_ASC");
    RewriteRuleSubtreeStream stream_expression = new RewriteRuleSubtreeStream(adaptor, "rule expression");
    pushMsg("column order", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1976:5: ( expression (asc= KW_ASC |desc= KW_DESC )? -> {$desc == null}? ^( TOK_TABSORTCOLNAMEASC expression ) -> ^( TOK_TABSORTCOLNAMEDESC expression ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1976:7: expression (asc= KW_ASC |desc= KW_DESC )?
      {
        pushFollow(FOLLOW_expression_in_columnRefOrder11997);
        expression777 = expression();

        state._fsp--;

        stream_expression.add(expression777.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1976:18: (asc= KW_ASC |desc= KW_DESC )?
        int alt226 = 3;
        switch (input.LA(1)) {
          case KW_ASC: {
            alt226 = 1;
          }
          break;
          case KW_DESC: {
            alt226 = 2;
          }
          break;
        }

        switch (alt226) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1976:19: asc= KW_ASC
          {
            asc = (Token) match(input, KW_ASC, FOLLOW_KW_ASC_in_columnRefOrder12002);
            stream_KW_ASC.add(asc);
          }
          break;
          case 2:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1976:32: desc= KW_DESC
          {
            desc = (Token) match(input, KW_DESC, FOLLOW_KW_DESC_in_columnRefOrder12008);
            stream_KW_DESC.add(desc);
          }
          break;
        }

        // AST REWRITE
        // elements: expression, expression
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1977:5: -> {$desc == null}? ^( TOK_TABSORTCOLNAMEASC expression )
        if (desc == null) {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1977:25: ^( TOK_TABSORTCOLNAMEASC expression )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC"), root_1);

            adaptor.addChild(root_1, stream_expression.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        } else // 1978:5: -> ^( TOK_TABSORTCOLNAMEDESC expression )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1978:25: ^( TOK_TABSORTCOLNAMEDESC expression )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_TABSORTCOLNAMEDESC, "TOK_TABSORTCOLNAMEDESC"), root_1);

            adaptor.addChild(root_1, stream_expression.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "columnRefOrder"

  public static class columnNameType_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "columnNameType"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1981:1: columnNameType : colName= identifier colType ( KW_COMMENT comment= StringLiteral )? -> {$comment == null}? ^( TOK_TABCOL $colName colType ) -> ^( TOK_TABCOL $colName colType $comment) ;
  public final HiveParser.columnNameType_return columnNameType() throws RecognitionException {
    HiveParser.columnNameType_return retval = new HiveParser.columnNameType_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token comment = null;
    Token KW_COMMENT779 = null;
    HiveParser_IdentifiersParser.identifier_return colName = null;

    HiveParser.colType_return colType778 = null;

    CommonTree comment_tree = null;
    CommonTree KW_COMMENT779_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_COMMENT = new RewriteRuleTokenStream(adaptor, "token KW_COMMENT");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_colType = new RewriteRuleSubtreeStream(adaptor, "rule colType");
    pushMsg("column specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1984:5: (colName= identifier colType ( KW_COMMENT comment= StringLiteral )? -> {$comment == null}? ^( TOK_TABCOL $colName colType ) -> ^( TOK_TABCOL $colName colType $comment) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1984:7: colName= identifier colType ( KW_COMMENT comment= StringLiteral )?
      {
        pushFollow(FOLLOW_identifier_in_columnNameType12082);
        colName = identifier();

        state._fsp--;

        stream_identifier.add(colName.getTree());

        pushFollow(FOLLOW_colType_in_columnNameType12084);
        colType778 = colType();

        state._fsp--;

        stream_colType.add(colType778.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1984:34: ( KW_COMMENT comment= StringLiteral )?
        int alt227 = 2;
        switch (input.LA(1)) {
          case KW_COMMENT: {
            alt227 = 1;
          }
          break;
        }

        switch (alt227) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1984:35: KW_COMMENT comment= StringLiteral
          {
            KW_COMMENT779 = (Token) match(input, KW_COMMENT, FOLLOW_KW_COMMENT_in_columnNameType12087);
            stream_KW_COMMENT.add(KW_COMMENT779);

            comment = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_columnNameType12091);
            stream_StringLiteral.add(comment);
          }
          break;
        }

        // AST REWRITE
        // elements: colType, comment, colName, colName, colType
        // token labels: comment
        // rule labels: colName, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_comment = new RewriteRuleTokenStream(adaptor, "token comment", comment);
        RewriteRuleSubtreeStream stream_colName =
            new RewriteRuleSubtreeStream(adaptor, "rule colName", colName != null ? colName.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1985:5: -> {$comment == null}? ^( TOK_TABCOL $colName colType )
        if (comment == null) {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1985:28: ^( TOK_TABCOL $colName colType )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABCOL, "TOK_TABCOL"), root_1);

            adaptor.addChild(root_1, stream_colName.nextTree());

            adaptor.addChild(root_1, stream_colType.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        } else // 1986:5: -> ^( TOK_TABCOL $colName colType $comment)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1986:28: ^( TOK_TABCOL $colName colType $comment)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABCOL, "TOK_TABCOL"), root_1);

            adaptor.addChild(root_1, stream_colName.nextTree());

            adaptor.addChild(root_1, stream_colType.nextTree());

            adaptor.addChild(root_1, stream_comment.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "columnNameType"

  public static class columnNameColonType_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "columnNameColonType"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1989:1: columnNameColonType : colName= identifier COLON colType ( KW_COMMENT comment= StringLiteral )? -> {$comment == null}? ^( TOK_TABCOL $colName colType ) -> ^( TOK_TABCOL $colName colType $comment) ;
  public final HiveParser.columnNameColonType_return columnNameColonType() throws RecognitionException {
    HiveParser.columnNameColonType_return retval = new HiveParser.columnNameColonType_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token comment = null;
    Token COLON780 = null;
    Token KW_COMMENT782 = null;
    HiveParser_IdentifiersParser.identifier_return colName = null;

    HiveParser.colType_return colType781 = null;

    CommonTree comment_tree = null;
    CommonTree COLON780_tree = null;
    CommonTree KW_COMMENT782_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_COLON = new RewriteRuleTokenStream(adaptor, "token COLON");
    RewriteRuleTokenStream stream_KW_COMMENT = new RewriteRuleTokenStream(adaptor, "token KW_COMMENT");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_colType = new RewriteRuleSubtreeStream(adaptor, "rule colType");
    pushMsg("column specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1992:5: (colName= identifier COLON colType ( KW_COMMENT comment= StringLiteral )? -> {$comment == null}? ^( TOK_TABCOL $colName colType ) -> ^( TOK_TABCOL $colName colType $comment) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:1992:7: colName= identifier COLON colType ( KW_COMMENT comment= StringLiteral )?
      {
        pushFollow(FOLLOW_identifier_in_columnNameColonType12177);
        colName = identifier();

        state._fsp--;

        stream_identifier.add(colName.getTree());

        COLON780 = (Token) match(input, COLON, FOLLOW_COLON_in_columnNameColonType12179);
        stream_COLON.add(COLON780);

        pushFollow(FOLLOW_colType_in_columnNameColonType12181);
        colType781 = colType();

        state._fsp--;

        stream_colType.add(colType781.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:1992:40: ( KW_COMMENT comment= StringLiteral )?
        int alt228 = 2;
        switch (input.LA(1)) {
          case KW_COMMENT: {
            alt228 = 1;
          }
          break;
        }

        switch (alt228) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:1992:41: KW_COMMENT comment= StringLiteral
          {
            KW_COMMENT782 = (Token) match(input, KW_COMMENT, FOLLOW_KW_COMMENT_in_columnNameColonType12184);
            stream_KW_COMMENT.add(KW_COMMENT782);

            comment = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_columnNameColonType12188);
            stream_StringLiteral.add(comment);
          }
          break;
        }

        // AST REWRITE
        // elements: colType, colName, comment, colName, colType
        // token labels: comment
        // rule labels: colName, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_comment = new RewriteRuleTokenStream(adaptor, "token comment", comment);
        RewriteRuleSubtreeStream stream_colName =
            new RewriteRuleSubtreeStream(adaptor, "rule colName", colName != null ? colName.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 1993:5: -> {$comment == null}? ^( TOK_TABCOL $colName colType )
        if (comment == null) {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1993:28: ^( TOK_TABCOL $colName colType )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABCOL, "TOK_TABCOL"), root_1);

            adaptor.addChild(root_1, stream_colName.nextTree());

            adaptor.addChild(root_1, stream_colType.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        } else // 1994:5: -> ^( TOK_TABCOL $colName colType $comment)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:1994:28: ^( TOK_TABCOL $colName colType $comment)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_TABCOL, "TOK_TABCOL"), root_1);

            adaptor.addChild(root_1, stream_colName.nextTree());

            adaptor.addChild(root_1, stream_colType.nextTree());

            adaptor.addChild(root_1, stream_comment.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "columnNameColonType"

  public static class colType_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "colType"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:1997:1: colType : type ;
  public final HiveParser.colType_return colType() throws RecognitionException {
    HiveParser.colType_return retval = new HiveParser.colType_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.type_return type783 = null;

    pushMsg("column type", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2000:5: ( type )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2000:7: type
      {
        root_0 = (CommonTree) adaptor.nil();

        pushFollow(FOLLOW_type_in_colType12272);
        type783 = type();

        state._fsp--;

        adaptor.addChild(root_0, type783.getTree());
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "colType"

  public static class colTypeList_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "colTypeList"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2003:1: colTypeList : colType ( COMMA colType )* -> ^( TOK_COLTYPELIST ( colType )+ ) ;
  public final HiveParser.colTypeList_return colTypeList() throws RecognitionException {
    HiveParser.colTypeList_return retval = new HiveParser.colTypeList_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token COMMA785 = null;
    HiveParser.colType_return colType784 = null;

    HiveParser.colType_return colType786 = null;

    CommonTree COMMA785_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleSubtreeStream stream_colType = new RewriteRuleSubtreeStream(adaptor, "rule colType");
    pushMsg("column type list", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2006:5: ( colType ( COMMA colType )* -> ^( TOK_COLTYPELIST ( colType )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2006:7: colType ( COMMA colType )*
      {
        pushFollow(FOLLOW_colType_in_colTypeList12299);
        colType784 = colType();

        state._fsp--;

        stream_colType.add(colType784.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2006:15: ( COMMA colType )*
        loop229:
        do {
          int alt229 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt229 = 1;
            }
            break;
          }

          switch (alt229) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2006:16: COMMA colType
            {
              COMMA785 = (Token) match(input, COMMA, FOLLOW_COMMA_in_colTypeList12302);
              stream_COMMA.add(COMMA785);

              pushFollow(FOLLOW_colType_in_colTypeList12304);
              colType786 = colType();

              state._fsp--;

              stream_colType.add(colType786.getTree());
            }
            break;

            default:
              break loop229;
          }
        } while (true);

        // AST REWRITE
        // elements: colType
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2006:32: -> ^( TOK_COLTYPELIST ( colType )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2006:35: ^( TOK_COLTYPELIST ( colType )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_COLTYPELIST, "TOK_COLTYPELIST"),
                root_1);

            if (!(stream_colType.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_colType.hasNext()) {
              adaptor.addChild(root_1, stream_colType.nextTree());
            }
            stream_colType.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "colTypeList"

  public static class type_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "type"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2009:1: type : ( primitiveType | listType | structType | mapType | unionType );
  public final HiveParser.type_return type() throws RecognitionException {
    HiveParser.type_return retval = new HiveParser.type_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.primitiveType_return primitiveType787 = null;

    HiveParser.listType_return listType788 = null;

    HiveParser.structType_return structType789 = null;

    HiveParser.mapType_return mapType790 = null;

    HiveParser.unionType_return unionType791 = null;

    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2010:5: ( primitiveType | listType | structType | mapType | unionType )
      int alt230 = 5;
      switch (input.LA(1)) {
        case KW_BIGINT:
        case KW_BINARY:
        case KW_BOOLEAN:
        case KW_CHAR:
        case KW_DATE:
        case KW_DATETIME:
        case KW_DECIMAL:
        case KW_DOUBLE:
        case KW_FLOAT:
        case KW_INT:
        case KW_SMALLINT:
        case KW_STRING:
        case KW_TIMESTAMP:
        case KW_TINYINT:
        case KW_VARCHAR: {
          alt230 = 1;
        }
        break;
        case KW_ARRAY: {
          alt230 = 2;
        }
        break;
        case KW_STRUCT: {
          alt230 = 3;
        }
        break;
        case KW_MAP: {
          alt230 = 4;
        }
        break;
        case KW_UNIONTYPE: {
          alt230 = 5;
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 230, 0, input);

          throw nvae;
      }

      switch (alt230) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2010:7: primitiveType
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_primitiveType_in_type12332);
          primitiveType787 = primitiveType();

          state._fsp--;

          adaptor.addChild(root_0, primitiveType787.getTree());
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2011:7: listType
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_listType_in_type12340);
          listType788 = listType();

          state._fsp--;

          adaptor.addChild(root_0, listType788.getTree());
        }
        break;
        case 3:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2012:7: structType
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_structType_in_type12348);
          structType789 = structType();

          state._fsp--;

          adaptor.addChild(root_0, structType789.getTree());
        }
        break;
        case 4:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2013:7: mapType
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_mapType_in_type12356);
          mapType790 = mapType();

          state._fsp--;

          adaptor.addChild(root_0, mapType790.getTree());
        }
        break;
        case 5:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2014:7: unionType
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_unionType_in_type12364);
          unionType791 = unionType();

          state._fsp--;

          adaptor.addChild(root_0, unionType791.getTree());
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "type"

  public static class primitiveType_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "primitiveType"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2016:1: primitiveType : ( KW_TINYINT -> TOK_TINYINT | KW_SMALLINT -> TOK_SMALLINT | KW_INT -> TOK_INT | KW_BIGINT -> TOK_BIGINT | KW_BOOLEAN -> TOK_BOOLEAN | KW_FLOAT -> TOK_FLOAT | KW_DOUBLE -> TOK_DOUBLE | KW_DATE -> TOK_DATE | KW_DATETIME -> TOK_DATETIME | KW_TIMESTAMP -> TOK_TIMESTAMP | KW_STRING -> TOK_STRING | KW_BINARY -> TOK_BINARY | KW_DECIMAL ( LPAREN prec= Number ( COMMA scale= Number )? RPAREN )? -> ^( TOK_DECIMAL ( $prec)? ( $scale)? ) | KW_VARCHAR LPAREN length= Number RPAREN -> ^( TOK_VARCHAR $length) | KW_CHAR LPAREN length= Number RPAREN -> ^( TOK_CHAR $length) );
  public final HiveParser.primitiveType_return primitiveType() throws RecognitionException {
    HiveParser.primitiveType_return retval = new HiveParser.primitiveType_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token prec = null;
    Token scale = null;
    Token length = null;
    Token KW_TINYINT792 = null;
    Token KW_SMALLINT793 = null;
    Token KW_INT794 = null;
    Token KW_BIGINT795 = null;
    Token KW_BOOLEAN796 = null;
    Token KW_FLOAT797 = null;
    Token KW_DOUBLE798 = null;
    Token KW_DATE799 = null;
    Token KW_DATETIME800 = null;
    Token KW_TIMESTAMP801 = null;
    Token KW_STRING802 = null;
    Token KW_BINARY803 = null;
    Token KW_DECIMAL804 = null;
    Token LPAREN805 = null;
    Token COMMA806 = null;
    Token RPAREN807 = null;
    Token KW_VARCHAR808 = null;
    Token LPAREN809 = null;
    Token RPAREN810 = null;
    Token KW_CHAR811 = null;
    Token LPAREN812 = null;
    Token RPAREN813 = null;

    CommonTree prec_tree = null;
    CommonTree scale_tree = null;
    CommonTree length_tree = null;
    CommonTree KW_TINYINT792_tree = null;
    CommonTree KW_SMALLINT793_tree = null;
    CommonTree KW_INT794_tree = null;
    CommonTree KW_BIGINT795_tree = null;
    CommonTree KW_BOOLEAN796_tree = null;
    CommonTree KW_FLOAT797_tree = null;
    CommonTree KW_DOUBLE798_tree = null;
    CommonTree KW_DATE799_tree = null;
    CommonTree KW_DATETIME800_tree = null;
    CommonTree KW_TIMESTAMP801_tree = null;
    CommonTree KW_STRING802_tree = null;
    CommonTree KW_BINARY803_tree = null;
    CommonTree KW_DECIMAL804_tree = null;
    CommonTree LPAREN805_tree = null;
    CommonTree COMMA806_tree = null;
    CommonTree RPAREN807_tree = null;
    CommonTree KW_VARCHAR808_tree = null;
    CommonTree LPAREN809_tree = null;
    CommonTree RPAREN810_tree = null;
    CommonTree KW_CHAR811_tree = null;
    CommonTree LPAREN812_tree = null;
    CommonTree RPAREN813_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleTokenStream stream_KW_SMALLINT = new RewriteRuleTokenStream(adaptor, "token KW_SMALLINT");
    RewriteRuleTokenStream stream_KW_DATE = new RewriteRuleTokenStream(adaptor, "token KW_DATE");
    RewriteRuleTokenStream stream_KW_DATETIME = new RewriteRuleTokenStream(adaptor, "token KW_DATETIME");
    RewriteRuleTokenStream stream_KW_TIMESTAMP = new RewriteRuleTokenStream(adaptor, "token KW_TIMESTAMP");
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_KW_BOOLEAN = new RewriteRuleTokenStream(adaptor, "token KW_BOOLEAN");
    RewriteRuleTokenStream stream_KW_DOUBLE = new RewriteRuleTokenStream(adaptor, "token KW_DOUBLE");
    RewriteRuleTokenStream stream_KW_BIGINT = new RewriteRuleTokenStream(adaptor, "token KW_BIGINT");
    RewriteRuleTokenStream stream_KW_CHAR = new RewriteRuleTokenStream(adaptor, "token KW_CHAR");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleTokenStream stream_KW_INT = new RewriteRuleTokenStream(adaptor, "token KW_INT");
    RewriteRuleTokenStream stream_KW_STRING = new RewriteRuleTokenStream(adaptor, "token KW_STRING");
    RewriteRuleTokenStream stream_KW_DECIMAL = new RewriteRuleTokenStream(adaptor, "token KW_DECIMAL");
    RewriteRuleTokenStream stream_KW_VARCHAR = new RewriteRuleTokenStream(adaptor, "token KW_VARCHAR");
    RewriteRuleTokenStream stream_Number = new RewriteRuleTokenStream(adaptor, "token Number");
    RewriteRuleTokenStream stream_KW_FLOAT = new RewriteRuleTokenStream(adaptor, "token KW_FLOAT");
    RewriteRuleTokenStream stream_KW_TINYINT = new RewriteRuleTokenStream(adaptor, "token KW_TINYINT");
    RewriteRuleTokenStream stream_KW_BINARY = new RewriteRuleTokenStream(adaptor, "token KW_BINARY");

    pushMsg("primitive type specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2019:5: ( KW_TINYINT -> TOK_TINYINT | KW_SMALLINT -> TOK_SMALLINT | KW_INT -> TOK_INT | KW_BIGINT -> TOK_BIGINT | KW_BOOLEAN -> TOK_BOOLEAN | KW_FLOAT -> TOK_FLOAT | KW_DOUBLE -> TOK_DOUBLE | KW_DATE -> TOK_DATE | KW_DATETIME -> TOK_DATETIME | KW_TIMESTAMP -> TOK_TIMESTAMP | KW_STRING -> TOK_STRING | KW_BINARY -> TOK_BINARY | KW_DECIMAL ( LPAREN prec= Number ( COMMA scale= Number )? RPAREN )? -> ^( TOK_DECIMAL ( $prec)? ( $scale)? ) | KW_VARCHAR LPAREN length= Number RPAREN -> ^( TOK_VARCHAR $length) | KW_CHAR LPAREN length= Number RPAREN -> ^( TOK_CHAR $length) )
      int alt233 = 15;
      switch (input.LA(1)) {
        case KW_TINYINT: {
          alt233 = 1;
        }
        break;
        case KW_SMALLINT: {
          alt233 = 2;
        }
        break;
        case KW_INT: {
          alt233 = 3;
        }
        break;
        case KW_BIGINT: {
          alt233 = 4;
        }
        break;
        case KW_BOOLEAN: {
          alt233 = 5;
        }
        break;
        case KW_FLOAT: {
          alt233 = 6;
        }
        break;
        case KW_DOUBLE: {
          alt233 = 7;
        }
        break;
        case KW_DATE: {
          alt233 = 8;
        }
        break;
        case KW_DATETIME: {
          alt233 = 9;
        }
        break;
        case KW_TIMESTAMP: {
          alt233 = 10;
        }
        break;
        case KW_STRING: {
          alt233 = 11;
        }
        break;
        case KW_BINARY: {
          alt233 = 12;
        }
        break;
        case KW_DECIMAL: {
          alt233 = 13;
        }
        break;
        case KW_VARCHAR: {
          alt233 = 14;
        }
        break;
        case KW_CHAR: {
          alt233 = 15;
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 233, 0, input);

          throw nvae;
      }

      switch (alt233) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2019:7: KW_TINYINT
        {
          KW_TINYINT792 = (Token) match(input, KW_TINYINT, FOLLOW_KW_TINYINT_in_primitiveType12386);
          stream_KW_TINYINT.add(KW_TINYINT792);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2019:24: -> TOK_TINYINT
          {
            adaptor.addChild(root_0, (CommonTree) adaptor.create(TOK_TINYINT, "TOK_TINYINT"));
          }

          retval.tree = root_0;
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2020:7: KW_SMALLINT
        {
          KW_SMALLINT793 = (Token) match(input, KW_SMALLINT, FOLLOW_KW_SMALLINT_in_primitiveType12407);
          stream_KW_SMALLINT.add(KW_SMALLINT793);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2020:24: -> TOK_SMALLINT
          {
            adaptor.addChild(root_0, (CommonTree) adaptor.create(TOK_SMALLINT, "TOK_SMALLINT"));
          }

          retval.tree = root_0;
        }
        break;
        case 3:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2021:7: KW_INT
        {
          KW_INT794 = (Token) match(input, KW_INT, FOLLOW_KW_INT_in_primitiveType12427);
          stream_KW_INT.add(KW_INT794);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2021:24: -> TOK_INT
          {
            adaptor.addChild(root_0, (CommonTree) adaptor.create(TOK_INT, "TOK_INT"));
          }

          retval.tree = root_0;
        }
        break;
        case 4:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2022:7: KW_BIGINT
        {
          KW_BIGINT795 = (Token) match(input, KW_BIGINT, FOLLOW_KW_BIGINT_in_primitiveType12452);
          stream_KW_BIGINT.add(KW_BIGINT795);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2022:24: -> TOK_BIGINT
          {
            adaptor.addChild(root_0, (CommonTree) adaptor.create(TOK_BIGINT, "TOK_BIGINT"));
          }

          retval.tree = root_0;
        }
        break;
        case 5:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2023:7: KW_BOOLEAN
        {
          KW_BOOLEAN796 = (Token) match(input, KW_BOOLEAN, FOLLOW_KW_BOOLEAN_in_primitiveType12474);
          stream_KW_BOOLEAN.add(KW_BOOLEAN796);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2023:24: -> TOK_BOOLEAN
          {
            adaptor.addChild(root_0, (CommonTree) adaptor.create(TOK_BOOLEAN, "TOK_BOOLEAN"));
          }

          retval.tree = root_0;
        }
        break;
        case 6:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2024:7: KW_FLOAT
        {
          KW_FLOAT797 = (Token) match(input, KW_FLOAT, FOLLOW_KW_FLOAT_in_primitiveType12495);
          stream_KW_FLOAT.add(KW_FLOAT797);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2024:24: -> TOK_FLOAT
          {
            adaptor.addChild(root_0, (CommonTree) adaptor.create(TOK_FLOAT, "TOK_FLOAT"));
          }

          retval.tree = root_0;
        }
        break;
        case 7:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2025:7: KW_DOUBLE
        {
          KW_DOUBLE798 = (Token) match(input, KW_DOUBLE, FOLLOW_KW_DOUBLE_in_primitiveType12518);
          stream_KW_DOUBLE.add(KW_DOUBLE798);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2025:24: -> TOK_DOUBLE
          {
            adaptor.addChild(root_0, (CommonTree) adaptor.create(TOK_DOUBLE, "TOK_DOUBLE"));
          }

          retval.tree = root_0;
        }
        break;
        case 8:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2026:7: KW_DATE
        {
          KW_DATE799 = (Token) match(input, KW_DATE, FOLLOW_KW_DATE_in_primitiveType12540);
          stream_KW_DATE.add(KW_DATE799);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2026:24: -> TOK_DATE
          {
            adaptor.addChild(root_0, (CommonTree) adaptor.create(TOK_DATE, "TOK_DATE"));
          }

          retval.tree = root_0;
        }
        break;
        case 9:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2027:7: KW_DATETIME
        {
          KW_DATETIME800 = (Token) match(input, KW_DATETIME, FOLLOW_KW_DATETIME_in_primitiveType12564);
          stream_KW_DATETIME.add(KW_DATETIME800);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2027:24: -> TOK_DATETIME
          {
            adaptor.addChild(root_0, (CommonTree) adaptor.create(TOK_DATETIME, "TOK_DATETIME"));
          }

          retval.tree = root_0;
        }
        break;
        case 10:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2028:7: KW_TIMESTAMP
        {
          KW_TIMESTAMP801 = (Token) match(input, KW_TIMESTAMP, FOLLOW_KW_TIMESTAMP_in_primitiveType12584);
          stream_KW_TIMESTAMP.add(KW_TIMESTAMP801);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2028:24: -> TOK_TIMESTAMP
          {
            adaptor.addChild(root_0, (CommonTree) adaptor.create(TOK_TIMESTAMP, "TOK_TIMESTAMP"));
          }

          retval.tree = root_0;
        }
        break;
        case 11:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2029:7: KW_STRING
        {
          KW_STRING802 = (Token) match(input, KW_STRING, FOLLOW_KW_STRING_in_primitiveType12603);
          stream_KW_STRING.add(KW_STRING802);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2029:24: -> TOK_STRING
          {
            adaptor.addChild(root_0, (CommonTree) adaptor.create(TOK_STRING, "TOK_STRING"));
          }

          retval.tree = root_0;
        }
        break;
        case 12:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2030:7: KW_BINARY
        {
          KW_BINARY803 = (Token) match(input, KW_BINARY, FOLLOW_KW_BINARY_in_primitiveType12625);
          stream_KW_BINARY.add(KW_BINARY803);

          // AST REWRITE
          // elements:
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2030:24: -> TOK_BINARY
          {
            adaptor.addChild(root_0, (CommonTree) adaptor.create(TOK_BINARY, "TOK_BINARY"));
          }

          retval.tree = root_0;
        }
        break;
        case 13:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2031:7: KW_DECIMAL ( LPAREN prec= Number ( COMMA scale= Number )? RPAREN )?
        {
          KW_DECIMAL804 = (Token) match(input, KW_DECIMAL, FOLLOW_KW_DECIMAL_in_primitiveType12647);
          stream_KW_DECIMAL.add(KW_DECIMAL804);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2031:18: ( LPAREN prec= Number ( COMMA scale= Number )? RPAREN )?
          int alt232 = 2;
          switch (input.LA(1)) {
            case LPAREN: {
              alt232 = 1;
            }
            break;
          }

          switch (alt232) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2031:19: LPAREN prec= Number ( COMMA scale= Number )? RPAREN
            {
              LPAREN805 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_primitiveType12650);
              stream_LPAREN.add(LPAREN805);

              prec = (Token) match(input, Number, FOLLOW_Number_in_primitiveType12654);
              stream_Number.add(prec);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2031:38: ( COMMA scale= Number )?
              int alt231 = 2;
              switch (input.LA(1)) {
                case COMMA: {
                  alt231 = 1;
                }
                break;
              }

              switch (alt231) {
                case 1:
                  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2031:39: COMMA scale= Number
                {
                  COMMA806 = (Token) match(input, COMMA, FOLLOW_COMMA_in_primitiveType12657);
                  stream_COMMA.add(COMMA806);

                  scale = (Token) match(input, Number, FOLLOW_Number_in_primitiveType12661);
                  stream_Number.add(scale);
                }
                break;
              }

              RPAREN807 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_primitiveType12665);
              stream_RPAREN.add(RPAREN807);
            }
            break;
          }

          // AST REWRITE
          // elements: prec, scale
          // token labels: prec, scale
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleTokenStream stream_prec = new RewriteRuleTokenStream(adaptor, "token prec", prec);
          RewriteRuleTokenStream stream_scale = new RewriteRuleTokenStream(adaptor, "token scale", scale);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2031:69: -> ^( TOK_DECIMAL ( $prec)? ( $scale)? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2031:72: ^( TOK_DECIMAL ( $prec)? ( $scale)? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DECIMAL, "TOK_DECIMAL"), root_1);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2031:87: ( $prec)?
              if (stream_prec.hasNext()) {
                adaptor.addChild(root_1, stream_prec.nextNode());
              }
              stream_prec.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2031:94: ( $scale)?
              if (stream_scale.hasNext()) {
                adaptor.addChild(root_1, stream_scale.nextNode());
              }
              stream_scale.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 14:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2032:7: KW_VARCHAR LPAREN length= Number RPAREN
        {
          KW_VARCHAR808 = (Token) match(input, KW_VARCHAR, FOLLOW_KW_VARCHAR_in_primitiveType12689);
          stream_KW_VARCHAR.add(KW_VARCHAR808);

          LPAREN809 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_primitiveType12691);
          stream_LPAREN.add(LPAREN809);

          length = (Token) match(input, Number, FOLLOW_Number_in_primitiveType12695);
          stream_Number.add(length);

          RPAREN810 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_primitiveType12697);
          stream_RPAREN.add(RPAREN810);

          // AST REWRITE
          // elements: length
          // token labels: length
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleTokenStream stream_length = new RewriteRuleTokenStream(adaptor, "token length", length);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2032:51: -> ^( TOK_VARCHAR $length)
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2032:57: ^( TOK_VARCHAR $length)
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_VARCHAR, "TOK_VARCHAR"), root_1);

              adaptor.addChild(root_1, stream_length.nextNode());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 15:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2033:7: KW_CHAR LPAREN length= Number RPAREN
        {
          KW_CHAR811 = (Token) match(input, KW_CHAR, FOLLOW_KW_CHAR_in_primitiveType12722);
          stream_KW_CHAR.add(KW_CHAR811);

          LPAREN812 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_primitiveType12724);
          stream_LPAREN.add(LPAREN812);

          length = (Token) match(input, Number, FOLLOW_Number_in_primitiveType12728);
          stream_Number.add(length);

          RPAREN813 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_primitiveType12730);
          stream_RPAREN.add(RPAREN813);

          // AST REWRITE
          // elements: length
          // token labels: length
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleTokenStream stream_length = new RewriteRuleTokenStream(adaptor, "token length", length);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2033:48: -> ^( TOK_CHAR $length)
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2033:54: ^( TOK_CHAR $length)
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_CHAR, "TOK_CHAR"), root_1);

              adaptor.addChild(root_1, stream_length.nextNode());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "primitiveType"

  public static class listType_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "listType"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2036:1: listType : KW_ARRAY LESSTHAN type GREATERTHAN -> ^( TOK_LIST type ) ;
  public final HiveParser.listType_return listType() throws RecognitionException {
    HiveParser.listType_return retval = new HiveParser.listType_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_ARRAY814 = null;
    Token LESSTHAN815 = null;
    Token GREATERTHAN817 = null;
    HiveParser.type_return type816 = null;

    CommonTree KW_ARRAY814_tree = null;
    CommonTree LESSTHAN815_tree = null;
    CommonTree GREATERTHAN817_tree = null;
    RewriteRuleTokenStream stream_LESSTHAN = new RewriteRuleTokenStream(adaptor, "token LESSTHAN");
    RewriteRuleTokenStream stream_KW_ARRAY = new RewriteRuleTokenStream(adaptor, "token KW_ARRAY");
    RewriteRuleTokenStream stream_GREATERTHAN = new RewriteRuleTokenStream(adaptor, "token GREATERTHAN");
    RewriteRuleSubtreeStream stream_type = new RewriteRuleSubtreeStream(adaptor, "rule type");
    pushMsg("list type", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2039:5: ( KW_ARRAY LESSTHAN type GREATERTHAN -> ^( TOK_LIST type ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2039:7: KW_ARRAY LESSTHAN type GREATERTHAN
      {
        KW_ARRAY814 = (Token) match(input, KW_ARRAY, FOLLOW_KW_ARRAY_in_listType12774);
        stream_KW_ARRAY.add(KW_ARRAY814);

        LESSTHAN815 = (Token) match(input, LESSTHAN, FOLLOW_LESSTHAN_in_listType12776);
        stream_LESSTHAN.add(LESSTHAN815);

        pushFollow(FOLLOW_type_in_listType12778);
        type816 = type();

        state._fsp--;

        stream_type.add(type816.getTree());

        GREATERTHAN817 = (Token) match(input, GREATERTHAN, FOLLOW_GREATERTHAN_in_listType12780);
        stream_GREATERTHAN.add(GREATERTHAN817);

        // AST REWRITE
        // elements: type
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2039:44: -> ^( TOK_LIST type )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2039:47: ^( TOK_LIST type )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_LIST, "TOK_LIST"), root_1);

            adaptor.addChild(root_1, stream_type.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "listType"

  public static class structType_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "structType"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2042:1: structType : KW_STRUCT LESSTHAN columnNameColonTypeList GREATERTHAN -> ^( TOK_STRUCT columnNameColonTypeList ) ;
  public final HiveParser.structType_return structType() throws RecognitionException {
    HiveParser.structType_return retval = new HiveParser.structType_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_STRUCT818 = null;
    Token LESSTHAN819 = null;
    Token GREATERTHAN821 = null;
    HiveParser.columnNameColonTypeList_return columnNameColonTypeList820 = null;

    CommonTree KW_STRUCT818_tree = null;
    CommonTree LESSTHAN819_tree = null;
    CommonTree GREATERTHAN821_tree = null;
    RewriteRuleTokenStream stream_KW_STRUCT = new RewriteRuleTokenStream(adaptor, "token KW_STRUCT");
    RewriteRuleTokenStream stream_LESSTHAN = new RewriteRuleTokenStream(adaptor, "token LESSTHAN");
    RewriteRuleTokenStream stream_GREATERTHAN = new RewriteRuleTokenStream(adaptor, "token GREATERTHAN");
    RewriteRuleSubtreeStream stream_columnNameColonTypeList =
        new RewriteRuleSubtreeStream(adaptor, "rule columnNameColonTypeList");
    pushMsg("struct type", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2045:5: ( KW_STRUCT LESSTHAN columnNameColonTypeList GREATERTHAN -> ^( TOK_STRUCT columnNameColonTypeList ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2045:7: KW_STRUCT LESSTHAN columnNameColonTypeList GREATERTHAN
      {
        KW_STRUCT818 = (Token) match(input, KW_STRUCT, FOLLOW_KW_STRUCT_in_structType12817);
        stream_KW_STRUCT.add(KW_STRUCT818);

        LESSTHAN819 = (Token) match(input, LESSTHAN, FOLLOW_LESSTHAN_in_structType12819);
        stream_LESSTHAN.add(LESSTHAN819);

        pushFollow(FOLLOW_columnNameColonTypeList_in_structType12821);
        columnNameColonTypeList820 = columnNameColonTypeList();

        state._fsp--;

        stream_columnNameColonTypeList.add(columnNameColonTypeList820.getTree());

        GREATERTHAN821 = (Token) match(input, GREATERTHAN, FOLLOW_GREATERTHAN_in_structType12823);
        stream_GREATERTHAN.add(GREATERTHAN821);

        // AST REWRITE
        // elements: columnNameColonTypeList
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2045:62: -> ^( TOK_STRUCT columnNameColonTypeList )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2045:65: ^( TOK_STRUCT columnNameColonTypeList )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_STRUCT, "TOK_STRUCT"), root_1);

            adaptor.addChild(root_1, stream_columnNameColonTypeList.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "structType"

  public static class mapType_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "mapType"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2048:1: mapType : KW_MAP LESSTHAN left= primitiveType COMMA right= type GREATERTHAN -> ^( TOK_MAP $left $right) ;
  public final HiveParser.mapType_return mapType() throws RecognitionException {
    HiveParser.mapType_return retval = new HiveParser.mapType_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_MAP822 = null;
    Token LESSTHAN823 = null;
    Token COMMA824 = null;
    Token GREATERTHAN825 = null;
    HiveParser.primitiveType_return left = null;

    HiveParser.type_return right = null;

    CommonTree KW_MAP822_tree = null;
    CommonTree LESSTHAN823_tree = null;
    CommonTree COMMA824_tree = null;
    CommonTree GREATERTHAN825_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleTokenStream stream_KW_MAP = new RewriteRuleTokenStream(adaptor, "token KW_MAP");
    RewriteRuleTokenStream stream_LESSTHAN = new RewriteRuleTokenStream(adaptor, "token LESSTHAN");
    RewriteRuleTokenStream stream_GREATERTHAN = new RewriteRuleTokenStream(adaptor, "token GREATERTHAN");
    RewriteRuleSubtreeStream stream_type = new RewriteRuleSubtreeStream(adaptor, "rule type");
    RewriteRuleSubtreeStream stream_primitiveType = new RewriteRuleSubtreeStream(adaptor, "rule primitiveType");
    pushMsg("map type", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2051:5: ( KW_MAP LESSTHAN left= primitiveType COMMA right= type GREATERTHAN -> ^( TOK_MAP $left $right) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2051:7: KW_MAP LESSTHAN left= primitiveType COMMA right= type GREATERTHAN
      {
        KW_MAP822 = (Token) match(input, KW_MAP, FOLLOW_KW_MAP_in_mapType12858);
        stream_KW_MAP.add(KW_MAP822);

        LESSTHAN823 = (Token) match(input, LESSTHAN, FOLLOW_LESSTHAN_in_mapType12860);
        stream_LESSTHAN.add(LESSTHAN823);

        pushFollow(FOLLOW_primitiveType_in_mapType12864);
        left = primitiveType();

        state._fsp--;

        stream_primitiveType.add(left.getTree());

        COMMA824 = (Token) match(input, COMMA, FOLLOW_COMMA_in_mapType12866);
        stream_COMMA.add(COMMA824);

        pushFollow(FOLLOW_type_in_mapType12870);
        right = type();

        state._fsp--;

        stream_type.add(right.getTree());

        GREATERTHAN825 = (Token) match(input, GREATERTHAN, FOLLOW_GREATERTHAN_in_mapType12872);
        stream_GREATERTHAN.add(GREATERTHAN825);

        // AST REWRITE
        // elements: left, right
        // token labels:
        // rule labels: left, right, retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_left =
            new RewriteRuleSubtreeStream(adaptor, "rule left", left != null ? left.tree : null);
        RewriteRuleSubtreeStream stream_right =
            new RewriteRuleSubtreeStream(adaptor, "rule right", right != null ? right.tree : null);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2052:5: -> ^( TOK_MAP $left $right)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2052:8: ^( TOK_MAP $left $right)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_MAP, "TOK_MAP"), root_1);

            adaptor.addChild(root_1, stream_left.nextTree());

            adaptor.addChild(root_1, stream_right.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "mapType"

  public static class unionType_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "unionType"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2055:1: unionType : KW_UNIONTYPE LESSTHAN colTypeList GREATERTHAN -> ^( TOK_UNIONTYPE colTypeList ) ;
  public final HiveParser.unionType_return unionType() throws RecognitionException {
    HiveParser.unionType_return retval = new HiveParser.unionType_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_UNIONTYPE826 = null;
    Token LESSTHAN827 = null;
    Token GREATERTHAN829 = null;
    HiveParser.colTypeList_return colTypeList828 = null;

    CommonTree KW_UNIONTYPE826_tree = null;
    CommonTree LESSTHAN827_tree = null;
    CommonTree GREATERTHAN829_tree = null;
    RewriteRuleTokenStream stream_KW_UNIONTYPE = new RewriteRuleTokenStream(adaptor, "token KW_UNIONTYPE");
    RewriteRuleTokenStream stream_LESSTHAN = new RewriteRuleTokenStream(adaptor, "token LESSTHAN");
    RewriteRuleTokenStream stream_GREATERTHAN = new RewriteRuleTokenStream(adaptor, "token GREATERTHAN");
    RewriteRuleSubtreeStream stream_colTypeList = new RewriteRuleSubtreeStream(adaptor, "rule colTypeList");
    pushMsg("uniontype type", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2058:5: ( KW_UNIONTYPE LESSTHAN colTypeList GREATERTHAN -> ^( TOK_UNIONTYPE colTypeList ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2058:7: KW_UNIONTYPE LESSTHAN colTypeList GREATERTHAN
      {
        KW_UNIONTYPE826 = (Token) match(input, KW_UNIONTYPE, FOLLOW_KW_UNIONTYPE_in_unionType12915);
        stream_KW_UNIONTYPE.add(KW_UNIONTYPE826);

        LESSTHAN827 = (Token) match(input, LESSTHAN, FOLLOW_LESSTHAN_in_unionType12917);
        stream_LESSTHAN.add(LESSTHAN827);

        pushFollow(FOLLOW_colTypeList_in_unionType12919);
        colTypeList828 = colTypeList();

        state._fsp--;

        stream_colTypeList.add(colTypeList828.getTree());

        GREATERTHAN829 = (Token) match(input, GREATERTHAN, FOLLOW_GREATERTHAN_in_unionType12921);
        stream_GREATERTHAN.add(GREATERTHAN829);

        // AST REWRITE
        // elements: colTypeList
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2058:53: -> ^( TOK_UNIONTYPE colTypeList )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2058:56: ^( TOK_UNIONTYPE colTypeList )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 =
                (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_UNIONTYPE, "TOK_UNIONTYPE"), root_1);

            adaptor.addChild(root_1, stream_colTypeList.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "unionType"

  public static class setOperator_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "setOperator"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2061:1: setOperator : KW_UNION KW_ALL -> ^( TOK_UNION ) ;
  public final HiveParser.setOperator_return setOperator() throws RecognitionException {
    HiveParser.setOperator_return retval = new HiveParser.setOperator_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_UNION830 = null;
    Token KW_ALL831 = null;

    CommonTree KW_UNION830_tree = null;
    CommonTree KW_ALL831_tree = null;
    RewriteRuleTokenStream stream_KW_UNION = new RewriteRuleTokenStream(adaptor, "token KW_UNION");
    RewriteRuleTokenStream stream_KW_ALL = new RewriteRuleTokenStream(adaptor, "token KW_ALL");

    pushMsg("set operator", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2064:5: ( KW_UNION KW_ALL -> ^( TOK_UNION ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2064:7: KW_UNION KW_ALL
      {
        KW_UNION830 = (Token) match(input, KW_UNION, FOLLOW_KW_UNION_in_setOperator12956);
        stream_KW_UNION.add(KW_UNION830);

        KW_ALL831 = (Token) match(input, KW_ALL, FOLLOW_KW_ALL_in_setOperator12958);
        stream_KW_ALL.add(KW_ALL831);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2064:23: -> ^( TOK_UNION )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2064:26: ^( TOK_UNION )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_UNION, "TOK_UNION"), root_1);

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "setOperator"

  public static class queryStatementExpression_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "queryStatementExpression"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2067:1: queryStatementExpression[boolean topLevel] : (w= withClause {...}?)? queryStatementExpressionBody[topLevel] -> queryStatementExpressionBody ;
  public final HiveParser.queryStatementExpression_return queryStatementExpression(boolean topLevel)
      throws RecognitionException {
    HiveParser.queryStatementExpression_return retval = new HiveParser.queryStatementExpression_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.withClause_return w = null;

    HiveParser.queryStatementExpressionBody_return queryStatementExpressionBody832 = null;

    RewriteRuleSubtreeStream stream_withClause = new RewriteRuleSubtreeStream(adaptor, "rule withClause");
    RewriteRuleSubtreeStream stream_queryStatementExpressionBody =
        new RewriteRuleSubtreeStream(adaptor, "rule queryStatementExpressionBody");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2068:5: ( (w= withClause {...}?)? queryStatementExpressionBody[topLevel] -> queryStatementExpressionBody )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2073:5: (w= withClause {...}?)? queryStatementExpressionBody[topLevel]
      {
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2073:5: (w= withClause {...}?)?
        int alt234 = 2;
        switch (input.LA(1)) {
          case KW_WITH: {
            alt234 = 1;
          }
          break;
        }

        switch (alt234) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2073:6: w= withClause {...}?
          {
            pushFollow(FOLLOW_withClause_in_queryStatementExpression12995);
            w = withClause();

            state._fsp--;

            stream_withClause.add(w.getTree());

            if (!((topLevel))) {
              throw new FailedPredicateException(input, "queryStatementExpression", "topLevel");
            }
          }
          break;
        }

        pushFollow(FOLLOW_queryStatementExpressionBody_in_queryStatementExpression13005);
        queryStatementExpressionBody832 = queryStatementExpressionBody(topLevel);

        state._fsp--;

        stream_queryStatementExpressionBody.add(queryStatementExpressionBody832.getTree());

        if ((w != null ? ((CommonTree) w.tree) : null) != null) {
          (queryStatementExpressionBody832 != null ? ((CommonTree) queryStatementExpressionBody832.tree)
              : null).insertChild(0, (w != null ? ((CommonTree) w.tree) : null));
        }

        // AST REWRITE
        // elements: queryStatementExpressionBody
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2079:5: -> queryStatementExpressionBody
        {
          adaptor.addChild(root_0, stream_queryStatementExpressionBody.nextTree());
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "queryStatementExpression"

  public static class queryStatementExpressionBody_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "queryStatementExpressionBody"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2082:1: queryStatementExpressionBody[boolean topLevel] : ( fromStatement[topLevel] | regularBody[topLevel] );
  public final HiveParser.queryStatementExpressionBody_return queryStatementExpressionBody(boolean topLevel)
      throws RecognitionException {
    HiveParser.queryStatementExpressionBody_return retval = new HiveParser.queryStatementExpressionBody_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.fromStatement_return fromStatement833 = null;

    HiveParser.regularBody_return regularBody834 = null;

    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2083:5: ( fromStatement[topLevel] | regularBody[topLevel] )
      int alt235 = 2;
      switch (input.LA(1)) {
        case KW_FROM: {
          alt235 = 1;
        }
        break;
        case KW_INSERT:
        case KW_MAP:
        case KW_REDUCE:
        case KW_SELECT: {
          alt235 = 2;
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 235, 0, input);

          throw nvae;
      }

      switch (alt235) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2084:5: fromStatement[topLevel]
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_fromStatement_in_queryStatementExpressionBody13039);
          fromStatement833 = fromStatement(topLevel);

          state._fsp--;

          adaptor.addChild(root_0, fromStatement833.getTree());
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2085:7: regularBody[topLevel]
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_regularBody_in_queryStatementExpressionBody13048);
          regularBody834 = regularBody(topLevel);

          state._fsp--;

          adaptor.addChild(root_0, regularBody834.getTree());
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "queryStatementExpressionBody"

  public static class withClause_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "withClause"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2088:1: withClause : KW_WITH cteStatement ( COMMA cteStatement )* -> ^( TOK_CTE ( cteStatement )+ ) ;
  public final HiveParser.withClause_return withClause() throws RecognitionException {
    HiveParser.withClause_return retval = new HiveParser.withClause_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_WITH835 = null;
    Token COMMA837 = null;
    HiveParser.cteStatement_return cteStatement836 = null;

    HiveParser.cteStatement_return cteStatement838 = null;

    CommonTree KW_WITH835_tree = null;
    CommonTree COMMA837_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleTokenStream stream_KW_WITH = new RewriteRuleTokenStream(adaptor, "token KW_WITH");
    RewriteRuleSubtreeStream stream_cteStatement = new RewriteRuleSubtreeStream(adaptor, "rule cteStatement");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2089:3: ( KW_WITH cteStatement ( COMMA cteStatement )* -> ^( TOK_CTE ( cteStatement )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2090:3: KW_WITH cteStatement ( COMMA cteStatement )*
      {
        KW_WITH835 = (Token) match(input, KW_WITH, FOLLOW_KW_WITH_in_withClause13066);
        stream_KW_WITH.add(KW_WITH835);

        pushFollow(FOLLOW_cteStatement_in_withClause13068);
        cteStatement836 = cteStatement();

        state._fsp--;

        stream_cteStatement.add(cteStatement836.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2090:24: ( COMMA cteStatement )*
        loop236:
        do {
          int alt236 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt236 = 1;
            }
            break;
          }

          switch (alt236) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2090:25: COMMA cteStatement
            {
              COMMA837 = (Token) match(input, COMMA, FOLLOW_COMMA_in_withClause13071);
              stream_COMMA.add(COMMA837);

              pushFollow(FOLLOW_cteStatement_in_withClause13073);
              cteStatement838 = cteStatement();

              state._fsp--;

              stream_cteStatement.add(cteStatement838.getTree());
            }
            break;

            default:
              break loop236;
          }
        } while (true);

        // AST REWRITE
        // elements: cteStatement
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2090:46: -> ^( TOK_CTE ( cteStatement )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2090:49: ^( TOK_CTE ( cteStatement )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_CTE, "TOK_CTE"), root_1);

            if (!(stream_cteStatement.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_cteStatement.hasNext()) {
              adaptor.addChild(root_1, stream_cteStatement.nextTree());
            }
            stream_cteStatement.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "withClause"

  public static class cteStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "cteStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2093:1: cteStatement : identifier KW_AS LPAREN queryStatementExpression[false] RPAREN -> ^( TOK_SUBQUERY queryStatementExpression identifier ) ;
  public final HiveParser.cteStatement_return cteStatement() throws RecognitionException {
    HiveParser.cteStatement_return retval = new HiveParser.cteStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_AS840 = null;
    Token LPAREN841 = null;
    Token RPAREN843 = null;
    HiveParser_IdentifiersParser.identifier_return identifier839 = null;

    HiveParser.queryStatementExpression_return queryStatementExpression842 = null;

    CommonTree KW_AS840_tree = null;
    CommonTree LPAREN841_tree = null;
    CommonTree RPAREN843_tree = null;
    RewriteRuleTokenStream stream_LPAREN = new RewriteRuleTokenStream(adaptor, "token LPAREN");
    RewriteRuleTokenStream stream_RPAREN = new RewriteRuleTokenStream(adaptor, "token RPAREN");
    RewriteRuleTokenStream stream_KW_AS = new RewriteRuleTokenStream(adaptor, "token KW_AS");
    RewriteRuleSubtreeStream stream_identifier = new RewriteRuleSubtreeStream(adaptor, "rule identifier");
    RewriteRuleSubtreeStream stream_queryStatementExpression =
        new RewriteRuleSubtreeStream(adaptor, "rule queryStatementExpression");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2094:4: ( identifier KW_AS LPAREN queryStatementExpression[false] RPAREN -> ^( TOK_SUBQUERY queryStatementExpression identifier ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2095:4: identifier KW_AS LPAREN queryStatementExpression[false] RPAREN
      {
        pushFollow(FOLLOW_identifier_in_cteStatement13099);
        identifier839 = identifier();

        state._fsp--;

        stream_identifier.add(identifier839.getTree());

        KW_AS840 = (Token) match(input, KW_AS, FOLLOW_KW_AS_in_cteStatement13101);
        stream_KW_AS.add(KW_AS840);

        LPAREN841 = (Token) match(input, LPAREN, FOLLOW_LPAREN_in_cteStatement13103);
        stream_LPAREN.add(LPAREN841);

        pushFollow(FOLLOW_queryStatementExpression_in_cteStatement13105);
        queryStatementExpression842 = queryStatementExpression(false);

        state._fsp--;

        stream_queryStatementExpression.add(queryStatementExpression842.getTree());

        RPAREN843 = (Token) match(input, RPAREN, FOLLOW_RPAREN_in_cteStatement13108);
        stream_RPAREN.add(RPAREN843);

        // AST REWRITE
        // elements: identifier, queryStatementExpression
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2096:4: -> ^( TOK_SUBQUERY queryStatementExpression identifier )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2096:7: ^( TOK_SUBQUERY queryStatementExpression identifier )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SUBQUERY, "TOK_SUBQUERY"), root_1);

            adaptor.addChild(root_1, stream_queryStatementExpression.nextTree());

            adaptor.addChild(root_1, stream_identifier.nextTree());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "cteStatement"

  public static class fromStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "fromStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2099:1: fromStatement[boolean topLevel] : ( singleFromStatement -> singleFromStatement ) (u= setOperator r= singleFromStatement -> ^( $u $r) )* -> {u != null && topLevel}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) ) ->;
  public final HiveParser.fromStatement_return fromStatement(boolean topLevel) throws RecognitionException {
    HiveParser.fromStatement_return retval = new HiveParser.fromStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.setOperator_return u = null;

    HiveParser.singleFromStatement_return r = null;

    HiveParser.singleFromStatement_return singleFromStatement844 = null;

    RewriteRuleSubtreeStream stream_setOperator = new RewriteRuleSubtreeStream(adaptor, "rule setOperator");
    RewriteRuleSubtreeStream stream_singleFromStatement =
        new RewriteRuleSubtreeStream(adaptor, "rule singleFromStatement");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2100:3: ( ( singleFromStatement -> singleFromStatement ) (u= setOperator r= singleFromStatement -> ^( $u $r) )* -> {u != null && topLevel}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) ) ->)
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2100:3: ( singleFromStatement -> singleFromStatement ) (u= setOperator r= singleFromStatement -> ^( $u $r) )*
      {
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2100:3: ( singleFromStatement -> singleFromStatement )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2100:4: singleFromStatement
        {
          pushFollow(FOLLOW_singleFromStatement_in_fromStatement13132);
          singleFromStatement844 = singleFromStatement();

          state._fsp--;

          stream_singleFromStatement.add(singleFromStatement844.getTree());

          // AST REWRITE
          // elements: singleFromStatement
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2100:25: -> singleFromStatement
          {
            adaptor.addChild(root_0, stream_singleFromStatement.nextTree());
          }

          retval.tree = root_0;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2101:2: (u= setOperator r= singleFromStatement -> ^( $u $r) )*
        loop237:
        do {
          int alt237 = 2;
          switch (input.LA(1)) {
            case KW_UNION: {
              alt237 = 1;
            }
            break;
          }

          switch (alt237) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2101:3: u= setOperator r= singleFromStatement
            {
              pushFollow(FOLLOW_setOperator_in_fromStatement13144);
              u = setOperator();

              state._fsp--;

              stream_setOperator.add(u.getTree());

              pushFollow(FOLLOW_singleFromStatement_in_fromStatement13148);
              r = singleFromStatement();

              state._fsp--;

              stream_singleFromStatement.add(r.getTree());

              // AST REWRITE
              // elements: u, r
              // token labels:
              // rule labels: r, u, retval
              // token list labels:
              // rule list labels:
              // wildcard labels:
              retval.tree = root_0;
              RewriteRuleSubtreeStream stream_r =
                  new RewriteRuleSubtreeStream(adaptor, "rule r", r != null ? r.tree : null);
              RewriteRuleSubtreeStream stream_u =
                  new RewriteRuleSubtreeStream(adaptor, "rule u", u != null ? u.tree : null);
              RewriteRuleSubtreeStream stream_retval =
                  new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

              root_0 = (CommonTree) adaptor.nil();
              // 2102:4: -> ^( $u $r)
              {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2102:7: ^( $u $r)
                {
                  CommonTree root_1 = (CommonTree) adaptor.nil();
                  root_1 = (CommonTree) adaptor.becomeRoot(stream_u.nextNode(), root_1);

                  adaptor.addChild(root_1, ((CommonTree) retval.tree));

                  adaptor.addChild(root_1, stream_r.nextTree());

                  adaptor.addChild(root_0, root_1);
                }
              }

              retval.tree = root_0;
            }
            break;

            default:
              break loop237;
          }
        } while (true);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2104:3: -> {u != null && topLevel}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) )
        if (u != null && topLevel) {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2104:31: ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2105:9: ^( TOK_FROM ^( TOK_SUBQUERY ) )
            {
              CommonTree root_2 = (CommonTree) adaptor.nil();
              root_2 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_FROM, "TOK_FROM"), root_2);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2106:11: ^( TOK_SUBQUERY )
              {
                CommonTree root_3 = (CommonTree) adaptor.nil();
                root_3 =
                    (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SUBQUERY, "TOK_SUBQUERY"), root_3);

                adaptor.addChild(root_3, ((CommonTree) retval.tree));

                adaptor.addChild(root_3, adaptor.create(Identifier, generateUnionAlias()));

                adaptor.addChild(root_2, root_3);
              }

              adaptor.addChild(root_1, root_2);
            }

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2111:9: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) )
            {
              CommonTree root_2 = (CommonTree) adaptor.nil();
              root_2 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_INSERT, "TOK_INSERT"), root_2);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2112:12: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
              {
                CommonTree root_3 = (CommonTree) adaptor.nil();
                root_3 =
                    (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"),
                        root_3);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2112:30: ^( TOK_DIR TOK_TMP_FILE )
                {
                  CommonTree root_4 = (CommonTree) adaptor.nil();
                  root_4 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DIR, "TOK_DIR"), root_4);

                  adaptor.addChild(root_4, (CommonTree) adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE"));

                  adaptor.addChild(root_3, root_4);
                }

                adaptor.addChild(root_2, root_3);
              }

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2113:12: ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) )
              {
                CommonTree root_3 = (CommonTree) adaptor.nil();
                root_3 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SELECT, "TOK_SELECT"), root_3);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2113:25: ^( TOK_SELEXPR TOK_ALLCOLREF )
                {
                  CommonTree root_4 = (CommonTree) adaptor.nil();
                  root_4 =
                      (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SELEXPR, "TOK_SELEXPR"), root_4);

                  adaptor.addChild(root_4, (CommonTree) adaptor.create(TOK_ALLCOLREF, "TOK_ALLCOLREF"));

                  adaptor.addChild(root_3, root_4);
                }

                adaptor.addChild(root_2, root_3);
              }

              adaptor.addChild(root_1, root_2);
            }

            adaptor.addChild(root_0, root_1);
          }
        } else // 2116:5: ->
        {
          adaptor.addChild(root_0, ((CommonTree) retval.tree));
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "fromStatement"

  public static class singleFromStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "singleFromStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2120:1: singleFromStatement : fromClause (b+= body )+ -> ^( TOK_QUERY fromClause ( body )+ ) ;
  public final HiveParser.singleFromStatement_return singleFromStatement() throws RecognitionException {
    HiveParser.singleFromStatement_return retval = new HiveParser.singleFromStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    List list_b = null;
    HiveParser_FromClauseParser.fromClause_return fromClause845 = null;

    RuleReturnScope b = null;
    RewriteRuleSubtreeStream stream_fromClause = new RewriteRuleSubtreeStream(adaptor, "rule fromClause");
    RewriteRuleSubtreeStream stream_body = new RewriteRuleSubtreeStream(adaptor, "rule body");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2121:5: ( fromClause (b+= body )+ -> ^( TOK_QUERY fromClause ( body )+ ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2122:5: fromClause (b+= body )+
      {
        pushFollow(FOLLOW_fromClause_in_singleFromStatement13355);
        fromClause845 = fromClause();

        state._fsp--;

        stream_fromClause.add(fromClause845.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2123:5: (b+= body )+
        int cnt238 = 0;
        loop238:
        do {
          int alt238 = 2;
          switch (input.LA(1)) {
            case KW_INSERT:
            case KW_MAP:
            case KW_REDUCE:
            case KW_SELECT: {
              alt238 = 1;
            }
            break;
          }

          switch (alt238) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2123:7: b+= body
            {
              pushFollow(FOLLOW_body_in_singleFromStatement13365);
              b = body();

              state._fsp--;

              stream_body.add(b.getTree());
              if (list_b == null) {
                list_b = new ArrayList();
              }
              list_b.add(b.getTree());
            }
            break;

            default:
              if (cnt238 >= 1) {
                break loop238;
              }
              EarlyExitException eee = new EarlyExitException(238, input);
              throw eee;
          }
          cnt238++;
        } while (true);

        // AST REWRITE
        // elements: body, fromClause
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2123:18: -> ^( TOK_QUERY fromClause ( body )+ )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2123:21: ^( TOK_QUERY fromClause ( body )+ )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);

            adaptor.addChild(root_1, stream_fromClause.nextTree());

            if (!(stream_body.hasNext())) {
              throw new RewriteEarlyExitException();
            }
            while (stream_body.hasNext()) {
              adaptor.addChild(root_1, stream_body.nextTree());
            }
            stream_body.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "singleFromStatement"

  public static class regularBody_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "regularBody"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2133:1: regularBody[boolean topLevel] : (i= insertClause (s= selectStatement[topLevel] ->| valuesClause -> ^( TOK_QUERY ^( TOK_FROM ^( TOK_VIRTUAL_TABLE ^( TOK_VIRTUAL_TABREF ^( TOK_ANONYMOUS ) ) valuesClause ) ) ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) ) ) | selectStatement[topLevel] );
  public final HiveParser.regularBody_return regularBody(boolean topLevel) throws RecognitionException {
    HiveParser.regularBody_return retval = new HiveParser.regularBody_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.insertClause_return i = null;

    HiveParser.selectStatement_return s = null;

    HiveParser_FromClauseParser.valuesClause_return valuesClause846 = null;

    HiveParser.selectStatement_return selectStatement847 = null;

    RewriteRuleSubtreeStream stream_insertClause = new RewriteRuleSubtreeStream(adaptor, "rule insertClause");
    RewriteRuleSubtreeStream stream_valuesClause = new RewriteRuleSubtreeStream(adaptor, "rule valuesClause");
    RewriteRuleSubtreeStream stream_selectStatement = new RewriteRuleSubtreeStream(adaptor, "rule selectStatement");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2134:4: (i= insertClause (s= selectStatement[topLevel] ->| valuesClause -> ^( TOK_QUERY ^( TOK_FROM ^( TOK_VIRTUAL_TABLE ^( TOK_VIRTUAL_TABREF ^( TOK_ANONYMOUS ) ) valuesClause ) ) ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) ) ) | selectStatement[topLevel] )
      int alt240 = 2;
      switch (input.LA(1)) {
        case KW_INSERT: {
          alt240 = 1;
        }
        break;
        case KW_MAP:
        case KW_REDUCE:
        case KW_SELECT: {
          alt240 = 2;
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 240, 0, input);

          throw nvae;
      }

      switch (alt240) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2135:4: i= insertClause (s= selectStatement[topLevel] ->| valuesClause -> ^( TOK_QUERY ^( TOK_FROM ^( TOK_VIRTUAL_TABLE ^( TOK_VIRTUAL_TABREF ^( TOK_ANONYMOUS ) ) valuesClause ) ) ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) ) )
        {
          pushFollow(FOLLOW_insertClause_in_regularBody13403);
          i = insertClause();

          state._fsp--;

          stream_insertClause.add(i.getTree());

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2136:4: (s= selectStatement[topLevel] ->| valuesClause -> ^( TOK_QUERY ^( TOK_FROM ^( TOK_VIRTUAL_TABLE ^( TOK_VIRTUAL_TABREF ^( TOK_ANONYMOUS ) ) valuesClause ) ) ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) ) )
          int alt239 = 2;
          switch (input.LA(1)) {
            case KW_MAP:
            case KW_REDUCE:
            case KW_SELECT: {
              alt239 = 1;
            }
            break;
            case KW_VALUES: {
              alt239 = 2;
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 239, 0, input);

              throw nvae;
          }

          switch (alt239) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2137:4: s= selectStatement[topLevel]
            {
              pushFollow(FOLLOW_selectStatement_in_regularBody13415);
              s = selectStatement(topLevel);

              state._fsp--;

              stream_selectStatement.add(s.getTree());

              (s != null ? ((CommonTree) s.tree) : null).getFirstChildWithType(TOK_INSERT)
                  .replaceChildren(0, 0, (i != null ? ((CommonTree) i.tree) : null));

              // AST REWRITE
              // elements:
              // token labels:
              // rule labels: retval
              // token list labels:
              // rule list labels:
              // wildcard labels:
              retval.tree = root_0;
              RewriteRuleSubtreeStream stream_retval =
                  new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

              root_0 = (CommonTree) adaptor.nil();
              // 2138:82: ->
              {
                adaptor.addChild(root_0, (s != null ? ((CommonTree) s.tree) : null));
              }

              retval.tree = root_0;
            }
            break;
            case 2:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2140:6: valuesClause
            {
              pushFollow(FOLLOW_valuesClause_in_regularBody13441);
              valuesClause846 = valuesClause();

              state._fsp--;

              stream_valuesClause.add(valuesClause846.getTree());

              // AST REWRITE
              // elements: valuesClause
              // token labels:
              // rule labels: retval
              // token list labels:
              // rule list labels:
              // wildcard labels:
              retval.tree = root_0;
              RewriteRuleSubtreeStream stream_retval =
                  new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

              root_0 = (CommonTree) adaptor.nil();
              // 2141:7: -> ^( TOK_QUERY ^( TOK_FROM ^( TOK_VIRTUAL_TABLE ^( TOK_VIRTUAL_TABREF ^( TOK_ANONYMOUS ) ) valuesClause ) ) ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) )
              {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2141:10: ^( TOK_QUERY ^( TOK_FROM ^( TOK_VIRTUAL_TABLE ^( TOK_VIRTUAL_TABREF ^( TOK_ANONYMOUS ) ) valuesClause ) ) ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) )
                {
                  CommonTree root_1 = (CommonTree) adaptor.nil();
                  root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);

                  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2142:13: ^( TOK_FROM ^( TOK_VIRTUAL_TABLE ^( TOK_VIRTUAL_TABREF ^( TOK_ANONYMOUS ) ) valuesClause ) )
                  {
                    CommonTree root_2 = (CommonTree) adaptor.nil();
                    root_2 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_FROM, "TOK_FROM"), root_2);

                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2143:15: ^( TOK_VIRTUAL_TABLE ^( TOK_VIRTUAL_TABREF ^( TOK_ANONYMOUS ) ) valuesClause )
                    {
                      CommonTree root_3 = (CommonTree) adaptor.nil();
                      root_3 = (CommonTree) adaptor.becomeRoot(
                          (CommonTree) adaptor.create(TOK_VIRTUAL_TABLE, "TOK_VIRTUAL_TABLE"), root_3);

                      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2143:35: ^( TOK_VIRTUAL_TABREF ^( TOK_ANONYMOUS ) )
                      {
                        CommonTree root_4 = (CommonTree) adaptor.nil();
                        root_4 = (CommonTree) adaptor.becomeRoot(
                            (CommonTree) adaptor.create(TOK_VIRTUAL_TABREF, "TOK_VIRTUAL_TABREF"), root_4);

                        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2143:56: ^( TOK_ANONYMOUS )
                        {
                          CommonTree root_5 = (CommonTree) adaptor.nil();
                          root_5 = (CommonTree) adaptor.becomeRoot(
                              (CommonTree) adaptor.create(TOK_ANONYMOUS, "TOK_ANONYMOUS"), root_5);

                          adaptor.addChild(root_4, root_5);
                        }

                        adaptor.addChild(root_3, root_4);
                      }

                      adaptor.addChild(root_3, stream_valuesClause.nextTree());

                      adaptor.addChild(root_2, root_3);
                    }

                    adaptor.addChild(root_1, root_2);
                  }

                  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2145:13: ^( TOK_INSERT ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) )
                  {
                    CommonTree root_2 = (CommonTree) adaptor.nil();
                    root_2 =
                        (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_INSERT, "TOK_INSERT"), root_2);

                    adaptor.addChild(root_2, (i != null ? ((CommonTree) i.tree) : null));

                    // org/apache/hadoop/hive/ql/parse/HiveParser.g:2145:36: ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) )
                    {
                      CommonTree root_3 = (CommonTree) adaptor.nil();
                      root_3 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SELECT, "TOK_SELECT"),
                          root_3);

                      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2145:49: ^( TOK_SELEXPR TOK_ALLCOLREF )
                      {
                        CommonTree root_4 = (CommonTree) adaptor.nil();
                        root_4 =
                            (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SELEXPR, "TOK_SELEXPR"),
                                root_4);

                        adaptor.addChild(root_4, (CommonTree) adaptor.create(TOK_ALLCOLREF, "TOK_ALLCOLREF"));

                        adaptor.addChild(root_3, root_4);
                      }

                      adaptor.addChild(root_2, root_3);
                    }

                    adaptor.addChild(root_1, root_2);
                  }

                  adaptor.addChild(root_0, root_1);
                }
              }

              retval.tree = root_0;
            }
            break;
          }
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2149:4: selectStatement[topLevel]
        {
          root_0 = (CommonTree) adaptor.nil();

          pushFollow(FOLLOW_selectStatement_in_regularBody13565);
          selectStatement847 = selectStatement(topLevel);

          state._fsp--;

          adaptor.addChild(root_0, selectStatement847.getTree());
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "regularBody"

  public static class selectStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "selectStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2152:2: selectStatement[boolean topLevel] : ( singleSelectStatement -> singleSelectStatement ) (u= setOperator b= singleSelectStatement -> ^( $u $b) )* -> {u != null && topLevel}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) ) ->;
  public final HiveParser.selectStatement_return selectStatement(boolean topLevel) throws RecognitionException {
    HiveParser.selectStatement_return retval = new HiveParser.selectStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.setOperator_return u = null;

    HiveParser.singleSelectStatement_return b = null;

    HiveParser.singleSelectStatement_return singleSelectStatement848 = null;

    RewriteRuleSubtreeStream stream_singleSelectStatement =
        new RewriteRuleSubtreeStream(adaptor, "rule singleSelectStatement");
    RewriteRuleSubtreeStream stream_setOperator = new RewriteRuleSubtreeStream(adaptor, "rule setOperator");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2153:2: ( ( singleSelectStatement -> singleSelectStatement ) (u= setOperator b= singleSelectStatement -> ^( $u $b) )* -> {u != null && topLevel}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) ) ->)
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2153:4: ( singleSelectStatement -> singleSelectStatement ) (u= setOperator b= singleSelectStatement -> ^( $u $b) )*
      {
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2153:4: ( singleSelectStatement -> singleSelectStatement )
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2153:5: singleSelectStatement
        {
          pushFollow(FOLLOW_singleSelectStatement_in_selectStatement13582);
          singleSelectStatement848 = singleSelectStatement();

          state._fsp--;

          stream_singleSelectStatement.add(singleSelectStatement848.getTree());

          // AST REWRITE
          // elements: singleSelectStatement
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2153:27: -> singleSelectStatement
          {
            adaptor.addChild(root_0, stream_singleSelectStatement.nextTree());
          }

          retval.tree = root_0;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2154:4: (u= setOperator b= singleSelectStatement -> ^( $u $b) )*
        loop241:
        do {
          int alt241 = 2;
          switch (input.LA(1)) {
            case KW_UNION: {
              alt241 = 1;
            }
            break;
          }

          switch (alt241) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2154:5: u= setOperator b= singleSelectStatement
            {
              pushFollow(FOLLOW_setOperator_in_selectStatement13595);
              u = setOperator();

              state._fsp--;

              stream_setOperator.add(u.getTree());

              pushFollow(FOLLOW_singleSelectStatement_in_selectStatement13599);
              b = singleSelectStatement();

              state._fsp--;

              stream_singleSelectStatement.add(b.getTree());

              // AST REWRITE
              // elements: u, b
              // token labels:
              // rule labels: b, u, retval
              // token list labels:
              // rule list labels:
              // wildcard labels:
              retval.tree = root_0;
              RewriteRuleSubtreeStream stream_b =
                  new RewriteRuleSubtreeStream(adaptor, "rule b", b != null ? b.tree : null);
              RewriteRuleSubtreeStream stream_u =
                  new RewriteRuleSubtreeStream(adaptor, "rule u", u != null ? u.tree : null);
              RewriteRuleSubtreeStream stream_retval =
                  new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

              root_0 = (CommonTree) adaptor.nil();
              // 2155:8: -> ^( $u $b)
              {
                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2155:11: ^( $u $b)
                {
                  CommonTree root_1 = (CommonTree) adaptor.nil();
                  root_1 = (CommonTree) adaptor.becomeRoot(stream_u.nextNode(), root_1);

                  adaptor.addChild(root_1, ((CommonTree) retval.tree));

                  adaptor.addChild(root_1, stream_b.nextTree());

                  adaptor.addChild(root_0, root_1);
                }
              }

              retval.tree = root_0;
            }
            break;

            default:
              break loop241;
          }
        } while (true);

        // AST REWRITE
        // elements:
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2157:4: -> {u != null && topLevel}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) )
        if (u != null && topLevel) {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2157:32: ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) ) )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2158:10: ^( TOK_FROM ^( TOK_SUBQUERY ) )
            {
              CommonTree root_2 = (CommonTree) adaptor.nil();
              root_2 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_FROM, "TOK_FROM"), root_2);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2159:12: ^( TOK_SUBQUERY )
              {
                CommonTree root_3 = (CommonTree) adaptor.nil();
                root_3 =
                    (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SUBQUERY, "TOK_SUBQUERY"), root_3);

                adaptor.addChild(root_3, ((CommonTree) retval.tree));

                adaptor.addChild(root_3, adaptor.create(Identifier, generateUnionAlias()));

                adaptor.addChild(root_2, root_3);
              }

              adaptor.addChild(root_1, root_2);
            }

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2164:10: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) ) )
            {
              CommonTree root_2 = (CommonTree) adaptor.nil();
              root_2 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_INSERT, "TOK_INSERT"), root_2);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2165:13: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
              {
                CommonTree root_3 = (CommonTree) adaptor.nil();
                root_3 =
                    (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"),
                        root_3);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2165:31: ^( TOK_DIR TOK_TMP_FILE )
                {
                  CommonTree root_4 = (CommonTree) adaptor.nil();
                  root_4 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DIR, "TOK_DIR"), root_4);

                  adaptor.addChild(root_4, (CommonTree) adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE"));

                  adaptor.addChild(root_3, root_4);
                }

                adaptor.addChild(root_2, root_3);
              }

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2166:13: ^( TOK_SELECT ^( TOK_SELEXPR TOK_ALLCOLREF ) )
              {
                CommonTree root_3 = (CommonTree) adaptor.nil();
                root_3 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SELECT, "TOK_SELECT"), root_3);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2166:26: ^( TOK_SELEXPR TOK_ALLCOLREF )
                {
                  CommonTree root_4 = (CommonTree) adaptor.nil();
                  root_4 =
                      (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_SELEXPR, "TOK_SELEXPR"), root_4);

                  adaptor.addChild(root_4, (CommonTree) adaptor.create(TOK_ALLCOLREF, "TOK_ALLCOLREF"));

                  adaptor.addChild(root_3, root_4);
                }

                adaptor.addChild(root_2, root_3);
              }

              adaptor.addChild(root_1, root_2);
            }

            adaptor.addChild(root_0, root_1);
          }
        } else // 2169:5: ->
        {
          adaptor.addChild(root_0, ((CommonTree) retval.tree));
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "selectStatement"

  public static class singleSelectStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "singleSelectStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2172:1: singleSelectStatement : selectClause ( fromClause )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? -> ^( TOK_QUERY ( fromClause )? ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) ) ;
  public final HiveParser.singleSelectStatement_return singleSelectStatement() throws RecognitionException {
    HiveParser.singleSelectStatement_return retval = new HiveParser.singleSelectStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser_SelectClauseParser.selectClause_return selectClause849 = null;

    HiveParser_FromClauseParser.fromClause_return fromClause850 = null;

    HiveParser_FromClauseParser.whereClause_return whereClause851 = null;

    HiveParser_IdentifiersParser.groupByClause_return groupByClause852 = null;

    HiveParser_IdentifiersParser.havingClause_return havingClause853 = null;

    HiveParser_IdentifiersParser.orderByClause_return orderByClause854 = null;

    HiveParser_IdentifiersParser.clusterByClause_return clusterByClause855 = null;

    HiveParser_IdentifiersParser.distributeByClause_return distributeByClause856 = null;

    HiveParser_IdentifiersParser.sortByClause_return sortByClause857 = null;

    HiveParser_SelectClauseParser.window_clause_return window_clause858 = null;

    HiveParser.limitClause_return limitClause859 = null;

    RewriteRuleSubtreeStream stream_whereClause = new RewriteRuleSubtreeStream(adaptor, "rule whereClause");
    RewriteRuleSubtreeStream stream_havingClause = new RewriteRuleSubtreeStream(adaptor, "rule havingClause");
    RewriteRuleSubtreeStream stream_clusterByClause = new RewriteRuleSubtreeStream(adaptor, "rule clusterByClause");
    RewriteRuleSubtreeStream stream_fromClause = new RewriteRuleSubtreeStream(adaptor, "rule fromClause");
    RewriteRuleSubtreeStream stream_selectClause = new RewriteRuleSubtreeStream(adaptor, "rule selectClause");
    RewriteRuleSubtreeStream stream_sortByClause = new RewriteRuleSubtreeStream(adaptor, "rule sortByClause");
    RewriteRuleSubtreeStream stream_groupByClause = new RewriteRuleSubtreeStream(adaptor, "rule groupByClause");
    RewriteRuleSubtreeStream stream_distributeByClause =
        new RewriteRuleSubtreeStream(adaptor, "rule distributeByClause");
    RewriteRuleSubtreeStream stream_limitClause = new RewriteRuleSubtreeStream(adaptor, "rule limitClause");
    RewriteRuleSubtreeStream stream_orderByClause = new RewriteRuleSubtreeStream(adaptor, "rule orderByClause");
    RewriteRuleSubtreeStream stream_window_clause = new RewriteRuleSubtreeStream(adaptor, "rule window_clause");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2173:4: ( selectClause ( fromClause )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? -> ^( TOK_QUERY ( fromClause )? ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2174:4: selectClause ( fromClause )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )?
      {
        pushFollow(FOLLOW_selectClause_in_singleSelectStatement13821);
        selectClause849 = selectClause();

        state._fsp--;

        stream_selectClause.add(selectClause849.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2175:4: ( fromClause )?
        int alt242 = 2;
        switch (input.LA(1)) {
          case KW_FROM: {
            alt242 = 1;
          }
          break;
        }

        switch (alt242) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2175:4: fromClause
          {
            pushFollow(FOLLOW_fromClause_in_singleSelectStatement13826);
            fromClause850 = fromClause();

            state._fsp--;

            stream_fromClause.add(fromClause850.getTree());
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2176:4: ( whereClause )?
        int alt243 = 2;
        switch (input.LA(1)) {
          case KW_WHERE: {
            alt243 = 1;
          }
          break;
        }

        switch (alt243) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2176:4: whereClause
          {
            pushFollow(FOLLOW_whereClause_in_singleSelectStatement13832);
            whereClause851 = whereClause();

            state._fsp--;

            stream_whereClause.add(whereClause851.getTree());
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2177:4: ( groupByClause )?
        int alt244 = 2;
        switch (input.LA(1)) {
          case KW_GROUP: {
            alt244 = 1;
          }
          break;
        }

        switch (alt244) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2177:4: groupByClause
          {
            pushFollow(FOLLOW_groupByClause_in_singleSelectStatement13838);
            groupByClause852 = groupByClause();

            state._fsp--;

            stream_groupByClause.add(groupByClause852.getTree());
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2178:4: ( havingClause )?
        int alt245 = 2;
        switch (input.LA(1)) {
          case KW_HAVING: {
            alt245 = 1;
          }
          break;
        }

        switch (alt245) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2178:4: havingClause
          {
            pushFollow(FOLLOW_havingClause_in_singleSelectStatement13844);
            havingClause853 = havingClause();

            state._fsp--;

            stream_havingClause.add(havingClause853.getTree());
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2179:4: ( orderByClause )?
        int alt246 = 2;
        switch (input.LA(1)) {
          case KW_ORDER: {
            alt246 = 1;
          }
          break;
        }

        switch (alt246) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2179:4: orderByClause
          {
            pushFollow(FOLLOW_orderByClause_in_singleSelectStatement13850);
            orderByClause854 = orderByClause();

            state._fsp--;

            stream_orderByClause.add(orderByClause854.getTree());
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2180:4: ( clusterByClause )?
        int alt247 = 2;
        switch (input.LA(1)) {
          case KW_CLUSTER: {
            alt247 = 1;
          }
          break;
        }

        switch (alt247) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2180:4: clusterByClause
          {
            pushFollow(FOLLOW_clusterByClause_in_singleSelectStatement13856);
            clusterByClause855 = clusterByClause();

            state._fsp--;

            stream_clusterByClause.add(clusterByClause855.getTree());
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2181:4: ( distributeByClause )?
        int alt248 = 2;
        switch (input.LA(1)) {
          case KW_DISTRIBUTE: {
            alt248 = 1;
          }
          break;
        }

        switch (alt248) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2181:4: distributeByClause
          {
            pushFollow(FOLLOW_distributeByClause_in_singleSelectStatement13862);
            distributeByClause856 = distributeByClause();

            state._fsp--;

            stream_distributeByClause.add(distributeByClause856.getTree());
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2182:4: ( sortByClause )?
        int alt249 = 2;
        switch (input.LA(1)) {
          case KW_SORT: {
            alt249 = 1;
          }
          break;
        }

        switch (alt249) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2182:4: sortByClause
          {
            pushFollow(FOLLOW_sortByClause_in_singleSelectStatement13868);
            sortByClause857 = sortByClause();

            state._fsp--;

            stream_sortByClause.add(sortByClause857.getTree());
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2183:4: ( window_clause )?
        int alt250 = 2;
        switch (input.LA(1)) {
          case KW_WINDOW: {
            alt250 = 1;
          }
          break;
        }

        switch (alt250) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2183:4: window_clause
          {
            pushFollow(FOLLOW_window_clause_in_singleSelectStatement13874);
            window_clause858 = window_clause();

            state._fsp--;

            stream_window_clause.add(window_clause858.getTree());
          }
          break;
        }

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2184:4: ( limitClause )?
        int alt251 = 2;
        switch (input.LA(1)) {
          case KW_LIMIT: {
            alt251 = 1;
          }
          break;
        }

        switch (alt251) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2184:4: limitClause
          {
            pushFollow(FOLLOW_limitClause_in_singleSelectStatement13880);
            limitClause859 = limitClause();

            state._fsp--;

            stream_limitClause.add(limitClause859.getTree());
          }
          break;
        }

        // AST REWRITE
        // elements: whereClause, window_clause, clusterByClause, selectClause, distributeByClause, havingClause, groupByClause, fromClause, orderByClause, sortByClause, limitClause
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2184:17: -> ^( TOK_QUERY ( fromClause )? ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2184:20: ^( TOK_QUERY ( fromClause )? ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2184:32: ( fromClause )?
            if (stream_fromClause.hasNext()) {
              adaptor.addChild(root_1, stream_fromClause.nextTree());
            }
            stream_fromClause.reset();

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2184:44: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? )
            {
              CommonTree root_2 = (CommonTree) adaptor.nil();
              root_2 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_INSERT, "TOK_INSERT"), root_2);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2184:57: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
              {
                CommonTree root_3 = (CommonTree) adaptor.nil();
                root_3 =
                    (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"),
                        root_3);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2184:75: ^( TOK_DIR TOK_TMP_FILE )
                {
                  CommonTree root_4 = (CommonTree) adaptor.nil();
                  root_4 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DIR, "TOK_DIR"), root_4);

                  adaptor.addChild(root_4, (CommonTree) adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE"));

                  adaptor.addChild(root_3, root_4);
                }

                adaptor.addChild(root_2, root_3);
              }

              adaptor.addChild(root_2, stream_selectClause.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2185:35: ( whereClause )?
              if (stream_whereClause.hasNext()) {
                adaptor.addChild(root_2, stream_whereClause.nextTree());
              }
              stream_whereClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2185:48: ( groupByClause )?
              if (stream_groupByClause.hasNext()) {
                adaptor.addChild(root_2, stream_groupByClause.nextTree());
              }
              stream_groupByClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2185:63: ( havingClause )?
              if (stream_havingClause.hasNext()) {
                adaptor.addChild(root_2, stream_havingClause.nextTree());
              }
              stream_havingClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2185:77: ( orderByClause )?
              if (stream_orderByClause.hasNext()) {
                adaptor.addChild(root_2, stream_orderByClause.nextTree());
              }
              stream_orderByClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2185:92: ( clusterByClause )?
              if (stream_clusterByClause.hasNext()) {
                adaptor.addChild(root_2, stream_clusterByClause.nextTree());
              }
              stream_clusterByClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2186:22: ( distributeByClause )?
              if (stream_distributeByClause.hasNext()) {
                adaptor.addChild(root_2, stream_distributeByClause.nextTree());
              }
              stream_distributeByClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2186:42: ( sortByClause )?
              if (stream_sortByClause.hasNext()) {
                adaptor.addChild(root_2, stream_sortByClause.nextTree());
              }
              stream_sortByClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2186:56: ( window_clause )?
              if (stream_window_clause.hasNext()) {
                adaptor.addChild(root_2, stream_window_clause.nextTree());
              }
              stream_window_clause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2186:71: ( limitClause )?
              if (stream_limitClause.hasNext()) {
                adaptor.addChild(root_2, stream_limitClause.nextTree());
              }
              stream_limitClause.reset();

              adaptor.addChild(root_1, root_2);
            }

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "singleSelectStatement"

  public static class selectStatementWithCTE_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "selectStatementWithCTE"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2189:1: selectStatementWithCTE : (w= withClause )? selectStatement[true] -> selectStatement ;
  public final HiveParser.selectStatementWithCTE_return selectStatementWithCTE() throws RecognitionException {
    HiveParser.selectStatementWithCTE_return retval = new HiveParser.selectStatementWithCTE_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.withClause_return w = null;

    HiveParser.selectStatement_return selectStatement860 = null;

    RewriteRuleSubtreeStream stream_withClause = new RewriteRuleSubtreeStream(adaptor, "rule withClause");
    RewriteRuleSubtreeStream stream_selectStatement = new RewriteRuleSubtreeStream(adaptor, "rule selectStatement");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2190:5: ( (w= withClause )? selectStatement[true] -> selectStatement )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2191:5: (w= withClause )? selectStatement[true]
      {
        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2191:5: (w= withClause )?
        int alt252 = 2;
        switch (input.LA(1)) {
          case KW_WITH: {
            alt252 = 1;
          }
          break;
        }

        switch (alt252) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2191:6: w= withClause
          {
            pushFollow(FOLLOW_withClause_in_selectStatementWithCTE13998);
            w = withClause();

            state._fsp--;

            stream_withClause.add(w.getTree());
          }
          break;
        }

        pushFollow(FOLLOW_selectStatement_in_selectStatementWithCTE14006);
        selectStatement860 = selectStatement(true);

        state._fsp--;

        stream_selectStatement.add(selectStatement860.getTree());

        if ((w != null ? ((CommonTree) w.tree) : null) != null) {
          (selectStatement860 != null ? ((CommonTree) selectStatement860.tree) : null).insertChild(0,
              (w != null ? ((CommonTree) w.tree) : null));
        }

        // AST REWRITE
        // elements: selectStatement
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2197:5: -> selectStatement
        {
          adaptor.addChild(root_0, stream_selectStatement.nextTree());
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "selectStatementWithCTE"

  public static class body_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "body"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2200:1: body : ( insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? -> ^( TOK_INSERT insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) | selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? -> ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) );
  public final HiveParser.body_return body() throws RecognitionException {
    HiveParser.body_return retval = new HiveParser.body_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    HiveParser.insertClause_return insertClause861 = null;

    HiveParser_SelectClauseParser.selectClause_return selectClause862 = null;

    HiveParser_FromClauseParser.lateralView_return lateralView863 = null;

    HiveParser_FromClauseParser.whereClause_return whereClause864 = null;

    HiveParser_IdentifiersParser.groupByClause_return groupByClause865 = null;

    HiveParser_IdentifiersParser.havingClause_return havingClause866 = null;

    HiveParser_IdentifiersParser.orderByClause_return orderByClause867 = null;

    HiveParser_IdentifiersParser.clusterByClause_return clusterByClause868 = null;

    HiveParser_IdentifiersParser.distributeByClause_return distributeByClause869 = null;

    HiveParser_IdentifiersParser.sortByClause_return sortByClause870 = null;

    HiveParser_SelectClauseParser.window_clause_return window_clause871 = null;

    HiveParser.limitClause_return limitClause872 = null;

    HiveParser_SelectClauseParser.selectClause_return selectClause873 = null;

    HiveParser_FromClauseParser.lateralView_return lateralView874 = null;

    HiveParser_FromClauseParser.whereClause_return whereClause875 = null;

    HiveParser_IdentifiersParser.groupByClause_return groupByClause876 = null;

    HiveParser_IdentifiersParser.havingClause_return havingClause877 = null;

    HiveParser_IdentifiersParser.orderByClause_return orderByClause878 = null;

    HiveParser_IdentifiersParser.clusterByClause_return clusterByClause879 = null;

    HiveParser_IdentifiersParser.distributeByClause_return distributeByClause880 = null;

    HiveParser_IdentifiersParser.sortByClause_return sortByClause881 = null;

    HiveParser_SelectClauseParser.window_clause_return window_clause882 = null;

    HiveParser.limitClause_return limitClause883 = null;

    RewriteRuleSubtreeStream stream_whereClause = new RewriteRuleSubtreeStream(adaptor, "rule whereClause");
    RewriteRuleSubtreeStream stream_havingClause = new RewriteRuleSubtreeStream(adaptor, "rule havingClause");
    RewriteRuleSubtreeStream stream_clusterByClause = new RewriteRuleSubtreeStream(adaptor, "rule clusterByClause");
    RewriteRuleSubtreeStream stream_lateralView = new RewriteRuleSubtreeStream(adaptor, "rule lateralView");
    RewriteRuleSubtreeStream stream_insertClause = new RewriteRuleSubtreeStream(adaptor, "rule insertClause");
    RewriteRuleSubtreeStream stream_selectClause = new RewriteRuleSubtreeStream(adaptor, "rule selectClause");
    RewriteRuleSubtreeStream stream_sortByClause = new RewriteRuleSubtreeStream(adaptor, "rule sortByClause");
    RewriteRuleSubtreeStream stream_groupByClause = new RewriteRuleSubtreeStream(adaptor, "rule groupByClause");
    RewriteRuleSubtreeStream stream_distributeByClause =
        new RewriteRuleSubtreeStream(adaptor, "rule distributeByClause");
    RewriteRuleSubtreeStream stream_limitClause = new RewriteRuleSubtreeStream(adaptor, "rule limitClause");
    RewriteRuleSubtreeStream stream_orderByClause = new RewriteRuleSubtreeStream(adaptor, "rule orderByClause");
    RewriteRuleSubtreeStream stream_window_clause = new RewriteRuleSubtreeStream(adaptor, "rule window_clause");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2201:4: ( insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? -> ^( TOK_INSERT insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) | selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? -> ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) )
      int alt273 = 2;
      switch (input.LA(1)) {
        case KW_INSERT: {
          alt273 = 1;
        }
        break;
        case KW_MAP:
        case KW_REDUCE:
        case KW_SELECT: {
          alt273 = 2;
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 273, 0, input);

          throw nvae;
      }

      switch (alt273) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2202:4: insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )?
        {
          pushFollow(FOLLOW_insertClause_in_body14037);
          insertClause861 = insertClause();

          state._fsp--;

          stream_insertClause.add(insertClause861.getTree());

          pushFollow(FOLLOW_selectClause_in_body14042);
          selectClause862 = selectClause();

          state._fsp--;

          stream_selectClause.add(selectClause862.getTree());

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2204:4: ( lateralView )?
          int alt253 = 2;
          switch (input.LA(1)) {
            case KW_LATERAL: {
              alt253 = 1;
            }
            break;
          }

          switch (alt253) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2204:4: lateralView
            {
              pushFollow(FOLLOW_lateralView_in_body14047);
              lateralView863 = lateralView();

              state._fsp--;

              stream_lateralView.add(lateralView863.getTree());
            }
            break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2205:4: ( whereClause )?
          int alt254 = 2;
          switch (input.LA(1)) {
            case KW_WHERE: {
              alt254 = 1;
            }
            break;
          }

          switch (alt254) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2205:4: whereClause
            {
              pushFollow(FOLLOW_whereClause_in_body14053);
              whereClause864 = whereClause();

              state._fsp--;

              stream_whereClause.add(whereClause864.getTree());
            }
            break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2206:4: ( groupByClause )?
          int alt255 = 2;
          switch (input.LA(1)) {
            case KW_GROUP: {
              alt255 = 1;
            }
            break;
          }

          switch (alt255) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2206:4: groupByClause
            {
              pushFollow(FOLLOW_groupByClause_in_body14059);
              groupByClause865 = groupByClause();

              state._fsp--;

              stream_groupByClause.add(groupByClause865.getTree());
            }
            break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2207:4: ( havingClause )?
          int alt256 = 2;
          switch (input.LA(1)) {
            case KW_HAVING: {
              alt256 = 1;
            }
            break;
          }

          switch (alt256) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2207:4: havingClause
            {
              pushFollow(FOLLOW_havingClause_in_body14065);
              havingClause866 = havingClause();

              state._fsp--;

              stream_havingClause.add(havingClause866.getTree());
            }
            break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2208:4: ( orderByClause )?
          int alt257 = 2;
          switch (input.LA(1)) {
            case KW_ORDER: {
              alt257 = 1;
            }
            break;
          }

          switch (alt257) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2208:4: orderByClause
            {
              pushFollow(FOLLOW_orderByClause_in_body14071);
              orderByClause867 = orderByClause();

              state._fsp--;

              stream_orderByClause.add(orderByClause867.getTree());
            }
            break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2209:4: ( clusterByClause )?
          int alt258 = 2;
          switch (input.LA(1)) {
            case KW_CLUSTER: {
              alt258 = 1;
            }
            break;
          }

          switch (alt258) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2209:4: clusterByClause
            {
              pushFollow(FOLLOW_clusterByClause_in_body14077);
              clusterByClause868 = clusterByClause();

              state._fsp--;

              stream_clusterByClause.add(clusterByClause868.getTree());
            }
            break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2210:4: ( distributeByClause )?
          int alt259 = 2;
          switch (input.LA(1)) {
            case KW_DISTRIBUTE: {
              alt259 = 1;
            }
            break;
          }

          switch (alt259) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2210:4: distributeByClause
            {
              pushFollow(FOLLOW_distributeByClause_in_body14083);
              distributeByClause869 = distributeByClause();

              state._fsp--;

              stream_distributeByClause.add(distributeByClause869.getTree());
            }
            break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2211:4: ( sortByClause )?
          int alt260 = 2;
          switch (input.LA(1)) {
            case KW_SORT: {
              alt260 = 1;
            }
            break;
          }

          switch (alt260) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2211:4: sortByClause
            {
              pushFollow(FOLLOW_sortByClause_in_body14089);
              sortByClause870 = sortByClause();

              state._fsp--;

              stream_sortByClause.add(sortByClause870.getTree());
            }
            break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2212:4: ( window_clause )?
          int alt261 = 2;
          switch (input.LA(1)) {
            case KW_WINDOW: {
              alt261 = 1;
            }
            break;
          }

          switch (alt261) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2212:4: window_clause
            {
              pushFollow(FOLLOW_window_clause_in_body14095);
              window_clause871 = window_clause();

              state._fsp--;

              stream_window_clause.add(window_clause871.getTree());
            }
            break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2213:4: ( limitClause )?
          int alt262 = 2;
          switch (input.LA(1)) {
            case KW_LIMIT: {
              alt262 = 1;
            }
            break;
          }

          switch (alt262) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2213:4: limitClause
            {
              pushFollow(FOLLOW_limitClause_in_body14101);
              limitClause872 = limitClause();

              state._fsp--;

              stream_limitClause.add(limitClause872.getTree());
            }
            break;
          }

          // AST REWRITE
          // elements: havingClause, lateralView, selectClause, groupByClause, clusterByClause, limitClause, insertClause, orderByClause, whereClause, distributeByClause, window_clause, sortByClause
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2213:17: -> ^( TOK_INSERT insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2213:20: ^( TOK_INSERT insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_INSERT, "TOK_INSERT"), root_1);

              adaptor.addChild(root_1, stream_insertClause.nextTree());

              adaptor.addChild(root_1, stream_selectClause.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2214:35: ( lateralView )?
              if (stream_lateralView.hasNext()) {
                adaptor.addChild(root_1, stream_lateralView.nextTree());
              }
              stream_lateralView.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2214:48: ( whereClause )?
              if (stream_whereClause.hasNext()) {
                adaptor.addChild(root_1, stream_whereClause.nextTree());
              }
              stream_whereClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2214:61: ( groupByClause )?
              if (stream_groupByClause.hasNext()) {
                adaptor.addChild(root_1, stream_groupByClause.nextTree());
              }
              stream_groupByClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2214:76: ( havingClause )?
              if (stream_havingClause.hasNext()) {
                adaptor.addChild(root_1, stream_havingClause.nextTree());
              }
              stream_havingClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2214:90: ( orderByClause )?
              if (stream_orderByClause.hasNext()) {
                adaptor.addChild(root_1, stream_orderByClause.nextTree());
              }
              stream_orderByClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2214:105: ( clusterByClause )?
              if (stream_clusterByClause.hasNext()) {
                adaptor.addChild(root_1, stream_clusterByClause.nextTree());
              }
              stream_clusterByClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2215:22: ( distributeByClause )?
              if (stream_distributeByClause.hasNext()) {
                adaptor.addChild(root_1, stream_distributeByClause.nextTree());
              }
              stream_distributeByClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2215:42: ( sortByClause )?
              if (stream_sortByClause.hasNext()) {
                adaptor.addChild(root_1, stream_sortByClause.nextTree());
              }
              stream_sortByClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2215:56: ( window_clause )?
              if (stream_window_clause.hasNext()) {
                adaptor.addChild(root_1, stream_window_clause.nextTree());
              }
              stream_window_clause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2215:71: ( limitClause )?
              if (stream_limitClause.hasNext()) {
                adaptor.addChild(root_1, stream_limitClause.nextTree());
              }
              stream_limitClause.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2217:4: selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )?
        {
          pushFollow(FOLLOW_selectClause_in_body14194);
          selectClause873 = selectClause();

          state._fsp--;

          stream_selectClause.add(selectClause873.getTree());

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2218:4: ( lateralView )?
          int alt263 = 2;
          switch (input.LA(1)) {
            case KW_LATERAL: {
              alt263 = 1;
            }
            break;
          }

          switch (alt263) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2218:4: lateralView
            {
              pushFollow(FOLLOW_lateralView_in_body14199);
              lateralView874 = lateralView();

              state._fsp--;

              stream_lateralView.add(lateralView874.getTree());
            }
            break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2219:4: ( whereClause )?
          int alt264 = 2;
          switch (input.LA(1)) {
            case KW_WHERE: {
              alt264 = 1;
            }
            break;
          }

          switch (alt264) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2219:4: whereClause
            {
              pushFollow(FOLLOW_whereClause_in_body14205);
              whereClause875 = whereClause();

              state._fsp--;

              stream_whereClause.add(whereClause875.getTree());
            }
            break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2220:4: ( groupByClause )?
          int alt265 = 2;
          switch (input.LA(1)) {
            case KW_GROUP: {
              alt265 = 1;
            }
            break;
          }

          switch (alt265) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2220:4: groupByClause
            {
              pushFollow(FOLLOW_groupByClause_in_body14211);
              groupByClause876 = groupByClause();

              state._fsp--;

              stream_groupByClause.add(groupByClause876.getTree());
            }
            break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2221:4: ( havingClause )?
          int alt266 = 2;
          switch (input.LA(1)) {
            case KW_HAVING: {
              alt266 = 1;
            }
            break;
          }

          switch (alt266) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2221:4: havingClause
            {
              pushFollow(FOLLOW_havingClause_in_body14217);
              havingClause877 = havingClause();

              state._fsp--;

              stream_havingClause.add(havingClause877.getTree());
            }
            break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2222:4: ( orderByClause )?
          int alt267 = 2;
          switch (input.LA(1)) {
            case KW_ORDER: {
              alt267 = 1;
            }
            break;
          }

          switch (alt267) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2222:4: orderByClause
            {
              pushFollow(FOLLOW_orderByClause_in_body14223);
              orderByClause878 = orderByClause();

              state._fsp--;

              stream_orderByClause.add(orderByClause878.getTree());
            }
            break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2223:4: ( clusterByClause )?
          int alt268 = 2;
          switch (input.LA(1)) {
            case KW_CLUSTER: {
              alt268 = 1;
            }
            break;
          }

          switch (alt268) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2223:4: clusterByClause
            {
              pushFollow(FOLLOW_clusterByClause_in_body14229);
              clusterByClause879 = clusterByClause();

              state._fsp--;

              stream_clusterByClause.add(clusterByClause879.getTree());
            }
            break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2224:4: ( distributeByClause )?
          int alt269 = 2;
          switch (input.LA(1)) {
            case KW_DISTRIBUTE: {
              alt269 = 1;
            }
            break;
          }

          switch (alt269) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2224:4: distributeByClause
            {
              pushFollow(FOLLOW_distributeByClause_in_body14235);
              distributeByClause880 = distributeByClause();

              state._fsp--;

              stream_distributeByClause.add(distributeByClause880.getTree());
            }
            break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2225:4: ( sortByClause )?
          int alt270 = 2;
          switch (input.LA(1)) {
            case KW_SORT: {
              alt270 = 1;
            }
            break;
          }

          switch (alt270) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2225:4: sortByClause
            {
              pushFollow(FOLLOW_sortByClause_in_body14241);
              sortByClause881 = sortByClause();

              state._fsp--;

              stream_sortByClause.add(sortByClause881.getTree());
            }
            break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2226:4: ( window_clause )?
          int alt271 = 2;
          switch (input.LA(1)) {
            case KW_WINDOW: {
              alt271 = 1;
            }
            break;
          }

          switch (alt271) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2226:4: window_clause
            {
              pushFollow(FOLLOW_window_clause_in_body14247);
              window_clause882 = window_clause();

              state._fsp--;

              stream_window_clause.add(window_clause882.getTree());
            }
            break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2227:4: ( limitClause )?
          int alt272 = 2;
          switch (input.LA(1)) {
            case KW_LIMIT: {
              alt272 = 1;
            }
            break;
          }

          switch (alt272) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2227:4: limitClause
            {
              pushFollow(FOLLOW_limitClause_in_body14253);
              limitClause883 = limitClause();

              state._fsp--;

              stream_limitClause.add(limitClause883.getTree());
            }
            break;
          }

          // AST REWRITE
          // elements: sortByClause, groupByClause, orderByClause, whereClause, lateralView, window_clause, limitClause, havingClause, clusterByClause, distributeByClause, selectClause
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2227:17: -> ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2227:20: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_INSERT, "TOK_INSERT"), root_1);

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2227:33: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
              {
                CommonTree root_2 = (CommonTree) adaptor.nil();
                root_2 =
                    (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"),
                        root_2);

                // org/apache/hadoop/hive/ql/parse/HiveParser.g:2227:51: ^( TOK_DIR TOK_TMP_FILE )
                {
                  CommonTree root_3 = (CommonTree) adaptor.nil();
                  root_3 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DIR, "TOK_DIR"), root_3);

                  adaptor.addChild(root_3, (CommonTree) adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE"));

                  adaptor.addChild(root_2, root_3);
                }

                adaptor.addChild(root_1, root_2);
              }

              adaptor.addChild(root_1, stream_selectClause.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2228:35: ( lateralView )?
              if (stream_lateralView.hasNext()) {
                adaptor.addChild(root_1, stream_lateralView.nextTree());
              }
              stream_lateralView.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2228:48: ( whereClause )?
              if (stream_whereClause.hasNext()) {
                adaptor.addChild(root_1, stream_whereClause.nextTree());
              }
              stream_whereClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2228:61: ( groupByClause )?
              if (stream_groupByClause.hasNext()) {
                adaptor.addChild(root_1, stream_groupByClause.nextTree());
              }
              stream_groupByClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2228:76: ( havingClause )?
              if (stream_havingClause.hasNext()) {
                adaptor.addChild(root_1, stream_havingClause.nextTree());
              }
              stream_havingClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2228:90: ( orderByClause )?
              if (stream_orderByClause.hasNext()) {
                adaptor.addChild(root_1, stream_orderByClause.nextTree());
              }
              stream_orderByClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2228:105: ( clusterByClause )?
              if (stream_clusterByClause.hasNext()) {
                adaptor.addChild(root_1, stream_clusterByClause.nextTree());
              }
              stream_clusterByClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2229:22: ( distributeByClause )?
              if (stream_distributeByClause.hasNext()) {
                adaptor.addChild(root_1, stream_distributeByClause.nextTree());
              }
              stream_distributeByClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2229:42: ( sortByClause )?
              if (stream_sortByClause.hasNext()) {
                adaptor.addChild(root_1, stream_sortByClause.nextTree());
              }
              stream_sortByClause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2229:56: ( window_clause )?
              if (stream_window_clause.hasNext()) {
                adaptor.addChild(root_1, stream_window_clause.nextTree());
              }
              stream_window_clause.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2229:71: ( limitClause )?
              if (stream_limitClause.hasNext()) {
                adaptor.addChild(root_1, stream_limitClause.nextTree());
              }
              stream_limitClause.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "body"

  public static class insertClause_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "insertClause"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2232:1: insertClause : ( KW_INSERT KW_OVERWRITE destination ( ifNotExists )? -> ^( TOK_DESTINATION destination ( ifNotExists )? ) | KW_INSERT KW_INTO ( KW_TABLE )? tableOrPartition -> ^( TOK_INSERT_INTO tableOrPartition ) );
  public final HiveParser.insertClause_return insertClause() throws RecognitionException {
    HiveParser.insertClause_return retval = new HiveParser.insertClause_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_INSERT884 = null;
    Token KW_OVERWRITE885 = null;
    Token KW_INSERT888 = null;
    Token KW_INTO889 = null;
    Token KW_TABLE890 = null;
    HiveParser.destination_return destination886 = null;

    HiveParser.ifNotExists_return ifNotExists887 = null;

    HiveParser_IdentifiersParser.tableOrPartition_return tableOrPartition891 = null;

    CommonTree KW_INSERT884_tree = null;
    CommonTree KW_OVERWRITE885_tree = null;
    CommonTree KW_INSERT888_tree = null;
    CommonTree KW_INTO889_tree = null;
    CommonTree KW_TABLE890_tree = null;
    RewriteRuleTokenStream stream_KW_INTO = new RewriteRuleTokenStream(adaptor, "token KW_INTO");
    RewriteRuleTokenStream stream_KW_INSERT = new RewriteRuleTokenStream(adaptor, "token KW_INSERT");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleTokenStream stream_KW_OVERWRITE = new RewriteRuleTokenStream(adaptor, "token KW_OVERWRITE");
    RewriteRuleSubtreeStream stream_destination = new RewriteRuleSubtreeStream(adaptor, "rule destination");
    RewriteRuleSubtreeStream stream_ifNotExists = new RewriteRuleSubtreeStream(adaptor, "rule ifNotExists");
    RewriteRuleSubtreeStream stream_tableOrPartition = new RewriteRuleSubtreeStream(adaptor, "rule tableOrPartition");
    pushMsg("insert clause", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2235:4: ( KW_INSERT KW_OVERWRITE destination ( ifNotExists )? -> ^( TOK_DESTINATION destination ( ifNotExists )? ) | KW_INSERT KW_INTO ( KW_TABLE )? tableOrPartition -> ^( TOK_INSERT_INTO tableOrPartition ) )
      int alt276 = 2;
      switch (input.LA(1)) {
        case KW_INSERT: {
          switch (input.LA(2)) {
            case KW_OVERWRITE: {
              alt276 = 1;
            }
            break;
            case KW_INTO: {
              alt276 = 2;
            }
            break;
            default:
              NoViableAltException nvae = new NoViableAltException("", 276, 1, input);

              throw nvae;
          }
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 276, 0, input);

          throw nvae;
      }

      switch (alt276) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2236:6: KW_INSERT KW_OVERWRITE destination ( ifNotExists )?
        {
          KW_INSERT884 = (Token) match(input, KW_INSERT, FOLLOW_KW_INSERT_in_insertClause14374);
          stream_KW_INSERT.add(KW_INSERT884);

          KW_OVERWRITE885 = (Token) match(input, KW_OVERWRITE, FOLLOW_KW_OVERWRITE_in_insertClause14376);
          stream_KW_OVERWRITE.add(KW_OVERWRITE885);

          pushFollow(FOLLOW_destination_in_insertClause14378);
          destination886 = destination();

          state._fsp--;

          stream_destination.add(destination886.getTree());

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2236:41: ( ifNotExists )?
          int alt274 = 2;
          switch (input.LA(1)) {
            case KW_IF: {
              alt274 = 1;
            }
            break;
          }

          switch (alt274) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2236:41: ifNotExists
            {
              pushFollow(FOLLOW_ifNotExists_in_insertClause14380);
              ifNotExists887 = ifNotExists();

              state._fsp--;

              stream_ifNotExists.add(ifNotExists887.getTree());
            }
            break;
          }

          // AST REWRITE
          // elements: destination, ifNotExists
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2236:54: -> ^( TOK_DESTINATION destination ( ifNotExists )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2236:57: ^( TOK_DESTINATION destination ( ifNotExists )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"),
                  root_1);

              adaptor.addChild(root_1, stream_destination.nextTree());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2236:87: ( ifNotExists )?
              if (stream_ifNotExists.hasNext()) {
                adaptor.addChild(root_1, stream_ifNotExists.nextTree());
              }
              stream_ifNotExists.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2237:6: KW_INSERT KW_INTO ( KW_TABLE )? tableOrPartition
        {
          KW_INSERT888 = (Token) match(input, KW_INSERT, FOLLOW_KW_INSERT_in_insertClause14399);
          stream_KW_INSERT.add(KW_INSERT888);

          KW_INTO889 = (Token) match(input, KW_INTO, FOLLOW_KW_INTO_in_insertClause14401);
          stream_KW_INTO.add(KW_INTO889);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2237:24: ( KW_TABLE )?
          int alt275 = 2;
          switch (input.LA(1)) {
            case KW_TABLE: {
              switch (input.LA(2)) {
                case Identifier:
                case KW_ADD:
                case KW_ADMIN:
                case KW_AFTER:
                case KW_ALL:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_AUTHORIZATION:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPACT:
                case KW_COMPACTIONS:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFAULT:
                case KW_DEFERRED:
                case KW_DEFINED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILE:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_JAR:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_METADATA:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NONE:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_OWNER:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PRINCIPALS:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RELOAD:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_REPLICATION:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_REWRITE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLES:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SERVER:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRANSACTIONS:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_URI:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH: {
                  alt275 = 1;
                }
                break;
                case KW_PARTITION: {
                  switch (input.LA(3)) {
                    case DOT:
                    case KW_MAP:
                    case KW_PARTITION:
                    case KW_REDUCE:
                    case KW_SELECT:
                    case KW_VALUES: {
                      alt275 = 1;
                    }
                    break;
                  }
                }
                break;
                case KW_VALUES: {
                  switch (input.LA(3)) {
                    case DOT:
                    case KW_MAP:
                    case KW_PARTITION:
                    case KW_REDUCE:
                    case KW_SELECT:
                    case KW_VALUES: {
                      alt275 = 1;
                    }
                    break;
                  }
                }
                break;
              }
            }
            break;
          }

          switch (alt275) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2237:24: KW_TABLE
            {
              KW_TABLE890 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_insertClause14403);
              stream_KW_TABLE.add(KW_TABLE890);
            }
            break;
          }

          pushFollow(FOLLOW_tableOrPartition_in_insertClause14406);
          tableOrPartition891 = tableOrPartition();

          state._fsp--;

          stream_tableOrPartition.add(tableOrPartition891.getTree());

          // AST REWRITE
          // elements: tableOrPartition
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2238:8: -> ^( TOK_INSERT_INTO tableOrPartition )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2238:11: ^( TOK_INSERT_INTO tableOrPartition )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_INSERT_INTO, "TOK_INSERT_INTO"),
                  root_1);

              adaptor.addChild(root_1, stream_tableOrPartition.nextTree());

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "insertClause"

  public static class destination_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "destination"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2241:1: destination : ( (local= KW_LOCAL )? KW_DIRECTORY StringLiteral ( tableRowFormat )? ( tableFileFormat )? -> ^( TOK_DIR StringLiteral ( $local)? ( tableRowFormat )? ( tableFileFormat )? ) | KW_TABLE tableOrPartition -> tableOrPartition );
  public final HiveParser.destination_return destination() throws RecognitionException {
    HiveParser.destination_return retval = new HiveParser.destination_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token local = null;
    Token KW_DIRECTORY892 = null;
    Token StringLiteral893 = null;
    Token KW_TABLE896 = null;
    HiveParser.tableRowFormat_return tableRowFormat894 = null;

    HiveParser.tableFileFormat_return tableFileFormat895 = null;

    HiveParser_IdentifiersParser.tableOrPartition_return tableOrPartition897 = null;

    CommonTree local_tree = null;
    CommonTree KW_DIRECTORY892_tree = null;
    CommonTree StringLiteral893_tree = null;
    CommonTree KW_TABLE896_tree = null;
    RewriteRuleTokenStream stream_StringLiteral = new RewriteRuleTokenStream(adaptor, "token StringLiteral");
    RewriteRuleTokenStream stream_KW_DIRECTORY = new RewriteRuleTokenStream(adaptor, "token KW_DIRECTORY");
    RewriteRuleTokenStream stream_KW_TABLE = new RewriteRuleTokenStream(adaptor, "token KW_TABLE");
    RewriteRuleTokenStream stream_KW_LOCAL = new RewriteRuleTokenStream(adaptor, "token KW_LOCAL");
    RewriteRuleSubtreeStream stream_tableRowFormat = new RewriteRuleSubtreeStream(adaptor, "rule tableRowFormat");
    RewriteRuleSubtreeStream stream_tableFileFormat = new RewriteRuleSubtreeStream(adaptor, "rule tableFileFormat");
    RewriteRuleSubtreeStream stream_tableOrPartition = new RewriteRuleSubtreeStream(adaptor, "rule tableOrPartition");
    pushMsg("destination specification", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2244:4: ( (local= KW_LOCAL )? KW_DIRECTORY StringLiteral ( tableRowFormat )? ( tableFileFormat )? -> ^( TOK_DIR StringLiteral ( $local)? ( tableRowFormat )? ( tableFileFormat )? ) | KW_TABLE tableOrPartition -> tableOrPartition )
      int alt280 = 2;
      switch (input.LA(1)) {
        case KW_DIRECTORY:
        case KW_LOCAL: {
          alt280 = 1;
        }
        break;
        case KW_TABLE: {
          alt280 = 2;
        }
        break;
        default:
          NoViableAltException nvae = new NoViableAltException("", 280, 0, input);

          throw nvae;
      }

      switch (alt280) {
        case 1:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2245:6: (local= KW_LOCAL )? KW_DIRECTORY StringLiteral ( tableRowFormat )? ( tableFileFormat )?
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2245:6: (local= KW_LOCAL )?
          int alt277 = 2;
          switch (input.LA(1)) {
            case KW_LOCAL: {
              alt277 = 1;
            }
            break;
          }

          switch (alt277) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2245:7: local= KW_LOCAL
            {
              local = (Token) match(input, KW_LOCAL, FOLLOW_KW_LOCAL_in_destination14456);
              stream_KW_LOCAL.add(local);
            }
            break;
          }

          KW_DIRECTORY892 = (Token) match(input, KW_DIRECTORY, FOLLOW_KW_DIRECTORY_in_destination14460);
          stream_KW_DIRECTORY.add(KW_DIRECTORY892);

          StringLiteral893 = (Token) match(input, StringLiteral, FOLLOW_StringLiteral_in_destination14462);
          stream_StringLiteral.add(StringLiteral893);

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2245:53: ( tableRowFormat )?
          int alt278 = 2;
          switch (input.LA(1)) {
            case KW_ROW: {
              alt278 = 1;
            }
            break;
          }

          switch (alt278) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2245:53: tableRowFormat
            {
              pushFollow(FOLLOW_tableRowFormat_in_destination14464);
              tableRowFormat894 = tableRowFormat();

              state._fsp--;

              stream_tableRowFormat.add(tableRowFormat894.getTree());
            }
            break;
          }

          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2245:69: ( tableFileFormat )?
          int alt279 = 2;
          switch (input.LA(1)) {
            case KW_STORED: {
              alt279 = 1;
            }
            break;
          }

          switch (alt279) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2245:69: tableFileFormat
            {
              pushFollow(FOLLOW_tableFileFormat_in_destination14467);
              tableFileFormat895 = tableFileFormat();

              state._fsp--;

              stream_tableFileFormat.add(tableFileFormat895.getTree());
            }
            break;
          }

          // AST REWRITE
          // elements: tableFileFormat, local, tableRowFormat, StringLiteral
          // token labels: local
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleTokenStream stream_local = new RewriteRuleTokenStream(adaptor, "token local", local);
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2246:8: -> ^( TOK_DIR StringLiteral ( $local)? ( tableRowFormat )? ( tableFileFormat )? )
          {
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2246:11: ^( TOK_DIR StringLiteral ( $local)? ( tableRowFormat )? ( tableFileFormat )? )
            {
              CommonTree root_1 = (CommonTree) adaptor.nil();
              root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DIR, "TOK_DIR"), root_1);

              adaptor.addChild(root_1, stream_StringLiteral.nextNode());

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2246:36: ( $local)?
              if (stream_local.hasNext()) {
                adaptor.addChild(root_1, stream_local.nextNode());
              }
              stream_local.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2246:43: ( tableRowFormat )?
              if (stream_tableRowFormat.hasNext()) {
                adaptor.addChild(root_1, stream_tableRowFormat.nextTree());
              }
              stream_tableRowFormat.reset();

              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2246:59: ( tableFileFormat )?
              if (stream_tableFileFormat.hasNext()) {
                adaptor.addChild(root_1, stream_tableFileFormat.nextTree());
              }
              stream_tableFileFormat.reset();

              adaptor.addChild(root_0, root_1);
            }
          }

          retval.tree = root_0;
        }
        break;
        case 2:
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2247:6: KW_TABLE tableOrPartition
        {
          KW_TABLE896 = (Token) match(input, KW_TABLE, FOLLOW_KW_TABLE_in_destination14500);
          stream_KW_TABLE.add(KW_TABLE896);

          pushFollow(FOLLOW_tableOrPartition_in_destination14502);
          tableOrPartition897 = tableOrPartition();

          state._fsp--;

          stream_tableOrPartition.add(tableOrPartition897.getTree());

          // AST REWRITE
          // elements: tableOrPartition
          // token labels:
          // rule labels: retval
          // token list labels:
          // rule list labels:
          // wildcard labels:
          retval.tree = root_0;
          RewriteRuleSubtreeStream stream_retval =
              new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

          root_0 = (CommonTree) adaptor.nil();
          // 2247:32: -> tableOrPartition
          {
            adaptor.addChild(root_0, stream_tableOrPartition.nextTree());
          }

          retval.tree = root_0;
        }
        break;
      }
      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "destination"

  public static class limitClause_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "limitClause"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2250:1: limitClause : KW_LIMIT num= Number -> ^( TOK_LIMIT $num) ;
  public final HiveParser.limitClause_return limitClause() throws RecognitionException {
    HiveParser.limitClause_return retval = new HiveParser.limitClause_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token num = null;
    Token KW_LIMIT898 = null;

    CommonTree num_tree = null;
    CommonTree KW_LIMIT898_tree = null;
    RewriteRuleTokenStream stream_Number = new RewriteRuleTokenStream(adaptor, "token Number");
    RewriteRuleTokenStream stream_KW_LIMIT = new RewriteRuleTokenStream(adaptor, "token KW_LIMIT");

    pushMsg("limit clause", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2253:4: ( KW_LIMIT num= Number -> ^( TOK_LIMIT $num) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2254:4: KW_LIMIT num= Number
      {
        KW_LIMIT898 = (Token) match(input, KW_LIMIT, FOLLOW_KW_LIMIT_in_limitClause14534);
        stream_KW_LIMIT.add(KW_LIMIT898);

        num = (Token) match(input, Number, FOLLOW_Number_in_limitClause14538);
        stream_Number.add(num);

        // AST REWRITE
        // elements: num
        // token labels: num
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleTokenStream stream_num = new RewriteRuleTokenStream(adaptor, "token num", num);
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2254:24: -> ^( TOK_LIMIT $num)
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2254:27: ^( TOK_LIMIT $num)
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_LIMIT, "TOK_LIMIT"), root_1);

            adaptor.addChild(root_1, stream_num.nextNode());

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "limitClause"

  public static class deleteStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "deleteStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2258:1: deleteStatement : KW_DELETE KW_FROM tableName ( whereClause )? -> ^( TOK_DELETE_FROM tableName ( whereClause )? ) ;
  public final HiveParser.deleteStatement_return deleteStatement() throws RecognitionException {
    HiveParser.deleteStatement_return retval = new HiveParser.deleteStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_DELETE899 = null;
    Token KW_FROM900 = null;
    HiveParser_FromClauseParser.tableName_return tableName901 = null;

    HiveParser_FromClauseParser.whereClause_return whereClause902 = null;

    CommonTree KW_DELETE899_tree = null;
    CommonTree KW_FROM900_tree = null;
    RewriteRuleTokenStream stream_KW_DELETE = new RewriteRuleTokenStream(adaptor, "token KW_DELETE");
    RewriteRuleTokenStream stream_KW_FROM = new RewriteRuleTokenStream(adaptor, "token KW_FROM");
    RewriteRuleSubtreeStream stream_whereClause = new RewriteRuleSubtreeStream(adaptor, "rule whereClause");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    pushMsg("delete statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2261:4: ( KW_DELETE KW_FROM tableName ( whereClause )? -> ^( TOK_DELETE_FROM tableName ( whereClause )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2262:4: KW_DELETE KW_FROM tableName ( whereClause )?
      {
        KW_DELETE899 = (Token) match(input, KW_DELETE, FOLLOW_KW_DELETE_in_deleteStatement14576);
        stream_KW_DELETE.add(KW_DELETE899);

        KW_FROM900 = (Token) match(input, KW_FROM, FOLLOW_KW_FROM_in_deleteStatement14578);
        stream_KW_FROM.add(KW_FROM900);

        pushFollow(FOLLOW_tableName_in_deleteStatement14580);
        tableName901 = tableName();

        state._fsp--;

        stream_tableName.add(tableName901.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2262:32: ( whereClause )?
        int alt281 = 2;
        switch (input.LA(1)) {
          case KW_WHERE: {
            alt281 = 1;
          }
          break;
        }

        switch (alt281) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2262:33: whereClause
          {
            pushFollow(FOLLOW_whereClause_in_deleteStatement14583);
            whereClause902 = whereClause();

            state._fsp--;

            stream_whereClause.add(whereClause902.getTree());
          }
          break;
        }

        // AST REWRITE
        // elements: whereClause, tableName
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2262:47: -> ^( TOK_DELETE_FROM tableName ( whereClause )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2262:50: ^( TOK_DELETE_FROM tableName ( whereClause )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_DELETE_FROM, "TOK_DELETE_FROM"),
                root_1);

            adaptor.addChild(root_1, stream_tableName.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2262:78: ( whereClause )?
            if (stream_whereClause.hasNext()) {
              adaptor.addChild(root_1, stream_whereClause.nextTree());
            }
            stream_whereClause.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "deleteStatement"

  public static class columnAssignmentClause_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "columnAssignmentClause"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2266:1: columnAssignmentClause : tableOrColumn EQUAL ^ precedencePlusExpression ;
  public final HiveParser.columnAssignmentClause_return columnAssignmentClause() throws RecognitionException {
    HiveParser.columnAssignmentClause_return retval = new HiveParser.columnAssignmentClause_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token EQUAL904 = null;
    HiveParser_FromClauseParser.tableOrColumn_return tableOrColumn903 = null;

    HiveParser_IdentifiersParser.precedencePlusExpression_return precedencePlusExpression905 = null;

    CommonTree EQUAL904_tree = null;

    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2267:4: ( tableOrColumn EQUAL ^ precedencePlusExpression )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2268:4: tableOrColumn EQUAL ^ precedencePlusExpression
      {
        root_0 = (CommonTree) adaptor.nil();

        pushFollow(FOLLOW_tableOrColumn_in_columnAssignmentClause14616);
        tableOrColumn903 = tableOrColumn();

        state._fsp--;

        adaptor.addChild(root_0, tableOrColumn903.getTree());

        EQUAL904 = (Token) match(input, EQUAL, FOLLOW_EQUAL_in_columnAssignmentClause14618);
        EQUAL904_tree = (CommonTree) adaptor.create(EQUAL904);
        root_0 = (CommonTree) adaptor.becomeRoot(EQUAL904_tree, root_0);

        pushFollow(FOLLOW_precedencePlusExpression_in_columnAssignmentClause14621);
        precedencePlusExpression905 = precedencePlusExpression();

        state._fsp--;

        adaptor.addChild(root_0, precedencePlusExpression905.getTree());
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "columnAssignmentClause"

  public static class setColumnsClause_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "setColumnsClause"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2272:1: setColumnsClause : KW_SET columnAssignmentClause ( COMMA columnAssignmentClause )* -> ^( TOK_SET_COLUMNS_CLAUSE ( columnAssignmentClause )* ) ;
  public final HiveParser.setColumnsClause_return setColumnsClause() throws RecognitionException {
    HiveParser.setColumnsClause_return retval = new HiveParser.setColumnsClause_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_SET906 = null;
    Token COMMA908 = null;
    HiveParser.columnAssignmentClause_return columnAssignmentClause907 = null;

    HiveParser.columnAssignmentClause_return columnAssignmentClause909 = null;

    CommonTree KW_SET906_tree = null;
    CommonTree COMMA908_tree = null;
    RewriteRuleTokenStream stream_COMMA = new RewriteRuleTokenStream(adaptor, "token COMMA");
    RewriteRuleTokenStream stream_KW_SET = new RewriteRuleTokenStream(adaptor, "token KW_SET");
    RewriteRuleSubtreeStream stream_columnAssignmentClause =
        new RewriteRuleSubtreeStream(adaptor, "rule columnAssignmentClause");
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2273:4: ( KW_SET columnAssignmentClause ( COMMA columnAssignmentClause )* -> ^( TOK_SET_COLUMNS_CLAUSE ( columnAssignmentClause )* ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2274:4: KW_SET columnAssignmentClause ( COMMA columnAssignmentClause )*
      {
        KW_SET906 = (Token) match(input, KW_SET, FOLLOW_KW_SET_in_setColumnsClause14641);
        stream_KW_SET.add(KW_SET906);

        pushFollow(FOLLOW_columnAssignmentClause_in_setColumnsClause14643);
        columnAssignmentClause907 = columnAssignmentClause();

        state._fsp--;

        stream_columnAssignmentClause.add(columnAssignmentClause907.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2274:34: ( COMMA columnAssignmentClause )*
        loop282:
        do {
          int alt282 = 2;
          switch (input.LA(1)) {
            case COMMA: {
              alt282 = 1;
            }
            break;
          }

          switch (alt282) {
            case 1:
              // org/apache/hadoop/hive/ql/parse/HiveParser.g:2274:35: COMMA columnAssignmentClause
            {
              COMMA908 = (Token) match(input, COMMA, FOLLOW_COMMA_in_setColumnsClause14646);
              stream_COMMA.add(COMMA908);

              pushFollow(FOLLOW_columnAssignmentClause_in_setColumnsClause14648);
              columnAssignmentClause909 = columnAssignmentClause();

              state._fsp--;

              stream_columnAssignmentClause.add(columnAssignmentClause909.getTree());
            }
            break;

            default:
              break loop282;
          }
        } while (true);

        // AST REWRITE
        // elements: columnAssignmentClause
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2274:66: -> ^( TOK_SET_COLUMNS_CLAUSE ( columnAssignmentClause )* )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2274:69: ^( TOK_SET_COLUMNS_CLAUSE ( columnAssignmentClause )* )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot(
                (CommonTree) adaptor.create(TOK_SET_COLUMNS_CLAUSE, "TOK_SET_COLUMNS_CLAUSE"), root_1);

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2274:94: ( columnAssignmentClause )*
            while (stream_columnAssignmentClause.hasNext()) {
              adaptor.addChild(root_1, stream_columnAssignmentClause.nextTree());
            }
            stream_columnAssignmentClause.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "setColumnsClause"

  public static class updateStatement_return extends ParserRuleReturnScope {
    CommonTree tree;

    public Object getTree() {
      return tree;
    }
  }

  ;

  // $ANTLR start "updateStatement"
  // org/apache/hadoop/hive/ql/parse/HiveParser.g:2281:1: updateStatement : KW_UPDATE tableName setColumnsClause ( whereClause )? -> ^( TOK_UPDATE_TABLE tableName setColumnsClause ( whereClause )? ) ;
  public final HiveParser.updateStatement_return updateStatement() throws RecognitionException {
    HiveParser.updateStatement_return retval = new HiveParser.updateStatement_return();
    retval.start = input.LT(1);

    CommonTree root_0 = null;

    Token KW_UPDATE910 = null;
    HiveParser_FromClauseParser.tableName_return tableName911 = null;

    HiveParser.setColumnsClause_return setColumnsClause912 = null;

    HiveParser_FromClauseParser.whereClause_return whereClause913 = null;

    CommonTree KW_UPDATE910_tree = null;
    RewriteRuleTokenStream stream_KW_UPDATE = new RewriteRuleTokenStream(adaptor, "token KW_UPDATE");
    RewriteRuleSubtreeStream stream_setColumnsClause = new RewriteRuleSubtreeStream(adaptor, "rule setColumnsClause");
    RewriteRuleSubtreeStream stream_whereClause = new RewriteRuleSubtreeStream(adaptor, "rule whereClause");
    RewriteRuleSubtreeStream stream_tableName = new RewriteRuleSubtreeStream(adaptor, "rule tableName");
    pushMsg("update statement", state);
    try {
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2284:4: ( KW_UPDATE tableName setColumnsClause ( whereClause )? -> ^( TOK_UPDATE_TABLE tableName setColumnsClause ( whereClause )? ) )
      // org/apache/hadoop/hive/ql/parse/HiveParser.g:2285:4: KW_UPDATE tableName setColumnsClause ( whereClause )?
      {
        KW_UPDATE910 = (Token) match(input, KW_UPDATE, FOLLOW_KW_UPDATE_in_updateStatement14690);
        stream_KW_UPDATE.add(KW_UPDATE910);

        pushFollow(FOLLOW_tableName_in_updateStatement14692);
        tableName911 = tableName();

        state._fsp--;

        stream_tableName.add(tableName911.getTree());

        pushFollow(FOLLOW_setColumnsClause_in_updateStatement14694);
        setColumnsClause912 = setColumnsClause();

        state._fsp--;

        stream_setColumnsClause.add(setColumnsClause912.getTree());

        // org/apache/hadoop/hive/ql/parse/HiveParser.g:2285:41: ( whereClause )?
        int alt283 = 2;
        switch (input.LA(1)) {
          case KW_WHERE: {
            alt283 = 1;
          }
          break;
        }

        switch (alt283) {
          case 1:
            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2285:41: whereClause
          {
            pushFollow(FOLLOW_whereClause_in_updateStatement14696);
            whereClause913 = whereClause();

            state._fsp--;

            stream_whereClause.add(whereClause913.getTree());
          }
          break;
        }

        // AST REWRITE
        // elements: tableName, whereClause, setColumnsClause
        // token labels:
        // rule labels: retval
        // token list labels:
        // rule list labels:
        // wildcard labels:
        retval.tree = root_0;
        RewriteRuleSubtreeStream stream_retval =
            new RewriteRuleSubtreeStream(adaptor, "rule retval", retval != null ? retval.tree : null);

        root_0 = (CommonTree) adaptor.nil();
        // 2285:54: -> ^( TOK_UPDATE_TABLE tableName setColumnsClause ( whereClause )? )
        {
          // org/apache/hadoop/hive/ql/parse/HiveParser.g:2285:57: ^( TOK_UPDATE_TABLE tableName setColumnsClause ( whereClause )? )
          {
            CommonTree root_1 = (CommonTree) adaptor.nil();
            root_1 = (CommonTree) adaptor.becomeRoot((CommonTree) adaptor.create(TOK_UPDATE_TABLE, "TOK_UPDATE_TABLE"),
                root_1);

            adaptor.addChild(root_1, stream_tableName.nextTree());

            adaptor.addChild(root_1, stream_setColumnsClause.nextTree());

            // org/apache/hadoop/hive/ql/parse/HiveParser.g:2285:103: ( whereClause )?
            if (stream_whereClause.hasNext()) {
              adaptor.addChild(root_1, stream_whereClause.nextTree());
            }
            stream_whereClause.reset();

            adaptor.addChild(root_0, root_1);
          }
        }

        retval.tree = root_0;
      }

      retval.stop = input.LT(-1);

      retval.tree = (CommonTree) adaptor.rulePostProcessing(root_0);
      adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

      popMsg(state);
    } catch (RecognitionException e) {
      reportError(e);
      throw e;
    } finally {
      // do for sure before leaving
    }
    return retval;
  }
  // $ANTLR end "updateStatement"

  // Delegated rules
  public HiveParser_IdentifiersParser.precedenceEqualExpression_return precedenceEqualExpression()
      throws RecognitionException {
    return gIdentifiersParser.precedenceEqualExpression();
  }

  public HiveParser_IdentifiersParser.sortByClause_return sortByClause() throws RecognitionException {
    return gIdentifiersParser.sortByClause();
  }

  public HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression_return precedenceUnaryPrefixExpression()
      throws RecognitionException {
    return gIdentifiersParser.precedenceUnaryPrefixExpression();
  }

  public HiveParser_IdentifiersParser.precedenceAndOperator_return precedenceAndOperator() throws RecognitionException {
    return gIdentifiersParser.precedenceAndOperator();
  }

  public HiveParser_FromClauseParser.subQuerySource_return subQuerySource() throws RecognitionException {
    return gFromClauseParser.subQuerySource();
  }

  public HiveParser_IdentifiersParser.descFuncNames_return descFuncNames() throws RecognitionException {
    return gIdentifiersParser.descFuncNames();
  }

  public HiveParser_IdentifiersParser.sysFuncNames_return sysFuncNames() throws RecognitionException {
    return gIdentifiersParser.sysFuncNames();
  }

  public HiveParser_FromClauseParser.tableBucketSample_return tableBucketSample() throws RecognitionException {
    return gFromClauseParser.tableBucketSample();
  }

  public HiveParser_IdentifiersParser.dropPartitionVal_return dropPartitionVal() throws RecognitionException {
    return gIdentifiersParser.dropPartitionVal();
  }

  public HiveParser_FromClauseParser.valuesTableConstructor_return valuesTableConstructor()
      throws RecognitionException {
    return gFromClauseParser.valuesTableConstructor();
  }

  public HiveParser_FromClauseParser.fromClause_return fromClause() throws RecognitionException {
    return gFromClauseParser.fromClause();
  }

  public HiveParser_IdentifiersParser.booleanValue_return booleanValue() throws RecognitionException {
    return gIdentifiersParser.booleanValue();
  }

  public HiveParser_SelectClauseParser.hintList_return hintList() throws RecognitionException {
    return gSelectClauseParser.hintList();
  }

  public HiveParser_IdentifiersParser.dropPartitionOperator_return dropPartitionOperator() throws RecognitionException {
    return gIdentifiersParser.dropPartitionOperator();
  }

  public HiveParser_FromClauseParser.tableAlias_return tableAlias() throws RecognitionException {
    return gFromClauseParser.tableAlias();
  }

  public HiveParser_FromClauseParser.tableSource_return tableSource() throws RecognitionException {
    return gFromClauseParser.tableSource();
  }

  public HiveParser_IdentifiersParser.precedenceAmpersandOperator_return precedenceAmpersandOperator()
      throws RecognitionException {
    return gIdentifiersParser.precedenceAmpersandOperator();
  }

  public HiveParser_FromClauseParser.partitionedTableFunction_return partitionedTableFunction()
      throws RecognitionException {
    return gFromClauseParser.partitionedTableFunction();
  }

  public HiveParser_FromClauseParser.virtualTableSource_return virtualTableSource() throws RecognitionException {
    return gFromClauseParser.virtualTableSource();
  }

  public HiveParser_IdentifiersParser.precedenceAndExpression_return precedenceAndExpression()
      throws RecognitionException {
    return gIdentifiersParser.precedenceAndExpression();
  }

  public HiveParser_SelectClauseParser.window_value_expression_return window_value_expression()
      throws RecognitionException {
    return gSelectClauseParser.window_value_expression();
  }

  public HiveParser_IdentifiersParser.charSetStringLiteral_return charSetStringLiteral() throws RecognitionException {
    return gIdentifiersParser.charSetStringLiteral();
  }

  public HiveParser_IdentifiersParser.functionIdentifier_return functionIdentifier() throws RecognitionException {
    return gIdentifiersParser.functionIdentifier();
  }

  public HiveParser_IdentifiersParser.precedenceBitwiseOrExpression_return precedenceBitwiseOrExpression()
      throws RecognitionException {
    return gIdentifiersParser.precedenceBitwiseOrExpression();
  }

  public HiveParser_SelectClauseParser.window_range_expression_return window_range_expression()
      throws RecognitionException {
    return gSelectClauseParser.window_range_expression();
  }

  public HiveParser_IdentifiersParser.partitionVal_return partitionVal() throws RecognitionException {
    return gIdentifiersParser.partitionVal();
  }

  public HiveParser_SelectClauseParser.trfmClause_return trfmClause() throws RecognitionException {
    return gSelectClauseParser.trfmClause();
  }

  public HiveParser_IdentifiersParser.stringLiteralSequence_return stringLiteralSequence() throws RecognitionException {
    return gIdentifiersParser.stringLiteralSequence();
  }

  public HiveParser_FromClauseParser.viewName_return viewName() throws RecognitionException {
    return gFromClauseParser.viewName();
  }

  public HiveParser_FromClauseParser.lateralView_return lateralView() throws RecognitionException {
    return gFromClauseParser.lateralView();
  }

  public HiveParser_SelectClauseParser.selectClause_return selectClause() throws RecognitionException {
    return gSelectClauseParser.selectClause();
  }

  public HiveParser_IdentifiersParser.timestampLiteral_return timestampLiteral() throws RecognitionException {
    return gIdentifiersParser.timestampLiteral();
  }

  public HiveParser_IdentifiersParser.groupByClause_return groupByClause() throws RecognitionException {
    return gIdentifiersParser.groupByClause();
  }

  public HiveParser_IdentifiersParser.identifier_return identifier() throws RecognitionException {
    return gIdentifiersParser.identifier();
  }

  public HiveParser_IdentifiersParser.precedenceStarOperator_return precedenceStarOperator()
      throws RecognitionException {
    return gIdentifiersParser.precedenceStarOperator();
  }

  public HiveParser_IdentifiersParser.dropPartitionSpec_return dropPartitionSpec() throws RecognitionException {
    return gIdentifiersParser.dropPartitionSpec();
  }

  public HiveParser_FromClauseParser.tableSample_return tableSample() throws RecognitionException {
    return gFromClauseParser.tableSample();
  }

  public HiveParser_SelectClauseParser.window_specification_return window_specification() throws RecognitionException {
    return gSelectClauseParser.window_specification();
  }

  public HiveParser_IdentifiersParser.precedencePlusExpression_return precedencePlusExpression()
      throws RecognitionException {
    return gIdentifiersParser.precedencePlusExpression();
  }

  public HiveParser_SelectClauseParser.window_frame_return window_frame() throws RecognitionException {
    return gSelectClauseParser.window_frame();
  }

  public HiveParser_IdentifiersParser.precedenceFieldExpression_return precedenceFieldExpression()
      throws RecognitionException {
    return gIdentifiersParser.precedenceFieldExpression();
  }

  public HiveParser_IdentifiersParser.nonParenthesizedFunctionName_return nonParenthesizedFunctionName()
      throws RecognitionException {
    return gIdentifiersParser.nonParenthesizedFunctionName();
  }

  public HiveParser_FromClauseParser.tableAllColumns_return tableAllColumns() throws RecognitionException {
    return gFromClauseParser.tableAllColumns();
  }

  public HiveParser_SelectClauseParser.hintArgName_return hintArgName() throws RecognitionException {
    return gSelectClauseParser.hintArgName();
  }

  public HiveParser_IdentifiersParser.groupByExpression_return groupByExpression() throws RecognitionException {
    return gIdentifiersParser.groupByExpression();
  }

  public HiveParser_IdentifiersParser.precedenceEqualOperator_return precedenceEqualOperator()
      throws RecognitionException {
    return gIdentifiersParser.precedenceEqualOperator();
  }

  public HiveParser_FromClauseParser.tableName_return tableName() throws RecognitionException {
    return gFromClauseParser.tableName();
  }

  public HiveParser_IdentifiersParser.principalIdentifier_return principalIdentifier() throws RecognitionException {
    return gIdentifiersParser.principalIdentifier();
  }

  public HiveParser_IdentifiersParser.partitionSpec_return partitionSpec() throws RecognitionException {
    return gIdentifiersParser.partitionSpec();
  }

  public HiveParser_SelectClauseParser.selectTrfmClause_return selectTrfmClause() throws RecognitionException {
    return gSelectClauseParser.selectTrfmClause();
  }

  public HiveParser_IdentifiersParser.partitionByClause_return partitionByClause() throws RecognitionException {
    return gIdentifiersParser.partitionByClause();
  }

  public HiveParser_IdentifiersParser.function_return function() throws RecognitionException {
    return gIdentifiersParser.function();
  }

  public HiveParser_IdentifiersParser.havingCondition_return havingCondition() throws RecognitionException {
    return gIdentifiersParser.havingCondition();
  }

  public HiveParser_IdentifiersParser.constant_return constant() throws RecognitionException {
    return gIdentifiersParser.constant();
  }

  public HiveParser_IdentifiersParser.precedenceOrOperator_return precedenceOrOperator() throws RecognitionException {
    return gIdentifiersParser.precedenceOrOperator();
  }

  public HiveParser_IdentifiersParser.dateLiteral_return dateLiteral() throws RecognitionException {
    return gIdentifiersParser.dateLiteral();
  }

  public HiveParser_IdentifiersParser.subQueryExpression_return subQueryExpression() throws RecognitionException {
    return gIdentifiersParser.subQueryExpression();
  }

  public HiveParser_IdentifiersParser.castExpression_return castExpression() throws RecognitionException {
    return gIdentifiersParser.castExpression();
  }

  public HiveParser_SelectClauseParser.hintArgs_return hintArgs() throws RecognitionException {
    return gSelectClauseParser.hintArgs();
  }

  public HiveParser_FromClauseParser.uniqueJoinToken_return uniqueJoinToken() throws RecognitionException {
    return gFromClauseParser.uniqueJoinToken();
  }

  public HiveParser_FromClauseParser.uniqueJoinSource_return uniqueJoinSource() throws RecognitionException {
    return gFromClauseParser.uniqueJoinSource();
  }

  public HiveParser_SelectClauseParser.hintName_return hintName() throws RecognitionException {
    return gSelectClauseParser.hintName();
  }

  public HiveParser_IdentifiersParser.clusterByClause_return clusterByClause() throws RecognitionException {
    return gIdentifiersParser.clusterByClause();
  }

  public HiveParser_IdentifiersParser.groupingSetExpression_return groupingSetExpression() throws RecognitionException {
    return gIdentifiersParser.groupingSetExpression();
  }

  public HiveParser_IdentifiersParser.functionName_return functionName() throws RecognitionException {
    return gIdentifiersParser.functionName();
  }

  public HiveParser_IdentifiersParser.precedenceBitwiseXorOperator_return precedenceBitwiseXorOperator()
      throws RecognitionException {
    return gIdentifiersParser.precedenceBitwiseXorOperator();
  }

  public HiveParser_SelectClauseParser.window_frame_boundary_return window_frame_boundary()
      throws RecognitionException {
    return gSelectClauseParser.window_frame_boundary();
  }

  public HiveParser_IdentifiersParser.distributeByClause_return distributeByClause() throws RecognitionException {
    return gIdentifiersParser.distributeByClause();
  }

  public HiveParser_IdentifiersParser.whenExpression_return whenExpression() throws RecognitionException {
    return gIdentifiersParser.whenExpression();
  }

  public HiveParser_IdentifiersParser.precedencePlusOperator_return precedencePlusOperator()
      throws RecognitionException {
    return gIdentifiersParser.precedencePlusOperator();
  }

  public HiveParser_FromClauseParser.valuesClause_return valuesClause() throws RecognitionException {
    return gFromClauseParser.valuesClause();
  }

  public HiveParser_IdentifiersParser.precedenceUnaryOperator_return precedenceUnaryOperator()
      throws RecognitionException {
    return gIdentifiersParser.precedenceUnaryOperator();
  }

  public HiveParser_IdentifiersParser.precedenceEqualNegatableOperator_return precedenceEqualNegatableOperator()
      throws RecognitionException {
    return gIdentifiersParser.precedenceEqualNegatableOperator();
  }

  public HiveParser_SelectClauseParser.window_defn_return window_defn() throws RecognitionException {
    return gSelectClauseParser.window_defn();
  }

  public HiveParser_SelectClauseParser.selectList_return selectList() throws RecognitionException {
    return gSelectClauseParser.selectList();
  }

  public HiveParser_FromClauseParser.partitionTableFunctionSource_return partitionTableFunctionSource()
      throws RecognitionException {
    return gFromClauseParser.partitionTableFunctionSource();
  }

  public HiveParser_IdentifiersParser.precedenceBitwiseXorExpression_return precedenceBitwiseXorExpression()
      throws RecognitionException {
    return gIdentifiersParser.precedenceBitwiseXorExpression();
  }

  public HiveParser_SelectClauseParser.selectItem_return selectItem() throws RecognitionException {
    return gSelectClauseParser.selectItem();
  }

  public HiveParser_IdentifiersParser.precedenceNotExpression_return precedenceNotExpression()
      throws RecognitionException {
    return gIdentifiersParser.precedenceNotExpression();
  }

  public HiveParser_IdentifiersParser.expression_return expression() throws RecognitionException {
    return gIdentifiersParser.expression();
  }

  public HiveParser_IdentifiersParser.precedenceBitwiseOrOperator_return precedenceBitwiseOrOperator()
      throws RecognitionException {
    return gIdentifiersParser.precedenceBitwiseOrOperator();
  }

  public HiveParser_IdentifiersParser.nonReserved_return nonReserved() throws RecognitionException {
    return gIdentifiersParser.nonReserved();
  }

  public HiveParser_FromClauseParser.aliasList_return aliasList() throws RecognitionException {
    return gFromClauseParser.aliasList();
  }

  public HiveParser_IdentifiersParser.nonParenthesizedFunction_return nonParenthesizedFunction()
      throws RecognitionException {
    return gIdentifiersParser.nonParenthesizedFunction();
  }

  public HiveParser_IdentifiersParser.precedenceAmpersandExpression_return precedenceAmpersandExpression()
      throws RecognitionException {
    return gIdentifiersParser.precedenceAmpersandExpression();
  }

  public HiveParser_FromClauseParser.whereClause_return whereClause() throws RecognitionException {
    return gFromClauseParser.whereClause();
  }

  public HiveParser_FromClauseParser.tableOrColumn_return tableOrColumn() throws RecognitionException {
    return gFromClauseParser.tableOrColumn();
  }

  public HiveParser_IdentifiersParser.atomExpression_return atomExpression() throws RecognitionException {
    return gIdentifiersParser.atomExpression();
  }

  public HiveParser_FromClauseParser.expressionList_return expressionList() throws RecognitionException {
    return gFromClauseParser.expressionList();
  }

  public HiveParser_FromClauseParser.uniqueJoinExpr_return uniqueJoinExpr() throws RecognitionException {
    return gFromClauseParser.uniqueJoinExpr();
  }

  public HiveParser_SelectClauseParser.window_clause_return window_clause() throws RecognitionException {
    return gSelectClauseParser.window_clause();
  }

  public HiveParser_SelectClauseParser.hintClause_return hintClause() throws RecognitionException {
    return gSelectClauseParser.hintClause();
  }

  public HiveParser_IdentifiersParser.precedenceOrExpression_return precedenceOrExpression()
      throws RecognitionException {
    return gIdentifiersParser.precedenceOrExpression();
  }

  public HiveParser_FromClauseParser.joinSource_return joinSource() throws RecognitionException {
    return gFromClauseParser.joinSource();
  }

  public HiveParser_SelectClauseParser.hintItem_return hintItem() throws RecognitionException {
    return gSelectClauseParser.hintItem();
  }

  public HiveParser_SelectClauseParser.selectExpressionList_return selectExpressionList() throws RecognitionException {
    return gSelectClauseParser.selectExpressionList();
  }

  public HiveParser_IdentifiersParser.caseExpression_return caseExpression() throws RecognitionException {
    return gIdentifiersParser.caseExpression();
  }

  public HiveParser_SelectClauseParser.window_frame_start_boundary_return window_frame_start_boundary()
      throws RecognitionException {
    return gSelectClauseParser.window_frame_start_boundary();
  }

  public HiveParser_IdentifiersParser.precedenceNotOperator_return precedenceNotOperator() throws RecognitionException {
    return gIdentifiersParser.precedenceNotOperator();
  }

  public HiveParser_FromClauseParser.joinToken_return joinToken() throws RecognitionException {
    return gFromClauseParser.joinToken();
  }

  public HiveParser_FromClauseParser.searchCondition_return searchCondition() throws RecognitionException {
    return gFromClauseParser.searchCondition();
  }

  public HiveParser_FromClauseParser.valueRowConstructor_return valueRowConstructor() throws RecognitionException {
    return gFromClauseParser.valueRowConstructor();
  }

  public HiveParser_IdentifiersParser.precedenceStarExpression_return precedenceStarExpression()
      throws RecognitionException {
    return gIdentifiersParser.precedenceStarExpression();
  }

  public HiveParser_FromClauseParser.partitioningSpec_return partitioningSpec() throws RecognitionException {
    return gFromClauseParser.partitioningSpec();
  }

  public HiveParser_IdentifiersParser.havingClause_return havingClause() throws RecognitionException {
    return gIdentifiersParser.havingClause();
  }

  public HiveParser_FromClauseParser.fromSource_return fromSource() throws RecognitionException {
    return gFromClauseParser.fromSource();
  }

  public HiveParser_IdentifiersParser.orderByClause_return orderByClause() throws RecognitionException {
    return gIdentifiersParser.orderByClause();
  }

  public HiveParser_IdentifiersParser.precedenceUnarySuffixExpression_return precedenceUnarySuffixExpression()
      throws RecognitionException {
    return gIdentifiersParser.precedenceUnarySuffixExpression();
  }

  public HiveParser_SelectClauseParser.selectExpression_return selectExpression() throws RecognitionException {
    return gSelectClauseParser.selectExpression();
  }

  public HiveParser_IdentifiersParser.expressions_return expressions() throws RecognitionException {
    return gIdentifiersParser.expressions();
  }

  public HiveParser_IdentifiersParser.nullCondition_return nullCondition() throws RecognitionException {
    return gIdentifiersParser.nullCondition();
  }

  public HiveParser_IdentifiersParser.tableOrPartition_return tableOrPartition() throws RecognitionException {
    return gIdentifiersParser.tableOrPartition();
  }

  public HiveParser_FromClauseParser.splitSample_return splitSample() throws RecognitionException {
    return gFromClauseParser.splitSample();
  }

  public HiveParser_FromClauseParser.tableNameColList_return tableNameColList() throws RecognitionException {
    return gFromClauseParser.tableNameColList();
  }

  protected DFA12 dfa12 = new DFA12(this);
  protected DFA204 dfa204 = new DFA204(this);
  static final String DFA12_eotS = "\u00b5\uffff";
  static final String DFA12_eofS = "\u00b5\uffff";
  static final String DFA12_minS = "\1\37\1\112\1\uffff\1\112\4\uffff\1\72\3\uffff\2\112\2\32\1\uffff"
      + "\1\152\14\uffff\1\170\37\uffff\7\12\1\uffff\3\12\3\uffff\10\12\1" + "\uffff\3\12\135\uffff";
  static final String DFA12_maxS = "\1\u0111\1\u0119\1\uffff\1\u0119\4\uffff\1\u0101\3\uffff\2\u00f6"
      + "\2\u011e\1\uffff\1\u00f6\14\uffff\1\u00a1\37\uffff\7\u0122\1\uffff"
      + "\3\u0122\3\uffff\1\u00b1\7\u0122\1\uffff\3\u0122\135\uffff";
  static final String DFA12_acceptS = "\2\uffff\1\2\1\uffff\1\6\1\7\1\10\2\uffff\1\12\1\22\1\24\4\uffff"
      + "\1\43\1\uffff\1\17\1\31\1\1\1\uffff\1\4\1\uffff\1\13\1\uffff\1\15"
      + "\1\5\1\14\1\20\1\uffff\1\32\1\3\1\uffff\1\21\1\11\12\uffff\1\35"
      + "\1\36\1\37\1\40\1\44\5\uffff\1\25\1\27\1\uffff\1\26\1\30\10\uffff"
      + "\1\33\3\uffff\1\41\12\uffff\1\34\3\uffff\1\42\3\uffff\1\16\3\uffff"
      + "\1\23\2\uffff\1\33\1\uffff\1\33\1\uffff\1\33\1\uffff\1\33\1\uffff"
      + "\1\33\1\uffff\1\33\1\uffff\1\33\1\uffff\1\33\1\uffff\1\33\1\uffff"
      + "\1\33\1\uffff\1\33\1\uffff\1\33\1\uffff\1\33\1\uffff\1\33\1\uffff"
      + "\1\33\1\uffff\1\33\1\uffff\1\33\1\uffff\1\33\1\uffff\1\33\1\uffff"
      + "\1\33\4\uffff\1\34\1\uffff\1\34\1\uffff\1\34\1\uffff\1\34\1\uffff"
      + "\1\34\1\uffff\1\34\1\uffff\1\34\1\uffff\1\34\1\uffff\1\34\1\uffff"
      + "\1\34\1\uffff\1\34\1\uffff\1\34\1\uffff\1\34\1\uffff\1\34\1\uffff"
      + "\1\34\1\uffff\1\34\1\uffff\1\34\1\uffff\1\34\1\uffff\1\34\1\uffff" + "\1\34";
  static final String DFA12_specialS = "\u00b5\uffff}>";
  static final String[] DFA12_transitionS = {"\1\5\1\13\41\uffff\1\1\23\uffff\2\6\6\uffff\1\3\33\uffff\1\16"
      + "\42\uffff\1\14\12\uffff\1\11\50\uffff\1\12\5\uffff\1\17\17\uffff"
      + "\1\20\2\uffff\1\10\32\uffff\1\4\6\uffff\1\15\4\uffff\1\2",
      "\1\24\37\uffff\1\26\15\uffff\1\32\13\uffff\1\22\55\uffff\1"
          + "\30\50\uffff\1\23\4\uffff\1\24\25\uffff\1\26\3\uffff\1\21\36" + "\uffff\1\30", "",
      "\1\40\55\uffff\1\42\13\uffff\1\35\126\uffff\1\37\4\uffff\1"
          + "\40\25\uffff\1\33\3\uffff\1\36\36\uffff\1\34", "", "", "", "",
      "\1\43\2\uffff\1\43\2\uffff\1\43\1\uffff\1\43\2\uffff\1\62\5"
          + "\uffff\1\43\51\uffff\1\43\3\uffff\1\43\1\56\11\uffff\2\43\30"
          + "\uffff\1\43\37\uffff\1\43\5\uffff\1\60\26\uffff\1\57\1\61\4"
          + "\uffff\1\43\24\uffff\2\43\1\uffff\1\43\7\uffff\1\43", "", "", "", "\1\71\u0095\uffff\1\71\25\uffff\1\70", "\1\74\u0095\uffff\1\74\25\uffff\1\73",
      "\4\111\1\76\1\77\1\111\1\uffff\17\111\2\uffff\1\111\1\uffff"
          + "\4\111\1\uffff\6\111\1\uffff\1\111\1\101\1\uffff\1\111\3\uffff"
          + "\2\111\1\uffff\10\111\1\110\7\111\1\uffff\2\111\1\102\1\111"
          + "\1\uffff\1\111\1\uffff\1\111\1\uffff\4\111\1\uffff\10\111\1"
          + "\uffff\3\111\1\uffff\1\111\1\uffff\4\111\1\uffff\2\111\1\uffff"
          + "\3\111\1\103\5\111\1\107\6\111\1\uffff\4\111\1\uffff\6\111\1"
          + "\104\3\111\2\uffff\4\111\1\uffff\3\111\1\uffff\4\111\1\uffff"
          + "\1\111\1\uffff\5\111\1\uffff\2\111\1\uffff\5\111\2\uffff\14"
          + "\111\1\uffff\22\111\1\105\10\111\1\106\14\111\1\uffff\3\111"
          + "\1\uffff\5\111\1\uffff\4\111\1\uffff\3\111\1\uffff\3\111\1\100"
          + "\10\111\1\uffff\1\111\2\uffff\1\111\1\uffff\1\111",
      "\4\130\1\115\1\116\1\130\1\uffff\17\130\2\uffff\1\130\1\uffff"
          + "\4\130\1\uffff\6\130\1\uffff\1\130\1\120\1\uffff\1\130\3\uffff"
          + "\2\130\1\uffff\10\130\1\127\7\130\1\uffff\2\130\1\121\1\130"
          + "\1\uffff\1\130\1\uffff\1\130\1\uffff\4\130\1\uffff\10\130\1"
          + "\uffff\3\130\1\uffff\1\130\1\uffff\1\130\1\114\2\130\1\uffff"
          + "\2\130\1\uffff\3\130\1\122\5\130\1\126\6\130\1\uffff\4\130\1"
          + "\uffff\6\130\1\123\3\130\2\uffff\4\130\1\uffff\3\130\1\uffff"
          + "\4\130\1\uffff\1\130\1\uffff\5\130\1\uffff\2\130\1\uffff\5\130"
          + "\2\uffff\14\130\1\uffff\22\130\1\124\10\130\1\125\14\130\1\uffff"
          + "\3\130\1\uffff\5\130\1\uffff\4\130\1\uffff\3\130\1\uffff\3\130"
          + "\1\117\10\130\1\uffff\1\130\2\uffff\1\130\1\uffff\1\130", "", "\1\26\15\uffff\1\32\50\uffff\1\134\124\uffff\1\26", "", "", "", "", "", "", "", "", "", "", "", "", "\1\42\50\uffff\1\140", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "\1\143\u00a5\uffff\1\105\116\uffff\1\145\42\uffff\1\105", "\1\147\u00a5\uffff\1\105\116\uffff\1\151\42\uffff\1\105", "\1\153\u00a5\uffff\1\105\116\uffff\1\155\42\uffff\1\105", "\1\157\u00a5\uffff\1\105\116\uffff\1\161\42\uffff\1\105", "\1\163\u00a5\uffff\1\105\116\uffff\1\165\42\uffff\1\105", "\1\167\u00a5\uffff\1\105\116\uffff\1\171\42\uffff\1\105", "\1\173\u00a5\uffff\1\105\116\uffff\1\175\42\uffff\1\105", "", "\1\177\u00a5\uffff\1\105\116\uffff\1\u0081\42\uffff\1\105", "\1\u0083\u00a5\uffff\1\105\116\uffff\1\u0085\42\uffff\1\105", "\1\u0087\u00a5\uffff\1\105\116\uffff\1\u0089\42\uffff\1\105", "", "", "", "\1\130\153\uffff\1\130\72\uffff\1\124", "\1\u008e\153\uffff\1\u0090\71\uffff\1\124\161\uffff\1\124", "\1\u0092\153\uffff\1\u0094\71\uffff\1\124\161\uffff\1\124", "\1\u0096\153\uffff\1\u0098\71\uffff\1\124\161\uffff\1\124", "\1\u009a\153\uffff\1\u009c\71\uffff\1\124\161\uffff\1\124", "\1\u009e\153\uffff\1\u00a0\71\uffff\1\124\161\uffff\1\124", "\1\u00a2\153\uffff\1\u00a4\71\uffff\1\124\161\uffff\1\124", "\1\u00a6\153\uffff\1\u00a8\71\uffff\1\124\161\uffff\1\124", "", "\1\u00aa\153\uffff\1\u00ac\71\uffff\1\124\161\uffff\1\124", "\1\u00ae\153\uffff\1\u00b0\71\uffff\1\124\161\uffff\1\124", "\1\u00b2\153\uffff\1\u00b4\71\uffff\1\124\161\uffff\1\124", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", ""};

  static final short[] DFA12_eot = DFA.unpackEncodedString(DFA12_eotS);
  static final short[] DFA12_eof = DFA.unpackEncodedString(DFA12_eofS);
  static final char[] DFA12_min = DFA.unpackEncodedStringToUnsignedChars(DFA12_minS);
  static final char[] DFA12_max = DFA.unpackEncodedStringToUnsignedChars(DFA12_maxS);
  static final short[] DFA12_accept = DFA.unpackEncodedString(DFA12_acceptS);
  static final short[] DFA12_special = DFA.unpackEncodedString(DFA12_specialS);
  static final short[][] DFA12_transition;

  static {
    int numStates = DFA12_transitionS.length;
    DFA12_transition = new short[numStates][];
    for (int i = 0; i < numStates; i++) {
      DFA12_transition[i] = DFA.unpackEncodedString(DFA12_transitionS[i]);
    }
  }

  class DFA12 extends DFA {

    public DFA12(BaseRecognizer recognizer) {
      this.recognizer = recognizer;
      this.decisionNumber = 12;
      this.eot = DFA12_eot;
      this.eof = DFA12_eof;
      this.min = DFA12_min;
      this.max = DFA12_max;
      this.accept = DFA12_accept;
      this.special = DFA12_special;
      this.transition = DFA12_transition;
    }

    public String getDescription() {
      return "696:1: ddlStatement : ( createDatabaseStatement | switchDatabaseStatement | dropDatabaseStatement | createTableStatement | dropTableStatement | truncateTableStatement | alterStatement | descStatement | showStatement | metastoreCheck | createViewStatement | dropViewStatement | createFunctionStatement | createMacroStatement | createIndexStatement | dropIndexStatement | dropFunctionStatement | reloadFunctionStatement | dropMacroStatement | analyzeStatement | lockStatement | unlockStatement | lockDatabase | unlockDatabase | createRoleStatement | dropRoleStatement | grantPrivileges | revokePrivileges | showGrants | showRoleGrants | showRolePrincipals | showRoles | grantRole | revokeRole | setRole | showCurrentRole );";
    }
  }

  static final String DFA204_eotS = "\127\uffff";
  static final String DFA204_eofS = "\1\2\126\uffff";
  static final String DFA204_minS = "\1\44\1\7\35\uffff\1\4\67\uffff";
  static final String DFA204_maxS = "\1\u012d\1\u0135\35\uffff\1\u0131\67\uffff";
  static final String DFA204_acceptS = "\2\uffff\1\2\70\uffff\1\1\33\uffff";
  static final String DFA204_specialS = "\127\uffff}>";
  static final String[] DFA204_transitionS = {"\1\2\20\uffff\1\2\5\uffff\1\2\40\uffff\1\2\31\uffff\1\2\4\uffff"
      + "\1\2\1\uffff\1\2\2\uffff\1\2\11\uffff\1\2\11\uffff\1\2\3\uffff"
      + "\2\2\2\uffff\1\2\5\uffff\1\1\12\uffff\1\2\5\uffff\1\2\31\uffff"
      + "\3\2\22\uffff\1\2\13\uffff\1\2\3\uffff\1\2\6\uffff\1\2\17\uffff"
      + "\1\2\11\uffff\1\2\2\uffff\1\2\4\uffff\1\2\1\uffff\1\2\17\uffff" + "\1\2",
      "\1\2\5\uffff\1\2\4\uffff\1\2\7\uffff\7\2\1\uffff\22\2\1\uffff"
          + "\4\2\1\uffff\6\2\1\uffff\2\2\1\uffff\1\2\1\uffff\4\2\1\uffff"
          + "\20\2\1\uffff\4\2\1\uffff\1\2\1\uffff\1\2\1\uffff\4\2\1\uffff"
          + "\10\2\1\uffff\3\2\1\uffff\1\2\1\uffff\4\2\1\uffff\23\2\1\uffff"
          + "\1\37\3\2\1\uffff\12\2\1\uffff\5\2\1\uffff\10\2\1\uffff\1\2"
          + "\1\uffff\5\2\1\uffff\2\2\1\uffff\5\2\2\uffff\14\2\1\uffff\22"
          + "\2\1\uffff\25\2\1\uffff\3\2\1\uffff\5\2\1\uffff\4\2\1\uffff"
          + "\3\2\1\uffff\14\2\1\uffff\1\2\2\uffff\1\2\1\uffff\1\2\3\uffff"
          + "\1\2\2\uffff\1\2\2\uffff\2\2\7\uffff\5\2", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "",
      "\3\2\3\uffff\1\2\3\uffff\2\2\1\uffff\1\2\2\uffff\2\2\1\uffff"
          + "\2\2\10\uffff\1\2\6\uffff\1\2\132\uffff\1\2\12\uffff\1\2\10"
          + "\uffff\1\2\23\uffff\1\2\6\uffff\1\2\33\uffff\1\2\1\uffff\1\2"
          + "\11\uffff\1\2\3\uffff\1\2\34\uffff\1\73\27\uffff\1\2\14\uffff"
          + "\4\2\1\uffff\3\2\1\uffff\1\2\7\uffff\1\2", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", ""};

  static final short[] DFA204_eot = DFA.unpackEncodedString(DFA204_eotS);
  static final short[] DFA204_eof = DFA.unpackEncodedString(DFA204_eofS);
  static final char[] DFA204_min = DFA.unpackEncodedStringToUnsignedChars(DFA204_minS);
  static final char[] DFA204_max = DFA.unpackEncodedStringToUnsignedChars(DFA204_maxS);
  static final short[] DFA204_accept = DFA.unpackEncodedString(DFA204_acceptS);
  static final short[] DFA204_special = DFA.unpackEncodedString(DFA204_specialS);
  static final short[][] DFA204_transition;

  static {
    int numStates = DFA204_transitionS.length;
    DFA204_transition = new short[numStates][];
    for (int i = 0; i < numStates; i++) {
      DFA204_transition[i] = DFA.unpackEncodedString(DFA204_transitionS[i]);
    }
  }

  class DFA204 extends DFA {

    public DFA204(BaseRecognizer recognizer) {
      this.recognizer = recognizer;
      this.decisionNumber = 204;
      this.eot = DFA204_eot;
      this.eof = DFA204_eof;
      this.min = DFA204_min;
      this.max = DFA204_max;
      this.accept = DFA204_accept;
      this.special = DFA204_special;
      this.transition = DFA204_transition;
    }

    public String getDescription() {
      return "1775:103: ( tableRowFormatMapKeysIdentifier )?";
    }
  }

  public static final BitSet FOLLOW_explainStatement_in_statement1034 = new BitSet(new long[]{0x0000000000000000L});
  public static final BitSet FOLLOW_EOF_in_statement1036 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_execStatement_in_statement1041 = new BitSet(new long[]{0x0000000000000000L});
  public static final BitSet FOLLOW_EOF_in_statement1043 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_EXPLAIN_in_explainStatement1064 = new BitSet(
      new long[]{0x0000004180000000L, 0x0460030040E80004L, 0x00000104A4000404L, 0x0000048401828000L, 0x0000000040029020L});
  public static final BitSet FOLLOW_explainOption_in_explainStatement1073 = new BitSet(
      new long[]{0x0000004180000000L, 0x0460030040E80004L, 0x00000104A4000404L, 0x0000048400828000L, 0x0000000040029020L});
  public static final BitSet FOLLOW_execStatement_in_explainStatement1076 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_REWRITE_in_explainStatement1107 = new BitSet(
      new long[]{0x0000000000000000L, 0x0040000000000000L, 0x0000000400000400L, 0x0000000400008000L, 0x0000000040000000L});
  public static final BitSet FOLLOW_queryStatementExpression_in_explainStatement1109 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_queryStatementExpression_in_execStatement1178 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_loadStatement_in_execStatement1187 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_exportStatement_in_execStatement1195 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_importStatement_in_execStatement1203 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_ddlStatement_in_execStatement1211 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_deleteStatement_in_execStatement1219 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_updateStatement_in_execStatement1227 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_LOAD_in_loadStatement1254 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000200L});
  public static final BitSet FOLLOW_KW_DATA_in_loadStatement1256 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000008000080L});
  public static final BitSet FOLLOW_KW_LOCAL_in_loadStatement1261 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000080L});
  public static final BitSet FOLLOW_KW_INPATH_in_loadStatement1265 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_loadStatement1270 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0200000000002000L});
  public static final BitSet FOLLOW_KW_OVERWRITE_in_loadStatement1276 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000002000L});
  public static final BitSet FOLLOW_KW_INTO_in_loadStatement1280 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L});
  public static final BitSet FOLLOW_KW_TABLE_in_loadStatement1282 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_tableOrPartition_in_loadStatement1287 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_FOR_in_replicationClause1339 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000002000000000L, 0x0000000000200000L});
  public static final BitSet FOLLOW_KW_METADATA_in_replicationClause1344 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000200000L});
  public static final BitSet FOLLOW_KW_REPLICATION_in_replicationClause1348 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_LPAREN_in_replicationClause1350 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_replicationClause1355 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L});
  public static final BitSet FOLLOW_RPAREN_in_replicationClause1358 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_EXPORT_in_exportStatement1402 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L});
  public static final BitSet FOLLOW_KW_TABLE_in_exportStatement1410 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_tableOrPartition_in_exportStatement1415 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x8000000000000000L});
  public static final BitSet FOLLOW_KW_TO_in_exportStatement1424 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_exportStatement1429 =
      new BitSet(new long[]{0x0000000000000002L, 0x0008000000000000L});
  public static final BitSet FOLLOW_replicationClause_in_exportStatement1438 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_IMPORT_in_importStatement1488 =
      new BitSet(new long[]{0x0000000000000000L, 0x0040040000000000L, 0x0000000000000000L, 0x0040000000000000L});
  public static final BitSet FOLLOW_KW_EXTERNAL_in_importStatement1503 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L});
  public static final BitSet FOLLOW_KW_TABLE_in_importStatement1507 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_tableOrPartition_in_importStatement1512 =
      new BitSet(new long[]{0x0000000000000000L, 0x0040000000000000L});
  public static final BitSet FOLLOW_KW_FROM_in_importStatement1526 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_importStatement1531 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000010000000L});
  public static final BitSet FOLLOW_location_in_importStatement1543 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_createDatabaseStatement_in_ddlStatement1595 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_switchDatabaseStatement_in_ddlStatement1603 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_dropDatabaseStatement_in_ddlStatement1611 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_createTableStatement_in_ddlStatement1619 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_dropTableStatement_in_ddlStatement1627 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_truncateTableStatement_in_ddlStatement1635 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_alterStatement_in_ddlStatement1643 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_descStatement_in_ddlStatement1651 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_showStatement_in_ddlStatement1659 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_metastoreCheck_in_ddlStatement1667 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_createViewStatement_in_ddlStatement1675 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_dropViewStatement_in_ddlStatement1683 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_createFunctionStatement_in_ddlStatement1691 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_createMacroStatement_in_ddlStatement1699 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_createIndexStatement_in_ddlStatement1707 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_dropIndexStatement_in_ddlStatement1715 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_dropFunctionStatement_in_ddlStatement1723 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_reloadFunctionStatement_in_ddlStatement1731 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_dropMacroStatement_in_ddlStatement1739 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_analyzeStatement_in_ddlStatement1747 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_lockStatement_in_ddlStatement1755 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_unlockStatement_in_ddlStatement1763 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_lockDatabase_in_ddlStatement1771 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_unlockDatabase_in_ddlStatement1779 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_createRoleStatement_in_ddlStatement1787 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_dropRoleStatement_in_ddlStatement1795 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_grantPrivileges_in_ddlStatement1803 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_revokePrivileges_in_ddlStatement1811 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_showGrants_in_ddlStatement1819 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_showRoleGrants_in_ddlStatement1827 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_showRolePrincipals_in_ddlStatement1835 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_showRoles_in_ddlStatement1843 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_grantRole_in_ddlStatement1851 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_revokeRole_in_ddlStatement1859 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_setRole_in_ddlStatement1867 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_showCurrentRole_in_ddlStatement1875 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_IF_in_ifExists1902 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000004000000000L});
  public static final BitSet FOLLOW_KW_EXISTS_in_ifExists1904 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_RESTRICT_in_restrictOrCascade1941 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_CASCADE_in_restrictOrCascade1959 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_IF_in_ifNotExists1996 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000080000000000L});
  public static final BitSet FOLLOW_KW_NOT_in_ifNotExists1998 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000004000000000L});
  public static final BitSet FOLLOW_KW_EXISTS_in_ifNotExists2000 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_STORED_in_storedAsDirs2037 = new BitSet(new long[]{0x0000001000000000L});
  public static final BitSet FOLLOW_KW_AS_in_storedAsDirs2039 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000001000000L});
  public static final BitSet FOLLOW_KW_DIRECTORIES_in_storedAsDirs2041 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_OR_in_orReplace2078 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000100000L});
  public static final BitSet FOLLOW_KW_REPLACE_in_orReplace2080 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_IGNORE_in_ignoreProtection2121 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000040L});
  public static final BitSet FOLLOW_KW_PROTECTION_in_ignoreProtection2123 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_CREATE_in_createDatabaseStatement2168 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000400L, 0x0000000000000000L, 0x0000000100000000L});
  public static final BitSet FOLLOW_KW_DATABASE_in_createDatabaseStatement2171 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFFL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_KW_SCHEMA_in_createDatabaseStatement2173 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFFL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_ifNotExists_in_createDatabaseStatement2184 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_identifier_in_createDatabaseStatement2197 = new BitSet(
      new long[]{0x0800000000000002L, 0x0000000000000000L, 0x0000000010000000L, 0x0000000000000000L, 0x0000000040000000L});
  public static final BitSet FOLLOW_databaseComment_in_createDatabaseStatement2207 = new BitSet(
      new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000010000000L, 0x0000000000000000L, 0x0000000040000000L});
  public static final BitSet FOLLOW_location_in_createDatabaseStatement2218 = new BitSet(
      new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000040000000L});
  public static final BitSet FOLLOW_KW_WITH_in_createDatabaseStatement2230 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000004000L});
  public static final BitSet FOLLOW_KW_DBPROPERTIES_in_createDatabaseStatement2232 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_dbProperties_in_createDatabaseStatement2236 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_LOCATION_in_location2297 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_location2301 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_LPAREN_in_dbProperties2343 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_dbPropertiesList_in_dbProperties2345 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L});
  public static final BitSet FOLLOW_RPAREN_in_dbProperties2347 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_keyValueProperty_in_dbPropertiesList2388 =
      new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_COMMA_in_dbPropertiesList2391 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_keyValueProperty_in_dbPropertiesList2393 =
      new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_KW_USE_in_switchDatabaseStatement2432 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_identifier_in_switchDatabaseStatement2434 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_DROP_in_dropDatabaseStatement2473 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000400L, 0x0000000000000000L, 0x0000000100000000L});
  public static final BitSet FOLLOW_KW_DATABASE_in_dropDatabaseStatement2476 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFFL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_KW_SCHEMA_in_dropDatabaseStatement2478 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFFL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_ifExists_in_dropDatabaseStatement2481 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_identifier_in_dropDatabaseStatement2484 =
      new BitSet(new long[]{0x0001000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000400000L});
  public static final BitSet FOLLOW_restrictOrCascade_in_dropDatabaseStatement2486 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_COMMENT_in_databaseComment2532 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_databaseComment2536 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_CREATE_in_createTableStatement2576 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000040000000000L, 0x0000000000000000L, 0x0440000000000000L});
  public static final BitSet FOLLOW_KW_TEMPORARY_in_createTableStatement2581 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000040000000000L, 0x0000000000000000L, 0x0040000000000000L});
  public static final BitSet FOLLOW_KW_EXTERNAL_in_createTableStatement2588 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L});
  public static final BitSet FOLLOW_KW_TABLE_in_createTableStatement2592 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFFL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_ifNotExists_in_createTableStatement2594 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_tableName_in_createTableStatement2599 = new BitSet(
      new long[]{0x0840001000000002L, 0x0000000000000000L, 0x2000000010800000L, 0x0204100040000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_KW_LIKE_in_createTableStatement2612 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_tableName_in_createTableStatement2616 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000010000000L, 0x0204000040000000L});
  public static final BitSet FOLLOW_tableRowFormat_in_createTableStatement2627 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000010000000L, 0x0204000000000000L});
  public static final BitSet FOLLOW_tableFileFormat_in_createTableStatement2639 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000010000000L, 0x0200000000000000L});
  public static final BitSet FOLLOW_location_in_createTableStatement2651 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0200000000000000L});
  public static final BitSet FOLLOW_tablePropertiesPrefixed_in_createTableStatement2663 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_LPAREN_in_createTableStatement2676 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_columnNameTypeList_in_createTableStatement2678 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L});
  public static final BitSet FOLLOW_RPAREN_in_createTableStatement2680 =
      new BitSet(new long[]{0x0840001000000002L, 0x0000000000000000L, 0x2000000010000000L, 0x0204100040000000L});
  public static final BitSet FOLLOW_tableComment_in_createTableStatement2693 =
      new BitSet(new long[]{0x0040001000000002L, 0x0000000000000000L, 0x2000000010000000L, 0x0204100040000000L});
  public static final BitSet FOLLOW_tablePartition_in_createTableStatement2705 =
      new BitSet(new long[]{0x0040001000000002L, 0x0000000000000000L, 0x0000000010000000L, 0x0204100040000000L});
  public static final BitSet FOLLOW_tableBuckets_in_createTableStatement2717 =
      new BitSet(new long[]{0x0000001000000002L, 0x0000000000000000L, 0x0000000010000000L, 0x0204100040000000L});
  public static final BitSet FOLLOW_tableSkewed_in_createTableStatement2729 =
      new BitSet(new long[]{0x0000001000000002L, 0x0000000000000000L, 0x0000000010000000L, 0x0204000040000000L});
  public static final BitSet FOLLOW_tableRowFormat_in_createTableStatement2741 =
      new BitSet(new long[]{0x0000001000000002L, 0x0000000000000000L, 0x0000000010000000L, 0x0204000000000000L});
  public static final BitSet FOLLOW_tableFileFormat_in_createTableStatement2753 =
      new BitSet(new long[]{0x0000001000000002L, 0x0000000000000000L, 0x0000000010000000L, 0x0200000000000000L});
  public static final BitSet FOLLOW_location_in_createTableStatement2765 =
      new BitSet(new long[]{0x0000001000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0200000000000000L});
  public static final BitSet FOLLOW_tablePropertiesPrefixed_in_createTableStatement2777 =
      new BitSet(new long[]{0x0000001000000002L});
  public static final BitSet FOLLOW_KW_AS_in_createTableStatement2790 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L, 0x0000000400008000L, 0x0000000040000000L});
  public static final BitSet FOLLOW_selectStatementWithCTE_in_createTableStatement2792 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_TRUNCATE_in_truncateTableStatement2999 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L});
  public static final BitSet FOLLOW_KW_TABLE_in_truncateTableStatement3001 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_tablePartitionPrefix_in_truncateTableStatement3003 =
      new BitSet(new long[]{0x0400000000000002L});
  public static final BitSet FOLLOW_KW_COLUMNS_in_truncateTableStatement3006 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_LPAREN_in_truncateTableStatement3008 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_columnNameList_in_truncateTableStatement3010 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L});
  public static final BitSet FOLLOW_RPAREN_in_truncateTableStatement3012 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_CREATE_in_createIndexStatement3047 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000010L});
  public static final BitSet FOLLOW_KW_INDEX_in_createIndexStatement3049 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_identifier_in_createIndexStatement3053 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0001000000000000L});
  public static final BitSet FOLLOW_KW_ON_in_createIndexStatement3061 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L});
  public static final BitSet FOLLOW_KW_TABLE_in_createIndexStatement3063 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_tableName_in_createIndexStatement3067 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_LPAREN_in_createIndexStatement3069 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_columnNameList_in_createIndexStatement3073 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L});
  public static final BitSet FOLLOW_RPAREN_in_createIndexStatement3075 = new BitSet(new long[]{0x0000001000000000L});
  public static final BitSet FOLLOW_KW_AS_in_createIndexStatement3083 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_createIndexStatement3087 = new BitSet(
      new long[]{0x0800000000000002L, 0x8000000000000000L, 0x0000000010000008L, 0x0204000040000000L, 0x0000000040000000L});
  public static final BitSet FOLLOW_autoRebuild_in_createIndexStatement3095 =
      new BitSet(new long[]{0x0800000000000002L, 0x8000000000000000L, 0x0000000010000008L, 0x0204000040000000L});
  public static final BitSet FOLLOW_indexPropertiesPrefixed_in_createIndexStatement3104 =
      new BitSet(new long[]{0x0800000000000002L, 0x0000000000000000L, 0x0000000010000008L, 0x0204000040000000L});
  public static final BitSet FOLLOW_indexTblName_in_createIndexStatement3113 =
      new BitSet(new long[]{0x0800000000000002L, 0x0000000000000000L, 0x0000000010000000L, 0x0204000040000000L});
  public static final BitSet FOLLOW_tableRowFormat_in_createIndexStatement3122 =
      new BitSet(new long[]{0x0800000000000002L, 0x0000000000000000L, 0x0000000010000000L, 0x0204000000000000L});
  public static final BitSet FOLLOW_tableFileFormat_in_createIndexStatement3131 =
      new BitSet(new long[]{0x0800000000000002L, 0x0000000000000000L, 0x0000000010000000L, 0x0200000000000000L});
  public static final BitSet FOLLOW_location_in_createIndexStatement3140 =
      new BitSet(new long[]{0x0800000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0200000000000000L});
  public static final BitSet FOLLOW_tablePropertiesPrefixed_in_createIndexStatement3149 =
      new BitSet(new long[]{0x0800000000000002L});
  public static final BitSet FOLLOW_indexComment_in_createIndexStatement3158 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_COMMENT_in_indexComment3315 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_indexComment3319 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_WITH_in_autoRebuild3360 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000020000L});
  public static final BitSet FOLLOW_KW_DEFERRED_in_autoRebuild3362 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000001000L});
  public static final BitSet FOLLOW_KW_REBUILD_in_autoRebuild3364 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_IN_in_indexTblName3400 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L});
  public static final BitSet FOLLOW_KW_TABLE_in_indexTblName3402 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_tableName_in_indexTblName3406 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_IDXPROPERTIES_in_indexPropertiesPrefixed3453 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_indexProperties_in_indexPropertiesPrefixed3456 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_LPAREN_in_indexProperties3489 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_indexPropertiesList_in_indexProperties3491 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L});
  public static final BitSet FOLLOW_RPAREN_in_indexProperties3493 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_keyValueProperty_in_indexPropertiesList3534 =
      new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_COMMA_in_indexPropertiesList3537 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_keyValueProperty_in_indexPropertiesList3539 =
      new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_KW_DROP_in_dropIndexStatement3577 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000010L});
  public static final BitSet FOLLOW_KW_INDEX_in_dropIndexStatement3579 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFFL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_ifExists_in_dropIndexStatement3581 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_identifier_in_dropIndexStatement3586 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0001000000000000L});
  public static final BitSet FOLLOW_KW_ON_in_dropIndexStatement3588 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_tableName_in_dropIndexStatement3592 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_DROP_in_dropTableStatement3637 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L});
  public static final BitSet FOLLOW_KW_TABLE_in_dropTableStatement3639 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFFL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_ifExists_in_dropTableStatement3641 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_tableName_in_dropTableStatement3644 =
      new BitSet(new long[]{0x0000000000000002L, 0x0008000000000000L, 0x0000000000000000L, 0x0000000000000080L});
  public static final BitSet FOLLOW_KW_PURGE_in_dropTableStatement3646 =
      new BitSet(new long[]{0x0000000000000002L, 0x0008000000000000L});
  public static final BitSet FOLLOW_replicationClause_in_dropTableStatement3649 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_ALTER_in_alterStatement3698 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L});
  public static final BitSet FOLLOW_KW_TABLE_in_alterStatement3700 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_tableName_in_alterStatement3702 = new BitSet(
      new long[]{0x9048000408000000L, 0x0000001244000000L, 0x1000080000002000L, 0x0000108000140000L, 0x000000000000A041L});
  public static final BitSet FOLLOW_alterTableStatementSuffix_in_alterStatement3704 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_ALTER_in_alterStatement3722 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000002000000L});
  public static final BitSet FOLLOW_KW_VIEW_in_alterStatement3724 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_tableName_in_alterStatement3726 = new BitSet(
      new long[]{0x0000001008000000L, 0x0000000040000000L, 0x0000000400000000L, 0x0000008400048000L, 0x0000000040002000L});
  public static final BitSet FOLLOW_KW_AS_in_alterStatement3728 = new BitSet(
      new long[]{0x0000000008000000L, 0x0000000040000000L, 0x0000000400000000L, 0x0000008400048000L, 0x0000000040002000L});
  public static final BitSet FOLLOW_alterViewStatementSuffix_in_alterStatement3731 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_ALTER_in_alterStatement3749 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000010L});
  public static final BitSet FOLLOW_KW_INDEX_in_alterStatement3751 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_alterIndexStatementSuffix_in_alterStatement3753 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_ALTER_in_alterStatement3765 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000400L, 0x0000000000000000L, 0x0000000100000000L});
  public static final BitSet FOLLOW_KW_DATABASE_in_alterStatement3768 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_KW_SCHEMA_in_alterStatement3770 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_alterDatabaseStatementSuffix_in_alterStatement3773 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_alterStatementSuffixRename_in_alterTableStatementSuffix3804 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_alterStatementSuffixUpdateStatsCol_in_alterTableStatementSuffix3813 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_alterStatementSuffixDropPartitions_in_alterTableStatementSuffix3821 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_alterStatementSuffixAddPartitions_in_alterTableStatementSuffix3830 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_alterStatementSuffixTouch_in_alterTableStatementSuffix3839 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_alterStatementSuffixArchive_in_alterTableStatementSuffix3847 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_alterStatementSuffixUnArchive_in_alterTableStatementSuffix3855 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_alterStatementSuffixProperties_in_alterTableStatementSuffix3863 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_alterStatementSuffixSkewedby_in_alterTableStatementSuffix3871 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_alterStatementSuffixExchangePartition_in_alterTableStatementSuffix3879 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_alterStatementPartitionKeyType_in_alterTableStatementSuffix3887 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_partitionSpec_in_alterTableStatementSuffix3895 = new BitSet(
      new long[]{0x9048000008000000L, 0x0000000204000000L, 0x0000080000002000L, 0x0000008000140000L, 0x0000000000008000L});
  public static final BitSet FOLLOW_alterTblPartitionStatementSuffix_in_alterTableStatementSuffix3898 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_alterStatementSuffixFileFormat_in_alterTblPartitionStatementSuffix3930 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_alterStatementSuffixLocation_in_alterTblPartitionStatementSuffix3936 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_alterStatementSuffixProtectMode_in_alterTblPartitionStatementSuffix3942 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_alterStatementSuffixMergeFiles_in_alterTblPartitionStatementSuffix3948 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_alterStatementSuffixSerdeProperties_in_alterTblPartitionStatementSuffix3954 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_alterStatementSuffixRenamePart_in_alterTblPartitionStatementSuffix3960 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_alterStatementSuffixBucketNum_in_alterTblPartitionStatementSuffix3966 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet
      FOLLOW_alterTblPartitionStatementSuffixSkewedLocation_in_alterTblPartitionStatementSuffix3972 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_alterStatementSuffixClusterbySortby_in_alterTblPartitionStatementSuffix3978 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_alterStatementSuffixCompact_in_alterTblPartitionStatementSuffix3984 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_alterStatementSuffixUpdateStatsCol_in_alterTblPartitionStatementSuffix3990 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_alterStatementSuffixRenameCol_in_alterTblPartitionStatementSuffix3996 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_alterStatementSuffixAddCol_in_alterTblPartitionStatementSuffix4002 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_PARTITION_in_alterStatementPartitionKeyType4024 =
      new BitSet(new long[]{0x0200000000000000L});
  public static final BitSet FOLLOW_KW_COLUMN_in_alterStatementPartitionKeyType4026 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_LPAREN_in_alterStatementPartitionKeyType4028 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_columnNameType_in_alterStatementPartitionKeyType4030 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L});
  public static final BitSet FOLLOW_RPAREN_in_alterStatementPartitionKeyType4032 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_alterViewSuffixProperties_in_alterViewStatementSuffix4065 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_alterStatementSuffixRename_in_alterViewStatementSuffix4073 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_alterStatementSuffixAddPartitions_in_alterViewStatementSuffix4082 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_alterStatementSuffixDropPartitions_in_alterViewStatementSuffix4091 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_selectStatementWithCTE_in_alterViewStatementSuffix4100 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_identifier_in_alterIndexStatementSuffix4129 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0001000000000000L});
  public static final BitSet FOLLOW_KW_ON_in_alterIndexStatementSuffix4131 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_tableName_in_alterIndexStatementSuffix4133 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x1000000000000000L, 0x0000008000001000L});
  public static final BitSet FOLLOW_partitionSpec_in_alterIndexStatementSuffix4135 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000008000001000L});
  public static final BitSet FOLLOW_KW_REBUILD_in_alterIndexStatementSuffix4150 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SET_in_alterIndexStatementSuffix4183 =
      new BitSet(new long[]{0x0000000000000000L, 0x8000000000000000L});
  public static final BitSet FOLLOW_KW_IDXPROPERTIES_in_alterIndexStatementSuffix4185 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_indexProperties_in_alterIndexStatementSuffix4193 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_alterDatabaseSuffixProperties_in_alterDatabaseStatementSuffix4244 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_alterDatabaseSuffixSetOwner_in_alterDatabaseStatementSuffix4252 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_identifier_in_alterDatabaseSuffixProperties4281 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000008000000000L});
  public static final BitSet FOLLOW_KW_SET_in_alterDatabaseSuffixProperties4283 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000004000L});
  public static final BitSet FOLLOW_KW_DBPROPERTIES_in_alterDatabaseSuffixProperties4285 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_dbProperties_in_alterDatabaseSuffixProperties4287 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_identifier_in_alterDatabaseSuffixSetOwner4331 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000008000000000L});
  public static final BitSet FOLLOW_KW_SET_in_alterDatabaseSuffixSetOwner4333 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0400000000000000L});
  public static final BitSet FOLLOW_KW_OWNER_in_alterDatabaseSuffixSetOwner4335 = new BitSet(
      new long[]{0x0000000000000000L, 0x0800000000000000L, 0x0000000000000000L, 0x0000000008000000L, 0x0000000000040000L});
  public static final BitSet FOLLOW_principalName_in_alterDatabaseSuffixSetOwner4337 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_RENAME_in_alterStatementSuffixRename4380 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x8000000000000000L});
  public static final BitSet FOLLOW_KW_TO_in_alterStatementSuffixRename4382 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_tableName_in_alterStatementSuffixRename4384 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_ADD_in_alterStatementSuffixAddCol4451 =
      new BitSet(new long[]{0x0400000000000000L});
  public static final BitSet FOLLOW_KW_REPLACE_in_alterStatementSuffixAddCol4457 =
      new BitSet(new long[]{0x0400000000000000L});
  public static final BitSet FOLLOW_KW_COLUMNS_in_alterStatementSuffixAddCol4460 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_LPAREN_in_alterStatementSuffixAddCol4462 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_columnNameTypeList_in_alterStatementSuffixAddCol4464 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L});
  public static final BitSet FOLLOW_RPAREN_in_alterStatementSuffixAddCol4466 =
      new BitSet(new long[]{0x0001000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000400000L});
  public static final BitSet FOLLOW_restrictOrCascade_in_alterStatementSuffixAddCol4468 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_CHANGE_in_alterStatementSuffixRenameCol4544 = new BitSet(
      new long[]{0xFFE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_KW_COLUMN_in_alterStatementSuffixRenameCol4546 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_identifier_in_alterStatementSuffixRenameCol4551 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_identifier_in_alterStatementSuffixRenameCol4555 = new BitSet(
      new long[]{0x00100E0800000000L, 0x000200002000B000L, 0x0000000400000800L, 0x6030200000000000L, 0x0000000001000400L});
  public static final BitSet FOLLOW_colType_in_alterStatementSuffixRenameCol4557 =
      new BitSet(new long[]{0x0801000020000002L, 0x0001000000000000L, 0x0000000000000000L, 0x0000000000400000L});
  public static final BitSet FOLLOW_KW_COMMENT_in_alterStatementSuffixRenameCol4560 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_alterStatementSuffixRenameCol4564 =
      new BitSet(new long[]{0x0001000020000002L, 0x0001000000000000L, 0x0000000000000000L, 0x0000000000400000L});
  public static final BitSet FOLLOW_alterStatementChangeColPosition_in_alterStatementSuffixRenameCol4568 =
      new BitSet(new long[]{0x0001000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000400000L});
  public static final BitSet FOLLOW_restrictOrCascade_in_alterStatementSuffixRenameCol4571 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_UPDATE_in_alterStatementSuffixUpdateStatsCol4626 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0002000000000000L});
  public static final BitSet FOLLOW_KW_STATISTICS_in_alterStatementSuffixUpdateStatsCol4628 =
      new BitSet(new long[]{0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_KW_FOR_in_alterStatementSuffixUpdateStatsCol4630 = new BitSet(
      new long[]{0xFFE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_KW_COLUMN_in_alterStatementSuffixUpdateStatsCol4632 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_identifier_in_alterStatementSuffixUpdateStatsCol4637 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000008000000000L});
  public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixUpdateStatsCol4639 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixUpdateStatsCol4641 =
      new BitSet(new long[]{0x0800000000000002L});
  public static final BitSet FOLLOW_KW_COMMENT_in_alterStatementSuffixUpdateStatsCol4644 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_alterStatementSuffixUpdateStatsCol4648 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_FIRST_in_alterStatementChangeColPosition4687 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_AFTER_in_alterStatementChangeColPosition4689 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_identifier_in_alterStatementChangeColPosition4693 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_ADD_in_alterStatementSuffixAddPartitions4746 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x1000000000000001L});
  public static final BitSet FOLLOW_ifNotExists_in_alterStatementSuffixAddPartitions4748 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x1000000000000000L});
  public static final BitSet FOLLOW_alterStatementSuffixAddPartitionsElement_in_alterStatementSuffixAddPartitions4751 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x1000000000000000L});
  public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixAddPartitionsElement4814 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000800000000000L, 0x0000000010000000L, 0x0000002000000000L});
  public static final BitSet FOLLOW_partitionFileFormat_in_alterStatementSuffixAddPartitionsElement4816 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000010000000L, 0x0000002000000000L});
  public static final BitSet FOLLOW_partitionSerdeProperties_in_alterStatementSuffixAddPartitionsElement4819 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000010000000L});
  public static final BitSet FOLLOW_location_in_alterStatementSuffixAddPartitionsElement4822 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_TOUCH_in_alterStatementSuffixTouch4850 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x1000000000000000L});
  public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixTouch4853 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x1000000000000000L});
  public static final BitSet FOLLOW_KW_ARCHIVE_in_alterStatementSuffixArchive4897 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x1000000000000000L});
  public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixArchive4900 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x1000000000000000L});
  public static final BitSet FOLLOW_KW_UNARCHIVE_in_alterStatementSuffixUnArchive4944 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x1000000000000000L});
  public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixUnArchive4947 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x1000000000000000L});
  public static final BitSet FOLLOW_KW_FILEFORMAT_in_partitionFileFormat4991 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_fileFormat_in_partitionFileFormat4993 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SERDEPROPERTIES_in_partitionSerdeProperties5028 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_tableProperties_in_partitionSerdeProperties5030 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_DROP_in_alterStatementSuffixDropPartitions5066 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x1000000000000001L});
  public static final BitSet FOLLOW_ifExists_in_alterStatementSuffixDropPartitions5068 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x1000000000000000L});
  public static final BitSet FOLLOW_dropPartitionSpec_in_alterStatementSuffixDropPartitions5071 =
      new BitSet(new long[]{0x0000000000000402L, 0x0008000000000000L, 0x0000000000000002L, 0x0000000000000080L});
  public static final BitSet FOLLOW_COMMA_in_alterStatementSuffixDropPartitions5074 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x1000000000000000L});
  public static final BitSet FOLLOW_dropPartitionSpec_in_alterStatementSuffixDropPartitions5076 =
      new BitSet(new long[]{0x0000000000000402L, 0x0008000000000000L, 0x0000000000000002L, 0x0000000000000080L});
  public static final BitSet FOLLOW_ignoreProtection_in_alterStatementSuffixDropPartitions5080 =
      new BitSet(new long[]{0x0000000000000002L, 0x0008000000000000L, 0x0000000000000000L, 0x0000000000000080L});
  public static final BitSet FOLLOW_KW_PURGE_in_alterStatementSuffixDropPartitions5083 =
      new BitSet(new long[]{0x0000000000000002L, 0x0008000000000000L});
  public static final BitSet FOLLOW_replicationClause_in_alterStatementSuffixDropPartitions5086 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixProperties5174 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0200000000000000L});
  public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_alterStatementSuffixProperties5176 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixProperties5178 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_UNSET_in_alterStatementSuffixProperties5198 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0200000000000000L});
  public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_alterStatementSuffixProperties5200 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000001L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_ifExists_in_alterStatementSuffixProperties5202 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixProperties5205 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SET_in_alterViewSuffixProperties5247 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0200000000000000L});
  public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_alterViewSuffixProperties5249 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_tableProperties_in_alterViewSuffixProperties5251 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_UNSET_in_alterViewSuffixProperties5271 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0200000000000000L});
  public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_alterViewSuffixProperties5273 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000001L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_ifExists_in_alterViewSuffixProperties5275 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_tableProperties_in_alterViewSuffixProperties5278 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixSerdeProperties5320 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000001000000000L});
  public static final BitSet FOLLOW_KW_SERDE_in_alterStatementSuffixSerdeProperties5322 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_alterStatementSuffixSerdeProperties5326 = new BitSet(
      new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000040000000L});
  public static final BitSet FOLLOW_KW_WITH_in_alterStatementSuffixSerdeProperties5329 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000002000000000L});
  public static final BitSet FOLLOW_KW_SERDEPROPERTIES_in_alterStatementSuffixSerdeProperties5331 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixSerdeProperties5333 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixSerdeProperties5359 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000002000000000L});
  public static final BitSet FOLLOW_KW_SERDEPROPERTIES_in_alterStatementSuffixSerdeProperties5361 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixSerdeProperties5363 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_tableName_in_tablePartitionPrefix5400 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x1000000000000000L});
  public static final BitSet FOLLOW_partitionSpec_in_tablePartitionPrefix5402 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixFileFormat5437 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000800000000000L});
  public static final BitSet FOLLOW_KW_FILEFORMAT_in_alterStatementSuffixFileFormat5439 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_fileFormat_in_alterStatementSuffixFileFormat5441 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_NOT_in_alterStatementSuffixClusterbySortby5472 =
      new BitSet(new long[]{0x0040000000000000L});
  public static final BitSet FOLLOW_KW_CLUSTERED_in_alterStatementSuffixClusterbySortby5474 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_NOT_in_alterStatementSuffixClusterbySortby5488 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000800000000000L});
  public static final BitSet FOLLOW_KW_SORTED_in_alterStatementSuffixClusterbySortby5490 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_tableBuckets_in_alterStatementSuffixClusterbySortby5504 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SET_in_alterTblPartitionStatementSuffixSkewedLocation5535 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000100000000000L});
  public static final BitSet FOLLOW_KW_SKEWED_in_alterTblPartitionStatementSuffixSkewedLocation5537 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000010000000L});
  public static final BitSet FOLLOW_KW_LOCATION_in_alterTblPartitionStatementSuffixSkewedLocation5539 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_skewedLocations_in_alterTblPartitionStatementSuffixSkewedLocation5541 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_LPAREN_in_skewedLocations5584 = new BitSet(
      new long[]{0x0000000000042080L, 0x0000080000001000L, 0x0000000000000000L, 0x2000000000000000L, 0x002C010400000010L});
  public static final BitSet FOLLOW_skewedLocationsList_in_skewedLocations5586 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L});
  public static final BitSet FOLLOW_RPAREN_in_skewedLocations5588 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_skewedLocationMap_in_skewedLocationsList5629 =
      new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_COMMA_in_skewedLocationsList5632 = new BitSet(
      new long[]{0x0000000000042080L, 0x0000080000001000L, 0x0000000000000000L, 0x2000000000000000L, 0x002C010400000010L});
  public static final BitSet FOLLOW_skewedLocationMap_in_skewedLocationsList5634 =
      new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_skewedValueLocationElement_in_skewedLocationMap5680 =
      new BitSet(new long[]{0x0000000000100000L});
  public static final BitSet FOLLOW_EQUAL_in_skewedLocationMap5682 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_skewedLocationMap5686 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixLocation5723 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000010000000L});
  public static final BitSet FOLLOW_location_in_alterStatementSuffixLocation5725 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_tableSkewed_in_alterStatementSuffixSkewedby5752 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_NOT_in_alterStatementSuffixSkewedby5767 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000100000000000L});
  public static final BitSet FOLLOW_KW_SKEWED_in_alterStatementSuffixSkewedby5769 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_NOT_in_alterStatementSuffixSkewedby5782 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0004000000000000L});
  public static final BitSet FOLLOW_storedAsDirs_in_alterStatementSuffixSkewedby5784 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_EXCHANGE_in_alterStatementSuffixExchangePartition5815 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x1000000000000000L});
  public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixExchangePartition5817 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000040000000L});
  public static final BitSet FOLLOW_KW_WITH_in_alterStatementSuffixExchangePartition5819 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L});
  public static final BitSet FOLLOW_KW_TABLE_in_alterStatementSuffixExchangePartition5821 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_tableName_in_alterStatementSuffixExchangePartition5825 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_alterProtectMode_in_alterStatementSuffixProtectMode5867 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_RENAME_in_alterStatementSuffixRenamePart5906 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x8000000000000000L});
  public static final BitSet FOLLOW_KW_TO_in_alterStatementSuffixRenamePart5908 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x1000000000000000L});
  public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixRenamePart5910 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_UPDATE_in_alterStatementSuffixStatsPart5948 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0002000000000000L});
  public static final BitSet FOLLOW_KW_STATISTICS_in_alterStatementSuffixStatsPart5950 =
      new BitSet(new long[]{0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_KW_FOR_in_alterStatementSuffixStatsPart5952 = new BitSet(
      new long[]{0xFFE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_KW_COLUMN_in_alterStatementSuffixStatsPart5954 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_identifier_in_alterStatementSuffixStatsPart5959 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000008000000000L});
  public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixStatsPart5961 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixStatsPart5963 =
      new BitSet(new long[]{0x0800000000000002L});
  public static final BitSet FOLLOW_KW_COMMENT_in_alterStatementSuffixStatsPart5966 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_alterStatementSuffixStatsPart5970 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_CONCATENATE_in_alterStatementSuffixMergeFiles6017 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_ENABLE_in_alterProtectMode6054 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000900000000000L, 0x0000000000000400L});
  public static final BitSet FOLLOW_alterProtectModeMode_in_alterProtectMode6056 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_DISABLE_in_alterProtectMode6073 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000900000000000L, 0x0000000000000400L});
  public static final BitSet FOLLOW_alterProtectModeMode_in_alterProtectMode6075 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_OFFLINE_in_alterProtectModeMode6111 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_NO_DROP_in_alterProtectModeMode6126 =
      new BitSet(new long[]{0x0001000000000002L});
  public static final BitSet FOLLOW_KW_CASCADE_in_alterProtectModeMode6128 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_READONLY_in_alterProtectModeMode6146 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_INTO_in_alterStatementSuffixBucketNum6180 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000010000000000L});
  public static final BitSet FOLLOW_Number_in_alterStatementSuffixBucketNum6184 =
      new BitSet(new long[]{0x0000400000000000L});
  public static final BitSet FOLLOW_KW_BUCKETS_in_alterStatementSuffixBucketNum6186 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_COMPACT_in_alterStatementSuffixCompact6226 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_alterStatementSuffixCompact6230 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_INPUTFORMAT_in_fileFormat6271 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_fileFormat6275 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0080000000000000L});
  public static final BitSet FOLLOW_KW_OUTPUTFORMAT_in_fileFormat6277 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_fileFormat6281 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000001000000000L});
  public static final BitSet FOLLOW_KW_SERDE_in_fileFormat6283 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_fileFormat6287 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000000000100L});
  public static final BitSet FOLLOW_KW_INPUTDRIVER_in_fileFormat6290 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_fileFormat6294 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L});
  public static final BitSet FOLLOW_KW_OUTPUTDRIVER_in_fileFormat6296 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_fileFormat6300 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_identifier_in_fileFormat6341 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_identifier_in_tabTypeExpr6377 = new BitSet(new long[]{0x0000000000020002L});
  public static final BitSet FOLLOW_DOT_in_tabTypeExpr6380 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_KW_ELEM_TYPE_in_tabTypeExpr6384 = new BitSet(new long[]{0x0000000000020002L});
  public static final BitSet FOLLOW_KW_KEY_TYPE_in_tabTypeExpr6388 = new BitSet(new long[]{0x0000000000020002L});
  public static final BitSet FOLLOW_KW_VALUE_TYPE_in_tabTypeExpr6392 = new BitSet(new long[]{0x0000000000020002L});
  public static final BitSet FOLLOW_identifier_in_tabTypeExpr6396 = new BitSet(new long[]{0x0000000000020002L});
  public static final BitSet FOLLOW_identifier_in_descTabTypeExpr6425 = new BitSet(
      new long[]{0xFDE9FFFDFC020002L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_DOT_in_descTabTypeExpr6428 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_KW_ELEM_TYPE_in_descTabTypeExpr6432 = new BitSet(
      new long[]{0xFDE9FFFDFC020002L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_KW_KEY_TYPE_in_descTabTypeExpr6436 = new BitSet(
      new long[]{0xFDE9FFFDFC020002L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_KW_VALUE_TYPE_in_descTabTypeExpr6440 = new BitSet(
      new long[]{0xFDE9FFFDFC020002L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_identifier_in_descTabTypeExpr6444 = new BitSet(
      new long[]{0xFDE9FFFDFC020002L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_identifier_in_descTabTypeExpr6449 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_tabTypeExpr_in_partTypeExpr6477 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x1000000000000000L});
  public static final BitSet FOLLOW_partitionSpec_in_partTypeExpr6479 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_descTabTypeExpr_in_descPartTypeExpr6519 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x1000000000000000L});
  public static final BitSet FOLLOW_partitionSpec_in_descPartTypeExpr6521 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_DESCRIBE_in_descStatement6561 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000400L, 0x0000000000000000L, 0x0000000100000000L});
  public static final BitSet FOLLOW_KW_DESC_in_descStatement6563 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000400L, 0x0000000000000000L, 0x0000000100000000L});
  public static final BitSet FOLLOW_KW_DATABASE_in_descStatement6567 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFFEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_KW_SCHEMA_in_descStatement6569 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFFEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_KW_EXTENDED_in_descStatement6572 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_identifier_in_descStatement6578 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_DESCRIBE_in_descStatement6600 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFFEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_KW_DESC_in_descStatement6602 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFFEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_KW_FORMATTED_in_descStatement6608 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_KW_EXTENDED_in_descStatement6612 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_KW_PRETTY_in_descStatement6616 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_descPartTypeExpr_in_descStatement6623 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_DESCRIBE_in_descStatement6646 =
      new BitSet(new long[]{0x0000000000000000L, 0x0100000000000000L});
  public static final BitSet FOLLOW_KW_DESC_in_descStatement6648 =
      new BitSet(new long[]{0x0000000000000000L, 0x0100000000000000L});
  public static final BitSet FOLLOW_KW_FUNCTION_in_descStatement6651 = new BitSet(
      new long[]{0xFDEBFFFFFDB0C070L, 0xDEBBFFEAF7FFFB16L, 0xF6FEFF7DFFBDFFFFL, 0xEEFFFFFBFFFF7FF9L, 0x001A02E356FFF77BL});
  public static final BitSet FOLLOW_KW_EXTENDED_in_descStatement6653 = new BitSet(
      new long[]{0xFDEBFFFFFDB0C070L, 0xDEBBFDEAF7FFFB16L, 0xF6FEFF7DFFBDFFFFL, 0xEEFFFFFBFFFF7FF9L, 0x001A02E356FFF77BL});
  public static final BitSet FOLLOW_descFuncNames_in_descStatement6659 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_ANALYZE_in_analyzeStatement6700 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L});
  public static final BitSet FOLLOW_KW_TABLE_in_analyzeStatement6702 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_tableOrPartition_in_analyzeStatement6707 =
      new BitSet(new long[]{0x4000000000000000L});
  public static final BitSet FOLLOW_KW_COMPUTE_in_analyzeStatement6710 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0002000000000000L});
  public static final BitSet FOLLOW_KW_STATISTICS_in_analyzeStatement6712 =
      new BitSet(new long[]{0x0000000000000002L, 0x0008000000000000L, 0x0800040000000000L});
  public static final BitSet FOLLOW_KW_NOSCAN_in_analyzeStatement6718 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_PARTIALSCAN_in_analyzeStatement6726 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_FOR_in_analyzeStatement6787 = new BitSet(new long[]{0x0400000000000000L});
  public static final BitSet FOLLOW_KW_COLUMNS_in_analyzeStatement6789 = new BitSet(
      new long[]{0xFDE9FFFDFC000002L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_columnNameList_in_analyzeStatement6794 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SHOW_in_showStatement6856 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000800L, 0x0000000000000000L, 0x0000000200000000L});
  public static final BitSet FOLLOW_KW_DATABASES_in_showStatement6859 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000000800000L});
  public static final BitSet FOLLOW_KW_SCHEMAS_in_showStatement6861 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000000800000L});
  public static final BitSet FOLLOW_KW_LIKE_in_showStatement6865 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0008000052FFF77BL});
  public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement6867 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SHOW_in_showStatement6886 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0080000000000000L});
  public static final BitSet FOLLOW_KW_TABLES_in_showStatement6888 = new BitSet(
      new long[]{0xFDE9FFFDFC000002L, 0xDEFBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0008000052FFF77BL});
  public static final BitSet FOLLOW_KW_FROM_in_showStatement6892 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_KW_IN_in_showStatement6894 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_identifier_in_showStatement6899 = new BitSet(
      new long[]{0xFDE9FFFDFC000002L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0008000052FFF77BL});
  public static final BitSet FOLLOW_KW_LIKE_in_showStatement6904 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0008000052FFF77BL});
  public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement6906 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement6908 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SHOW_in_showStatement6936 = new BitSet(new long[]{0x0400000000000000L});
  public static final BitSet FOLLOW_KW_COLUMNS_in_showStatement6938 =
      new BitSet(new long[]{0x0000000000000000L, 0x0040000000000000L, 0x0000000000000008L});
  public static final BitSet FOLLOW_KW_FROM_in_showStatement6941 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_KW_IN_in_showStatement6943 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_tableName_in_showStatement6946 =
      new BitSet(new long[]{0x0000000000000002L, 0x0040000000000000L, 0x0000000000000008L});
  public static final BitSet FOLLOW_KW_FROM_in_showStatement6950 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_KW_IN_in_showStatement6952 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_identifier_in_showStatement6957 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SHOW_in_showStatement6983 =
      new BitSet(new long[]{0x0000000000000000L, 0x0200000000000000L});
  public static final BitSet FOLLOW_KW_FUNCTIONS_in_showStatement6985 = new BitSet(
      new long[]{0xFDE9FFFDFC000002L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0008000052FFF77BL});
  public static final BitSet FOLLOW_KW_LIKE_in_showStatement6988 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0008000052FFF77BL});
  public static final BitSet FOLLOW_showFunctionIdentifier_in_showStatement6990 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_showFunctionIdentifier_in_showStatement6992 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SHOW_in_showStatement7015 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x4000000000000000L});
  public static final BitSet FOLLOW_KW_PARTITIONS_in_showStatement7017 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_tableName_in_showStatement7021 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x1000000000000000L});
  public static final BitSet FOLLOW_partitionSpec_in_showStatement7023 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SHOW_in_showStatement7045 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000004L});
  public static final BitSet FOLLOW_KW_CREATE_in_showStatement7047 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L});
  public static final BitSet FOLLOW_KW_TABLE_in_showStatement7049 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_tableName_in_showStatement7053 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SHOW_in_showStatement7070 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L});
  public static final BitSet FOLLOW_KW_TABLE_in_showStatement7072 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000020000000000L});
  public static final BitSet FOLLOW_KW_EXTENDED_in_showStatement7074 =
      new BitSet(new long[]{0x0000000000000000L, 0x0040000000000000L, 0x0000000000800008L});
  public static final BitSet FOLLOW_KW_FROM_in_showStatement7078 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_KW_IN_in_showStatement7080 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_identifier_in_showStatement7085 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000800000L});
  public static final BitSet FOLLOW_KW_LIKE_in_showStatement7089 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0008000052FFF77BL});
  public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement7091 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x1000000000000000L});
  public static final BitSet FOLLOW_partitionSpec_in_showStatement7093 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SHOW_in_showStatement7121 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0200000000000000L});
  public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_showStatement7123 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_tableName_in_showStatement7125 = new BitSet(
      new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_LPAREN_in_showStatement7128 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_showStatement7132 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L});
  public static final BitSet FOLLOW_RPAREN_in_showStatement7134 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SHOW_in_showStatement7156 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000040000000L});
  public static final BitSet FOLLOW_KW_LOCKS_in_showStatement7158 = new BitSet(
      new long[]{0xFDE9FFFDFC000002L, 0xDEBBFFEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_partTypeExpr_in_showStatement7163 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000020000000000L});
  public static final BitSet FOLLOW_KW_EXTENDED_in_showStatement7170 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SHOW_in_showStatement7194 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000040000000L});
  public static final BitSet FOLLOW_KW_LOCKS_in_showStatement7196 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000400L, 0x0000000000000000L, 0x0000000100000000L});
  public static final BitSet FOLLOW_KW_DATABASE_in_showStatement7199 = new BitSet(new long[]{0x0000000004000000L});
  public static final BitSet FOLLOW_KW_SCHEMA_in_showStatement7201 = new BitSet(new long[]{0x0000000004000000L});
  public static final BitSet FOLLOW_Identifier_in_showStatement7207 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000020000000000L});
  public static final BitSet FOLLOW_KW_EXTENDED_in_showStatement7213 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SHOW_in_showStatement7236 =
      new BitSet(new long[]{0x0000000000000000L, 0x0020000000000000L, 0x0000000000000030L});
  public static final BitSet FOLLOW_KW_FORMATTED_in_showStatement7241 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000030L});
  public static final BitSet FOLLOW_KW_INDEX_in_showStatement7246 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0001000000000000L});
  public static final BitSet FOLLOW_KW_INDEXES_in_showStatement7248 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0001000000000000L});
  public static final BitSet FOLLOW_KW_ON_in_showStatement7251 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0008000052FFF77BL});
  public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement7253 =
      new BitSet(new long[]{0x0000000000000002L, 0x0040000000000000L, 0x0000000000000008L});
  public static final BitSet FOLLOW_KW_FROM_in_showStatement7257 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_KW_IN_in_showStatement7259 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_identifier_in_showStatement7264 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SHOW_in_showStatement7294 = new BitSet(new long[]{0x2000000000000000L});
  public static final BitSet FOLLOW_KW_COMPACTIONS_in_showStatement7296 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SHOW_in_showStatement7310 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000002L});
  public static final BitSet FOLLOW_KW_TRANSACTIONS_in_showStatement7312 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SHOW_in_showStatement7326 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000001L});
  public static final BitSet FOLLOW_KW_CONF_in_showStatement7328 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_showStatement7330 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_LOCK_in_lockStatement7365 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L});
  public static final BitSet FOLLOW_KW_TABLE_in_lockStatement7367 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_tableName_in_lockStatement7369 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000002000000000L, 0x1000000000000000L, 0x0000020000000000L});
  public static final BitSet FOLLOW_partitionSpec_in_lockStatement7371 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000002000000000L, 0x0000000000000000L, 0x0000020000000000L});
  public static final BitSet FOLLOW_lockMode_in_lockStatement7374 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_LOCK_in_lockDatabase7414 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000400L, 0x0000000000000000L, 0x0000000100000000L});
  public static final BitSet FOLLOW_KW_DATABASE_in_lockDatabase7417 = new BitSet(new long[]{0x0000000004000000L});
  public static final BitSet FOLLOW_KW_SCHEMA_in_lockDatabase7419 = new BitSet(new long[]{0x0000000004000000L});
  public static final BitSet FOLLOW_Identifier_in_lockDatabase7425 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000002000000000L, 0x0000000000000000L, 0x0000020000000000L});
  public static final BitSet FOLLOW_lockMode_in_lockDatabase7428 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_UNLOCK_in_unlockStatement7497 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L});
  public static final BitSet FOLLOW_KW_TABLE_in_unlockStatement7499 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_tableName_in_unlockStatement7501 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x1000000000000000L});
  public static final BitSet FOLLOW_partitionSpec_in_unlockStatement7503 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_UNLOCK_in_unlockDatabase7543 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000400L, 0x0000000000000000L, 0x0000000100000000L});
  public static final BitSet FOLLOW_KW_DATABASE_in_unlockDatabase7546 = new BitSet(new long[]{0x0000000004000000L});
  public static final BitSet FOLLOW_KW_SCHEMA_in_unlockDatabase7548 = new BitSet(new long[]{0x0000000004000000L});
  public static final BitSet FOLLOW_Identifier_in_unlockDatabase7554 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_CREATE_in_createRoleStatement7591 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000008000000L});
  public static final BitSet FOLLOW_KW_ROLE_in_createRoleStatement7593 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_identifier_in_createRoleStatement7597 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_DROP_in_dropRoleStatement7637 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000008000000L});
  public static final BitSet FOLLOW_KW_ROLE_in_dropRoleStatement7639 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_identifier_in_dropRoleStatement7643 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_GRANT_in_grantPrivileges7683 = new BitSet(
      new long[]{0x00000000C0000000L, 0x0000000040080004L, 0x0000000020000410L, 0x0000080400000000L, 0x0000000000008000L});
  public static final BitSet FOLLOW_privilegeList_in_grantPrivileges7687 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0001000000000000L, 0x8000000000000000L});
  public static final BitSet FOLLOW_privilegeObject_in_grantPrivileges7695 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x8000000000000000L});
  public static final BitSet FOLLOW_KW_TO_in_grantPrivileges7704 = new BitSet(
      new long[]{0x0000000000000000L, 0x0800000000000000L, 0x0000000000000000L, 0x0000000008000000L, 0x0000000000040000L});
  public static final BitSet FOLLOW_principalSpecification_in_grantPrivileges7706 = new BitSet(
      new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000040000000L});
  public static final BitSet FOLLOW_withGrantOption_in_grantPrivileges7714 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_REVOKE_in_revokePrivileges7763 = new BitSet(
      new long[]{0x00000000C0000000L, 0x0400000040080004L, 0x0000000020000410L, 0x0000080400000000L, 0x0000000000008000L});
  public static final BitSet FOLLOW_grantOptionFor_in_revokePrivileges7765 = new BitSet(
      new long[]{0x00000000C0000000L, 0x0000000040080004L, 0x0000000020000410L, 0x0000080400000000L, 0x0000000000008000L});
  public static final BitSet FOLLOW_privilegeList_in_revokePrivileges7768 =
      new BitSet(new long[]{0x0000000000000000L, 0x0040000000000000L, 0x0001000000000000L});
  public static final BitSet FOLLOW_privilegeObject_in_revokePrivileges7770 =
      new BitSet(new long[]{0x0000000000000000L, 0x0040000000000000L});
  public static final BitSet FOLLOW_KW_FROM_in_revokePrivileges7773 = new BitSet(
      new long[]{0x0000000000000000L, 0x0800000000000000L, 0x0000000000000000L, 0x0000000008000000L, 0x0000000000040000L});
  public static final BitSet FOLLOW_principalSpecification_in_revokePrivileges7775 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_GRANT_in_grantRole7822 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_KW_ROLE_in_grantRole7824 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_identifier_in_grantRole7827 =
      new BitSet(new long[]{0x0000000000000400L, 0x0000000000000000L, 0x0000000000000000L, 0x8000000000000000L});
  public static final BitSet FOLLOW_COMMA_in_grantRole7830 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_identifier_in_grantRole7832 =
      new BitSet(new long[]{0x0000000000000400L, 0x0000000000000000L, 0x0000000000000000L, 0x8000000000000000L});
  public static final BitSet FOLLOW_KW_TO_in_grantRole7836 = new BitSet(
      new long[]{0x0000000000000000L, 0x0800000000000000L, 0x0000000000000000L, 0x0000000008000000L, 0x0000000000040000L});
  public static final BitSet FOLLOW_principalSpecification_in_grantRole7838 = new BitSet(
      new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000040000000L});
  public static final BitSet FOLLOW_withAdminOption_in_grantRole7840 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_REVOKE_in_revokeRole7886 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_adminOptionFor_in_revokeRole7888 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_KW_ROLE_in_revokeRole7891 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_identifier_in_revokeRole7894 =
      new BitSet(new long[]{0x0000000000000400L, 0x0040000000000000L});
  public static final BitSet FOLLOW_COMMA_in_revokeRole7897 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_identifier_in_revokeRole7899 =
      new BitSet(new long[]{0x0000000000000400L, 0x0040000000000000L});
  public static final BitSet FOLLOW_KW_FROM_in_revokeRole7903 = new BitSet(
      new long[]{0x0000000000000000L, 0x0800000000000000L, 0x0000000000000000L, 0x0000000008000000L, 0x0000000000040000L});
  public static final BitSet FOLLOW_principalSpecification_in_revokeRole7905 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SHOW_in_showRoleGrants7950 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000008000000L});
  public static final BitSet FOLLOW_KW_ROLE_in_showRoleGrants7952 =
      new BitSet(new long[]{0x0000000000000000L, 0x0400000000000000L});
  public static final BitSet FOLLOW_KW_GRANT_in_showRoleGrants7954 = new BitSet(
      new long[]{0x0000000000000000L, 0x0800000000000000L, 0x0000000000000000L, 0x0000000008000000L, 0x0000000000040000L});
  public static final BitSet FOLLOW_principalName_in_showRoleGrants7956 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SHOW_in_showRoles7996 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000010000000L});
  public static final BitSet FOLLOW_KW_ROLES_in_showRoles7998 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SHOW_in_showCurrentRole8035 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000020L});
  public static final BitSet FOLLOW_KW_CURRENT_in_showCurrentRole8037 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000010000000L});
  public static final BitSet FOLLOW_KW_ROLES_in_showCurrentRole8039 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SET_in_setRole8076 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000008000000L});
  public static final BitSet FOLLOW_KW_ROLE_in_setRole8078 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_identifier_in_setRole8082 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SHOW_in_showGrants8122 =
      new BitSet(new long[]{0x0000000000000000L, 0x0400000000000000L});
  public static final BitSet FOLLOW_KW_GRANT_in_showGrants8124 = new BitSet(
      new long[]{0x0000000000000002L, 0x0800000000000000L, 0x0001000000000000L, 0x0000000008000000L, 0x0000000000040000L});
  public static final BitSet FOLLOW_principalName_in_showGrants8126 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0001000000000000L});
  public static final BitSet FOLLOW_KW_ON_in_showGrants8130 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFF16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_privilegeIncludeColObject_in_showGrants8132 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SHOW_in_showRolePrincipals8177 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000010L});
  public static final BitSet FOLLOW_KW_PRINCIPALS_in_showRolePrincipals8179 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_identifier_in_showRolePrincipals8183 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_ALL_in_privilegeIncludeColObject8224 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_privObjectCols_in_privilegeIncludeColObject8238 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_ON_in_privilegeObject8273 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFF16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_privObject_in_privilegeObject8275 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_DATABASE_in_privObject8302 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_KW_SCHEMA_in_privObject8304 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_identifier_in_privObject8307 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_TABLE_in_privObject8323 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_tableName_in_privObject8326 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x1000000000000000L});
  public static final BitSet FOLLOW_partitionSpec_in_privObject8328 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_URI_in_privObject8348 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_privObject8353 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SERVER_in_privObject8372 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_identifier_in_privObject8374 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_DATABASE_in_privObjectCols8400 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_KW_SCHEMA_in_privObjectCols8402 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_identifier_in_privObjectCols8405 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_TABLE_in_privObjectCols8421 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_tableName_in_privObjectCols8424 = new BitSet(
      new long[]{0x0000000000000002L, 0x0000000000000000L, 0x1000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_LPAREN_in_privObjectCols8427 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_columnNameList_in_privObjectCols8431 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L});
  public static final BitSet FOLLOW_RPAREN_in_privObjectCols8433 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x1000000000000000L});
  public static final BitSet FOLLOW_partitionSpec_in_privObjectCols8437 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_URI_in_privObjectCols8461 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_privObjectCols8466 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SERVER_in_privObjectCols8485 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_identifier_in_privObjectCols8487 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_privlegeDef_in_privilegeList8522 = new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_COMMA_in_privilegeList8525 = new BitSet(
      new long[]{0x00000000C0000000L, 0x0000000040080004L, 0x0000000020000410L, 0x0000080400000000L, 0x0000000000008000L});
  public static final BitSet FOLLOW_privlegeDef_in_privilegeList8527 = new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_privilegeType_in_privlegeDef8569 = new BitSet(
      new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_LPAREN_in_privlegeDef8572 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_columnNameList_in_privlegeDef8576 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L});
  public static final BitSet FOLLOW_RPAREN_in_privlegeDef8578 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_ALL_in_privilegeType8623 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_ALTER_in_privilegeType8637 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_UPDATE_in_privilegeType8651 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_CREATE_in_privilegeType8665 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_DROP_in_privilegeType8679 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_INDEX_in_privilegeType8693 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_LOCK_in_privilegeType8707 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SELECT_in_privilegeType8721 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SHOW_DATABASE_in_privilegeType8735 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_INSERT_in_privilegeType8749 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_DELETE_in_privilegeType8763 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_principalName_in_principalSpecification8796 =
      new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_COMMA_in_principalSpecification8799 = new BitSet(
      new long[]{0x0000000000000000L, 0x0800000000000000L, 0x0000000000000000L, 0x0000000008000000L, 0x0000000000040000L});
  public static final BitSet FOLLOW_principalName_in_principalSpecification8801 =
      new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_KW_USER_in_principalName8839 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000080052FFF77BL});
  public static final BitSet FOLLOW_principalIdentifier_in_principalName8841 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_GROUP_in_principalName8857 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000080052FFF77BL});
  public static final BitSet FOLLOW_principalIdentifier_in_principalName8859 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_ROLE_in_principalName8875 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_identifier_in_principalName8877 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_WITH_in_withGrantOption8912 =
      new BitSet(new long[]{0x0000000000000000L, 0x0400000000000000L});
  public static final BitSet FOLLOW_KW_GRANT_in_withGrantOption8914 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0002000000000000L});
  public static final BitSet FOLLOW_KW_OPTION_in_withGrantOption8916 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_GRANT_in_grantOptionFor8953 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0002000000000000L});
  public static final BitSet FOLLOW_KW_OPTION_in_grantOptionFor8955 =
      new BitSet(new long[]{0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_KW_FOR_in_grantOptionFor8957 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_ADMIN_in_adminOptionFor8990 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0002000000000000L});
  public static final BitSet FOLLOW_KW_OPTION_in_adminOptionFor8992 =
      new BitSet(new long[]{0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_KW_FOR_in_adminOptionFor8994 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_WITH_in_withAdminOption9027 = new BitSet(new long[]{0x0000000010000000L});
  public static final BitSet FOLLOW_KW_ADMIN_in_withAdminOption9029 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0002000000000000L});
  public static final BitSet FOLLOW_KW_OPTION_in_withAdminOption9031 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_MSCK_in_metastoreCheck9068 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000080000L});
  public static final BitSet FOLLOW_KW_REPAIR_in_metastoreCheck9073 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L});
  public static final BitSet FOLLOW_KW_TABLE_in_metastoreCheck9078 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_tableName_in_metastoreCheck9080 =
      new BitSet(new long[]{0x0000000000000402L, 0x0000000000000000L, 0x1000000000000000L});
  public static final BitSet FOLLOW_partitionSpec_in_metastoreCheck9082 = new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_COMMA_in_metastoreCheck9086 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x1000000000000000L});
  public static final BitSet FOLLOW_partitionSpec_in_metastoreCheck9088 = new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_resource_in_resourceList9141 = new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_COMMA_in_resourceList9144 =
      new BitSet(new long[]{0x0000000400000000L, 0x0000400000000000L, 0x0000000000010000L});
  public static final BitSet FOLLOW_resource_in_resourceList9146 = new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_resourceType_in_resource9184 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_resource9188 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_JAR_in_resourceType9225 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_FILE_in_resourceType9239 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_ARCHIVE_in_resourceType9253 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_CREATE_in_createFunctionStatement9284 =
      new BitSet(new long[]{0x0000000000000000L, 0x0100000000000000L, 0x0000000000000000L, 0x0400000000000000L});
  public static final BitSet FOLLOW_KW_TEMPORARY_in_createFunctionStatement9289 =
      new BitSet(new long[]{0x0000000000000000L, 0x0100000000000000L});
  public static final BitSet FOLLOW_KW_FUNCTION_in_createFunctionStatement9293 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_functionIdentifier_in_createFunctionStatement9295 =
      new BitSet(new long[]{0x0000001000000000L});
  public static final BitSet FOLLOW_KW_AS_in_createFunctionStatement9297 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_createFunctionStatement9299 = new BitSet(
      new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000080000L});
  public static final BitSet FOLLOW_KW_USING_in_createFunctionStatement9308 =
      new BitSet(new long[]{0x0000000400000000L, 0x0000400000000000L, 0x0000000000010000L});
  public static final BitSet FOLLOW_resourceList_in_createFunctionStatement9312 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_DROP_in_dropFunctionStatement9398 =
      new BitSet(new long[]{0x0000000000000000L, 0x0100000000000000L, 0x0000000000000000L, 0x0400000000000000L});
  public static final BitSet FOLLOW_KW_TEMPORARY_in_dropFunctionStatement9403 =
      new BitSet(new long[]{0x0000000000000000L, 0x0100000000000000L});
  public static final BitSet FOLLOW_KW_FUNCTION_in_dropFunctionStatement9407 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFFL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_ifExists_in_dropFunctionStatement9409 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_functionIdentifier_in_dropFunctionStatement9412 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_RELOAD_in_reloadFunctionStatement9490 =
      new BitSet(new long[]{0x0000000000000000L, 0x0100000000000000L});
  public static final BitSet FOLLOW_KW_FUNCTION_in_reloadFunctionStatement9492 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_CREATE_in_createMacroStatement9520 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0400000000000000L});
  public static final BitSet FOLLOW_KW_TEMPORARY_in_createMacroStatement9522 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000200000000L});
  public static final BitSet FOLLOW_KW_MACRO_in_createMacroStatement9524 = new BitSet(new long[]{0x0000000004000000L});
  public static final BitSet FOLLOW_Identifier_in_createMacroStatement9526 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_LPAREN_in_createMacroStatement9534 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000200052FFF77BL});
  public static final BitSet FOLLOW_columnNameTypeList_in_createMacroStatement9536 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L});
  public static final BitSet FOLLOW_RPAREN_in_createMacroStatement9539 = new BitSet(
      new long[]{0xFDEFFFFDFC042080L, 0xDEBBFDEAF7FFFBD6L, 0xF6FAFF7DFFBDFFFFL, 0xEEFFFFFBFFFF7FF9L, 0x003C032452FFF77BL});
  public static final BitSet FOLLOW_expression_in_createMacroStatement9541 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_DROP_in_dropMacroStatement9585 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0400000000000000L});
  public static final BitSet FOLLOW_KW_TEMPORARY_in_dropMacroStatement9587 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000200000000L});
  public static final BitSet FOLLOW_KW_MACRO_in_dropMacroStatement9589 =
      new BitSet(new long[]{0x0000000004000000L, 0x0000000000000000L, 0x0000000000000001L});
  public static final BitSet FOLLOW_ifExists_in_dropMacroStatement9591 = new BitSet(new long[]{0x0000000004000000L});
  public static final BitSet FOLLOW_Identifier_in_dropMacroStatement9594 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_CREATE_in_createViewStatement9636 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0004000000000000L, 0x0000000000000000L, 0x0000000002000000L});
  public static final BitSet FOLLOW_orReplace_in_createViewStatement9639 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000002000000L});
  public static final BitSet FOLLOW_KW_VIEW_in_createViewStatement9643 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFFL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_ifNotExists_in_createViewStatement9646 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_tableName_in_createViewStatement9652 = new BitSet(
      new long[]{0x0800001000000000L, 0x0000000000000000L, 0x2000000000000000L, 0x0200000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_LPAREN_in_createViewStatement9663 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_columnNameCommentList_in_createViewStatement9665 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L});
  public static final BitSet FOLLOW_RPAREN_in_createViewStatement9667 =
      new BitSet(new long[]{0x0800001000000000L, 0x0000000000000000L, 0x2000000000000000L, 0x0200000000000000L});
  public static final BitSet FOLLOW_tableComment_in_createViewStatement9671 =
      new BitSet(new long[]{0x0000001000000000L, 0x0000000000000000L, 0x2000000000000000L, 0x0200000000000000L});
  public static final BitSet FOLLOW_viewPartition_in_createViewStatement9674 =
      new BitSet(new long[]{0x0000001000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0200000000000000L});
  public static final BitSet FOLLOW_tablePropertiesPrefixed_in_createViewStatement9685 =
      new BitSet(new long[]{0x0000001000000000L});
  public static final BitSet FOLLOW_KW_AS_in_createViewStatement9696 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L, 0x0000000400008000L, 0x0000000040000000L});
  public static final BitSet FOLLOW_selectStatementWithCTE_in_createViewStatement9706 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_PARTITIONED_in_viewPartition9829 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0001000000000000L});
  public static final BitSet FOLLOW_KW_ON_in_viewPartition9831 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_LPAREN_in_viewPartition9833 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_columnNameList_in_viewPartition9835 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L});
  public static final BitSet FOLLOW_RPAREN_in_viewPartition9837 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_DROP_in_dropViewStatement9876 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000002000000L});
  public static final BitSet FOLLOW_KW_VIEW_in_dropViewStatement9878 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFFL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_ifExists_in_dropViewStatement9880 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_viewName_in_dropViewStatement9883 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_functionIdentifier_in_showFunctionIdentifier9921 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_StringLiteral_in_showFunctionIdentifier9929 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_identifier_in_showStmtIdentifier9956 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_StringLiteral_in_showStmtIdentifier9964 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_COMMENT_in_tableComment9997 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_tableComment10001 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_PARTITIONED_in_tablePartition10038 = new BitSet(new long[]{0x0000800000000000L});
  public static final BitSet FOLLOW_KW_BY_in_tablePartition10040 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_LPAREN_in_tablePartition10042 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_columnNameTypeList_in_tablePartition10044 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L});
  public static final BitSet FOLLOW_RPAREN_in_tablePartition10046 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_CLUSTERED_in_tableBuckets10091 = new BitSet(new long[]{0x0000800000000000L});
  public static final BitSet FOLLOW_KW_BY_in_tableBuckets10093 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_LPAREN_in_tableBuckets10095 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_columnNameList_in_tableBuckets10099 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L});
  public static final BitSet FOLLOW_RPAREN_in_tableBuckets10101 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000002000L, 0x0000800000000000L});
  public static final BitSet FOLLOW_KW_SORTED_in_tableBuckets10104 = new BitSet(new long[]{0x0000800000000000L});
  public static final BitSet FOLLOW_KW_BY_in_tableBuckets10106 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_LPAREN_in_tableBuckets10108 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_columnNameOrderList_in_tableBuckets10112 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L});
  public static final BitSet FOLLOW_RPAREN_in_tableBuckets10114 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000002000L});
  public static final BitSet FOLLOW_KW_INTO_in_tableBuckets10118 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000010000000000L});
  public static final BitSet FOLLOW_Number_in_tableBuckets10122 = new BitSet(new long[]{0x0000400000000000L});
  public static final BitSet FOLLOW_KW_BUCKETS_in_tableBuckets10124 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SKEWED_in_tableSkewed10176 = new BitSet(new long[]{0x0000800000000000L});
  public static final BitSet FOLLOW_KW_BY_in_tableSkewed10178 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_LPAREN_in_tableSkewed10180 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_columnNameList_in_tableSkewed10184 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L});
  public static final BitSet FOLLOW_RPAREN_in_tableSkewed10186 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0001000000000000L});
  public static final BitSet FOLLOW_KW_ON_in_tableSkewed10188 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_LPAREN_in_tableSkewed10190 = new BitSet(
      new long[]{0x0000000000042080L, 0x0000080000001000L, 0x0000000000000000L, 0x2000000000000000L, 0x002C010400000010L});
  public static final BitSet FOLLOW_skewedValueElement_in_tableSkewed10195 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L});
  public static final BitSet FOLLOW_RPAREN_in_tableSkewed10198 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0004000000000000L});
  public static final BitSet FOLLOW_storedAsDirs_in_tableSkewed10201 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_rowFormatSerde_in_rowFormat10249 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_rowFormatDelimited_in_rowFormat10265 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_RECORDREADER_in_recordReader10314 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_recordReader10316 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_RECORDWRITER_in_recordWriter10365 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_recordWriter10367 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_ROW_in_rowFormatSerde10416 =
      new BitSet(new long[]{0x0000000000000000L, 0x0010000000000000L});
  public static final BitSet FOLLOW_KW_FORMAT_in_rowFormatSerde10418 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000001000000000L});
  public static final BitSet FOLLOW_KW_SERDE_in_rowFormatSerde10420 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_rowFormatSerde10424 = new BitSet(
      new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000040000000L});
  public static final BitSet FOLLOW_KW_WITH_in_rowFormatSerde10427 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000002000000000L});
  public static final BitSet FOLLOW_KW_SERDEPROPERTIES_in_rowFormatSerde10429 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_tableProperties_in_rowFormatSerde10433 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_ROW_in_rowFormatDelimited10485 =
      new BitSet(new long[]{0x0000000000000000L, 0x0010000000000000L});
  public static final BitSet FOLLOW_KW_FORMAT_in_rowFormatDelimited10487 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000100000L});
  public static final BitSet FOLLOW_KW_DELIMITED_in_rowFormatDelimited10489 =
      new BitSet(new long[]{0x0100000000000002L, 0x0000200000000000L, 0x0000200402000000L});
  public static final BitSet FOLLOW_tableRowFormatFieldIdentifier_in_rowFormatDelimited10491 =
      new BitSet(new long[]{0x0100000000000002L, 0x0000000000000000L, 0x0000200402000000L});
  public static final BitSet FOLLOW_tableRowFormatCollItemsIdentifier_in_rowFormatDelimited10494 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000200402000000L});
  public static final BitSet FOLLOW_tableRowFormatMapKeysIdentifier_in_rowFormatDelimited10497 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000200002000000L});
  public static final BitSet FOLLOW_tableRowFormatLinesIdentifier_in_rowFormatDelimited10500 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000200000000000L});
  public static final BitSet FOLLOW_tableRowNullFormat_in_rowFormatDelimited10503 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_rowFormatDelimited_in_tableRowFormat10562 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_rowFormatSerde_in_tableRowFormat10582 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_tablePropertiesPrefixed10629 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_tableProperties_in_tablePropertiesPrefixed10632 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_LPAREN_in_tableProperties10665 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_tablePropertiesList_in_tableProperties10667 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L});
  public static final BitSet FOLLOW_RPAREN_in_tableProperties10669 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_keyValueProperty_in_tablePropertiesList10710 =
      new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_COMMA_in_tablePropertiesList10713 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_keyValueProperty_in_tablePropertiesList10715 =
      new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_keyProperty_in_tablePropertiesList10740 =
      new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_COMMA_in_tablePropertiesList10743 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_keyProperty_in_tablePropertiesList10745 =
      new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_StringLiteral_in_keyValueProperty10791 =
      new BitSet(new long[]{0x0000000000100000L});
  public static final BitSet FOLLOW_EQUAL_in_keyValueProperty10793 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_keyValueProperty10797 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_StringLiteral_in_keyProperty10844 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_FIELDS_in_tableRowFormatFieldIdentifier10888 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0800000000000000L});
  public static final BitSet FOLLOW_KW_TERMINATED_in_tableRowFormatFieldIdentifier10890 =
      new BitSet(new long[]{0x0000800000000000L});
  public static final BitSet FOLLOW_KW_BY_in_tableRowFormatFieldIdentifier10892 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_tableRowFormatFieldIdentifier10896 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000800000000L});
  public static final BitSet FOLLOW_KW_ESCAPED_in_tableRowFormatFieldIdentifier10899 =
      new BitSet(new long[]{0x0000800000000000L});
  public static final BitSet FOLLOW_KW_BY_in_tableRowFormatFieldIdentifier10901 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_tableRowFormatFieldIdentifier10905 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_COLLECTION_in_tableRowFormatCollItemsIdentifier10957 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000008000L});
  public static final BitSet FOLLOW_KW_ITEMS_in_tableRowFormatCollItemsIdentifier10959 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0800000000000000L});
  public static final BitSet FOLLOW_KW_TERMINATED_in_tableRowFormatCollItemsIdentifier10961 =
      new BitSet(new long[]{0x0000800000000000L});
  public static final BitSet FOLLOW_KW_BY_in_tableRowFormatCollItemsIdentifier10963 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_tableRowFormatCollItemsIdentifier10967 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_MAP_in_tableRowFormatMapKeysIdentifier11013 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000040000L});
  public static final BitSet FOLLOW_KW_KEYS_in_tableRowFormatMapKeysIdentifier11015 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0800000000000000L});
  public static final BitSet FOLLOW_KW_TERMINATED_in_tableRowFormatMapKeysIdentifier11017 =
      new BitSet(new long[]{0x0000800000000000L});
  public static final BitSet FOLLOW_KW_BY_in_tableRowFormatMapKeysIdentifier11019 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_tableRowFormatMapKeysIdentifier11023 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_LINES_in_tableRowFormatLinesIdentifier11069 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0800000000000000L});
  public static final BitSet FOLLOW_KW_TERMINATED_in_tableRowFormatLinesIdentifier11071 =
      new BitSet(new long[]{0x0000800000000000L});
  public static final BitSet FOLLOW_KW_BY_in_tableRowFormatLinesIdentifier11073 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_tableRowFormatLinesIdentifier11077 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_NULL_in_tableRowNullFormat11123 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000040000L});
  public static final BitSet FOLLOW_KW_DEFINED_in_tableRowNullFormat11125 = new BitSet(new long[]{0x0000001000000000L});
  public static final BitSet FOLLOW_KW_AS_in_tableRowNullFormat11127 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_tableRowNullFormat11131 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_STORED_in_tableFileFormat11176 = new BitSet(new long[]{0x0000001000000000L});
  public static final BitSet FOLLOW_KW_AS_in_tableFileFormat11178 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000200L});
  public static final BitSet FOLLOW_KW_INPUTFORMAT_in_tableFileFormat11180 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_tableFileFormat11184 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0080000000000000L});
  public static final BitSet FOLLOW_KW_OUTPUTFORMAT_in_tableFileFormat11186 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_tableFileFormat11190 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000000000100L});
  public static final BitSet FOLLOW_KW_INPUTDRIVER_in_tableFileFormat11193 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_tableFileFormat11197 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0040000000000000L});
  public static final BitSet FOLLOW_KW_OUTPUTDRIVER_in_tableFileFormat11199 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_tableFileFormat11203 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_STORED_in_tableFileFormat11241 = new BitSet(new long[]{0x0000800000000000L});
  public static final BitSet FOLLOW_KW_BY_in_tableFileFormat11243 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_tableFileFormat11247 = new BitSet(
      new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000040000000L});
  public static final BitSet FOLLOW_KW_WITH_in_tableFileFormat11259 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000002000000000L});
  public static final BitSet FOLLOW_KW_SERDEPROPERTIES_in_tableFileFormat11261 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_tableProperties_in_tableFileFormat11265 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_STORED_in_tableFileFormat11296 = new BitSet(new long[]{0x0000001000000000L});
  public static final BitSet FOLLOW_KW_AS_in_tableFileFormat11298 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_identifier_in_tableFileFormat11302 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_columnNameType_in_columnNameTypeList11344 =
      new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_COMMA_in_columnNameTypeList11347 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_columnNameType_in_columnNameTypeList11349 =
      new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_columnNameColonType_in_columnNameColonTypeList11387 =
      new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_COMMA_in_columnNameColonTypeList11390 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_columnNameColonType_in_columnNameColonTypeList11392 =
      new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_columnName_in_columnNameList11430 = new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_COMMA_in_columnNameList11433 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_columnName_in_columnNameList11435 = new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_identifier_in_columnName11479 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_columnNameOrder_in_columnNameOrderList11506 =
      new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_COMMA_in_columnNameOrderList11509 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_columnNameOrder_in_columnNameOrderList11511 =
      new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_skewedColumnValues_in_skewedValueElement11556 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_skewedColumnValuePairList_in_skewedValueElement11565 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_skewedColumnValuePair_in_skewedColumnValuePairList11592 =
      new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_COMMA_in_skewedColumnValuePairList11595 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_skewedColumnValuePair_in_skewedColumnValuePairList11597 =
      new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_LPAREN_in_skewedColumnValuePair11642 = new BitSet(
      new long[]{0x0000000000042080L, 0x0000080000001000L, 0x0000000000000000L, 0x2000000000000000L, 0x002C010000000010L});
  public static final BitSet FOLLOW_skewedColumnValues_in_skewedColumnValuePair11646 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L});
  public static final BitSet FOLLOW_RPAREN_in_skewedColumnValuePair11648 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_skewedColumnValue_in_skewedColumnValues11691 =
      new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_COMMA_in_skewedColumnValues11694 = new BitSet(
      new long[]{0x0000000000042080L, 0x0000080000001000L, 0x0000000000000000L, 0x2000000000000000L, 0x002C010000000010L});
  public static final BitSet FOLLOW_skewedColumnValue_in_skewedColumnValues11696 =
      new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_constant_in_skewedColumnValue11740 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_skewedColumnValue_in_skewedValueLocationElement11774 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_skewedColumnValuePair_in_skewedValueLocationElement11783 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_identifier_in_columnNameOrder11814 =
      new BitSet(new long[]{0x0000002000000002L, 0x0000000000400000L});
  public static final BitSet FOLLOW_KW_ASC_in_columnNameOrder11819 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_DESC_in_columnNameOrder11825 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_columnNameComment_in_columnNameCommentList11897 =
      new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_COMMA_in_columnNameCommentList11900 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_columnNameComment_in_columnNameCommentList11902 =
      new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_identifier_in_columnNameComment11942 = new BitSet(new long[]{0x0800000000000002L});
  public static final BitSet FOLLOW_KW_COMMENT_in_columnNameComment11945 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_columnNameComment11949 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_expression_in_columnRefOrder11997 =
      new BitSet(new long[]{0x0000002000000002L, 0x0000000000400000L});
  public static final BitSet FOLLOW_KW_ASC_in_columnRefOrder12002 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_DESC_in_columnRefOrder12008 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_identifier_in_columnNameType12082 = new BitSet(
      new long[]{0x00100E0800000000L, 0x000200002000B000L, 0x0000000400000800L, 0x6030200000000000L, 0x0000000001000400L});
  public static final BitSet FOLLOW_colType_in_columnNameType12084 = new BitSet(new long[]{0x0800000000000002L});
  public static final BitSet FOLLOW_KW_COMMENT_in_columnNameType12087 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_columnNameType12091 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_identifier_in_columnNameColonType12177 =
      new BitSet(new long[]{0x0000000000000200L});
  public static final BitSet FOLLOW_COLON_in_columnNameColonType12179 = new BitSet(
      new long[]{0x00100E0800000000L, 0x000200002000B000L, 0x0000000400000800L, 0x6030200000000000L, 0x0000000001000400L});
  public static final BitSet FOLLOW_colType_in_columnNameColonType12181 = new BitSet(new long[]{0x0800000000000002L});
  public static final BitSet FOLLOW_KW_COMMENT_in_columnNameColonType12184 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_columnNameColonType12188 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_type_in_colType12272 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_colType_in_colTypeList12299 = new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_COMMA_in_colTypeList12302 = new BitSet(
      new long[]{0x00100E0800000000L, 0x000200002000B000L, 0x0000000400000800L, 0x6030200000000000L, 0x0000000001000400L});
  public static final BitSet FOLLOW_colType_in_colTypeList12304 = new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_primitiveType_in_type12332 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_listType_in_type12340 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_structType_in_type12348 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_mapType_in_type12356 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_unionType_in_type12364 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_TINYINT_in_primitiveType12386 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SMALLINT_in_primitiveType12407 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_INT_in_primitiveType12427 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_BIGINT_in_primitiveType12452 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_BOOLEAN_in_primitiveType12474 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_FLOAT_in_primitiveType12495 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_DOUBLE_in_primitiveType12518 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_DATE_in_primitiveType12540 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_DATETIME_in_primitiveType12564 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_TIMESTAMP_in_primitiveType12584 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_STRING_in_primitiveType12603 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_BINARY_in_primitiveType12625 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_DECIMAL_in_primitiveType12647 = new BitSet(
      new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_LPAREN_in_primitiveType12650 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000010000000000L});
  public static final BitSet FOLLOW_Number_in_primitiveType12654 = new BitSet(
      new long[]{0x0000000000000400L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L});
  public static final BitSet FOLLOW_COMMA_in_primitiveType12657 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000010000000000L});
  public static final BitSet FOLLOW_Number_in_primitiveType12661 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L});
  public static final BitSet FOLLOW_RPAREN_in_primitiveType12665 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_VARCHAR_in_primitiveType12689 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_LPAREN_in_primitiveType12691 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000010000000000L});
  public static final BitSet FOLLOW_Number_in_primitiveType12695 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L});
  public static final BitSet FOLLOW_RPAREN_in_primitiveType12697 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_CHAR_in_primitiveType12722 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_LPAREN_in_primitiveType12724 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000010000000000L});
  public static final BitSet FOLLOW_Number_in_primitiveType12728 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L});
  public static final BitSet FOLLOW_RPAREN_in_primitiveType12730 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_ARRAY_in_listType12774 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000100000000L});
  public static final BitSet FOLLOW_LESSTHAN_in_listType12776 = new BitSet(
      new long[]{0x00100E0800000000L, 0x000200002000B000L, 0x0000000400000800L, 0x6030200000000000L, 0x0000000001000400L});
  public static final BitSet FOLLOW_type_in_listType12778 = new BitSet(new long[]{0x0000000000800000L});
  public static final BitSet FOLLOW_GREATERTHAN_in_listType12780 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_STRUCT_in_structType12817 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000100000000L});
  public static final BitSet FOLLOW_LESSTHAN_in_structType12819 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_columnNameColonTypeList_in_structType12821 =
      new BitSet(new long[]{0x0000000000800000L});
  public static final BitSet FOLLOW_GREATERTHAN_in_structType12823 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_MAP_in_mapType12858 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000100000000L});
  public static final BitSet FOLLOW_LESSTHAN_in_mapType12860 = new BitSet(
      new long[]{0x00100E0000000000L, 0x000200002000B000L, 0x0000000000000800L, 0x6010200000000000L, 0x0000000001000000L});
  public static final BitSet FOLLOW_primitiveType_in_mapType12864 = new BitSet(new long[]{0x0000000000000400L});
  public static final BitSet FOLLOW_COMMA_in_mapType12866 = new BitSet(
      new long[]{0x00100E0800000000L, 0x000200002000B000L, 0x0000000400000800L, 0x6030200000000000L, 0x0000000001000400L});
  public static final BitSet FOLLOW_type_in_mapType12870 = new BitSet(new long[]{0x0000000000800000L});
  public static final BitSet FOLLOW_GREATERTHAN_in_mapType12872 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_UNIONTYPE_in_unionType12915 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000100000000L});
  public static final BitSet FOLLOW_LESSTHAN_in_unionType12917 = new BitSet(
      new long[]{0x00100E0800000000L, 0x000200002000B000L, 0x0000000400000800L, 0x6030200000000000L, 0x0000000001000400L});
  public static final BitSet FOLLOW_colTypeList_in_unionType12919 = new BitSet(new long[]{0x0000000000800000L});
  public static final BitSet FOLLOW_GREATERTHAN_in_unionType12921 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_UNION_in_setOperator12956 = new BitSet(new long[]{0x0000000040000000L});
  public static final BitSet FOLLOW_KW_ALL_in_setOperator12958 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_withClause_in_queryStatementExpression12995 =
      new BitSet(new long[]{0x0000000000000000L, 0x0040000000000000L, 0x0000000400000400L, 0x0000000400008000L});
  public static final BitSet FOLLOW_queryStatementExpressionBody_in_queryStatementExpression13005 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_fromStatement_in_queryStatementExpressionBody13039 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_regularBody_in_queryStatementExpressionBody13048 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_WITH_in_withClause13066 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_cteStatement_in_withClause13068 = new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_COMMA_in_withClause13071 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_cteStatement_in_withClause13073 = new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_identifier_in_cteStatement13099 = new BitSet(new long[]{0x0000001000000000L});
  public static final BitSet FOLLOW_KW_AS_in_cteStatement13101 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L});
  public static final BitSet FOLLOW_LPAREN_in_cteStatement13103 = new BitSet(
      new long[]{0x0000000000000000L, 0x0040000000000000L, 0x0000000400000400L, 0x0000000400008000L, 0x0000000040000000L});
  public static final BitSet FOLLOW_queryStatementExpression_in_cteStatement13105 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000200000000000L});
  public static final BitSet FOLLOW_RPAREN_in_cteStatement13108 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_singleFromStatement_in_fromStatement13132 = new BitSet(
      new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000200L});
  public static final BitSet FOLLOW_setOperator_in_fromStatement13144 =
      new BitSet(new long[]{0x0000000000000000L, 0x0040000000000000L});
  public static final BitSet FOLLOW_singleFromStatement_in_fromStatement13148 = new BitSet(
      new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000200L});
  public static final BitSet FOLLOW_fromClause_in_singleFromStatement13355 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000400000400L, 0x0000000400008000L});
  public static final BitSet FOLLOW_body_in_singleFromStatement13365 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000400000400L, 0x0000000400008000L});
  public static final BitSet FOLLOW_insertClause_in_regularBody13403 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L, 0x0000000400008000L, 0x0000000000400000L});
  public static final BitSet FOLLOW_selectStatement_in_regularBody13415 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_valuesClause_in_regularBody13441 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_selectStatement_in_regularBody13565 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_singleSelectStatement_in_selectStatement13582 = new BitSet(
      new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000200L});
  public static final BitSet FOLLOW_setOperator_in_selectStatement13595 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L, 0x0000000400008000L});
  public static final BitSet FOLLOW_singleSelectStatement_in_selectStatement13599 = new BitSet(
      new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000200L});
  public static final BitSet FOLLOW_selectClause_in_singleSelectStatement13821 = new BitSet(
      new long[]{0x0020000000000002L, 0x2840000010000000L, 0x0008000001000000L, 0x0000400000000000L, 0x0000000028000000L});
  public static final BitSet FOLLOW_fromClause_in_singleSelectStatement13826 = new BitSet(
      new long[]{0x0020000000000002L, 0x2800000010000000L, 0x0008000001000000L, 0x0000400000000000L, 0x0000000028000000L});
  public static final BitSet FOLLOW_whereClause_in_singleSelectStatement13832 = new BitSet(
      new long[]{0x0020000000000002L, 0x2800000010000000L, 0x0008000001000000L, 0x0000400000000000L, 0x0000000020000000L});
  public static final BitSet FOLLOW_groupByClause_in_singleSelectStatement13838 = new BitSet(
      new long[]{0x0020000000000002L, 0x2000000010000000L, 0x0008000001000000L, 0x0000400000000000L, 0x0000000020000000L});
  public static final BitSet FOLLOW_havingClause_in_singleSelectStatement13844 = new BitSet(
      new long[]{0x0020000000000002L, 0x0000000010000000L, 0x0008000001000000L, 0x0000400000000000L, 0x0000000020000000L});
  public static final BitSet FOLLOW_orderByClause_in_singleSelectStatement13850 = new BitSet(
      new long[]{0x0020000000000002L, 0x0000000010000000L, 0x0000000001000000L, 0x0000400000000000L, 0x0000000020000000L});
  public static final BitSet FOLLOW_clusterByClause_in_singleSelectStatement13856 = new BitSet(
      new long[]{0x0000000000000002L, 0x0000000010000000L, 0x0000000001000000L, 0x0000400000000000L, 0x0000000020000000L});
  public static final BitSet FOLLOW_distributeByClause_in_singleSelectStatement13862 = new BitSet(
      new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000001000000L, 0x0000400000000000L, 0x0000000020000000L});
  public static final BitSet FOLLOW_sortByClause_in_singleSelectStatement13868 = new BitSet(
      new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000001000000L, 0x0000000000000000L, 0x0000000020000000L});
  public static final BitSet FOLLOW_window_clause_in_singleSelectStatement13874 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000001000000L});
  public static final BitSet FOLLOW_limitClause_in_singleSelectStatement13880 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_withClause_in_selectStatementWithCTE13998 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L, 0x0000000400008000L});
  public static final BitSet FOLLOW_selectStatement_in_selectStatementWithCTE14006 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_insertClause_in_body14037 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000400000000L, 0x0000000400008000L});
  public static final BitSet FOLLOW_selectClause_in_body14042 = new BitSet(
      new long[]{0x0020000000000002L, 0x2800000010000000L, 0x0008000001100000L, 0x0000400000000000L, 0x0000000028000000L});
  public static final BitSet FOLLOW_lateralView_in_body14047 = new BitSet(
      new long[]{0x0020000000000002L, 0x2800000010000000L, 0x0008000001000000L, 0x0000400000000000L, 0x0000000028000000L});
  public static final BitSet FOLLOW_whereClause_in_body14053 = new BitSet(
      new long[]{0x0020000000000002L, 0x2800000010000000L, 0x0008000001000000L, 0x0000400000000000L, 0x0000000020000000L});
  public static final BitSet FOLLOW_groupByClause_in_body14059 = new BitSet(
      new long[]{0x0020000000000002L, 0x2000000010000000L, 0x0008000001000000L, 0x0000400000000000L, 0x0000000020000000L});
  public static final BitSet FOLLOW_havingClause_in_body14065 = new BitSet(
      new long[]{0x0020000000000002L, 0x0000000010000000L, 0x0008000001000000L, 0x0000400000000000L, 0x0000000020000000L});
  public static final BitSet FOLLOW_orderByClause_in_body14071 = new BitSet(
      new long[]{0x0020000000000002L, 0x0000000010000000L, 0x0000000001000000L, 0x0000400000000000L, 0x0000000020000000L});
  public static final BitSet FOLLOW_clusterByClause_in_body14077 = new BitSet(
      new long[]{0x0000000000000002L, 0x0000000010000000L, 0x0000000001000000L, 0x0000400000000000L, 0x0000000020000000L});
  public static final BitSet FOLLOW_distributeByClause_in_body14083 = new BitSet(
      new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000001000000L, 0x0000400000000000L, 0x0000000020000000L});
  public static final BitSet FOLLOW_sortByClause_in_body14089 = new BitSet(
      new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000001000000L, 0x0000000000000000L, 0x0000000020000000L});
  public static final BitSet FOLLOW_window_clause_in_body14095 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000001000000L});
  public static final BitSet FOLLOW_limitClause_in_body14101 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_selectClause_in_body14194 = new BitSet(
      new long[]{0x0020000000000002L, 0x2800000010000000L, 0x0008000001100000L, 0x0000400000000000L, 0x0000000028000000L});
  public static final BitSet FOLLOW_lateralView_in_body14199 = new BitSet(
      new long[]{0x0020000000000002L, 0x2800000010000000L, 0x0008000001000000L, 0x0000400000000000L, 0x0000000028000000L});
  public static final BitSet FOLLOW_whereClause_in_body14205 = new BitSet(
      new long[]{0x0020000000000002L, 0x2800000010000000L, 0x0008000001000000L, 0x0000400000000000L, 0x0000000020000000L});
  public static final BitSet FOLLOW_groupByClause_in_body14211 = new BitSet(
      new long[]{0x0020000000000002L, 0x2000000010000000L, 0x0008000001000000L, 0x0000400000000000L, 0x0000000020000000L});
  public static final BitSet FOLLOW_havingClause_in_body14217 = new BitSet(
      new long[]{0x0020000000000002L, 0x0000000010000000L, 0x0008000001000000L, 0x0000400000000000L, 0x0000000020000000L});
  public static final BitSet FOLLOW_orderByClause_in_body14223 = new BitSet(
      new long[]{0x0020000000000002L, 0x0000000010000000L, 0x0000000001000000L, 0x0000400000000000L, 0x0000000020000000L});
  public static final BitSet FOLLOW_clusterByClause_in_body14229 = new BitSet(
      new long[]{0x0000000000000002L, 0x0000000010000000L, 0x0000000001000000L, 0x0000400000000000L, 0x0000000020000000L});
  public static final BitSet FOLLOW_distributeByClause_in_body14235 = new BitSet(
      new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000001000000L, 0x0000400000000000L, 0x0000000020000000L});
  public static final BitSet FOLLOW_sortByClause_in_body14241 = new BitSet(
      new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000001000000L, 0x0000000000000000L, 0x0000000020000000L});
  public static final BitSet FOLLOW_window_clause_in_body14247 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000001000000L});
  public static final BitSet FOLLOW_limitClause_in_body14253 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_INSERT_in_insertClause14374 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0200000000000000L});
  public static final BitSet FOLLOW_KW_OVERWRITE_in_insertClause14376 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000002000000L, 0x0000000008000000L, 0x0040000000000000L});
  public static final BitSet FOLLOW_destination_in_insertClause14378 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000000000001L});
  public static final BitSet FOLLOW_ifNotExists_in_insertClause14380 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_INSERT_in_insertClause14399 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000002000L});
  public static final BitSet FOLLOW_KW_INTO_in_insertClause14401 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_KW_TABLE_in_insertClause14403 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_tableOrPartition_in_insertClause14406 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_LOCAL_in_destination14456 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000002000000L});
  public static final BitSet FOLLOW_KW_DIRECTORY_in_destination14460 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0008000000000000L});
  public static final BitSet FOLLOW_StringLiteral_in_destination14462 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0004000040000000L});
  public static final BitSet FOLLOW_tableRowFormat_in_destination14464 =
      new BitSet(new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0004000000000000L});
  public static final BitSet FOLLOW_tableFileFormat_in_destination14467 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_TABLE_in_destination14500 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_tableOrPartition_in_destination14502 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_LIMIT_in_limitClause14534 = new BitSet(
      new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000010000000000L});
  public static final BitSet FOLLOW_Number_in_limitClause14538 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_DELETE_in_deleteStatement14576 =
      new BitSet(new long[]{0x0000000000000000L, 0x0040000000000000L});
  public static final BitSet FOLLOW_KW_FROM_in_deleteStatement14578 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_tableName_in_deleteStatement14580 = new BitSet(
      new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000008000000L});
  public static final BitSet FOLLOW_whereClause_in_deleteStatement14583 = new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_tableOrColumn_in_columnAssignmentClause14616 =
      new BitSet(new long[]{0x0000000000100000L});
  public static final BitSet FOLLOW_EQUAL_in_columnAssignmentClause14618 = new BitSet(
      new long[]{0xFDEFFFFDFC042080L, 0xDEBBFDEAF7FFFBD6L, 0xF6FAF77DFFBDFFFFL, 0xEEFFFFFBFFFF7FF9L, 0x003C032452FFF77BL});
  public static final BitSet FOLLOW_precedencePlusExpression_in_columnAssignmentClause14621 =
      new BitSet(new long[]{0x0000000000000002L});
  public static final BitSet FOLLOW_KW_SET_in_setColumnsClause14641 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_columnAssignmentClause_in_setColumnsClause14643 =
      new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_COMMA_in_setColumnsClause14646 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_columnAssignmentClause_in_setColumnsClause14648 =
      new BitSet(new long[]{0x0000000000000402L});
  public static final BitSet FOLLOW_KW_UPDATE_in_updateStatement14690 = new BitSet(
      new long[]{0xFDE9FFFDFC000000L, 0xDEBBFDEAF7FFFB16L, 0xF6FAF779FFBDFFFEL, 0xEEFFFFFBFFFF7FF9L, 0x0000000052FFF77BL});
  public static final BitSet FOLLOW_tableName_in_updateStatement14692 =
      new BitSet(new long[]{0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000008000000000L});
  public static final BitSet FOLLOW_setColumnsClause_in_updateStatement14694 = new BitSet(
      new long[]{0x0000000000000002L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000000000000L, 0x0000000008000000L});
  public static final BitSet FOLLOW_whereClause_in_updateStatement14696 = new BitSet(new long[]{0x0000000000000002L});
}
